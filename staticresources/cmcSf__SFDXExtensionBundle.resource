{
    "recordTypeMap": {},
    "RecordSetBundles": [
        {
            "Records": [
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v52.0/sobjects/copado__Function__c/a0k09000000FKgfAAG"
                    },
                    "copado__API_Name__c": "Devhub_Package_Info",
                    "copado__Description__c": "Extracts package and package versions info from a DevHub",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"packageNameOrId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.packageNameOrId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"session\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"baseUrl\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst { execSync, exec } = require('child_process'),\n\t{ session, baseUrl, packageNameOrId, isTest } = process.env,\n\turl = baseUrl.substring(0, baseUrl.indexOf('/', baseUrl.indexOf('/') + 2)),\n\t{ writeFileSync } = require('fs'),\n\tcheckLog = 'Please check the logs for details',\n\tPACKAGE_DETAILS_FILE_NAME = 'PackageAndVersions.json',\n    STDIO = {\n        INHERIT: 'inherit',\n        PIPE: 'pipe',\n        IGNORE: 'ignore'\n    },\n\tTEMP = 'temp';\n\n// EXECUTION\n\nfunction execute() {\n\ttry {\n\t\tthis.createSFDXProject();\n\t\tthis.setInstanceURL();\n\n\t\tconst pkg = this.getPackageDetails();\n\n\t\tif (pkg) {\n\t\t\tconst versions = this.getPackageVersions(pkg.Id);\n\n\t\t\twriteFileSync(PACKAGE_DETAILS_FILE_NAME, JSON.stringify({ pkg, versions }));\n\t\t\tthis.uploadFile(PACKAGE_DETAILS_FILE_NAME);\n\t\t} else {\n\t\t\tthrow `Couldn't find details of package ${packageNameOrId} in devHub.`;\n\t\t}\n\t} catch (err) {\n\t\t//Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n\t\tif (err?.status === 3) {\n\t\t\tprocess.exit(1);\n\t\t}\n\t\texecSync(this.showError(err.toString()));\n\t}\n}\n\n// SCRIPT FUNCTIONS\n\nfunction showError(error) {\n\tconst refinedErrorMsg = this.maskSensitiveInformation(error);\n\treturn `copado -p 'Error' -e ${this.escapeSpecialCharacters(JSON.stringify(refinedErrorMsg)).replace(/\\\\n/g, '\\n').replace(/\\\\t/g, '\\t')} && exit 3`;\n}\n\nfunction setInstanceURL() {\n\tthis.asyncCopadoLogMessage('Setting Instance Url');\n    execSync(`\n        sf config set org-instance-url=${url} || (${this.showError(`Error setting instance URL, ${checkLog}`)})\n\t`);\n}\n\nfunction createSFDXProject() {\n    this.asyncCopadoLogMessage('Creating SFDX Project');\n\texecSync(`\n        sf project generate --name ${TEMP} || (${this.showError(`Error creating SF project, ${checkLog}`)})\n    `);\n\tprocess.chdir(TEMP);\n}\n\nfunction getPackageList() {\n    this.asyncCopadoLogMessage('Getting Package Info');\n\treturn JSON.parse(\n\t\texecSync(`\n            sf package list --target-dev-hub ${session} --json\n\t    `).toString()\n\t);\n}\n\nfunction getPackageDetails() {\n\tconst packages = this.getPackageList();\n\tif (packages.status) {\n\t\tthrow `${packages.name}: ${packages.message}`;\n\t} else {\n\t\treturn packages.result.find(element => element.Name == packageNameOrId || element.Id == packageNameOrId);\n\t}\n}\n\nfunction getPackageVersions(packageId) {\n    this.asyncCopadoLogMessage('Getting Package Version Info');\n\tconst versions = JSON.parse(\n\t\texecSync(`\n            sf package version list --target-dev-hub ${session} --packages ${packageId} --json\n        `).toString()\n\t);\n\n\tif (versions.status) {\n\t\tthrow `${versions.name}: ${versions.message}`;\n\t} else {\n\t\treturn versions.result;\n\t}\n}\n\nfunction escapeSpecialCharacters(text) {\n\tlet result = text.replace(/`/g, '\\\\`').replace(/\\$/g, '\\\\$');\n\n\treturn result;\n}\n\nfunction maskSensitiveInformation(data) {\n\tconst sensitiveInfo = ['--target-dev-hub', '-u', '-v'],\n\t\tmaskingSequence = '*****';\n\n\tconst arrayOfData = data.split(' ');\n\tsensitiveInfo.forEach(subString => {\n\t\tconst keyIndex = arrayOfData.indexOf(subString);\n\t\tif (keyIndex > -1) {\n\t\t\tarrayOfData[keyIndex + 1] = maskingSequence;\n\t\t\tdata = arrayOfData.join(' ');\n\t\t}\n\t});\n\treturn data;\n}\n\nfunction uploadFile(fileName) {\n\texecSync(`copado --uploadfile ${fileName} || (${this.showError(`Error uploading ${fileName}, ${checkLog}`)})`, { stdio: 'inherit' });\n}\n\nfunction asyncCopadoLogMessage(msg) {\n    new Promise(resolve => {\n        exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, (err, response, stderr) => {\n            resolve();\n        });\n    });\n}\n\n\nmodule.exports.execute = execute;\nmodule.exports.createSFDXProject = createSFDXProject;\nmodule.exports.setInstanceURL = setInstanceURL;\nmodule.exports.getPackageDetails = getPackageDetails;\nmodule.exports.getPackageVersions = getPackageVersions;\nmodule.exports.uploadFile = uploadFile;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\nmodule.exports.showError = showError;\nmodule.exports.escapeSpecialCharacters = escapeSpecialCharacters;\nmodule.exports.getPackageList = getPackageList;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1.0",
                    "copado__Worker_Size__c": "S",
                    "CreatedDate": "2021-09-16T15:20:01.000+0000",
                    "Id": "a0k09000000FKgfAAG",
                    "IsDeleted": false,
                    "LastModifiedDate": "2021-09-28T13:50:51.000+0000",
                    "LastReferencedDate": "2021-09-29T14:36:54.000+0000",
                    "LastViewedDate": "2021-09-29T14:36:54.000+0000",
                    "Name": "Devhub Package Info",
                    "SystemModstamp": "2021-09-28T13:50:51.000+0000"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v57.0/sobjects/copado__Function__c/a0l7Q000000iAiJQAU"
                    },
                    "copado__API_Name__c": "sfdx_install_package",
                    "copado__Callback_Type__c": "Flow",
                    "copado__FlowHandler__c": "cmcSf.Installed_Package_Callback",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"packages\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.GetInstallationKeys}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationBaseUrl\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationSession\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"retrialTimes\",\n  \"defaultValue\" : \"{$Property.sfdx_package_install_retrial_time}\"\n}, {\n  \"name\" : \"apiVersion\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.apiVersion}\"\n}, {\n  \"name\" : \"devhubSession\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"name\" : \"devhubBaseUrl\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"name\" : \"installationSecurityType\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.installSecurityType}\"\n}, {\n  \"name\" : \"pollInterval\",\n  \"defaultValue\" : \"{$Property.sfdx_package_install_poll_time_in_seconds}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n\nconst { execSync } = require('child_process'),\n    {\n        packages,\n        destinationBaseUrl,\n        destinationSession,\n        apiVersion,\n        devhubSession,\n        devhubBaseUrl,\n        installationSecurityType,\n        pollInterval,\n        retrialTimes,\n        isTest\n    } = process.env,\n    destinationUrl = getUrl(destinationBaseUrl),\n    devhubUrl = getUrl(devhubBaseUrl),\n    fetchReportRetrialTimes = retrialTimes ? parseInt(retrialTimes) : 3,\n    installPollIntervalInSec = pollInterval ? parseInt(pollInterval) : 30,\n    TEMP = 'temp';\n\n// EXECUTION\n\nasync function execute() {\n    try {\n\n        this.createSFDXProject();\n\n        const listOfPackages = JSON.parse(packages),\n            response = this.getVersionsWithStatus(listOfPackages),\n            mainPackageId = listOfPackages.length && listOfPackages[listOfPackages.length - 1]?.id;\n\n        const filteredPackages = this.filterPackagesToInstall(response, listOfPackages);\n\n        if (filteredPackages?.length) {\n\n            this.setInstanceURL(destinationUrl, 'destination org');\n            await this.installPackages(filteredPackages, mainPackageId);\n        }\n\n        execSync(`copado -p 'Updating Results' -r ${JSON.stringify(JSON.stringify(response))}`);\n    } catch (error) {\n        //Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n        if (error?.status === 3) {\n            process.exit(1);\n        }\n        execSync(this.showErrorCmd(error.toString()));\n    }\n}\n\n// SCRIPT FUNCTIONS\n\nfunction setInstanceURL(url, destination) {\n    execSync(\n        `\n        copado -p 'Setting instance url(${destination})'\n        sf config set org-instance-url=${url} || (${this.showErrorCmd(`Error setting instance URL`)})\n    `,\n        { stdio: 'inherit' }\n    );\n}\n\nasync function installPackages(listOfPackages, mainPackageId) {\n    for await (pkg of listOfPackages) {\n        if (pkg.id) {\n            const isMainPackage = mainPackageId === pkg.id;\n            await this.install(pkg, isMainPackage);\n        } else {\n            throw 'Could not find Subscriber Package Version Id';\n        }\n    }\n}\n\nfunction installPackage(pckg, isMainPackage) {\n    let params = `--target-org ${destinationSession} --package ${pckg.id} --no-prompt`;\n    params += pckg.key ? ` --installation-key '${pckg.key}'` : '';\n    params += apiVersion ? ` --api-version ${apiVersion}` : '';\n    params += isMainPackage && installationSecurityType ? ` --security-type ${installationSecurityType}` : '';\n\n    const installCmd = `sf package install ${params} --json || true`;\n    this.logger(`Package Install Command ==> ${installCmd}`);\n\n    const response = JSON.parse(\n        execSync(`\n            copado -p 'Installing package ${pckg.id}'\n            ${installCmd}\n        `).toString()\n    );\n\n    this.logger(`Package Install Response ==> ${JSON.stringify(response)}`);\n    if (response?.status) {\n        throw `Error installing packageID ${pckg.id} : ${response?.name}: ${response?.message}`;\n    }\n\n    return response;\n}\n\nasync function pollInstallStatus(jobId, packageId) {\n    let counter = 0;\n    return new Promise((resolve, reject) => {\n        const poll = setInterval(() => {\n            const response = this.getInstallRequestReport(jobId, destinationSession);\n\n            if (!response?.status && response?.result?.Status === 'SUCCESS') {\n                this.logger(`Package with Id ${packageId} successfully installed. ${JSON.stringify(response)}`);\n\n                clearInterval(poll);\n                resolve(response);\n            } else if (response?.status) {\n                this.logger(`Package with Id ${packageId} failed to install or fetch report. ${JSON.stringify(response)}`);\n\n                if ((response?.message?.includes('ETIMEDOUT') || response?.name === 'INVALID_FIELD') && ++counter <= fetchReportRetrialTimes) {\n                    this.logger(`Retrying attempt ${counter} to fetch installation status of jobId: ${jobId}`);\n                } else {\n                    clearInterval(poll);\n                    reject(response?.message);\n                }\n            }\n        }, installPollIntervalInSec * 1000);\n    });\n}\n\nasync function install(pkg, isMainPackage) {\n    try {\n        const installResponse = this.installPackage(pkg, isMainPackage);\n\n        const jobId = installResponse?.result?.Id;\n        if (jobId) {\n            await this.pollInstallStatus(jobId, pkg.id);\n        } else {\n            throw `Could not receieve package install request id for package: ${pkg.id}`;\n        }\n    } catch (error) {\n        execSync(this.showErrorCmd(error.toString()));\n    }\n}\n\nfunction showErrorCmd(error) {\n    let modifiedError = error + ', Please check the logs for details';\n    const refinedErrorMsg = this.maskSensitiveInformation(modifiedError, { '--target-org': destinationSession });\n    return `copado -p 'Error' -e ${this.escapeSpecialCharacters(JSON.stringify(refinedErrorMsg)).replace(/\\\\n/g, '\\n')} && exit 3`;\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nfunction checkVersionFromDevhub(subscriberId, installationKey) {\n    this.setInstanceURL(devhubUrl, 'devhub');\n\n    const query = `SELECT MajorVersion, MinorVersion, PatchVersion, BuildNumber, SubscriberPackageId FROM SubscriberPackageVersion WHERE Id='${subscriberId}' ${\n        installationKey ? `AND InstallationKey='${installationKey}'` : ''\n    }`;\n    let result = execSync(`\n            copado -p 'Querying SubscriberPackageVersion Tooling API'\n\t\t\tsf data query --use-tooling-api --query \"${query}\" --target-org ${devhubSession} --json || true\n\t\t`).toString();\n    this.logger(`SubscriberPackageVersion Tooling API response => ${result}`);\n\n    result = JSON.parse(result);\n    if (result?.status) {\n        throw `${result?.name} - ${result?.message}`;\n    }\n    return result;\n}\n\nfunction getInstalledPackageVersion(SubscriberPackageId) {\n    this.setInstanceURL(destinationUrl, 'destination org');\n\n    const query = `SELECT Id, SubscriberPackageId, SubscriberPackage.NamespacePrefix, SubscriberPackage.Name, SubscriberPackageVersion.Id, SubscriberPackageVersion.Name, SubscriberPackageVersion.MajorVersion, SubscriberPackageVersion.MinorVersion, SubscriberPackageVersion.PatchVersion, SubscriberPackageVersion.BuildNumber FROM InstalledSubscriberPackage where SubscriberPackageId = '${SubscriberPackageId}'`;\n    let result = execSync(`\n            copado -p 'Querying InstalledSubscriberPackage Tooling API'\n\t\t\tsf data query --use-tooling-api --query \"${query}\" --target-org ${destinationSession} --json || true\n\t\t`).toString();\n    this.logger(`InstalledSubscriberPackage Tooling API response => ${result}`);\n\n    result = JSON.parse(result);\n    if (result?.status) {\n        throw `${result?.name} - ${result?.message}`;\n    }\n    return result;\n}\n\nfunction compareVersion(installed, installing) {\n    const value = installed.localeCompare(installing, undefined, { numeric: true, sensitivity: 'base' });\n    return value < 0;\n}\n\nfunction checkVersionCompatibility(pkg) {\n    let installPkg = true,\n        version = !pkg.subscriberPackageId && this.checkVersionFromDevhub(pkg.id, pkg.key);\n\n    if (version?.result?.records.length || pkg.subscriberPackageId) {\n        const installedVersion = this.getInstalledPackageVersion(version?.result?.records[0].SubscriberPackageId || pkg.subscriberPackageId);\n\n        if (installedVersion?.result?.totalSize) {\n            const installed = installedVersion.result.records[0].SubscriberPackageVersion,\n                installing = version?.result?.records[0];\n\n            installPkg = this.compareVersion(this.generateVersionName(installed), installing ? this.generateVersionName(installing) : pkg.versionNumber);\n        }\n    }\n    return installPkg ? 'success' : 'skipped';\n}\n\nfunction generateVersionName(version) {\n    return `${version.MajorVersion}.${version.MinorVersion}.${version.PatchVersion}.${version.BuildNumber}`;\n}\n\nfunction getVersionsWithStatus(packages) {\n    let subscriberIds = [];\n\n    for (pkg of packages) {\n        const status = this.checkVersionCompatibility(pkg);\n        subscriberIds.push({ versionId: pkg.id, status: status });\n    }\n\n    return subscriberIds;\n}\n\nfunction filterPackagesToInstall(response, listOfPackages) {\n    return response.reduce((filtered, option) => {\n        if (option.status === 'success') {\n            filtered.push({ id: option.versionId, key: listOfPackages.find((pkg) => pkg.id === option.versionId).key });\n        }\n        return filtered;\n    }, []);\n}\n\nfunction getUrl(baseUrl) {\n    return baseUrl.substring(0, baseUrl.indexOf('/', baseUrl.indexOf('/') + 2));\n}\n\nfunction escapeSpecialCharacters(text) {\n    let result = text.replace(/`/g, '\\\\`').replace(/\\$/g, '\\\\$');\n\n    return result;\n}\n\nfunction maskSensitiveInformation(data, sensitiveFlags) {\n    const maskingSequence = '*****';\n\n    const arrayOfData = data.split(' ');\n    Object.keys(sensitiveFlags).forEach((subStr) => {\n        const keyIndex = arrayOfData.indexOf(subStr);\n        if (keyIndex > -1) {\n            arrayOfData[keyIndex + 1] = maskingSequence;\n            arrayOfData.splice(keyIndex + 2, sensitiveFlags[subStr].split(' ').length - 1);\n        }\n    });\n    return arrayOfData.join(' ');\n}\n\nfunction getInstallRequestReport(jobId, session) {\n    return JSON.parse(\n        execSync(`\n        copado -p 'Fetch installation status for jobID: ${jobId}'\n        sf package install report --request-id ${jobId} --target-org ${session} --json || true\n    `).toString()\n    );\n}\n\nfunction createSFDXProject() {\n    execSync(`\n        sf project generate --name ${TEMP} || (${this.showErrorCmd(`Error creating SF project`)})\n    `, { stdio: 'inherit' });\n\n    process.chdir(TEMP);\n}\n\nmodule.exports.setInstanceURL = setInstanceURL;\nmodule.exports.installPackages = installPackages;\nmodule.exports.installPackage = installPackage;\nmodule.exports.pollInstallStatus = pollInstallStatus;\nmodule.exports.install = install;\nmodule.exports.showErrorCmd = showErrorCmd;\nmodule.exports.logger = logger;\nmodule.exports.checkVersionFromDevhub = checkVersionFromDevhub;\nmodule.exports.getInstalledPackageVersion = getInstalledPackageVersion;\nmodule.exports.compareVersion = compareVersion;\nmodule.exports.checkVersionCompatibility = checkVersionCompatibility;\nmodule.exports.generateVersionName = generateVersionName;\nmodule.exports.getVersionsWithStatus = getVersionsWithStatus;\nmodule.exports.filterPackagesToInstall = filterPackagesToInstall;\nmodule.exports.escapeSpecialCharacters = escapeSpecialCharacters;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\nmodule.exports.getInstallRequestReport = getInstallRequestReport;\nmodule.exports.createSFDXProject = createSFDXProject;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\nmodule.exports.execute = execute;\n\n!isTest && this.execute();",
                    "copado__Timeout__c": 200,
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1.0",
                    "Id": "a0l7Q000000iAiJQAU",
                    "LastReferencedDate": "2023-04-13T06:43:00.000+0000",
                    "LastViewedDate": "2023-04-13T06:43:00.000+0000",
                    "Name": "Sfdx Install Package"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q000000MDYvQAO"
                    },
                    "copado__API_Name__c": "sfdx_deploy",
                    "copado__Callback_Type__c": "Flow",
                    "copado__Description__c": "Deploys promotion branch",
                    "copado__FlowHandler__c": "cmcSf.Deploy_Function_Callback",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"fileChangesId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"promotion\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.promotionBranchName}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"targetBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.destinationBranchName}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationInstanceUrl\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationSessionid\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationEnv\",\n  \"defaultValue\" : \"{$Destination.apex.EnvironmentVariables}\"\n}, {\n  \"name\" : \"findAndReplaceRules\",\n  \"defaultValue\" : \"{$Context.apex.GlobalFindAndReplaceDestinationId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"isValidation\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.deploymentDryRun}\"\n}, {\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"name\" : \"testLevel\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.Promotion__r.cmcSf__Apex_Test_Level__c}\"\n}, {\n  \"name\" : \"debugMode\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.Promotion__r.cmcSf__Debug_Mode__c}\"\n}, {\n  \"name\" : \"gitDepth\",\n  \"defaultValue\" : \"{$Pipeline.Property.gitDepth_deploy}\"\n}, {\n  \"name\" : \"validationId\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.Promotion__r.cmcSf__Validate_Deploy_Request_Id__c}\"\n}, {\n  \"name\" : \"testSuiteAndTestClassFileVersionDetails\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.GetFileVersionIdOfTestClassTestSuite}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"name\" : \"waitTime\",\n  \"defaultValue\" : \"220\"\n}, {\n  \"name\" : \"sourceInstanceUrl\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"name\" : \"sourceSessionid\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"name\" : \"mergeProfile\",\n  \"defaultValue\" : \"false\"\n}, {\n  \"name\" : \"overriddenApiVersion\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"isProductionEnvironment\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.IdentifyProductionEnvironment}\"\n}, {\n  \"name\" : \"hasVlocityChanges\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.HasVlocityChanges}\"\n}, {\n  \"name\" : \"rollBackEnabled\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.IsRollBackEnabled}\"\n}, {\n  \"name\" : \"fetchDeployReportRetrialTimes\",\n  \"defaultValue\" : \"{$Pipeline.Property.fetch_deploy_report_retrial_times}\"\n}, {\n  \"name\" : \"deployPollTime\",\n  \"defaultValue\" : \"{$Pipeline.Property.deploy_poll_time}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n/**\n * Performs deploy of selected user story metadata changes.\n * Returns (If ACTION success) destination branch with merged changes of the user story metadata\n * (If ACTION failed) Returns details with error status on the job execution\n * @param fileChangesId\n * @param promotion\n * @param targetBranch\n * @param destinationInstanceUrl\n * @param destinationSessionid\n * @param git_json\n * @param destinationEnv\n * @param findAndReplaceRules\n * @param isValidation\n * @param gitName\n * @param gitEmail\n * @param testLevel\n * @param testSuiteAndTestClassFileVersionDetails\n * @param maxBuffer\n * @param sourceSessionid\n * @param sourceInstanceUrl\n * @param waitTime\n * @param mergeProfile\n * @param hasVlocityChanges\n */\n\n/*\nglobal __dirname\n*/\nconst child_process = require('child_process'),\n\tfs = require('fs'),\n\tprocess = require('process'),\n\t{\n\t\tdestinationSessionid,\n\t\tpromotion,\n\t\ttargetBranch,\n\t\tisValidation,\n\t\tdestinationInstanceUrl,\n\t\tAPI_VERSION,\n\t\tisTest,\n\t\tsourceInstanceUrl,\n\t\tsourceSessionid,\n\t\tgitDepth,\n\t\thasVlocityChanges,\n\t\tmaxBuffer,\n\t\tdestinationEnv,\n\t\tfetchDeployReportRetrialTimes,\n\t\tdeployPollTime\n\t} = process.env,\n\t{ Ux } = isTest ? require('@salesforce/sf-plugins-core') : require('/usr/local/lib/node_modules/@salesforce/sf-plugins-core'),\n\t{ CopaReconcilerInput, Retriever, Reconciler, Merger, Operation } = isTest\n\t\t? require('./__tests__/__mocks__/copado-metadata-reconciler')\n\t\t: require('/usr/local/lib/node_modules/@mcdx/copado-metadata-reconciler'),\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tAPP_DIRECTORY = getPath('/app'),\n\tTARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n\tENCODED_CHANGES_FILE = 'encoded_changes.json',\n\tENCODED_CHANGES_WITH_SF_METADATA_VALIDITY = 'encoded_changes_with_sf_metadata_validity.json',\n\tFILES_TO_INCLUDE = `${TEMP_DIRECTORY}/filesToInclude.json`,\n\tROLLBACK_JSON = `${TEMP_DIRECTORY}/CopadoRollbackChanges.json`,\n\tOUTPUT_JSON_FILE_PATH = `${TEMP_DIRECTORY}/output.json`,\n\tCOPADO_INFO_PREFIX = 'CopadoFunction INFO',\n\tMAXBUFFER = parseInt(maxBuffer),\n\tACTIONS = {\n\t\tADD: 'add',\n\t\tRETRIEVE_ONLY: 'retrieveonly',\n\t\tFULL: 'full',\n\t\tDELETE: 'delete',\n\t\tSELECTIVE_COMMIT: 'selectivecommit'\n\t},\n\tTYPES = {\n\t\tPERMISSION_SET: 'permissionset',\n\t\tPROFILE: 'profile'\n\t},\n\tSTDIO = {\n\t\tINHERIT: 'inherit',\n\t\tPIPE: 'pipe',\n\t\tIGNORE: 'ignore'\n\t},\n\tMETADATA_FOR_MERGE_IN_PROFILE = [\n\t\t'apexclass',\n\t\t'customapplication',\n\t\t'customobject',\n\t\t'customfield',\n\t\t'layout',\n\t\t'apexpage',\n\t\t'customtab',\n\t\t'recordtype',\n\t\t'systempermissions'\n\t],\n\tTEST_LEVEL = {\n\t\tRUN_SPECIFIED_TESTS: 'RunSpecifiedTests',\n\t\tNO_TEST_RUN: 'NoTestRun'\n\t},\n\tCONSTANTS = {\n\t\tCOMPONENT_TYPE: 'componentType',\n\t\tFULL_NAME: 'fullName',\n\t\tPROBLEM: 'problem',\n\t\tTEST_SUITE_FILE_NAME:'cmcSf_TestSuites',\n\t\tTEST_CLASS_FILE_NAME:'cmcSf_TestClasses'\n\t},\n\tDEPLOYMENT_STATUS = {\n\t\tCANCELED: 'Canceled',\n\t\tPENDING: 'Pending',\n\t\tINPROGRESS: 'InProgress'\n\t},\n\tROLLBACK_ACTION = {\n\t\tUNCHANGED: 'Unchanged',\n\t\tDELETE: 'Delete',\n\t\tCREATE: 'Create',\n\t\tUPDATE: 'Update',\n\t\tRETRIEVEONLY: 'RetrieveOnly'\n\t},\n\tCATEGORY = { SFDX: 'sfdx' },\n\tGIT_DEPTH = getGitDepth(gitDepth),\n\tvlocityChangesPresent = hasVlocityChanges?.toLowerCase() === 'true',\n\tCOPADO_RETRIEVE_XML = 'CopadoRetrieve.xml',\n\tCOPADO_DESTRUCTIVE_XML = 'CopadoDestructive.xml',\n\tRESULT_INFO = {\n\t\tLEVEL: {\n\t\t\tINFO: 'INFO',\n\t\t\tERROR: 'ERROR',\n\t\t\tWARN: 'WARN'\n\t\t},\n\t\tCATEGORY: {\n\t\t\tUNKNOWN_EXCEPTION: 'Unknown Exception',\n\t\t\tCOPADO_INFO: 'Copado Info',\n\t\t\tAPEX_TEST_RUN: 'Apex Test Run',\n\t\t\tFLOW_TEST_RUN: 'Flow Test Run',\n\t\t\tCOPADO_METADATA_INTELLIGENCE: 'Copado Metadata Intelligence',\n\t\t\tGIT_SERVICE: 'Git Service',\n\t\t\tCOPADO_SERVICE: 'Copado Service',\n\t\t\tSFDX_CLI: 'SFDX CLI',\n\t\t\tMETADATA_RECONCILER: 'Metadata Reconciler',\n\t\t\tMETADATA_EXECUTION: `Metadata ${isValidation === 'true' ? 'Validation' : 'Deployment'}`,\n\t\t\tFILE_SYSTEM: 'File System'\n\t\t},\n\t\tADDITIONAL_INFORMATION: {\n\t\t\tAPEX_TEST_FAILURE: 'Apex Test Failure',\n\t\t\tCODE_COVERAGE_ERROR: 'Code Coverage Error',\n\t\t\tFLOW_TEST_FAILURE: 'Flow Test Failure',\n\t\t\tAPEX_TEST_RUN_SUMMARY: 'Test Run Summary',\n\t\t\tCONSOLIDATED_RESULT: `Consolidated ${isValidation === 'true' ? 'Validation' : 'Deployment'} Result`,\n\t\t\tMETADATA_VALIDATION_SUCCESSFUL: 'Metadata Validation Successful',\n\t\t\tMETADATA_DEPLOYMENT_REQUEST: 'Metadata Deployment Request',\n\t\t\tPOLL_STATUS: `Poll ${isValidation === 'true' ? 'Validation' : 'Deployment'} Status`,\n\t\t\tQUICK_DEPLOYMENT: 'Quick Deployment',\n\t\t\tGIT_STATUS: 'Git Status',\n\t\t\tROLLBACK_BRANCH_CHECKOUT: 'Rollback Branch Checkout',\n\t\t\tGIT_COMMIT: 'Git Commit',\n\t\t\tGIT_CONFIG: 'Git Configuration',\n\t\t\tSFDX_CONFIG: 'SFDX Configuration',\n\t\t\tSFDX_DEPLOYMENT: 'SFDX Deployment',\n\t\t\tFULL_PROFILE_RECONCILIATION: 'Full Profile Reconciliation',\n\t\t\tFULL_PROFILE_MERGE: 'Full Profile Merge',\n\t\t\tPROMOTION_BRANCH_CHECKOUT: 'Promotion Branch Checkout',\n\t\t\tTARGET_BRANCH_CHECKOUT: 'Target Branch Checkout',\n\t\t\tDEBUG_BRANCH_CHECKOUT: 'Debug Branch Checkout',\n\t\t\tENRICHER_SERVICE: 'Enricher Service',\n\t\t\tMETADATA_PROCESSOR: 'Metadata Processor',\n\t\t\tMETADATA_ANALYZER: 'Metadata Analyzer',\n\t\t\tENV_VARIABLE_REPLACEMENT: 'Environment Variable Replacement',\n\t\t\tGLOBAL_FIND_AND_REPLACE: 'Global Find and Replace',\n\t\t\tUPLOAD_FILES: 'Upload Files',\n\t\t\tGIT_MERGE: 'Git Merge',\n\t\t\tGIT_PUSH: 'Git Push',\n\t\t\tGIT_ADD: 'Git Add',\n\t\t\tDOWNLOAD_FILES: 'Download Files',\n\t\t\tFINDING_TEST_CLASSES:`Finding Test Classes For ${isValidation === 'true' ? 'Validation' : 'Deployment'}`\n\t\t}\n\t},\n\tresultViewerJson = [],\n\tCUSTOM_ERROR = {\n\t\tCOMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n\t},\n\tRESULT_TABLE_COLUMNS = [\n\t\t{\n\t\t\tlabel: 'Level',\n\t\t\tfieldName: 'Level',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Level',\n\t\t\tinitialWidth: 80\n\t\t},\n\t\t{\n\t\t\tlabel: 'Category',\n\t\t\tfieldName: 'Category',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Category',\n\t\t\tinitialWidth: 120\n\t\t},\n\t\t{\n\t\t\tlabel: 'Additional Information',\n\t\t\tfieldName: 'AdditionalInformation',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Additional_Information',\n\t\t\tinitialWidth: 200\n\t\t},\n\t\t{\n\t\t\tlabel: 'Message',\n\t\t\tfieldName: 'Message',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Message'\n\t\t}\n\t],\n\tRESULT_TABLE_HEADER = {\n\t\tlabel: 'Deployment Result',\n\t\tcustomLabel: 'Deployment_Result'\n\t},\n\tHEADER_ICON = 'standard:note',\n\tNUMBER_OF_REPORT_RETRIALS = parseInt(fetchDeployReportRetrialTimes) >= 0 ? parseInt(fetchDeployReportRetrialTimes) : 10,\n\tDEPLOY_REPORT_POLL_TIME = parseInt(deployPollTime) >= 0 ? parseInt(deployPollTime) >= 0 : 1,\n\t{ cpus } = require('os');\n\nlet sourceApiVersion = isTest ? API_VERSION : '';\nlet isSfMetadataPresent,\n\texecutionError,\n\ttotalTimeByType = {},\n\tprocesses = [];\n\n// EXECUTION\n\nasync function execute() {\n\tconst {\n\t\tdebugMode,\n\t\ttargetBranch,\n\t\tvalidationId,\n\t\tmergeProfile,\n\t\toverriddenApiVersion,\n\t\tgitEmail,\n\t\tgitName,\n\t\tfindAndReplaceRules,\n\t\tdestinationEnv,\n\t\trollBackEnabled\n\t} = process.env;\n\tlet debugBranch;\n\tlet doDeployment = true;\n\tlet deployResult;\n\tlet rollBackBranchName = getRollBackBranchName(promotion);\n\tlet isRollBack = isRollBackEnabled(isValidation, rollBackEnabled);\n\ttry {\n\t\tthis.checkChangesWrtCategory(`${APP_DIRECTORY}/${ENCODED_CHANGES_FILE}`);\n\n\t\tsourceApiVersion = this.getApiVersion(overriddenApiVersion, API_VERSION);\n\n\t\tthis.analyzeMetadata(`${APP_DIRECTORY}/${ENCODED_CHANGES_FILE}`, `${APP_DIRECTORY}/${ENCODED_CHANGES_WITH_SF_METADATA_VALIDITY}`);\n\t\tconst changes = this.prepareChanges(`${APP_DIRECTORY}/${ENCODED_CHANGES_WITH_SF_METADATA_VALIDITY}`);\n\t\tthis.fetchPromotionBranch(promotion, GIT_DEPTH);\n\t\tthis.configureGit(gitEmail, gitName);\n\t\tlet retrieveResult = [];\n\t\tif (isRollBack) {\n\t\t\tretrieveResult = await this.executeRollBackLogic(changes, findAndReplaceRules, rollBackBranchName);\n\t\t}\n\t\tthis.gitMergePromotionToTarget(promotion, targetBranch, GIT_DEPTH);\n\t\tthis.validateSFDXProjectJson(`${TARGET_DIRECTORY}/sfdx-project.json`);\n\t\tthis.updateSourceApiVersion(`${TARGET_DIRECTORY}/sfdx-project.json`, sourceApiVersion);\n\t\tawait this.processFullProfiles(changes, mergeProfile);\n\t\tif (debugMode === 'true') {\n\t\t\tdebugBranch = `copadoDebug/${promotion?.split('/')[1]}`;\n\t\t\tthis.createDebugPromotionBranch(debugBranch);\n\t\t}\n\t\tthis.processMetadata(changes, `${APP_DIRECTORY}/${ENCODED_CHANGES_FILE}`);\n\t\tif (changes.add?.length || changes.profiles?.length) {\n\t\t\tthis.varReplace(destinationEnv, null);\n\t\t}\n\t\tthis.yamlFindAndReplace(changes, findAndReplaceRules, promotion);\n\t\tif (debugMode === 'true') {\n\t\t\tthis.pushDebugPromotionBranch(debugBranch);\n\t\t}\n\n\t\tthis.setInstanceUrl(destinationInstanceUrl);\n\n\t\tif (isValidation === 'false' && validationId) {\n\t\t\t({ doDeployment, deployResult } = await this.executeQuickDeploy(validationId, isValidation));\n\t\t}\n\t\tif (doDeployment) {\n\t\t\tconst manifest = this.createManifest(changes);\n\t\t\tdeployResult = await this.deploy(manifest, isValidation);\n\t\t}\n\n\t\t//Vlocity Check --> so that push operation only happens when we do not have vlocity specific changes.\n\t\tconst pushToRemote = isValidation === 'true' || vlocityChangesPresent ? [] : [this.pushChangesToRemote(targetBranch)];\n\t\tawait Promise.all([...pushToRemote, this.cleanDeploymentFiles()]);\n\n\t\tif (isRollBack) {\n\t\t\tawait Promise.all([\n\t\t\t\tthis.gitPush(rollBackBranchName),\n\t\t\t\tthis.createCopadoRollbackChangesFile(\n\t\t\t\t\tchanges,\n\t\t\t\t\tdeployResult,\n\t\t\t\t\tretrieveResult && retrieveResult[0]?.sfdxRetrieveResult ? retrieveResult[0].sfdxRetrieveResult : []\n\t\t\t\t)\n\t\t\t]);\n\t\t}\n\t\tthis.printMetrics();\n\t} catch (err) {\n\t\tthis.logger(`Error stack: ${err.stack}`);\n\t\tif (!(err instanceof CommandExecutionError)) {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, 'See logs for more info', err.message);\n\t\t}\n\t\texecutionError = err.message || err?.toString() || 'Unknown Error occurred';\n\t} finally {\n\t\tif (resultViewerJson?.length) {\n\t\t\tthis.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n\t\t}\n\t\tif (executionError) {\n\t\t\tthis.executeCommand(this.getErrorCmdString(executionError));\n\t\t\tprocess.exit(1);\n\t\t}\n\t}\n}\n\n/*\n * This function creates a RollBack branch from the target org before the actual deployment\n * We start this process by first checking out the rollback branch from target .\n * Retrieve metadata from destination org and store it in the target repo , apply Global find and replaces to the files retrieved and then commit changes to rollback branch.\n */\nasync function executeRollBackLogic(changes, findAndReplaceRules, rollBackBranchName) {\n\tlet filePaths = [];\n\tconst changesCloned = { ...changes };\n\tlet retrieveResult = [];\n\tthis.checkoutRollBackBranch(rollBackBranchName, targetBranch);\n\tthis.logger(`Changes List in Rollback : ${JSON.stringify(changesCloned)}`);\n\tthis.prepareMetadataChangesList(changesCloned);\n\n\tif (changesCloned.hasSfdxMetadata()) {\n\t\tretrieveResult = await Promise.all(this.retrieveOrgMetadata(changesCloned, rollBackBranchName));\n\t\tfilePaths = getFilePaths(retrieveResult);\n\t}\n\tif (filePaths?.length > 0 && !changesCloned.Sfdx?.hasOnlyDestructiveChanges()) {\n\t\tfs.writeFileSync(FILES_TO_INCLUDE, JSON.stringify(filePaths));\n\t\tif (fs.existsSync(FILES_TO_INCLUDE)) {\n\t\t\tthis.varReplace(destinationEnv, FILES_TO_INCLUDE);\n\t\t\tthis.yamlFindAndReplace(changesCloned, findAndReplaceRules, rollBackBranchName, FILES_TO_INCLUDE);\n\t\t}\n\t}\n\n\tthis.commitChangesInRollbackBranch(100, filePaths, rollBackBranchName);\n\treturn retrieveResult;\n}\n\nfunction getFilePaths(retrieveResult) {\n\tlet filePaths = [];\n\tretrieveResult.forEach(element => {\n\t\tif (element.sfdxRetrieveResult) {\n\t\t\telement.sfdxRetrieveResult?.result?.files\n\t\t\t\t?.filter(file => file.state !== 'Failed' && file.filePath !== undefined)\n\t\t\t\t.forEach(file => {\n\t\t\t\t\tfilePaths.push(file.filePath?.replace(`${TARGET_DIRECTORY}/`, ''));\n\t\t\t\t});\n\t\t} else if (element.sfPowerKitRetrieveResult) {\n\t\t\telement.sfPowerKitRetrieveResult?.result?.filter(file => file?.path !== undefined).forEach(file => filePaths.push(file?.path));\n\t\t}\n\t});\n\treturn filePaths;\n}\n\nfunction createCopadoRollbackChangesFile(changeList, deploymentResult, retrieveResult) {\n\treturn new Promise((resolve, reject) => {\n\t\tif (changeList && deploymentResult && deploymentResult.status === 0) {\n\t\t\tconst rollbackChanges = new Map();\n\t\t\tchangeList?.all?.forEach(element => {\n\t\t\t\tif (!element.j || JSON.parse(element.j).isSfMetadata) {\n\t\t\t\t\trollbackChanges.set(`${element.t?.toLowerCase()}${element.n?.toLowerCase()}`, {\n\t\t\t\t\t\tn: element.n,\n\t\t\t\t\t\tt: element.t,\n\t\t\t\t\t\ta: element.a,\n\t\t\t\t\t\tc: element.c,\n\t\t\t\t\t\tr: element.a?.toLowerCase() === 'retrieveonly',\n\t\t\t\t\t\ts: true,\n\t\t\t\t\t\tf: element.a?.toLowerCase() === 'full'\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t});\n\t\t\tdeploymentResult.result?.details?.componentSuccesses?.forEach(element => {\n\t\t\t\tconst metadataTypeAndName = `${element.componentType?.toLowerCase()}${element.fullName?.toLowerCase()}`;\n\t\t\t\tconst metadataInfo = rollbackChanges.get(metadataTypeAndName);\n\t\t\t\tif (element.success && metadataInfo) {\n\t\t\t\t\tif (element.created) {\n\t\t\t\t\t\tmetadataInfo.a = ROLLBACK_ACTION.DELETE;\n\t\t\t\t\t} else if (element.changed) {\n\t\t\t\t\t\tmetadataInfo.a = ROLLBACK_ACTION.UPDATE;\n\t\t\t\t\t} else if (element.deleted) {\n\t\t\t\t\t\tmetadataInfo.a = ROLLBACK_ACTION.CREATE;\n\t\t\t\t\t\tmetadataInfo.f = metadataInfo.t?.toLowerCase() === 'profile';\n\t\t\t\t\t} else {\n\t\t\t\t\t\tmetadataInfo.a = metadataInfo.a?.toLowerCase() === 'retrieveonly' ? ROLLBACK_ACTION.RETRIEVEONLY : ROLLBACK_ACTION.UNCHANGED;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\t\t\tretrieveResult?.result?.files?.forEach(element => {\n\t\t\t\tif (element.state === 'Failed' && element.error === `Entity of type '${element.type}' named '${element.fullName}' cannot be found`) {\n\t\t\t\t\tconst metadataTypeAndName = `${element.type?.toLowerCase()}${element.fullName?.toLowerCase()}`;\n\t\t\t\t\tconst metadataInfo = rollbackChanges.get(metadataTypeAndName);\n\t\t\t\t\tif (metadataInfo) {\n\t\t\t\t\t\tmetadataInfo.a = ROLLBACK_ACTION.DELETE;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\t\t\tif (rollbackChanges.size) {\n\t\t\t\tfs.writeFileSync(ROLLBACK_JSON, JSON.stringify(Array.from(rollbackChanges.values())));\n\t\t\t\tthis.asyncCopadoLogMessage('Uploading Rollback Changes File');\n\t\t\t\tconst command = `\n                copado --uploadfile \"${ROLLBACK_JSON}\" --name \"Copado Rollback changes\"\n            `;\n\t\t\t\tchild_process.exec(command, this.getOptions(), error => {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\tthis.populateResultViewer(\n\t\t\t\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\t\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\t\t\t\t\tRESULT_INFO.CATEGORY.UPLOAD_FILES,\n\t\t\t\t\t\t\terror\n\t\t\t\t\t\t);\n\t\t\t\t\t\treject('Error uploading rollback changes file');\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresolve();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t});\n}\n\nfunction getRollBackBranchName(promotion) {\n\treturn 'rollback/' + promotion.split('/')[1];\n}\n\nfunction isRollBackEnabled(isValidation, rollBackEnabled) {\n\treturn isValidation?.toLowerCase() !== 'true' && rollBackEnabled?.toLowerCase() === 'true';\n}\nfunction asyncCopadoLogMessage(msg, logLevel) {\n\tif (msg) {\n\t\tthis.populateResultViewer(logLevel ? logLevel : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n\t\tnew Promise(resolve => {\n\t\t\tchild_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, () => {\n\t\t\t\tresolve();\n\t\t\t});\n\t\t});\n\t}\n}\n\nfunction gitPush(rollBackBranchName) {\n\tthis.asyncCopadoLogMessage(`Pushing all changes to ${rollBackBranchName}`);\n\tconst gitPush = `git push origin \"${rollBackBranchName}\"`;\n\treturn new Promise((resolve, reject) => {\n\t\tchild_process.exec(gitPush, this.getOptions(), (error, stdout, stderr) => {\n\t\t\tthis.handleResponse(error, stdout, stderr, reject);\n\t\t\tresolve();\n\t\t});\n\t});\n}\nfunction commitChangesInRollbackBranch(gitDepth, filepathsList, rollBackBranchName) {\n\tconst resultData = {};\n\tthis.logger('START Git Status porcelain');\n\tconst gitStatus = this.executeCommand('git status --porcelain', RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS);\n\tif (!gitStatus) {\n\t\tresultData.status = 'No Changes';\n\t} else {\n\t\tthis.asyncCopadoLogMessage('Rollback branch pushed to remote');\n\t\tthis.gitCommit('Committing Salesforce Files to rollback branch', rollBackBranchName, filepathsList, true);\n\t}\n}\n\nfunction checkoutRollBackBranch(rollBackBranch) {\n\tthis.asyncCopadoLogMessage('Creating rollback branch from target branch');\n\tconst checkoutRollbackBranch = `\n    git reset --hard || true\n    git fetch origin ${targetBranch}\n    git branch -D ${rollBackBranch} || true\n    git checkout -b ${rollBackBranch} origin/${targetBranch} || exit 1`;\n\tthis.executeCommand(checkoutRollbackBranch, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.ROLLBACK_BRANCH_CHECKOUT);\n\n\tif (vlocityChangesPresent) {\n\t\tthis.executeCommand(\n\t\t\t`copado -p \"Saving rollback details\" -r '${JSON.stringify({ rollbackBranchCreated: true })}'`,\n\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_SERVICE\n\t\t);\n\t}\n}\n\nfunction getSFChanges(committedMetadata) {\n\tthis.logger(`committedMetadata: ${committedMetadata}`);\n\treturn committedMetadata.filter(selection => !selection.c || selection.c?.toLowerCase() == CATEGORY.SFDX);\n}\n\nfunction options() {\n\treturn {\n\t\tshell: true,\n\t\tmaxBuffer: MAXBUFFER\n\t};\n}\n\nfunction prepareMetadataChangesList(commitChanges) {\n\tconst sfdxChanges = this.getSFChanges(commitChanges.all);\n\tcommitChanges.Sfdx = {\n\t\totherSfdx: sfdxChanges?.filter(\n\t\t\tselectedMetadata =>\n\t\t\t\tselectedMetadata.t.toLowerCase() !== TYPES.PROFILE ||\n\t\t\t\t(selectedMetadata.t.toLowerCase() === TYPES.PROFILE &&\n\t\t\t\t\tselectedMetadata.a.toLowerCase() !== ACTIONS.DELETE &&\n\t\t\t\t\tselectedMetadata.a.toLowerCase() !== ACTIONS.FULL)\n\t\t),\n\t\tdelete: sfdxChanges?.filter(selectedMetadata => selectedMetadata.a.toLowerCase() === ACTIONS.DELETE),\n\t\tprofiles: sfdxChanges?.filter(\n\t\t\tselectedMetadata =>\n\t\t\t\tselectedMetadata.t.toLowerCase() === TYPES.PROFILE &&\n\t\t\t\t(selectedMetadata.a.toLowerCase() === ACTIONS.DELETE || selectedMetadata.a.toLowerCase() === ACTIONS.FULL)\n\t\t),\n\t\tgetMetadataList: operation => {\n\t\t\tif (commitChanges.Sfdx[operation]) {\n\t\t\t\treturn commitChanges.Sfdx[operation].map(change => `${change.t}:${change.n}`).join(',');\n\t\t\t}\n\t\t},\n\t\thasOnlyDestructiveChanges: () => {\n\t\t\treturn commitChanges?.Sfdx.delete?.length > 0 && commitChanges?.Sfdx.delete?.length === sfdxChanges.length;\n\t\t}\n\t};\n\tcommitChanges.hasSfdxMetadata = function () {\n\t\treturn sfdxChanges?.length > 0 ? true : false;\n\t};\n}\n\nfunction retrieveOrgMetadata(commitChanges, rollBackBranchName) {\n\tthis.setup(rollBackBranchName);\n\tconst promises = [];\n\tcommitChanges?.Sfdx.otherSfdx?.length &&\n\t\tpromises.push(\n\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\tthis.sfdxRetrieve(commitChanges, resolve, reject);\n\t\t\t})\n\t\t);\n\n\tcommitChanges?.Sfdx.profiles?.length &&\n\t\tpromises.push(\n\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\tthis.retrieveFullProfile(commitChanges, resolve, reject);\n\t\t\t})\n\t\t);\n\n\treturn promises;\n}\n\nfunction sfdxRetrieve(commitChanges, resolve) {\n\tthis.buildManifest(commitChanges.Sfdx.getMetadataList('otherSfdx'), false);\n\tthis.logger('START -Salesforce- Retrieve Destination Org Metadata');\n\tthis.asyncCopadoLogMessage('START -Salesforce- Retrieve Destination Org Metadata');\n\tconst retrieve = `sf project retrieve start --target-org \"${destinationSessionid}\" --manifest ${TARGET_DIRECTORY}/${COPADO_RETRIEVE_XML} --ignore-conflicts --json || true`;\n\tchild_process.exec(retrieve, { stdio: STDIO.INHERIT, maxBuffer: MAXBUFFER }, (err, retrieveResult) => {\n\t\tthis.logger('END -Salesforce- Retrieve Destination Org Metadata');\n\t\tthis.asyncCopadoLogMessage('END -Salesforce- Retrieve Destination Org Metadata');\n\t\tretrieveResult = JSON.parse(retrieveResult.toString());\n\t\tif (retrieveResult.status && retrieveResult.message) {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.SFDX_CLI, '', retrieveResult.message);\n\t\t}\n\t\tfs.rmSync(`${TARGET_DIRECTORY}/${COPADO_RETRIEVE_XML}`);\n\t\tresolve({ sfdxRetrieveResult: retrieveResult });\n\t});\n}\n\nfunction retrieveFullProfile(commitChanges, resolve, reject) {\n\tthis.asyncCopadoLogMessage('START -Salesforce- Retrieving Full Profile');\n\n\tconst request = this.getMetadataReconcilerRequest();\n\n\trequest.accessToken = sourceSessionid;\n\trequest.instanceUrl = this.getInstanceUrl(sourceInstanceUrl);\n\trequest.profiles = commitChanges.Sfdx.profiles.map(profile => profile.n);\n\trequest.operation = Operation.FULL_PROFILE;\n\n\tnew Retriever().run(request)?.then(() => {\n\n\t\tconst profileResult = JSON.parse(fs.readFileSync(OUTPUT_JSON_FILE_PATH, 'utf-8'));\n\t\tthis.logger(profileResult);\n\t\tfs.rmSync('sfpowerkit-cache.db', {\n\t\t\tforce: true\n\t\t});\n\t\tresolve({ sfPowerKitRetrieveResult: profileResult });\n\n\t}).catch(error => {\n\t\tconst errorMessage = error.message || error?.toString() || 'Unknown Error occurred';\n\t\tthis.populateResultViewer(\n\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\tRESULT_INFO.CATEGORY.SF_POWER_KIT,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.SF_POWERKIT_FULL_PROFILE,\n\t\t\terrorMessage\n\t\t);\n\t\treject(\n\t\t\tnew CommandExecutionError(errorMessage, RESULT_INFO.CATEGORY.SF_POWER_KIT, RESULT_INFO.ADDITIONAL_INFORMATION.SF_POWERKIT_FULL_PROFILE)\n\t\t);\n\t});\n}\n\nfunction setup(rollBackBranchName) {\n\tconst { destinationInstanceUrl } = process.env;\n\tthis.checkSFDXProjectJson(rollBackBranchName, sourceApiVersion);\n\tthis.configureSFDXCLI(sourceApiVersion, destinationInstanceUrl);\n}\n\nfunction checkSFDXProjectJson(branchName, sourceApiVersion) {\n\tconst sfdxProjectJsonPath = `${TARGET_DIRECTORY}/sfdx-project.json`;\n\tif (fs.existsSync(sfdxProjectJsonPath)) {\n\t\tlet fileContent = this.readFromPath(sfdxProjectJsonPath);\n\t\tif (fileContent.sourceApiVersion !== sourceApiVersion) {\n\t\t\tconst commitMessage = `Updated sourceApiVersion from ${fileContent.sourceApiVersion} to ${sourceApiVersion} in sfdx-project.json to align the commit, promote and deploy operations with the latest supported api version of Copado`;\n\t\t\tfileContent.sourceApiVersion = sourceApiVersion;\n\t\t\tfs.writeFileSync(sfdxProjectJsonPath, JSON.stringify(fileContent, null, 2));\n\t\t\tthis.gitCommit(commitMessage, branchName, ['sfdx-project.json']);\n\t\t}\n\t} else {\n\t\tthrow new Error(\n\t\t\t`Invalid configuration in ${branchName}. sfdx-project.json is invalid or missing at project root. Copado Commit and Deploy operations are required to run from within a valid sfdx project.`\n\t\t);\n\t}\n}\n\nfunction executeCommandinChunks(fileList, chunkSize, cmd) {\n\tif (fileList.length > 0) {\n\t\tlet fileIndex = 0;\n\t\tdo {\n\t\t\tlet endIndex = fileIndex + parseInt(chunkSize) > fileList.length ? fileList.length : fileIndex + parseInt(chunkSize);\n\t\t\tlet fileChunk = fileList.slice(fileIndex, endIndex);\n\t\t\tthis.executeCommand(\n\t\t\t\tcmd.replace(/REPLACE_VALUE/g, fileChunk.map(file => `'${file}'`).join(' ')),\n\t\t\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_ADD, true\n\t\t\t);\n\t\t\tfileIndex = endIndex;\n\t\t} while (fileIndex < fileList.length);\n\t}\n}\n\nfunction gitCommit(commitMessage, branchName, filePaths, allowCommitWithNoChanges) {\n\tthis.logger(`Committing ${commitMessage} in ${branchName}`);\n\tthis.executeCommand('rm -f .git/index.lock', RESULT_INFO.CATEGORY.FILE_SYSTEM, RESULT_INFO.ADDITIONAL_INFORMATION.FILE_SYSTEM);\n\tthis.executeCommandinChunks(filePaths, 10, 'git add -f REPLACE_VALUE');\n\tconst gitCommit = `git commit -m \"${commitMessage}\" || ${allowCommitWithNoChanges ? 'true' : 'exit 1'}`;\n\tthis.executeCommand(gitCommit, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_COMMIT);\n}\n\nfunction configureSFDXCLI(sourceApiVersion, destinationInstanceUrl) {\n\tconst baseUrl = this.getInstanceUrl(destinationInstanceUrl);\n\tconst configSet = `\n        sf config set org-instance-url=${baseUrl} || exit 1\n        sf config set org-api-version=${sourceApiVersion} || exit 1\n    `;\n\tthis.executeCommand(configSet, RESULT_INFO.CATEGORY.SFDX_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.SFDX_CONFIG);\n}\n\n// SCRIPT FUNCTIONS\n\nfunction checkChangesWrtCategory(sfdxFilePath) {\n\tisSfMetadataPresent = fs.existsSync(sfdxFilePath);\n\n\tif (isSfMetadataPresent) {\n\t\tthis.logger('Salesforce changes found.');\n\t} else {\n\t\tthis.logger('Salesforce changes not found.');\n\t\tthis.asyncCopadoLogMessage('No Salesforce Metadata');\n\t}\n\n\tif (vlocityChangesPresent) {\n\t\tthis.logger('Vlocity changes found.');\n\t} else {\n\t\tthis.logger('Vlocity changes not found.');\n\t}\n\n\tif (vlocityChangesPresent && !isSfMetadataPresent) {\n\t\tprocess.exit(0);\n\t}\n}\n\nfunction prepareChanges(filePath) {\n\tlet changes = {};\n\tchanges.all = this.readFromPath(filePath);\n\tchanges = {\n\t\t...changes,\n\t\tadd: changes.all.filter(\n\t\t\tselectedMetadata =>\n\t\t\t\t[ACTIONS.ADD, ACTIONS.SELECTIVE_COMMIT].includes(selectedMetadata.a.toLowerCase()) ||\n\t\t\t\t(selectedMetadata.a.toLowerCase() == ACTIONS.FULL && selectedMetadata.t.toLowerCase() != TYPES.PROFILE)\n\t\t),\n\t\tdelete: changes.all.filter(selectedMetadata => selectedMetadata.a.toLowerCase() == ACTIONS.DELETE),\n\t\tprofiles: changes.all.filter(\n\t\t\tselectedMetadata => selectedMetadata.a.toLowerCase() == ACTIONS.FULL && selectedMetadata.t.toLowerCase() == TYPES.PROFILE\n\t\t),\n\t\tgetSFMetadataList(type) {\n\t\t\treturn this[type].reduce((metadatas, metadata) => {\n\t\t\t\tif (metadata.j) {\n\t\t\t\t\tconst metadataInformation = JSON.parse(metadata.j);\n\t\t\t\t\tif (metadataInformation.isSfMetadata) {\n\t\t\t\t\t\treturn getMetadataTypeAndName(metadatas, metadata);\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn metadatas;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\treturn getMetadataTypeAndName(metadatas, metadata);\n\t\t\t\t}\n\t\t\t}, '');\n\t\t}\n\t};\n\tif (changes?.profiles?.length) {\n\t\tchanges.fullProfiles = changes?.profiles?.map(profile => profile.n);\n\t}\n\treturn changes;\n}\n\nfunction fetchPromotionBranch(promotion, gitDepth) {\n\tthis.logger('START Fetching promotion branch');\n\tfs.mkdirSync(TARGET_DIRECTORY, { recursive: true });\n\tprocess.chdir(TARGET_DIRECTORY);\n\tthis.asyncCopadoLogMessage(`Fetching ${promotion}`);\n\tthis.executeCommand(\n\t\t`\n        copado-git-get \"${promotion}\" --depth \"${gitDepth}\" || exit 1\n    `,\n\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.PROMOTION_BRANCH_CHECKOUT\n\t);\n\tthis.logger('END Fetching promotion branch');\n}\n\nfunction configureGit(gitEmail, gitName) {\n\tconst configureGit = `\n    git config --local user.email \"${gitEmail}\" || exit 1\n    git config --local user.name \"${gitName}\" || exit 1\n    git config --global diff.renames false || exit 1\n    git config --global merge.renames false || exit 1\n    git config --global status.renames false || exit 1\n    git config --global core.quotePath false || exit 1\n    `;\n\tthis.executeCommand(`${configureGit}`, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CONFIG);\n}\n\nfunction validateSFDXProjectJson(sfdxProjectJsonPath) {\n\tif (!fs.existsSync(sfdxProjectJsonPath)) {\n\t\tthrow new Error(\n\t\t\t'Invalid configuration. sfdx-project.json is invalid or missing at project root. Copado Commit and Deploy operations are required to run from within a valid sfdx project.'\n\t\t);\n\t}\n}\n\nfunction updateSourceApiVersion(sfdxProjectJsonPath, sourceApiVersion) {\n\tlet fileContent = this.readFromPath(sfdxProjectJsonPath);\n\tif (fileContent.sourceApiVersion !== sourceApiVersion) {\n\t\tconst commitMessage = `Updated sourceApiVersion from ${fileContent.sourceApiVersion} to ${sourceApiVersion} in sfdx-project.json to align the commit, promote and deploy operations with the latest supported api version of Copado`;\n\t\tfileContent.sourceApiVersion = sourceApiVersion;\n\t\tfs.writeFileSync(sfdxProjectJsonPath, JSON.stringify(fileContent, null, 2));\n\t\tthis.commitGit(commitMessage);\n\t}\n}\n\nfunction enrichChangeList(changeListPath) {\n\tthis.asyncCopadoLogMessage('Processing metadata');\n\tthis.executeCommand(\n\t\t`\nenricher -p ${changeListPath} --repo ${TARGET_DIRECTORY}/ || exit 1`,\n\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.ENRICHER_SERVICE\n\t);\n}\n\nfunction processMetadata(changes, changeListPath) {\n\tthis.logger('START Metadata processor');\n\tthis.executeCommand(\n\t\t`\nmetadata-processor \"${changeListPath}\" \"${TARGET_DIRECTORY}\" -o TRIM --enrich || exit 1`,\n\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.METADATA_PROCESSOR\n\t);\n\n\tconst parentMetadataFile = this.getParentMetadataFile(changeListPath);\n\tif (fs.existsSync(parentMetadataFile)) {\n\t\tthis.addParentMetadataToOriginalChangeList(changes, this.readFromPath(parentMetadataFile));\n\t}\n\tthis.logger('END Metadata processor');\n}\n\nfunction addParentMetadataToOriginalChangeList(changes, parentMetadataList) {\n\tif (parentMetadataList?.length) {\n\t\tchanges.add = changes.add.concat(parentMetadataList.filter(change => change.a.toLowerCase() == ACTIONS.ADD));\n\t}\n}\n\nfunction getParentMetadataFile(filePath) {\n\tconst index = filePath.lastIndexOf('/');\n\tconst directory = filePath.substring(0, index + 1);\n\n\treturn directory + 'internal_' + filePath.substring(index + 1);\n}\n\nfunction varReplace(environmentVariables, filesToInclude) {\n\tif (environmentVariables && JSON.parse(environmentVariables)?.length) {\n\t\tthis.logger('START varReplace');\n\t\tconst command = `varreplace '${environmentVariables}' '${TARGET_DIRECTORY}' ${filesToInclude ? '--valuename=true --include=' + `${filesToInclude}` : ''\n\t\t\t} || exit 1`;\n\t\tthis.asyncCopadoLogMessage('Replacing environment variables');\n\t\tthis.executeCommand(command, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.ENV_VARIABLE_REPLACEMENT);\n\t\tthis.logger('END varReplace');\n\t}\n}\n\nfunction yamlFindAndReplace(changes, findAndReplaceRules, branch, filesToInclude) {\n\tthis.logger('START Yaml Replace');\n\tif ((changes.add?.length > 0 || changes.profiles?.length > 0) && findAndReplaceRules) {\n\t\tthis.asyncCopadoLogMessage('Applying global find and replace rules');\n\t\tthis.executeCommand(\n\t\t\t`\n        copado --downloadfiles \"${findAndReplaceRules}\" --downloaddir ${TEMP_DIRECTORY}/ || exit 1\n\n        # YAML Replace service called, Target Dir:  \"/tmp/Copado\", Path to YML: \"/app/repository/\"\n        yamlreplace \"${TEMP_DIRECTORY}/Copado\" \"${TARGET_DIRECTORY}\" -b \"${branch}\" ${filesToInclude ? ' --include=' + `${filesToInclude}` : ''\n\t\t\t} || exit 1\n    `,\n\t\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GLOBAL_FIND_AND_REPLACE\n\t\t);\n\t}\n\tthis.logger('END Yaml Replace');\n}\n\nfunction executeSFDXDeployCmd(command) {\n\treturn this.executeCommand(command, RESULT_INFO.CATEGORY.SFDX_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.SFDX_DEPLOYMENT, true, true);\n}\n\n// Create SFDX Deploy command w.r.t. to flags\nasync function getSFDXDeployCmd(isDestructiveChangesPresent, isValidation) {\n\tconst { testLevel, isProductionEnvironment } = process.env;\n\tlet sfdxDeployCommand = 'sf project deploy start --ignore-conflicts --json --async';\n\n\tif (isValidation == 'true') {\n\t\tsfdxDeployCommand += ' --dry-run';\n\t}\n\tsfdxDeployCommand += ` --target-org ${destinationSessionid}`;\n\n\tsfdxDeployCommand += await this.getTestRunParam(testLevel, isProductionEnvironment);\n\n\tsfdxDeployCommand +=\n\t\t` --manifest ${COPADO_RETRIEVE_XML}` +\n\t\t(isDestructiveChangesPresent ? ` --post-destructive-changes ${COPADO_DESTRUCTIVE_XML} --ignore-warnings` : '');\n\tthis.logger(`Deploy command: ${sfdxDeployCommand}`);\n\treturn `${sfdxDeployCommand}`;\n}\n\nasync function getTestRunParam(testLevel, isProductionEnvironment) {\n\tlet testRunParam = '';\n\tif (testLevel) {\n\t\tconst testRun = testLevel?.split(' ')?.join('');\n\t\tif (testRun && !(testRun === TEST_LEVEL.NO_TEST_RUN && isProductionEnvironment === 'true')) {\n\t\t\ttestRunParam += ` --test-level ${testRun}`;\n\t\t\tif (testRun === TEST_LEVEL.RUN_SPECIFIED_TESTS) {\n\t\t\t\tconst { testSuiteAndTestClassFileVersionDetails } = process.env;\n\t\t\t\tconst contentVersionIdsOfTestClassesAndTestSuites = this.getContentVersionIdsOfTestClassesAndTestSuites(\n\t\t\t\t\ttestSuiteAndTestClassFileVersionDetails\n\t\t\t\t);\n\t\t\t\tconst apexTestClasses = await this.getDeploymentTestClasses(contentVersionIdsOfTestClassesAndTestSuites);\n\t\t\t\ttestRunParam = testRunParam + ' --tests ' + apexTestClasses;\n\t\t\t}\n\t\t}\n\t}\n\treturn testRunParam;\n}\n\nasync function getDeploymentTestClasses(contentVersionIdsOfTestClassesAndTestSuites) {\n\tthis.asyncCopadoLogMessage(`Finding test classes for ${isValidation === 'true' ? 'validation' : 'deployment'}`);\n\tconst commands = [];\n\tcontentVersionIdsOfTestClassesAndTestSuites.forEach(contentVersionId => {\n\t\tconst command = {};\n\t\tcommand.value = `\n\t\t\t  mkdir -p ${TEMP_DIRECTORY}/${contentVersionId}\n\t\t\t  copado --downloadfiles \"${contentVersionId}\" --downloaddir ${TEMP_DIRECTORY}/${contentVersionId}\n\t\t  `;\n\t\tcommands.push(command);\n\t});\n\n\tconst totalCpus = cpus().length;\n\tconst parallelCommandExecutor = new this.ParallelCommandExecutor(commands, totalCpus == 1 ? 1 : totalCpus - 1);\n\tthis.startWatch(RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILES, processes);\n\tawait Promise.all(parallelCommandExecutor.startExecution());\n\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILES, processes);\n\n\tlet testClasses = new Set();\n\tthis.startWatch(RESULT_INFO.CATEGORY.FILE_SYSTEM, RESULT_INFO.ADDITIONAL_INFORMATION.FINDING_TEST_CLASSES, processes);\n\tconst testSuitesAndTestClassesFileContent = await Promise.all(\n\t\tthis.getPromisesToReadTestSuitesAndTestClassesFile(contentVersionIdsOfTestClassesAndTestSuites)\n\t);\n\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.FINDING_TEST_CLASSES, processes);\n\ttestSuitesAndTestClassesFileContent.forEach(fileContent => {\n\t\ttestClasses = new Set([...testClasses, ...this.getSelectedTestClasses(fileContent)]);\n\t});\n\n\tif (!testClasses.size) {\n\t\tthrow new Error('No test classes were selected by the user');\n\t}\n\treturn [...testClasses].join(' ');\n}\n\nfunction uploadDeploymentResultOnJobStep(isValidation) {\n\tconst deployResultDir = this.getDeploymentResultFile(isValidation);\n\tif (fs.existsSync(deployResultDir)) {\n\t\tconst uploadFile = `copado --uploadfile ${deployResultDir}`;\n\t\tthis.executeCommand(uploadFile, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES);\n\t} else {\n\t\tthis.logger(`Could not find ${deployResultDir} `);\n\t}\n}\n\nfunction createDeploymentResultFile(deployResult, isValidation) {\n\tconst deployResultDir = this.getDeploymentResultFile(isValidation);\n\n\tfs.writeFileSync(deployResultDir, JSON.stringify(deployResult, null, 2));\n\tthis.uploadDeploymentResultOnJobStep(isValidation);\n}\n\nfunction getDeploymentResultFile(isValidation) {\n\treturn `${TEMP_DIRECTORY}/${isValidation === 'true' ? 'Validation' : 'Deployment'}Result.json`;\n}\n\nfunction handleDeployResult(deployResult, isValidation) {\n\tthis.createDeploymentResultFile(deployResult, isValidation);\n\n\tlet errorResponse = '';\n\tconst details = deployResult?.result?.details,\n\t\tcomponentFailures = details?.componentFailures,\n\t\tcomponentSuccesses = details?.componentSuccesses,\n\t\tfailures = details?.runTestResult?.failures,\n\t\tcodeCoverageWarnings = details?.runTestResult?.codeCoverageWarnings,\n\t\tflowCoverageWarnings = details?.runTestResult?.flowCoverageWarnings;\n\n\t// If any errors or warning, display to progress indicator and fail the job execution\n\tif (deployResult?.status) {\n\t\tif (deployResult?.message) {\n\t\t\terrorResponse = `${deployResult?.message}`;\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.METADATA_EXECUTION, '', errorResponse);\n\t\t} else if (deployResult?.result?.errorMessage) {\n\t\t\terrorResponse = `${deployResult?.result?.errorMessage}`;\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.METADATA_EXECUTION, '', errorResponse);\n\t\t} else if (deployResult?.result?.status == DEPLOYMENT_STATUS.CANCELED) {\n\t\t\terrorResponse = `The ${isValidation === 'true' ? 'validation' : 'deployment'} was cancelled on the target org.`;\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.METADATA_EXECUTION, '', errorResponse);\n\t\t}\n\t}\n\n\t// apex test failures\n\tif (failures) {\n\t\tconst failureMessage = this.getFailedTestsErrorMessage(failures);\n\t\tthis.populateResultViewer(\n\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\tRESULT_INFO.CATEGORY.APEX_TEST_RUN,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.APEX_TEST_FAILURE,\n\t\t\tfailureMessage\n\t\t);\n\t\terrorResponse = this.populateErrorResponse(failureMessage, errorResponse);\n\t}\n\n\t// code coverage errors\n\tif (codeCoverageWarnings) {\n\t\tconst failureMessage = this.getFailedTestsErrorMessage(codeCoverageWarnings);\n\t\tthis.populateResultViewer(\n\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\tRESULT_INFO.CATEGORY.APEX_TEST_RUN,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.CODE_COVERAGE_ERROR,\n\t\t\tfailureMessage\n\t\t);\n\t\terrorResponse = this.populateErrorResponse(failureMessage, errorResponse);\n\t}\n\n\t// flow coverage errors\n\tif (flowCoverageWarnings) {\n\t\tconst failureMessage = this.getFailedTestsErrorMessage(flowCoverageWarnings);\n\t\tthis.populateResultViewer(\n\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\tRESULT_INFO.CATEGORY.FLOW_TEST_RUN,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.FLOW_TEST_FAILURE,\n\t\t\tfailureMessage\n\t\t);\n\t\terrorResponse = this.populateErrorResponse(failureMessage, errorResponse);\n\t}\n\n\t// metadata component deployment failures\n\tif (componentFailures) {\n\t\tconst errorMetadata = this.filterFailedMedataByProblemType(componentFailures, 'Error');\n\t\tif (errorMetadata.length) {\n\t\t\tconst failureMessage = this.getFailedComponentsErrorMessage(errorMetadata);\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.METADATA_EXECUTION, '', failureMessage);\n\t\t\terrorResponse = this.populateErrorResponse(failureMessage, errorResponse);\n\t\t}\n\t}\n\n\t// deployment warnings\n\tif (componentSuccesses?.length) {\n\t\tconst warningMetadata = this.filterFailedMedataByProblemType(componentSuccesses, 'Warning');\n\t\tif (warningMetadata?.length) {\n\t\t\tconst message = `WARNING Deploying Metadata: ${this.getFailedComponentsErrorMessage(warningMetadata)}`;\n\t\t\tthis.asyncCopadoLogMessage(message.substring(0, 254), RESULT_INFO.LEVEL.WARN);\n\t\t\tthis.logger(message);\n\t\t}\n\t}\n\n\tif (errorResponse) {\n\t\tthrow new CommandExecutionError(errorResponse.substring(0, 131072), RESULT_INFO.CATEGORY.METADATA_EXECUTION, '');\n\t}\n\n\tif (!deployResult.status) {\n\t\tthis.populateResultViewer(\n\t\t\tRESULT_INFO.LEVEL.INFO,\n\t\t\tRESULT_INFO.CATEGORY.APEX_TEST_RUN,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.APEX_TEST_RUN_SUMMARY,\n\t\t\t`Total Tests : ${deployResult.result.numberTestsCompleted} | Completed Tests : ${deployResult.result.numberTestsTotal}`\n\t\t);\n\t\tconst message = componentSuccesses?.reduce((metadataInfo, component) => {\n\t\t\treturn component.componentType\n\t\t\t\t? metadataInfo\n\t\t\t\t\t? `${metadataInfo}, ${component.componentType} : ${component.fullName}`\n\t\t\t\t\t: `${component.componentType} : ${component.fullName}`\n\t\t\t\t: metadataInfo;\n\t\t}, '');\n\t\tthis.populateResultViewer(\n\t\t\tRESULT_INFO.LEVEL.INFO,\n\t\t\tRESULT_INFO.CATEGORY.METADATA_EXECUTION,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.CONSOLIDATED_RESULT,\n\t\t\tmessage\n\t\t);\n\t\tif (isValidation === 'true') {\n\t\t\tthis.populateValidationIdOnResultRecord(deployResult.result.id);\n\t\t}\n\t}\n}\n\nfunction filterFailedMedataByProblemType(failedComponents, problemType) {\n\tlet result = [];\n\tif (Array.isArray(failedComponents)) {\n\t\tresult = failedComponents.filter(component => component.problemType == problemType);\n\t} else if (failedComponents.problemType == problemType) {\n\t\tresult = [failedComponents];\n\t}\n\treturn result;\n}\n\nfunction getFailedComponentsErrorMessage(failedComponents) {\n\tlet result = '';\n\tif (Array.isArray(failedComponents)) {\n\t\tresult = failedComponents\n\t\t\t.map(failure => failure[CONSTANTS.COMPONENT_TYPE].concat(':', failure[CONSTANTS.FULL_NAME], ':', failure[CONSTANTS.PROBLEM]))\n\t\t\t.join('\\n');\n\t} else {\n\t\tresult = failedComponents[CONSTANTS.COMPONENT_TYPE]\n\t\t\t.concat(':', failedComponents[CONSTANTS.FULL_NAME], ':', failedComponents[CONSTANTS.PROBLEM])\n\t\t\t.toString();\n\t}\n\treturn result;\n}\n\nfunction getFailedTestsErrorMessage(failedTests) {\n\tlet result = '';\n\tif (Array.isArray(failedTests)) {\n\t\tlet failedTestsError = failedTests.map(failedTest => {\n\t\t\tlet error = '';\n\t\t\terror = failedTest.name ? (error ? error.concat('-', failedTest.name) : error.concat(failedTest.name)) : error;\n\t\t\terror = failedTest.methodName ? (error ? error.concat('-', failedTest.methodName) : error.concat(failedTest.methodName)) : error;\n\t\t\terror = error ? error.concat('-', failedTest.message) : error.concat(failedTest.message);\n\t\t\treturn error;\n\t\t});\n\t\tif (failedTestsError?.length) {\n\t\t\tresult = failedTestsError.join('\\n');\n\t\t}\n\t} else {\n\t\tif (typeof failedTests.name != 'object') {\n\t\t\tresult = result.concat(`${failedTests.name}`);\n\t\t}\n\t\tresult = failedTests.methodName ? (result ? result.concat('-', failedTests.methodName) : result.concat(failedTests.methodName)) : result;\n\t\tresult = result ? result.concat('-', failedTests.message) : result.concat(failedTests.message);\n\t}\n\treturn result;\n}\n\nfunction populateErrorResponse(errorMessage, errorResponse) {\n\tconst delimiter = '\\n';\n\terrorResponse = (errorResponse && errorResponse?.trim().concat(`${delimiter}`, errorMessage.trim())) || errorResponse.concat(errorMessage.trim());\n\treturn errorResponse;\n}\n\nfunction cleanDeploymentFiles() {\n\tconst cleanUp = `\n    git reset --hard\n    rm -rf ${COPADO_RETRIEVE_XML} ${COPADO_DESTRUCTIVE_XML}\n`;\n\treturn new Promise((resolve, reject) => {\n\t\tchild_process.exec(cleanUp, this.getOptions(), (error, stdout, stderr) => {\n\t\t\tthis.handleResponse(error, stdout, stderr, reject);\n\t\t\tresolve();\n\t\t});\n\t});\n}\n\nfunction gitMergePromotionToTarget(promotion, targetBranch, gitDepth) {\n\tthis.logger('START Merging promotion branch to target branch');\n\tthis.asyncCopadoLogMessage(`Checking out ${promotion} branch`);\n\tlet checkoutTargetBranch = `\n        git reset --hard || exit 1\n\t\tgit clean -fd\n        ${this.fetchCheckoutBranch(targetBranch, gitDepth, false)}\n    `;\n\n\tthis.executeCommand(checkoutTargetBranch, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.TARGET_BRANCH_CHECKOUT);\n\t// Add git rollBack logic here\n\ttry {\n\t\tconst merge = `git merge \"${promotion}\" --no-commit -Xignore-space-change`;\n\t\tthis.executeCommand(merge, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_MERGE);\n\t} catch (error) {\n\t\tthis.evaluateMergeStatus();\n\t\tthrow error;\n\t}\n\tthis.commitGit(`Merging ${promotion} into ${targetBranch} after auto conflict resolution`);\n\tthis.logger('END Merging promotion branch to target branch');\n}\n\nfunction commitGit(commitMessage) {\n\tthis.executeCommand(\n\t\t`           \n    git add . || exit 1 # add all the resolved changes, if any\n    git commit -am \"${commitMessage}\" || true`,\n\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_COMMIT\n\t);\n}\n\nfunction evaluateMergeStatus() {\n\tconst gitStatus = this.executeCommand('git status --porcelain=v1 -uno', RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS),\n\t\tporcelainStatus = gitStatus.split('\\n').map(str => str.split(' ')?.[0]),\n\t\tisConflict = porcelainStatus.length ? ['AA', 'UU', 'DD', 'UA', 'UD', 'DU', 'AU'].some(s => porcelainStatus.includes(s)) : false;\n\tlet infoMessage;\n\n\tif (isConflict) {\n\t\tthrow new Error(\n\t\t\t`Changes detected in target branch '${targetBranch}' after promotion branch '${promotion}' was created, please recreate promotion branch out of the new target branch state.`\n\t\t);\n\t} else if (!gitStatus) {\n\t\tinfoMessage = 'Already up to date';\n\t} else {\n\t\tinfoMessage = `Changes detected in target branch '${targetBranch}' after promotion branch '${promotion}' was created.`;\n\t}\n\tinfoMessage && this.asyncCopadoLogMessage(infoMessage);\n\tthis.logger(infoMessage);\n}\n\nasync function reconcileFullProfile(changes, request) {\n\tthis.asyncCopadoLogMessage('Reconciling full profile');\n\tthis.startWatch(RESULT_INFO.CATEGORY.METADATA_RECONCILER, RESULT_INFO.ADDITIONAL_INFORMATION.FULL_PROFILE_RECONCILIATION, processes);\n\n\trequest.instanceUrl = this.getInstanceUrl(destinationInstanceUrl);\n\trequest.accessToken = destinationSessionid;\n\trequest.profiles = changes?.fullProfiles;\n\trequest.operation = Operation.RECONCILE_PROFILE;\n\n\tawait new Reconciler().run(request);\n\n\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.FULL_PROFILE_RECONCILIATION, processes);\n\n\tconst reconciledProfileOutput = this.readFromPath(OUTPUT_JSON_FILE_PATH);\n\n\tif (!reconciledProfileOutput) {\n\t\tthrow new Error('Error reconciling full profile');\n\t}\n\tthis.evaluateResponse(reconciledProfileOutput);\n}\n\nfunction pushChangesToRemote(remoteBranchName) {\n\tthis.asyncCopadoLogMessage(`Pushing changes to ${remoteBranchName}`);\n\tconst push = `git push origin \"${remoteBranchName}\"`;\n\tconst deploymentSuccessMessage =\n\t\t'Important Information: Be aware that the contents of your deployment were successfully deployed to the target org and have not been removed based on this error';\n\treturn new Promise((resolve, reject) => {\n\t\tchild_process.exec(push, this.getOptions(), (error, stdout, stderr) => {\n\t\t\tthis.handleResponse(error, stdout, stderr, reject, deploymentSuccessMessage);\n\t\t\tresolve();\n\t\t});\n\t});\n}\n\nfunction createDebugPromotionBranch(debugBranch) {\n\tthis.logger('START Creating Debug Promotion Branch');\n\tthis.asyncCopadoLogMessage(`Creating Debug branch ${debugBranch}`);\n\tconst deleteCheckoutDebugBranch = `\ngit branch -D ${debugBranch} || true\ngit checkout -b ${debugBranch} || exit 1`;\n\n\tthis.executeCommand(deleteCheckoutDebugBranch, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.DEBUG_BRANCH_CHECKOUT);\n\tthis.logger('END Creating Debug Promotion Branch');\n}\n\nfunction pushDebugPromotionBranch(debugBranch) {\n\tthis.logger('START Pushing Debug Promotion Branch');\n\tthis.asyncCopadoLogMessage(`Pushing changes to ${debugBranch}`);\n\tthis.commitGit(`Copado Debug Branch Commit for Promotion ${debugBranch}`);\n\tthis.executeCommand(`git push -f origin  \"${debugBranch}\" || exit 1`, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_PUSH);\n\tthis.logger('END Pushing Debug Promotion Branch');\n}\n\nfunction setInstanceUrl(instanceUrl) {\n\tconst baseUrl = this.getInstanceUrl(instanceUrl);\n\tthis.executeCommand(\n\t\t`\n# Set instance URL within sfdx-config.json\nsf config set org-instance-url=${baseUrl} || exit 1`,\n\t\tRESULT_INFO.CATEGORY.SFDX_CLI,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.SFDX_CONFIG\n\t);\n}\n\nfunction getErrorCmdString(error) {\n\tconst suffix = 'Please check the logs for details.';\n\tconst errorMessage = JSON.stringify(error.trim()?.substring(0, 32760) + '; ' + suffix);\n\treturn `copado -p \"Error\" -e ${errorMessage}`;\n}\n\nfunction populateValidationIdOnResultRecord(validationId) {\n\tthis.populateResultViewer(\n\t\tRESULT_INFO.LEVEL.INFO,\n\t\tRESULT_INFO.CATEGORY.METADATA_EXECUTION,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.METADATA_VALIDATION_SUCCESSFUL,\n\t\t`Validation Id : ${validationId}`\n\t);\n\tthis.executeCommand(`copado -p \"Saving validation id\" -r '${JSON.stringify({ validationId })}' && exit 0`, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_SERVICE);\n}\n\nasync function executeQuickDeploy(validationId, isValidation) {\n\tthis.logger('START -Salesforce- Quick Deploy');\n\tlet doDeployment = true;\n\tthis.asyncCopadoLogMessage('START -Salesforce- Quick Deploy');\n\tthis.startWatch(RESULT_INFO.CATEGORY.METADATA_EXECUTION, RESULT_INFO.ADDITIONAL_INFORMATION.QUICK_DEPLOYMENT, processes);\n\tconst deployResult = await this.executeCommandAsync(\n\t\t`sf project deploy quick --json --job-id ${validationId} --target-org ${destinationSessionid}`,\n\t\tRESULT_INFO.CATEGORY.METADATA_EXECUTION,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.QUICK_DEPLOYMENT,\n\t\ttrue,\n\t\ttrue\n\t);\n\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.QUICK_DEPLOYMENT, processes);\n\tthis.createDeploymentResultFile(deployResult, isValidation);\n\t// Here we are checking whether quick deploy was successful or not, status 0 means success and other status means failure\n\tif (deployResult.status) {\n\t\tthis.asyncCopadoLogMessage(deployResult.message?.substring(0, 254));\n\t} else {\n\t\tthis.asyncCopadoLogMessage('END -Salesforce- Quick Deploy done successfully');\n\t\tdoDeployment = false;\n\t}\n\tthis.logger('END -Salesforce- Quick Deploy');\n\treturn { doDeployment, deployResult };\n}\n\nfunction readFromPath(filePath) {\n\tif (!fs.existsSync(filePath)) {\n\t\tthrow new Error(`Could not find file at path: ${filePath}`);\n\t}\n\tconst data = fs.readFileSync(filePath, 'utf-8');\n\tlet result;\n\ttry {\n\t\tresult = JSON.parse(data);\n\t} catch (err) {\n\t\tthrow new Error(`Content at ${filePath} is not a valid JSON`);\n\t}\n\treturn result;\n}\n\nfunction executeCommand(command, category, additionalInfo, disableMetrics, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\n\tif (!disableMetrics) {\n\t\tthis.startWatch(category, additionalInfo, processes);\n\t}\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.log(response, disableLogs);\n\tthis.endWatch(additionalInfo, processes);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\tif (!disableMetrics) {\n\t\t\t\tthis.endWatch(additionalInfo, processes);\n\t\t\t}\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n\t\tconst truncatedError = JSON.stringify(\n\t\t\terrorMessage\n\t\t\t\t.split('\\n')\n\t\t\t\t.filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n\t\t\t\t.join(' ')\n\t\t);\n\t\tthrow new CommandExecutionError(truncatedError, category, additionalInfo);\n\t}\n}\nfunction getMetadataReconcilerRequest() {\n\tconst request = new CopaReconcilerInput();\n\trequest.repositoryPath = TARGET_DIRECTORY;\n\trequest.jsonOutputPath = TEMP_DIRECTORY;\n\treturn request;\n}\n\nasync function processFullProfiles(changes, mergeProfile) {\n\tthis.logger('START reconcile full profiles');\n\tif (changes?.profiles?.length) {\n\t\tconst request = this.getMetadataReconcilerRequest();\n\t\tawait this.reconcileFullProfile(changes, request);\n\t\tif (mergeProfile === 'true') {\n\t\t\tawait this.mergeFullProfile(changes, request);\n\t\t}\n\t\tfs.rmSync('sfpowerkit-cache.db', {\n\t\t\tforce: true\n\t\t});\n\t\tthis.commitGit(`Cleaned full profile in promotion ${promotion}`);\n\t}\n\tthis.logger('END reconcile full profiles');\n}\n\nasync function mergeFullProfile(changes, request) {\n\tconst metadataItems = this.findMergeableMetadataInScope(changes);\n\tif (metadataItems?.length) {\n\t\tthis.asyncCopadoLogMessage('Merging selected metadata permissions to the profile');\n\t\tthis.startWatch(RESULT_INFO.CATEGORY.METADATA_RECONCILER, RESULT_INFO.ADDITIONAL_INFORMATION.FULL_PROFILE_MERGE, processes);\n\n\t\trequest.instanceUrl = this.getInstanceUrl(sourceInstanceUrl);\n\t\trequest.accessToken = sourceSessionid;\n\t\trequest.metadatas = metadataItems;\n\t\trequest.profiles = changes?.fullProfiles;\n\t\trequest.operation = Operation.MERGE_PROFILE;\n\n\t\tawait new Merger().run(request);\n\n\t\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.FULL_PROFILE_MERGE, processes);\n\n\t\tconst mergedFullProfileResponse = this.readFromPath(OUTPUT_JSON_FILE_PATH);\n\t\tif (!mergedFullProfileResponse) {\n\t\t\tthrow new Error('Error merging permissions to full profile');\n\t\t}\n\t\tthis.evaluateResponse(mergedFullProfileResponse);\n\t}\n}\n\nfunction findMergeableMetadataInScope(changes) {\n\tconst metadataItems = [];\n\tchanges?.add?.forEach(change => {\n\t\tif (METADATA_FOR_MERGE_IN_PROFILE.includes(change?.t?.toLowerCase())) {\n\t\t\tmetadataItems.push(`${change?.t}:${change?.n}`);\n\t\t}\n\t});\n\treturn metadataItems;\n}\n\nfunction evaluateResponse(response) {\n\tif (response?.status && response?.message) {\n\t\tthrow new Error(`${response.commandName + ': ' + response.message}`);\n\t}\n}\n\nfunction getApiVersion(overriddenApiVersion, apiVersion) {\n\tconst finalApiVersion = overriddenApiVersion || apiVersion;\n\tconst regExpApiVersion = /\\d\\d\\.0/;\n\tif (!regExpApiVersion.test(finalApiVersion)) {\n\t\tthrow new Error(`Invalid API Version: ${finalApiVersion}`);\n\t}\n\treturn finalApiVersion;\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction getMetadataTypeAndName(metadatas, metadata) {\n\treturn metadatas ? `${metadatas},${metadata.t}:${metadata.n}` : `${metadata.t}:${metadata.n}`;\n}\n\nfunction analyzeMetadata(changeListPath, outputFile) {\n\tthis.logger('START metadata analyzer');\n\tthis.executeCommand(\n\t\t`metadata-analyzer --changefile '${changeListPath}' --out '${outputFile}' || exit 1`,\n\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.METADATA_ANALYZER\n\t);\n\tthis.logger('END metadata analyzer');\n}\n\nfunction createManifest(changes) {\n\tconst ADD_MANIFEST = changes.getSFMetadataList('add');\n\tconst PROFILE_MANIFEST = changes.getSFMetadataList('profiles');\n\tconst DELETE_MANIFEST = changes.getSFMetadataList('delete');\n\tlet result = { isSuccess: false, isDestructiveChangesPresent: false };\n\n\tlet manifest = '';\n\n\tif (ADD_MANIFEST) {\n\t\tmanifest = ADD_MANIFEST;\n\t}\n\n\tif (PROFILE_MANIFEST) {\n\t\tmanifest = manifest ? `${manifest},${PROFILE_MANIFEST}` : PROFILE_MANIFEST;\n\t}\n\n\tthis.buildManifest(manifest, false);\n\tresult.isSuccess = true;\n\n\tif (DELETE_MANIFEST) {\n\t\tthis.buildManifest(DELETE_MANIFEST, true);\n\t\tresult.isSuccess = true;\n\t\tresult.isDestructiveChangesPresent = true;\n\t}\n\n\treturn result;\n}\n\nfunction buildManifest(changesList, isDestructiveManifest) {\n\tconst manifestFileName = isDestructiveManifest ? `${TARGET_DIRECTORY}/${COPADO_DESTRUCTIVE_XML}` : `${TARGET_DIRECTORY}/${COPADO_RETRIEVE_XML}`;\n\t// Create Map\n\tlet metadataByType = new Map();\n\tchangesList.split(',').forEach(element => {\n\t\tconst metadataItem = element.split(':');\n\t\tif (!metadataByType.has(metadataItem[0])) {\n\t\t\tmetadataByType.set(metadataItem[0], []);\n\t\t}\n\t\tmetadataByType.get(metadataItem[0]).push(metadataItem[1]);\n\t});\n\n\t// Create manifest file\n\tlet manifest = [];\n\tmanifest.push('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\" ?>\\n');\n\tmanifest.push('<Package xmlns=\"http://soap.sforce.com/2006/04/metadata\">\\n');\n\tmetadataByType.forEach((value, key) => {\n\t\tif (value && key) {\n\t\t\tmanifest.push('\\t<types>\\n');\n\t\t\tvalue.forEach(item => {\n\t\t\t\tmanifest.push(`\\t\\t<members>${item}</members>\\n`);\n\t\t\t});\n\n\t\t\tmanifest.push(`\\t\\t<name>${key}</name>\\n`);\n\t\t\tmanifest.push('\\t</types>\\n');\n\t\t}\n\t});\n\n\tmanifest.push(`\\t<version>${sourceApiVersion}</version>\\n`);\n\tmanifest.push('</Package>\\n');\n\tfs.writeFileSync(manifestFileName, manifest.join(''));\n}\n\nasync function deploy(manifest, isValidation) {\n\tthis.logger('START -Salesforce- Deployment');\n\tlet deployResult;\n\tif (manifest.isSuccess) {\n\t\tthis.asyncCopadoLogMessage('START -Salesforce- Deploying Promotion Changes');\n\t\tconst deploymentRequest = this.executeCommand(\n\t\t\tawait this.getSFDXDeployCmd(manifest.isDestructiveChangesPresent, isValidation),\n\t\t\tRESULT_INFO.CATEGORY.METADATA_EXECUTION,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.METADATA_DEPLOYMENT_REQUEST,\n\t\t\tfalse,\n\t\t\ttrue,\n\t\t\ttrue\n\t\t);\n\t\tif (deploymentRequest?.status) {\n\t\t\tthrow new Error(`${deploymentRequest.commandName} : ${deploymentRequest.message}`);\n\t\t} else {\n\t\t\tthis.logger(`Deployment Request Id:  ${deploymentRequest?.result?.id}`);\n\t\t\tdeployResult = await this.checkDeploymentStatus(deploymentRequest?.result?.id, 0);\n\t\t\tthis.handleDeployResult(deployResult, isValidation);\n\t\t}\n\t\tthis.asyncCopadoLogMessage('END -Salesforce- Deploying Promotion Changes');\n\t}\n\tthis.logger('END -Salesforce- Deployment');\n\treturn deployResult;\n}\n\nasync function checkDeploymentStatus(jobId, numberOfRetries) {\n\tthis.startWatch(RESULT_INFO.CATEGORY.METADATA_EXECUTION, RESULT_INFO.ADDITIONAL_INFORMATION.POLL_STATUS, processes);\n\tlet response = await this.executeCommandAsync(\n\t\t`sf project deploy report --wait ${DEPLOY_REPORT_POLL_TIME} --job-id ${jobId} --json --target-org ${destinationSessionid} || true`,\n\t\tRESULT_INFO.CATEGORY.METADATA_EXECUTION,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.POLL_STATUS,\n\t\ttrue,\n\t\ttrue\n\t);\n\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.POLL_STATUS, processes);\n\tif (response?.status && (response?.message?.includes('ETIMEDOUT') || response?.message?.includes('Metadata API request failed'))) {\n\t\tif (numberOfRetries < NUMBER_OF_REPORT_RETRIALS) {\n\t\t\tthis.logger(`Fetching Deployment Report failed : ${response?.message}\n        Retrying Attempt ${++numberOfRetries}`);\n\t\t\treturn await this.checkDeploymentStatus(jobId, ++numberOfRetries);\n\t\t} else {\n\t\t\treturn response;\n\t\t}\n\t}\n\tif (response?.result?.status == DEPLOYMENT_STATUS.INPROGRESS || response?.result?.status == DEPLOYMENT_STATUS.PENDING) {\n\t\tnumberOfRetries = 0;\n\t\tif (response?.result?.status == DEPLOYMENT_STATUS.INPROGRESS) {\n\t\t\tthis.asyncCopadoLogMessage(response?.result?.stateDetail);\n\t\t}\n\t\treturn await this.checkDeploymentStatus(jobId, numberOfRetries);\n\t} else {\n\t\treturn response;\n\t}\n}\n\nfunction getGitDepth(gitDepth) {\n\tgitDepth = parseInt(gitDepth);\n\treturn gitDepth >= 0 ? gitDepth : 100;\n}\n\nfunction fetchCheckoutBranch(branch, gitDepth, forceCreate) {\n\treturn (\n\t\t`( git fetch origin ${branch} --depth ${gitDepth} && git checkout ${branch} )` +\n\t\t(forceCreate ? ` || git checkout -b ${branch}` : '') +\n\t\t' || exit 1'\n\t);\n}\n\nfunction handleResponse(error, stdout, stderr, reject, deploymentSuccessMessage) {\n\tif (stdout) {\n\t\tconsole.log(stdout);\n\t}\n\tif (stderr) {\n\t\tconsole.log(stderr);\n\t}\n\tif (error?.code) {\n\t\tconst errorResponse = stderr ? (deploymentSuccessMessage ? `${stderr} ${deploymentSuccessMessage}` : stderr) : `Error executing the command ${error.cmd}`;\n\t\tif (reject) {\n\t\t\treject(new Error(errorResponse));\n\t\t\treturn;\n\t\t}\n\t\tthrow new Error(errorResponse);\n\t}\n}\n\nfunction getOptions() {\n\tconst { maxBuffer } = process.env;\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(maxBuffer)\n\t};\n\treturn options;\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nfunction log(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tconsole.log(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tconsole.log(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n\tif (message) {\n\t\tresultViewerJson.push({\n\t\t\tLevel: level,\n\t\t\tCategory: category,\n\t\t\tAdditionalInformation: additionalInfo,\n\t\t\tMessage: message\n\t\t});\n\t}\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n\tconst RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n\tconst fileContent = { data, columns, header, headerIcon };\n\tfs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n\tthis.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n\tnew Promise((resolve, reject) => {\n\t\tchild_process.exec(`copado --uploadfile ${filePath}`, {}, err => {\n\t\t\tif (err) {\n\t\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.CATEGORY.UPLOAD_FILES, err);\n\t\t\t\treject(err);\n\t\t\t} else {\n\t\t\t\tresolve();\n\t\t\t}\n\t\t});\n\t});\n}\n\nfunction executeCommandAsync(command, category, additionalInfo, hasJsonResponse, disableLog) {\n\treturn new Promise((resolve, reject) => {\n\t\tlet output = '',\n\t\t\terror = '';\n\t\tconst childProcess = child_process.spawn(command, [], { shell: true });\n\n\t\tchildProcess.stdout.on('data', data => {\n\t\t\toutput += data?.toString();\n\t\t});\n\n\t\tchildProcess.stderr.on('data', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('close', code => {\n\t\t\tif (code !== 0) {\n\t\t\t\tlet errorMessage = '';\n\t\t\t\tif (hasJsonResponse) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tresolve(JSON.parse(output));\n\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\terrorMessage = error;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\terrorMessage = error;\n\t\t\t\t}\n\t\t\t\terrorMessage = errorMessage ? errorMessage : `Error executing the command ${command}`;\n\n\t\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n\t\t\t\tconst truncatedError = JSON.stringify(\n\t\t\t\t\terrorMessage\n\t\t\t\t\t\t.split('\\n')\n\t\t\t\t\t\t.filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n\t\t\t\t\t\t.join(' ')\n\t\t\t\t);\n\t\t\t\treject(new CommandExecutionError(truncatedError, category, additionalInfo));\n\t\t\t}\n\t\t\tif (!disableLog) {\n\t\t\t\tthis.logger(`code: ${code?.toString()}`);\n\t\t\t\tthis.logger(`stdout: ${output}`);\n\t\t\t\tthis.logger(`stderr: ${error}`);\n\t\t\t}\n\t\t\tresolve(hasJsonResponse ? JSON.parse(output) : output);\n\t\t});\n\n\t\tchildProcess.on('error', error => {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, error);\n\t\t\tconst truncatedError = JSON.stringify(\n\t\t\t\terror\n\t\t\t\t\t.split('\\n')\n\t\t\t\t\t.filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n\t\t\t\t\t.join(' ')\n\t\t\t);\n\t\t\treject(new CommandExecutionError(truncatedError, category, additionalInfo));\n\t\t});\n\t});\n}\n\nfunction startWatch(processType, processName, processes) {\n\tif (!processName || !processType) {\n\t\treturn;\n\t}\n\tconst startTime = process.hrtime();\n\tif (!totalTimeByType[processType]) {\n\t\ttotalTimeByType[processType] = 0;\n\t}\n\tprocesses.push({ name: processName, type: processType, startTime, endTime: null, elapsedTime: null });\n}\n\nfunction endWatch(processType, processes) {\n\tif (!processType) {\n\t\treturn;\n\t}\n\tconst processIndex = processes.length;\n\tif (!processIndex && processes[processIndex - 1].type !== processType) {\n\t\tconsole.error(`Process '${processType}' not started.`);\n\t\treturn;\n\t}\n\tconst endTime = process.hrtime();\n\tconst elapsedTime = process.hrtime(processes[processIndex - 1].startTime);\n\tprocesses[processIndex - 1].endTime = endTime;\n\tprocesses[processIndex - 1].elapsedTime = elapsedTime[0] * 1e9 + elapsedTime[1];\n}\n\nfunction printMetrics() {\n\tlet ux = new Ux();\n\tthis.logger('\\n');\n\tux.styledHeader('   ====================      OVERALL METRICS      ====================   ');\n\tconst resultData = [];\n\tprocesses.forEach(process => {\n\t\t// store data\n\t\tresultData.push({\n\t\t\tprocessType: '| ' + process.type,\n\t\t\tprocessName: '| ' + process.name,\n\t\t\t'startTime(UTC)': process.startTime ? '| ' + this.formatTime(process.startTime) : '| ' + 'N/A',\n\t\t\t'endTime(UTC)': process.endTime ? '| ' + this.formatTime(process.endTime) : '| ' + 'N/A',\n\t\t\telapseTime: process.elapsedTime ? '| ' + `${(process.elapsedTime / 1e9).toFixed(2)} s` + ' |' : '| ' + 'N/A' + ' |'\n\t\t});\n\t\t// Aggregate total time by type\n\t\tif (process.elapsedTime) {\n\t\t\tif (!totalTimeByType[process.type]) {\n\t\t\t\ttotalTimeByType[process.type] = 0;\n\t\t\t}\n\t\t\ttotalTimeByType[process.type] += process.elapsedTime;\n\t\t}\n\t});\n\n\tux.table(resultData, { processType: {}, processName: {}, 'startTime(UTC)': {}, 'endTime(UTC)': {}, elapseTime: {} });\n\tthis.logger('\\n' + '   ====================       EXECUTION SUMMARY      ====================   ');\n\t// Print total aggregate time by type\n\tObject.entries(totalTimeByType).forEach(([type, totalTime]) => {\n\t\tthis.logger(`${type} Total Time: ${(totalTime / 1e9).toFixed(2)} seconds`);\n\t});\n\tthis.logger('   ====================       EXECUTION SUMMARY      ====================   ' + '\\n');\n}\n\nfunction formatTime(time) {\n\tconst date = new Date(time[0] * 1000 + time[1] / 1e6);\n\tconst hours = date.getUTCHours().toString().padStart(2, '0');\n\tconst minutes = date.getUTCMinutes().toString().padStart(2, '0');\n\tconst seconds = date.getUTCSeconds().toString().padStart(2, '0');\n\tconst milliseconds = date.getUTCMilliseconds().toString().padStart(3, '0');\n\treturn `${hours}:${minutes}:${seconds}.${milliseconds}`;\n}\n\nfunction getInstanceUrl(instanceUrl) {\n\treturn instanceUrl?.substring(0, instanceUrl?.indexOf('/', instanceUrl?.indexOf('/') + 2));\n}\n\nclass CommandExecutionError extends Error {\n\tconstructor(message, category, additionalInfo) {\n\t\tsuper(`${category ? category + ' - ' : ''}${additionalInfo ? additionalInfo + ' : ' : ''}${message}`);\n\t\tthis.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n\t}\n}\n\nfunction getPromisesToReadTestSuitesAndTestClassesFile(contentVersionIdsOfTestClassesAndTestSuites) {\n\tconst promises = [];\n\tcontentVersionIdsOfTestClassesAndTestSuites.forEach(contentVersionId => {\n\t\tconst testSuiteFilePath = `${TEMP_DIRECTORY}/${contentVersionId}/${CONSTANTS.TEST_SUITE_FILE_NAME}`;\n\t\tconst testClassFilePath = `${TEMP_DIRECTORY}/${contentVersionId}/${CONSTANTS.TEST_CLASS_FILE_NAME}`;\n\t\tif (fs.existsSync(testSuiteFilePath)) {\n\t\t\tpromises.push(this.readFileAsync(testSuiteFilePath, true));\n\t\t}\n\t\tif (fs.existsSync(testClassFilePath)) {\n\t\t\tpromises.push(this.readFileAsync(testClassFilePath, true));\n\t\t}\n\t});\n\treturn promises;\n}\n\nfunction getSelectedTestClasses(testClassesAndTestSuitesFileContent) {\n\tlet result = new Set();\n\ttestClassesAndTestSuitesFileContent?.forEach(data => {\n\t\tif (data.children) {\n\t\t\tresult = new Set([...result, ...this.getSelectedTestClasses(data.children)]);\n\t\t} else if (data.s) {\n\t\t\tresult.add(data.n);\n\t\t}\n\t});\n\treturn result;\n}\n\nfunction getContentVersionIdsOfTestClassesAndTestSuites(testSuiteAndTestClassFileVersionDetails) {\n\tlet result;\n\ttry {\n\t\tresult = testSuiteAndTestClassFileVersionDetails ? JSON.parse(testSuiteAndTestClassFileVersionDetails) : [];\n\t} catch (error) {\n\t\tthrow new Error(`Error finding test suite and test class file ids, ${error.toString()}`);\n\t}\n\treturn result;\n}\n\nclass ParallelCommandExecutor {\n\tcommands;\n\tmaxAllowedChildProcesses;\n\n\tconstructor(commands, maxAllowedChildProcesses) {\n\t\tthis.commands = commands;\n\t\tthis.maxAllowedChildProcesses = maxAllowedChildProcesses;\n\t}\n\n\tstartExecution() {\n\t\tconst promises = [];\n\t\tlet totalConsumedChildProcesses = 0;\n\t\tconst totalCommands = this.commands?.length;\n\t\tif (!totalCommands || totalCommands < 1) {\n\t\t\tthrow new Error('No commands supplied to the command processor');\n\t\t}\n\n\t\twhile (this.commands.length && this.maxAllowedChildProcesses > totalConsumedChildProcesses) {\n\t\t\tpromises.push(\n\t\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\t\tthis._executeCommand(this.commands.shift(), resolve, reject);\n\t\t\t\t})\n\t\t\t);\n\t\t\ttotalConsumedChildProcesses++;\n\t\t}\n\t\tlogger(`Parallel command executor started ${promises.length} child process(es) for processing ${totalCommands} command(s)`);\n\t\treturn promises;\n\t}\n\n\t_executeCommand(command, resolve, reject) {\n\t\tlet output = '',\n\t\t\terror = '';\n\t\tconst childProcess = child_process.spawn(command.value, [], {\n\t\t\tshell: true\n\t\t});\n\n\t\tchildProcess.stdout.on('data', data => {\n\t\t\toutput += data?.toString();\n\t\t});\n\n\t\tchildProcess.stderr.on('data', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('error', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('close', code => {\n\t\t\tif (!command.disableLogs) {\n\t\t\t\tlogger(`command: ${command.value}, \\ncode: ${code}`);\n\t\t\t\tif (output) {\n\t\t\t\t\tlogger(output);\n\t\t\t\t}\n\t\t\t\tif (error) {\n\t\t\t\t\tlogger(error);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (code !== 0) {\n\t\t\t\tlet errorMessage = '';\n\t\t\t\tif (command.hasJsonResponse) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\terrorMessage = JSON.parse(output);\n\t\t\t\t\t} catch (err) {\n\t\t\t\t\t\terrorMessage = err.toString();\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\terrorMessage = error;\n\t\t\t\t}\n\t\t\t\terrorMessage = errorMessage ? errorMessage : `Error executing the command ${command.value}`;\n\t\t\t\treject(errorMessage);\n\t\t\t} else {\n\t\t\t\tthis._handleNextExecution(resolve, reject);\n\t\t\t}\n\t\t});\n\t}\n\n\t_handleNextExecution(resolve, reject) {\n\t\tif (this.commands.length) {\n\t\t\tthis._executeCommand(this.commands.shift(), resolve, reject);\n\t\t} else {\n\t\t\tlogger('Parallel command executor resolved a child process');\n\t\t\tresolve('Parallel command executor resolved a child process');\n\t\t}\n\t}\n}\n\nfunction readFileAsync(filePath, isJsonContent) {\n\treturn new Promise((resolve, reject) => {\n\t\tfs.readFile(filePath, (error, data) => {\n\t\t\tif (error) {\n\t\t\t\treject(error);\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tresolve(isJsonContent ? JSON.parse(data.toString()) : data.toString());\n\t\t\t\t} catch (err) {\n\t\t\t\t\treject(err.toString());\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t});\n}\n\nmodule.exports.prepareChanges = prepareChanges;\nmodule.exports.fetchPromotionBranch = fetchPromotionBranch;\nmodule.exports.configureGit = configureGit;\nmodule.exports.updateSourceApiVersion = updateSourceApiVersion;\nmodule.exports.validateSFDXProjectJson = validateSFDXProjectJson;\nmodule.exports.enrichChangeList = enrichChangeList;\nmodule.exports.processMetadata = processMetadata;\nmodule.exports.getParentMetadataFile = getParentMetadataFile;\nmodule.exports.addParentMetadataToOriginalChangeList = addParentMetadataToOriginalChangeList;\nmodule.exports.varReplace = varReplace;\nmodule.exports.yamlFindAndReplace = yamlFindAndReplace;\nmodule.exports.executeSFDXDeployCmd = executeSFDXDeployCmd;\nmodule.exports.getSFDXDeployCmd = getSFDXDeployCmd;\nmodule.exports.getTestRunParam = getTestRunParam;\nmodule.exports.getDeploymentTestClasses = getDeploymentTestClasses;\nmodule.exports.uploadDeploymentResultOnJobStep = uploadDeploymentResultOnJobStep;\nmodule.exports.handleDeployResult = handleDeployResult;\nmodule.exports.filterFailedMedataByProblemType = filterFailedMedataByProblemType;\nmodule.exports.getFailedTestsErrorMessage = getFailedTestsErrorMessage;\nmodule.exports.getFailedComponentsErrorMessage = getFailedComponentsErrorMessage;\nmodule.exports.populateErrorResponse = populateErrorResponse;\nmodule.exports.cleanDeploymentFiles = cleanDeploymentFiles;\nmodule.exports.gitMergePromotionToTarget = gitMergePromotionToTarget;\nmodule.exports.commitGit = commitGit;\nmodule.exports.evaluateMergeStatus = evaluateMergeStatus;\nmodule.exports.reconcileFullProfile = reconcileFullProfile;\nmodule.exports.pushChangesToRemote = pushChangesToRemote;\nmodule.exports.createDebugPromotionBranch = createDebugPromotionBranch;\nmodule.exports.pushDebugPromotionBranch = pushDebugPromotionBranch;\nmodule.exports.setInstanceUrl = setInstanceUrl;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.populateValidationIdOnResultRecord = populateValidationIdOnResultRecord;\nmodule.exports.executeQuickDeploy = executeQuickDeploy;\nmodule.exports.readFromPath = readFromPath;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.processFullProfiles = processFullProfiles;\nmodule.exports.mergeFullProfile = mergeFullProfile;\nmodule.exports.findMergeableMetadataInScope = findMergeableMetadataInScope;\nmodule.exports.evaluateResponse = evaluateResponse;\nmodule.exports.getApiVersion = getApiVersion;\nmodule.exports.execute = execute;\nmodule.exports.analyzeMetadata = analyzeMetadata;\nmodule.exports.createManifest = createManifest;\nmodule.exports.buildManifest = buildManifest;\nmodule.exports.deploy = deploy;\nmodule.exports.fetchCheckoutBranch = fetchCheckoutBranch;\nmodule.exports.getGitDepth = getGitDepth;\nmodule.exports.handleResponse = handleResponse;\nmodule.exports.getOptions = getOptions;\nmodule.exports.createDeploymentResultFile = createDeploymentResultFile;\nmodule.exports.getDeploymentResultFile = getDeploymentResultFile;\nmodule.exports.getDeploymentResultFile = getDeploymentResultFile;\nmodule.exports.checkChangesWrtCategory = checkChangesWrtCategory;\nmodule.exports.log = log;\nmodule.exports.logger = logger;\nmodule.exports.sfdxRetrieve = sfdxRetrieve;\nmodule.exports.prepareMetadataChangesList = prepareMetadataChangesList;\nmodule.exports.checkoutRollBackBranch = checkoutRollBackBranch;\nmodule.exports.getSFChanges = getSFChanges;\nmodule.exports.retrieveOrgMetadata = retrieveOrgMetadata;\nmodule.exports.retrieveFullProfile = retrieveFullProfile;\nmodule.exports.executeRollBackLogic = executeRollBackLogic;\nmodule.exports.setup = setup;\nmodule.exports.checkSFDXProjectJson = checkSFDXProjectJson;\nmodule.exports.configureSFDXCLI = configureSFDXCLI;\nmodule.exports.gitCommit = gitCommit;\nmodule.exports.options = options;\nmodule.exports.gitPush = gitPush;\nmodule.exports.commitChangesInRollbackBranch = commitChangesInRollbackBranch;\nmodule.exports.executeCommandinChunks = executeCommandinChunks;\nmodule.exports.readFromPath = readFromPath;\nmodule.exports.createCopadoRollbackChangesFile = createCopadoRollbackChangesFile;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.getRollBackBranchName = getRollBackBranchName;\nmodule.exports.isRollBackEnabled = isRollBackEnabled;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.checkDeploymentStatus = checkDeploymentStatus;\nmodule.exports.executeCommandAsync = executeCommandAsync;\nmodule.exports.getFilePaths = getFilePaths;\nmodule.exports.startWatch = startWatch;\nmodule.exports.endWatch = endWatch;\nmodule.exports.formatTime = formatTime;\nmodule.exports.printMetrics = printMetrics;\nmodule.exports.getMetadataReconcilerRequest = getMetadataReconcilerRequest;\nmodule.exports.getInstanceUrl = getInstanceUrl;\nmodule.exports.getSelectedTestClasses = getSelectedTestClasses;\nmodule.exports.getContentVersionIdsOfTestClassesAndTestSuites = getContentVersionIdsOfTestClassesAndTestSuites;\nmodule.exports.getPromisesToReadTestSuitesAndTestClassesFile = getPromisesToReadTestSuitesAndTestClassesFile;\nmodule.exports.ParallelCommandExecutor = ParallelCommandExecutor;\nmodule.exports.readFileAsync = readFileAsync;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Timeout__c": 120,
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0l7Q000000MDYvQAO",
                    "LastReferencedDate": "2024-01-03T08:40:44.000+0000",
                    "LastViewedDate": "2024-01-03T08:40:44.000+0000",
                    "Name": "Deploy"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q000000iAiLQAU"
                    },
                    "copado__ApexClass__c": "cmcSf.CommitFunctionCallback",
                    "copado__API_Name__c": "sfdx_commit",
                    "copado__Callback_Type__c": "ApexClass",
                    "copado__Description__c": "Performs git commit on user stories",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"fileChangesId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"fileName\",\n  \"defaultValue\" : \"Copado Commit changes\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEndPoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"name\" : \"namespace\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"baseBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.baseBranch}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEnv\",\n  \"defaultValue\" : \"{$Source.apex.EnvironmentVariables}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"findAndReplaceFileId\",\n  \"defaultValue\" : \"{$Context.apex.GlobalFindAndReplaceSourceId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"featureBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.featureBranchName}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"recreateIfExists\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.recreateFeatureBranch}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"commitMessage\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.message}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEnvironmentBranch\",\n  \"defaultValue\" : \"{$Context.apex.SourceEnvironmentBranch}\"\n}, {\n  \"name\" : \"gitDepth\",\n  \"defaultValue\" : \"{$Pipeline.Property.gitDepth_commit}\"\n}, {\n  \"name\" : \"timeout\",\n  \"defaultValue\" : \"180000\"\n}, {\n  \"name\" : \"chunkSize\",\n  \"defaultValue\" : \"10\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"name\" : \"overriddenApiVersion\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"commitId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.commitId}\"\n}, {\n  \"name\" : \"vlocityFilesPath\",\n  \"defaultValue\" : \"/app/vlocity/\"\n}, {\n  \"name\" : \"disableEarlyCommitCompletion\",\n  \"defaultValue\" : \"{$Pipeline.Property.disableEarlyCommitCompletion}\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n/**\n * Performs commit of selected user story metadata changes.\n * Returns (If ACTION success) new feature branch in user repo with all the changes and returns the commit id in the result record\n * (If ACTION failed) Returns details with error status on user story commit record\n * @param fileChangesId\n * @param fileName\n * @param sourceSessionId\n * @param sourceEndPoint\n * @param git_json\n * @param baseBranch\n * @param sourceEnv\n * @param findAndReplaceFileId\n * @param featureBranch\n * @param recreateIfExists\n * @param commitMessage\n * @param gitEmail\n * @param gitName\n * @param sourceEnvironmentBranch\n * @param maxBuffer\n * @param gitDepth\n * @param timeout\n * @param chunkSize\n * @param overriddenApiVersion\n * @param commitId\n */\n\n/*\nglobal  Buffer, __dirname\n*/\n\nconst child_process = require('child_process'),\n\tfs = require('fs'),\n\thttps = require('https'),\n\tprocess = require('process'),\n\t{\n\t\tfeatureBranch,\n\t\tsourceSessionId,\n\t\tmaxBuffer,\n\t\tisTest,\n\t\tgitDepth,\n\t\tfindAndReplaceFileId,\n\t\tsourceEnv,\n\t\tAPI_VERSION,\n\t\tcommitId,\n\t\tvlocityFilesPath,\n\t\tchunkSize,\n\t\tdisableEarlyCommitCompletion,\n\t\tsourceEndPoint\n\t} = process.env,\n\t{ Ux } = isTest ? require('@salesforce/sf-plugins-core') : require('/usr/local/lib/node_modules/@salesforce/sf-plugins-core'),\n\t{ Retriever, CopaReconcilerInput, Operation } = isTest ? require('../common/__mocks__/modules/copado-metadata-reconciler') : require('/usr/local/lib/node_modules/@mcdx/copado-metadata-reconciler'),\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tAPP_DIRECTORY = getPath('/app'),\n\tTARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n\tCOMMIT_CHANGES_FILE_PATH = `${APP_DIRECTORY}/encoded_changes.json`,\n\tRETRIEVE_RESULT_PATH = `${TEMP_DIRECTORY}/retrieveResult.json`,\n\tFULL_PROFILE_RETRIEVE_RESULT_PATH = `${TEMP_DIRECTORY}/fullProfileResult.json`,\n\tFILES_TO_INCLUDE = `${TEMP_DIRECTORY}/filesToInclude.json`,\n\tOUTPUT_JSON_FILE_PATH = `${TEMP_DIRECTORY}/output.json`,\n\tACTIONS = {\n\t\tADD: 'add',\n\t\tRETRIEVE_ONLY: 'retrieveonly',\n\t\tFULL: 'full',\n\t\tDELETE: 'delete',\n\t\tSELECTIVE_COMMIT: 'selectivecommit'\n\t},\n\tTYPES = {\n\t\tPERMISSION_SET: 'permissionset',\n\t\tPROFILE: 'profile',\n\t\tCUSTOM_OBJECT: 'customobject'\n\t},\n\tSTDIO = {\n\t\tINHERIT: 'inherit',\n\t\tPIPE: 'pipe',\n\t\tIGNORE: 'ignore'\n\t},\n\tPARENT_NESTED_METADATA = ['customlabels', 'workflow', 'sharingrules', 'escalationrules', 'matchingrules', 'autoresponserules', 'assignmentrules'],\n\tMAXBUFFER = parseInt(maxBuffer),\n\tCOPADO_YML = 'Copado',\n\tCOMMIT_OPERATION = 'Commit Operation',\n\tGIT_DEPTH = getGitDepth(gitDepth),\n\tCOPADO_INFO_PREFIX = 'CopadoFunction INFO',\n\tSELECTIVE_COMMIT_SUFFIX = {\n\t\tSESSION: 'session',\n\t\tCOMMIT: 'commit'\n\t},\n\tPORCELAIN_STATUS = {\n\t\tADDED: 'A',\n\t\tDELETED: 'D',\n\t\tUNMERGED: 'U'\n\t},\n\tGIT_STATUS_FILE_PATH = `${TEMP_DIRECTORY}/git_status.txt`,\n\tCATEGORY = {\n\t\tVLOCITY: 'vlocity',\n\t\tSFDX: 'sfdx'\n\t},\n\tCOPADO_RETRIEVE_XML = 'CopadoRetrieve.xml',\n\tRETRIEVE_ERRORS_TO_BE_DISCARDED = ['cannot retrieve a standard tab'],\n\tRESULT_INFO = {\n\t\tLEVEL: {\n\t\t\tINFO: 'INFO',\n\t\t\tERROR: 'ERROR',\n\t\t\tWARN: 'WARN'\n\t\t},\n\t\tCATEGORY: {\n\t\t\tUNKNOWN_EXCEPTION: 'Unknown Exception',\n\t\t\tCOPADO_INFO: 'Copado Info',\n\t\t\tCOPADO_METADATA_INTELLIGENCE: 'Copado Metadata Intelligence',\n\t\t\tGIT: 'Git',\n\t\t\tCOPADO_SERVICE: 'Copado Service',\n\t\t\tSFDX_CLI: 'Salesforce CLI',\n\t\t\tFILE_SYSTEM: 'File System',\n\t\t\tGIT_SERVICE: 'Git Service',\n\t\t\tCOMMIT_INFO: 'Commit Info',\n\t\t\tMETADATA_RECONCILER: 'Metadata Reconciler',\n\t\t\tSELECTIVE_COMMIT: 'Selective Commit'\n\t\t},\n\t\tADDITIONAL_INFORMATION: {\n\t\t\tMETADATA_RETRIEVAL: 'Metadata Retrieval',\n\t\t\tQUICK_DEPLOYMENT: 'Quick Deployment',\n\t\t\tGIT_STATUS: 'Git Status',\n\t\t\tDELETE_FEATURE_BRANCH: 'Delete Feature Branch',\n\t\t\tGIT_COMMIT: 'Git Commit',\n\t\t\tGIT_CONFIG: 'Git Configuration',\n\t\t\tSFDX_CONFIG: 'SFDX Configuration',\n\t\t\tFULL_PROFILE_RETRIEVAL: 'Full Profile Retrieval',\n\t\t\tFEATURE_BRANCH_CHECKOUT: 'Feature Branch Checkout',\n\t\t\tENRICHER_SERVICE: 'Enricher Service',\n\t\t\tMETADATA_PROCESSOR: 'Metadata Processor',\n\t\t\tENV_VARIABLE_REPLACEMENT: 'Environment Variable Replacement',\n\t\t\tGLOBAL_FIND_AND_REPLACE: 'Global Find and Replace',\n\t\t\tCOPADO_MERGE: 'Copado Merge',\n\t\t\tUPLOAD_FILES: 'Upload Files',\n\t\t\tDOWNLOAD_FILES: 'Download Files',\n\t\t\tGIT_MERGE: 'Git Merge',\n\t\t\tGIT_PUSH: 'Git Push',\n\t\t\tGIT_ADD: 'Git Add',\n\t\t\tGIT_CLEAN: 'Git Clean',\n\t\t\tGIT_CLONE: 'Git Clone',\n\t\t\tGIT_CHECKOUT: 'Git Checkout',\n\t\t\tGIT_FIND_COMMIT_ID: 'Git Find Commit Id',\n\t\t\tGIT_LIST_UNTRACKED_FILES: 'Git List Untracked Files',\n\t\t\tGIT_MERGE_PUSH_FEATURE_BRANCH: 'Git Merge & Push Feature Branch',\n\t\t\tMISSING_DETAILS: 'Missing Details'\n\t\t}\n\t},\n\tresultViewerJson = [],\n\tCUSTOM_ERROR = {\n\t\tCOMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n\t},\n\tSELECTIVE_COMMIT_SUPPORTED_METADATA = ['Layout', 'FlexiPage'],\n\tRESULT_TABLE_HEADER = {\n\t\tlabel: 'Commit Result',\n\t\tcustomLabel: 'Commit_Result'\n\t},\n\tHEADER_ICON = 'standard:note',\n\tRESULT_TABLE_COLUMNS = [\n\t\t{\n\t\t\tlabel: 'Level',\n\t\t\tfieldName: 'Level',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Level',\n\t\t\tinitialWidth: 80\n\t\t},\n\t\t{\n\t\t\tlabel: 'Category',\n\t\t\tfieldName: 'Category',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Category',\n\t\t\tinitialWidth: 120\n\t\t},\n\t\t{\n\t\t\tlabel: 'Additional Information',\n\t\t\tfieldName: 'AdditionalInformation',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Additional_Information',\n\t\t\tinitialWidth: 200\n\t\t},\n\t\t{\n\t\t\tlabel: 'Message',\n\t\t\tfieldName: 'Message',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Message'\n\t\t}\n\t];\n\nlet commitChanges = {},\n\tsourceApiVersion = isTest ? API_VERSION : '',\n\tfilesInScope = [],\n\ttotalTimeByType = {},\n\tprocesses = [],\n\texecutionError;\n\n// SCRIPT FUNCTIONS\n\nasync function execute(commitChanges) {\n\ttry {\n\t\tconsole.time(COMMIT_OPERATION);\n\t\tthis.validateCommitId(commitId);\n\t\tawait Promise.all(this.initialSetup(commitChanges));\n\n\t\tif (fs.existsSync(vlocityFilesPath)) {\n\t\t\tthis.copyFiles(vlocityFilesPath, TARGET_DIRECTORY);\n\t\t}\n\t\tif (commitChanges.hasSfdxMetadata() && !commitChanges.Sfdx?.hasOnlyDestructiveChanges()) {\n\t\t\tawait Promise.all(this.retrieveOrgMetadata(commitChanges));\n\t\t}\n\t\tthis.enrichChangeList(COMMIT_CHANGES_FILE_PATH, RETRIEVE_RESULT_PATH, 'COMMIT');\n\t\tthis.uploadFile(COMMIT_CHANGES_FILE_PATH, 'EnrichedChanges.json');\n\t\tthis.updateSelectiveCommitFiles(commitChanges.Sfdx.selectiveCommit, TARGET_DIRECTORY);\n\t\tfilesInScope.push(...this.getFilesInScope());\n\n\t\tif (filesInScope && !commitChanges.Sfdx?.hasOnlyDestructiveChanges()) {\n\t\t\tthis.varReplace(sourceEnv);\n\t\t\tthis.findAndReplace(findAndReplaceFileId, featureBranch);\n\t\t}\n\t\tif (commitChanges.hasSfdxMetadata()) {\n\t\t\tthis.processMetadata();\n\t\t\tthis.discardRetrieveOnlyFiles(commitChanges);\n\t\t}\n\t\tthis.startWatch(RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_MERGE_PUSH_FEATURE_BRANCH, processes);\n\t\tawait this.commitAndUpdateEnvironmentBranches(GIT_DEPTH, disableEarlyCommitCompletion);\n\n\t\tconsole.timeEnd(COMMIT_OPERATION);\n\t} catch (err) {\n\t\tthis.logger(`Error stack: ${err.stack}`);\n\t\tif (!(err instanceof CommandExecutionError)) {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, 'See logs for more info', err.message);\n\t\t}\n\t\texecutionError = err.message || err?.toString() || 'Unknown Error occurred';\n\t} finally {\n\t\tthis.printMetrics();\n\t\tif (resultViewerJson?.length) {\n\t\t\tthis.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n\t\t}\n\t\tif (executionError) {\n\t\t\tthis.executeCommand(this.getErrorCmdString(executionError));\n\t\t\tprocess.exit(1);\n\t\t}\n\t}\n}\n\n// SCRIPT FUNCTIONS\n\nfunction encodeFileNames(committedMetadata, filePath) {\n\tthis.validateCommittedChanges(committedMetadata);\n\n\tfor (let commitChange of committedMetadata) {\n\t\tif (!commitChange.c) {\n\t\t\tcommitChange.c = CATEGORY.SFDX;\n\t\t}\n\t\tif (commitChange.c?.toLowerCase() == CATEGORY.SFDX) {\n\t\t\tswitch (commitChange.t) {\n\t\t\t\tcase 'DashboardFolder':\n\t\t\t\tcase 'ReportFolder':\n\t\t\t\tcase 'Document':\n\t\t\t\t\tcommitChange.n = commitChange.n.replace(/%2F/gi, '/');\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'EmailTemplate':\n\t\t\t\t\tcommitChange.n = commitChange.n.replace(/%24/gi, '$').replace(/%2F/gi, '/');\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Layout': {\n\t\t\t\t\tconst regExp = '(?:([a-zA-Z_][a-zA-Z0-9_]{0,14}?(?!__c-))__)?([^-]+)-(?:([a-zA-Z_][a-zA-Z0-9_]{0,14}?_?(?!__c$))__)?(.+)\\n?';\n\t\t\t\t\t/*\n                        The above regExp divides the layout full name into 4 groups:\n                        1. customobject namespace\n                        2. customobject name\n                        3. layout namespace\n                        4. layout mame\n                        The match function returns these groups respectively in the indices 1,2,3,4\n                    */\n\t\t\t\t\tconst layoutFullName = commitChange.n.match(regExp);\n\t\t\t\t\tlet layoutName = layoutFullName[4].replace(/_{2}(?!c)/g, match => {\n\t\t\t\t\t\treturn match.replace(/_/gi, '%5F');\n\t\t\t\t\t});\n\t\t\t\t\tlayoutName = layoutName.replace(/\\./, '%2E');\n\t\t\t\t\tcommitChange.n = `${layoutFullName[1] ? layoutFullName[1] + '__' : ''}${layoutFullName[2]}-${\n\t\t\t\t\t\tlayoutFullName[3] ? layoutFullName[3] + '__' : ''\n\t\t\t\t\t}${layoutName}`;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tcase 'Profile':\n\t\t\t\t\tcommitChange.n = commitChange.n.replace(/\\./gi, '%2E').replace(/__/gi, '%5F%5F');\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tfs.writeFileSync(filePath, JSON.stringify(committedMetadata, null, 2));\n}\n\nfunction getSFChanges(committedMetadata) {\n\treturn committedMetadata.filter(selection => !selection.c || selection.c?.toLowerCase() == CATEGORY.SFDX);\n}\n\nfunction getCommitChanges(dir, commitChangesFileName, encodedChangesFileName) {\n\tlet result;\n\t// If condition would only be satisfied when Encoded Changes file has been Created in Vlocity Retrieve step.\n\tif (fs.existsSync(encodedChangesFileName)) {\n\t\tresult = this.readFromPath(encodedChangesFileName);\n\t} else {\n\t\tlet downloadedFileName;\n\t\tif (fs.existsSync(`${dir}/${commitChangesFileName}`)) {\n\t\t\tdownloadedFileName = commitChangesFileName;\n\t\t} else if (fs.existsSync(`${dir}/${commitChangesFileName}.json`)) {\n\t\t\tdownloadedFileName = `${commitChangesFileName}.json`;\n\t\t} else {\n\t\t\tthrow new Error('Error fetching Commit Changes');\n\t\t}\n\t\tresult = this.readFromPath(`${dir}/${downloadedFileName}`);\n\t}\n\treturn result;\n}\n\nfunction validateCommittedChanges(committedMetadata) {\n\tconst isValid =\n\t\tArray.isArray(committedMetadata) &&\n\t\tcommittedMetadata?.length &&\n\t\tcommittedMetadata?.filter(change => !change.n || !change.t || !change.a)?.length == 0;\n\tif (!isValid) {\n\t\tthrow new Error('The Commit Changes do not follow the Commit Action Contract');\n\t}\n}\n\nfunction prepareMetadataChangesList(filePath, commitChanges) {\n\tconst allChanges = this.readFromPath(filePath);\n\tconst sfdxChanges = this.getSFChanges(allChanges);\n\n\tcommitChanges.Sfdx = {\n\t\taddOrRetrieve: sfdxChanges.filter(\n\t\t\tselectedMetadata =>\n\t\t\t\tselectedMetadata.a.toLowerCase() == ACTIONS.RETRIEVE_ONLY ||\n\t\t\t\tselectedMetadata.a.toLowerCase() == ACTIONS.ADD ||\n\t\t\t\tselectedMetadata.a.toLowerCase() == ACTIONS.SELECTIVE_COMMIT ||\n\t\t\t\t(selectedMetadata.a.toLowerCase() == ACTIONS.FULL && selectedMetadata.t.toLowerCase() != TYPES.PROFILE)\n\t\t),\n\t\tdelete: sfdxChanges.filter(selectedMetadata => selectedMetadata.a.toLowerCase() == ACTIONS.DELETE),\n\t\tprofiles: sfdxChanges.filter(\n\t\t\tselectedMetadata => selectedMetadata.a.toLowerCase() == ACTIONS.FULL && selectedMetadata.t.toLowerCase() == TYPES.PROFILE\n\t\t),\n\t\tretrieveOnly: sfdxChanges.filter(selectedMetadata => selectedMetadata.a.toLowerCase() == ACTIONS.RETRIEVE_ONLY),\n\t\tselectiveCommit: sfdxChanges.filter(selectedMetadata => selectedMetadata.a.toLowerCase() == ACTIONS.SELECTIVE_COMMIT),\n\t\thasOnlyDestructiveChanges: () => {\n\t\t\treturn commitChanges?.Sfdx.delete?.length > 0 && commitChanges?.Sfdx.delete?.length === sfdxChanges.length;\n\t\t}\n\t};\n\n\tcommitChanges.hasSfdxMetadata = function () {\n\t\treturn sfdxChanges?.length > 0 ? true : false;\n\t};\n}\n\nfunction checkNestedParentMetadataDeletion(commitChanges) {\n\tconst notToDeleteMetadataTypes = new Set();\n\tif (commitChanges?.Sfdx?.delete?.length) {\n\t\tcommitChanges.Sfdx.delete.filter(change => {\n\t\t\tif (PARENT_NESTED_METADATA?.includes(change.t.toLowerCase())) {\n\t\t\t\tnotToDeleteMetadataTypes.add(change.t);\n\t\t\t}\n\t\t});\n\t\tif (notToDeleteMetadataTypes.size) {\n\t\t\tthrow new Error(\n\t\t\t\t`${[...notToDeleteMetadataTypes].join(\n\t\t\t\t\t','\n\t\t\t\t)} cannot be selected for a destructive commit. Try re-committing after removing these metadata`\n\t\t\t);\n\t\t}\n\t}\n}\nfunction setup() {\n\tthis.checkSFDXProjectJson(featureBranch, sourceApiVersion);\n\tthis.configureSFDXCLI(sourceApiVersion, sourceEndPoint);\n}\n\nfunction checkSFDXProjectJson(branchName, sourceApiVersion) {\n\tconst sfdxProjectJsonPath = `${TARGET_DIRECTORY}/sfdx-project.json`;\n\tif (fs.existsSync(sfdxProjectJsonPath)) {\n\t\tlet fileContent = this.readFromPath(sfdxProjectJsonPath);\n\t\tif (fileContent.sourceApiVersion !== sourceApiVersion) {\n\t\t\tconst commitMessage = `Updated sourceApiVersion from ${fileContent.sourceApiVersion} to ${sourceApiVersion} in sfdx-project.json to align the commit, promote and deploy operations with the latest supported api version of Copado`;\n\t\t\tfileContent.sourceApiVersion = sourceApiVersion;\n\t\t\tfs.writeFileSync(sfdxProjectJsonPath, JSON.stringify(fileContent, null, 2));\n\t\t\tthis.gitCommit(commitMessage, branchName, ['sfdx-project.json']);\n\t\t}\n\t} else {\n\t\tthrow new Error(\n\t\t\t`Invalid configuration in ${branchName}. sfdx-project.json is invalid or missing at project root. Copado Commit and Deploy operations are required to run from within a valid sfdx project.`\n\t\t);\n\t}\n}\n\nfunction configureSFDXCLI(sourceApiVersion, sourceEndPoint) {\n\tconst baseUrl = this.getInstanceUrl(sourceEndPoint);\n\n\tconst configSet = `\n    sf config set org-instance-url=${baseUrl} || exit 1\n    sf config set org-api-version=${sourceApiVersion}`;\n\n\tthis.executeCommand(configSet, RESULT_INFO.CATEGORY.SFDX_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.SFDX_CONFIG);\n}\n\nfunction sfdxRetrieve(commitChanges, resolve, reject) {\n\tthis.logger('START -Salesforce- Retrieving Metadata');\n\tthis.buildManifest(commitChanges.Sfdx.addOrRetrieve);\n\n\tthis.asyncCopadoLogMessage('START -Salesforce- Retrieving Metadata');\n\tthis.startWatch(RESULT_INFO.CATEGORY.SFDX_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.METADATA_RETRIEVAL, processes);\n\tconst retrieve = `\n    sf project retrieve start --target-org \"${sourceSessionId}\" --manifest ${TARGET_DIRECTORY}/${COPADO_RETRIEVE_XML}  --ignore-conflicts --json || true\n    `;\n\tthis.logger(`Retrieve command: ${retrieve}`);\n\tchild_process.exec(retrieve, { stdio: STDIO.INHERIT, maxBuffer: MAXBUFFER }, (err, retrieveResult) => {\n\t\tthis.asyncCopadoLogMessage('END -Salesforce- Retrieving Metadata');\n\t\tthis.logger('END -Salesforce- Retrieving metadata');\n\t\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.METADATA_RETRIEVAL, processes);\n\n\t\tretrieveResult = JSON.parse(retrieveResult.toString());\n\n\t\tfs.writeFileSync(RETRIEVE_RESULT_PATH, JSON.stringify(retrieveResult));\n\t\tthis.uploadFile(RETRIEVE_RESULT_PATH);\n\t\tif (retrieveResult.status && retrieveResult.message) {\n\t\t\tthis.populateResultViewer(\n\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\tRESULT_INFO.CATEGORY.SFDX_CLI,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.METADATA_RETRIEVAL,\n\t\t\t\tretrieveResult.message\n\t\t\t);\n\t\t\treject(\n\t\t\t\tnew CommandExecutionError(\n\t\t\t\t\tretrieveResult.message,\n\t\t\t\t\tRESULT_INFO.CATEGORY.SFDX_CLI,\n\t\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.METADATA_RETRIEVAL\n\t\t\t\t)\n\t\t\t);\n\t\t\treturn;\n\t\t}\n\t\tconst failedMetadataItems = retrieveResult?.result?.files?.filter(file => {\n\t\t\treturn file.state === 'Failed' && !RETRIEVE_ERRORS_TO_BE_DISCARDED.includes(file.error?.toLowerCase());\n\t\t});\n\n\t\tif (failedMetadataItems?.length) {\n\t\t\tconst err = failedMetadataItems.map(metadata => metadata.error).toString();\n\t\t\tthis.populateResultViewer(\n\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\tRESULT_INFO.CATEGORY.SFDX_CLI,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.METADATA_RETRIEVAL,\n\t\t\t\terr\n\t\t\t);\n\t\t\treject(new CommandExecutionError(err, RESULT_INFO.CATEGORY.SFDX_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.METADATA_RETRIEVAL));\n\t\t\treturn;\n\t\t}\n\t\tfs.rmSync(`${TARGET_DIRECTORY}/${COPADO_RETRIEVE_XML}`);\n\t\tresolve(retrieveResult);\n\t});\n}\n\nfunction updateSelectiveCommitFiles(selectiveChanges, fileDirectory) {\n\tif (!selectiveChanges.length) {\n\t\treturn;\n\t}\n\n\tthis.logger('START Selective Commit');\n\tthis.asyncCopadoLogMessage('Applying Selective Commit Changes');\n\tconst enrichedChanges = this.readFromPath(COMMIT_CHANGES_FILE_PATH);\n\tselectiveChanges.forEach(change => {\n\t\tif (change.j && SELECTIVE_COMMIT_SUPPORTED_METADATA.includes(change.t)) {\n\t\t\tconst changeJson = JSON.parse(change.j);\n\t\t\tif (changeJson?.selectiveCommitFileId && changeJson?.selectiveCommitHash) {\n\t\t\t\tthis.executeCommand(\n\t\t\t\t\tthis.downloadFile(changeJson.selectiveCommitFileId, `${TEMP_DIRECTORY}/`),\n\t\t\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILES,\n\t\t\t\t\ttrue\n\t\t\t\t);\n\t\t\t\tconst enrichedChange = enrichedChanges.find(\n\t\t\t\t\tenrichedChange => enrichedChange.n === change.n && enrichedChange.t === change.t && enrichedChange.a === change.a\n\t\t\t\t);\n\t\t\t\tif (enrichedChange?.j) {\n\t\t\t\t\tconst enrichedChangeJson = JSON.parse(enrichedChange.j);\n\t\t\t\t\tif (enrichedChangeJson?.filePath && fs.existsSync(`${fileDirectory}/${enrichedChangeJson.filePath}`)) {\n\t\t\t\t\t\tconst selectiveCommitFilePath = this.getSelectiveCommitFile(`${change.t}:${change.n}`, changeJson.selectiveCommitHash);\n\t\t\t\t\t\tconst selectiveCommitContent = fs.readFileSync(selectiveCommitFilePath, 'utf-8');\n\t\t\t\t\t\tfs.writeFileSync(`${fileDirectory}/${enrichedChangeJson.filePath}`, selectiveCommitContent);\n\t\t\t\t\t\tthis.uploadSelectiveCommitFileOnResult(selectiveCommitFilePath, changeJson.selectiveCommitHash);\n\t\t\t\t\t\tthis.populateResultViewer(\n\t\t\t\t\t\t\tRESULT_INFO.LEVEL.INFO,\n\t\t\t\t\t\t\tRESULT_INFO.CATEGORY.SELECTIVE_COMMIT,\n\t\t\t\t\t\t\t'',\n\t\t\t\t\t\t\t`Applied Selective Commit changes for ${change.t}:${change.n} on feature branch.`\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tconst errorMessage = `Selected metadata ${change.t}:${change.n} doesn't support Selective Commit.`;\n\t\t\tthis.populateResultViewer(\n\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\tRESULT_INFO.CATEGORY.SELECTIVE_COMMIT,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.MISSING_DETAILS,\n\t\t\t\terrorMessage\n\t\t\t);\n\t\t\tthrow new CommandExecutionError(errorMessage);\n\t\t}\n\t});\n\tthis.logger('END Selective Commit');\n}\n\nfunction retrieveFullProfile(commitChanges, resolve, reject) {\n\tthis.logger('START -Salesforce- Retrieving Full Profile');\n\tthis.asyncCopadoLogMessage('START -Salesforce- Retrieving Full Profile');\n\n\tthis.startWatch(RESULT_INFO.CATEGORY.METADATA_RECONCILER, RESULT_INFO.ADDITIONAL_INFORMATION.FULL_PROFILE_RETRIEVAL, processes);\n\n\tconst profiles = commitChanges.Sfdx.profiles.map(profile => profile.n);\n\tconst request = this.getMetadataReconcilerRequest(profiles, Operation.FULL_PROFILE);\n\n\tnew Retriever()\n\t\t.run(request)\n\t\t?.then(() => {\n\t\t\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.FULL_PROFILE_RETRIEVAL, processes);\n\n\t\t\tconst profileResult = JSON.parse(fs.readFileSync(OUTPUT_JSON_FILE_PATH, 'utf-8'));\n\n\t\t\tconst skippedProfiles = profileResult?.filter(profile => profile?.state === 'Skipped')?.map(profile => profile?.fullName);\n\t\t\tif (skippedProfiles?.length > 0) {\n\t\t\t\tconst errorMessage = `The profiles ${skippedProfiles?.join(',')} were skipped during retrieval.`;\n\t\t\t\tthis.populateResultViewer(\n\t\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\t\tRESULT_INFO.CATEGORY.SF_POWER_KIT,\n\t\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.SF_POWERKIT_FULL_PROFILE,\n\t\t\t\t\terrorMessage\n\t\t\t\t);\n\t\t\t\treject(\n\t\t\t\t\tnew CommandExecutionError(\n\t\t\t\t\t\terrorMessage,\n\t\t\t\t\t\tRESULT_INFO.CATEGORY.SF_POWER_KIT,\n\t\t\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.SF_POWERKIT_FULL_PROFILE\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t} else {\n\t\t\t\tfs.writeFileSync(FULL_PROFILE_RETRIEVE_RESULT_PATH, JSON.stringify(profileResult));\n\t\t\t\tthis.logger(profileResult);\n\t\t\t\tthis.updateCommitChangeFileWithProfilePaths(profileResult);\n\t\t\t\tfs.rmSync('sfpowerkit-cache.db', {\n\t\t\t\t\tforce: true\n\t\t\t\t});\n\t\t\t\tresolve();\n\t\t\t}\n\t\t})\n\t\t.catch(error => {\n\t\t\tconst errorMessage = error.message || error?.toString() || 'Unknown Error occurred';\n\t\t\tthis.populateResultViewer(\n\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\tRESULT_INFO.CATEGORY.SF_POWER_KIT,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.SF_POWERKIT_FULL_PROFILE,\n\t\t\t\terrorMessage\n\t\t\t);\n\t\t\treject(\n\t\t\t\tnew CommandExecutionError(\n\t\t\t\t\terrorMessage,\n\t\t\t\t\tRESULT_INFO.CATEGORY.SF_POWER_KIT,\n\t\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.SF_POWERKIT_FULL_PROFILE\n\t\t\t\t)\n\t\t\t);\n\t\t});\n}\n\nfunction updateCommitChangeFileWithProfilePaths(profileResult) {\n\tlet changes = this.readFromPath(COMMIT_CHANGES_FILE_PATH);\n\tchanges.forEach(change => {\n\t\tif (change.a.toLowerCase() == ACTIONS.FULL && change.t?.toLowerCase() == TYPES.PROFILE) {\n\t\t\tconst matchedProfile = profileResult?.find(profile => profile.fullName == change.n && profile.state !== 'Skipped');\n\t\t\tif (matchedProfile) {\n\t\t\t\tchange.j = JSON.stringify({\n\t\t\t\t\tfilePath: [matchedProfile.path]\n\t\t\t\t});\n\t\t\t\tfilesInScope.push(matchedProfile.path);\n\t\t\t}\n\t\t}\n\t});\n\tfs.writeFileSync(COMMIT_CHANGES_FILE_PATH, JSON.stringify(changes));\n}\nfunction retrieveOrgMetadata(commitChanges) {\n\tthis.setup();\n\tconst promises = [];\n\tcommitChanges?.Sfdx.profiles?.length &&\n\t\tpromises.push(\n\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\tthis.retrieveFullProfile(commitChanges, resolve, reject);\n\t\t\t})\n\t\t);\n\tcommitChanges?.Sfdx.addOrRetrieve?.length &&\n\t\tpromises.push(\n\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\tthis.sfdxRetrieve(commitChanges, resolve, reject);\n\t\t\t})\n\t\t);\n\treturn promises;\n}\n\nfunction varReplace(sourceEnv) {\n\tthis.logger('START Var Replace');\n\tif (fs.existsSync(FILES_TO_INCLUDE) && sourceEnv && JSON.parse(sourceEnv)?.length) {\n\t\tthis.asyncCopadoLogMessage('Replacing environment variables, if any');\n\t\tconst varreplace = `varreplace '${sourceEnv}' '${TARGET_DIRECTORY}' --valuename=true --include=${FILES_TO_INCLUDE}`;\n\t\tthis.executeCommand(\n\t\t\tvarreplace,\n\t\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.ENV_VARIABLE_REPLACEMENT\n\t\t);\n\t}\n\tthis.logger('END Var Replace');\n}\n\nfunction getFilesInScope() {\n\tthis.logger('START Get files in scope');\n\tif (fs.existsSync(RETRIEVE_RESULT_PATH)) {\n\t\tconst retrieveResult = this.readFromPath(RETRIEVE_RESULT_PATH);\n\t\tretrieveResult?.result?.files?.forEach(file => {\n\t\t\tif (file.filePath) {\n\t\t\t\tfilesInScope.push(file.filePath.substring(TARGET_DIRECTORY.length + 1));\n\t\t\t}\n\t\t});\n\t}\n\n\tfilesInScope.push(...this.getFilePaths(COMMIT_CHANGES_FILE_PATH, [ACTIONS.ADD, ACTIONS.SELECTIVE_COMMIT], [CATEGORY.VLOCITY]));\n\n\tif (filesInScope?.length) {\n\t\tfs.writeFileSync(FILES_TO_INCLUDE, JSON.stringify(filesInScope));\n\t}\n\n\tthis.logger('END Get files in scope');\n\treturn filesInScope;\n}\n\nfunction createTargetDirectoryAndFetchBaseBranch(baseBranch, gitDepth) {\n\tthis.startWatch(RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CLONE, processes);\n\tthis.logger('START Creating target directory and fetching base branch');\n\tif (!baseBranch) {\n\t\tthrow new Error('No base branch provided');\n\t}\n\treturn `\n    mkdir -p ${TARGET_DIRECTORY}\n    cd ${TARGET_DIRECTORY}\n    copado-git-get --depth \"${gitDepth}\" \"${baseBranch}\"`;\n}\n\nfunction options() {\n\treturn {\n\t\tshell: true,\n\t\tmaxBuffer: MAXBUFFER\n\t};\n}\n\nfunction initialSetup(commitChanges) {\n\tthis.logger('START Initial setup');\n\tconst promises = [];\n\tconst { gitEmail, gitName, recreateIfExists, fileChangesId, overriddenApiVersion, API_VERSION, fileName, baseBranch } = process.env;\n\tpromises.push(\n\t\tnew Promise((resolve, reject) => {\n\t\t\tchild_process.exec(this.createTargetDirectoryAndFetchBaseBranch(baseBranch, GIT_DEPTH), this.options(), (error, stdout, stderr) => {\n\t\t\t\tthis.logger('END Creating target directory and fetching base branch');\n\t\t\t\tthis.handleResponse(\n\t\t\t\t\terror,\n\t\t\t\t\t{ stdout, stderr },\n\t\t\t\t\t{ category: RESULT_INFO.CATEGORY.GIT_SERVICE, additionalInfo: RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CHECKOUT },\n\t\t\t\t\treject\n\t\t\t\t);\n\t\t\t\ttry {\n\t\t\t\t\tthis.changeWorkingDirectory(TARGET_DIRECTORY);\n\t\t\t\t\tthis.configureGit(gitEmail, gitName);\n\t\t\t\t\tthis.fetchCreateFeatureBranch(recreateIfExists, featureBranch, GIT_DEPTH);\n\t\t\t\t\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CLONE, processes);\n\t\t\t\t\tresolve();\n\t\t\t\t} catch (err) {\n\t\t\t\t\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CLONE, processes);\n\t\t\t\t\treject(new Error(err));\n\t\t\t\t}\n\t\t\t});\n\t\t})\n\t);\n\n\tpromises.push(\n\t\tnew Promise((resolve, reject) => {\n\t\t\tchild_process.exec(this.downloadFile(fileChangesId, TEMP_DIRECTORY), this.options(), (error, stdout, stderr) => {\n\t\t\t\tthis.handleResponse(\n\t\t\t\t\terror,\n\t\t\t\t\t{ stdout, stderr },\n\t\t\t\t\t{ category: RESULT_INFO.CATEGORY.COPADO_SERVICE, additionalInfo: RESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILES },\n\t\t\t\t\treject\n\t\t\t\t);\n\t\t\t\ttry {\n\t\t\t\t\tsourceApiVersion = this.getApiVersion(overriddenApiVersion, API_VERSION);\n\t\t\t\t\tconst committedMetadata = this.getCommitChanges(TEMP_DIRECTORY, fileName, COMMIT_CHANGES_FILE_PATH);\n\t\t\t\t\tthis.encodeFileNames(committedMetadata, COMMIT_CHANGES_FILE_PATH);\n\t\t\t\t\tthis.prepareMetadataChangesList(COMMIT_CHANGES_FILE_PATH, commitChanges);\n\t\t\t\t\tthis.checkNestedParentMetadataDeletion(commitChanges);\n\t\t\t\t\tresolve();\n\t\t\t\t} catch (err) {\n\t\t\t\t\treject(new Error(err));\n\t\t\t\t}\n\t\t\t});\n\t\t})\n\t);\n\tthis.logger('END Initial setup');\n\treturn promises;\n}\n\nfunction handleResponse(error, { stdout, stderr }, cmdInfo, reject) {\n\tif (stdout) {\n\t\tconsole.log(stdout);\n\t}\n\tif (stderr) {\n\t\tconsole.log(stderr);\n\t}\n\tif (error?.code) {\n\t\tconst errorResponse = stderr ? stderr : `Error executing the command ${error.cmd}`;\n\t\tif (reject) {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, cmdInfo.category, cmdInfo.additionalInfo, errorResponse);\n\t\t\tconst truncatedError = errorResponse\n\t\t\t\t.split('\\n')\n\t\t\t\t.filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n\t\t\t\t.join(' ');\n\t\t\treject(new CommandExecutionError(truncatedError, cmdInfo.category, cmdInfo.additionalInfo));\n\t\t\treturn;\n\t\t}\n\t\tthrow new Error(errorResponse);\n\t}\n}\n\nfunction changeWorkingDirectory(dir) {\n\tprocess.chdir(dir);\n}\n\nfunction fetchCreateFeatureBranch(recreateIfExists, featureBranch, gitDepth) {\n\tthis.logger('START fetch Create Feature Branch');\n\tif (featureBranch) {\n\t\tif (recreateIfExists == 'true') {\n\t\t\tthis.asyncCopadoLogMessage(`Removing branch ${featureBranch}`);\n\t\t\tconst deleteLocalAndRemoteBranch = `\n            git branch -D \"${featureBranch}\" || true\n            git push origin --delete \"${featureBranch}\" || true`;\n\t\t\tthis.executeCommand(\n\t\t\t\tdeleteLocalAndRemoteBranch,\n\t\t\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.DELETE_FEATURE_BRANCH,\n\t\t\t\ttrue\n\t\t\t);\n\t\t}\n\t\tthis.asyncCopadoLogMessage(`Fetching/creating branch ${featureBranch}`);\n\t\tthis.executeCommand(\n\t\t\tthis.fetchCheckoutBranch(featureBranch, gitDepth, true),\n\t\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.FEATURE_BRANCH_CHECKOUT,\n\t\t\ttrue\n\t\t);\n\t} else {\n\t\tthrow new Error('No feature branch provided');\n\t}\n\tthis.logger('END fetch Create Feature Branch');\n}\n\nfunction findAndReplace(findAndReplaceFileId, featureBranch) {\n\tthis.logger('START YAML replace');\n\tconst PATH_TO_YAML = `${TEMP_DIRECTORY}/${COPADO_YML}`;\n\tif (findAndReplaceFileId && fs.existsSync(FILES_TO_INCLUDE)) {\n\t\tthis.asyncCopadoLogMessage('Applying global find and replace rules');\n\t\tthis.executeCommand(\n\t\t\tthis.downloadFile(findAndReplaceFileId, `${TEMP_DIRECTORY}/`, COPADO_YML),\n\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILES\n\t\t);\n\t\tif (fs.existsSync(PATH_TO_YAML)) {\n\t\t\tconst findAndReplace = `yamlreplace \"${PATH_TO_YAML}\" \"${TARGET_DIRECTORY}\" -b \"${featureBranch}\" --include=${FILES_TO_INCLUDE}`;\n\t\t\tthis.executeCommand(\n\t\t\t\tfindAndReplace,\n\t\t\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GLOBAL_FIND_AND_REPLACE\n\t\t\t);\n\t\t} else {\n\t\t\tthrow new Error('Could not find the Copado.yml file');\n\t\t}\n\t}\n\tthis.logger('END YAML replace');\n}\n\nfunction getEnrichServiceCommand(filePath, retrieveResultPath, operationType) {\n\treturn `enricher -p ${filePath} --repo ${TARGET_DIRECTORY}/ ${\n\t\tretrieveResultPath && fs.existsSync(retrieveResultPath) ? `--cliresponse ${retrieveResultPath}` : '--quick true'\n\t} ${operationType ? `--operation ${operationType}` : ''}`;\n}\n\nfunction enrichChangeList(filePath, retrieveResultPath, operationType) {\n\tthis.logger('START Enricher');\n\tthis.executeCommand(\n\t\tthis.getEnrichServiceCommand(filePath, retrieveResultPath, operationType),\n\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.ENRICHER_SERVICE\n\t);\n\tthis.logger('END Enricher');\n}\n\nfunction processMetadata() {\n\tthis.logger('START Metadata Processor');\n\tthis.asyncCopadoLogMessage('Processing metadata');\n\tconst processsMetadata = `metadata-processor \"${COMMIT_CHANGES_FILE_PATH}\" \"${TARGET_DIRECTORY}\" -o COMMIT`;\n\tthis.executeCommand(processsMetadata, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.METADATA_PROCESSOR);\n\tthis.logger('END Metadata Processor');\n}\n\nfunction gitCommit(commitMessage, branchName, filePaths, allowCommitWithNoChanges) {\n\tcommitMessage = commitMessage.replace(/[`\"$\\\\]/g, '\\\\$&');\n\tlet gitCommit = '';\n\tthis.asyncCopadoLogMessage(`Committing ${commitMessage} in ${branchName}`);\n\tif (filePaths?.length) {\n\t\t// If filePaths have path to a folder as well as paths to files inside it , it causes failure during staging as the folder could be deleted first & no files would be left inside folder in next iteration ,\n\t\t// To avoid any kind of failure during the commit process we introduce a fallback mechanism -If there is an issue in adding files to git using filepaths we simply do 'git add .' and continue with our process\n\t\ttry {\n\t\t\tthis.executeCommandinChunks(filePaths, chunkSize, 'git add -f REPLACE_VALUE', {\n\t\t\t\tcategory: RESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\t\tadditionalInfo: RESULT_INFO.ADDITIONAL_INFORMATION.GIT_ADD\n\t\t\t});\n\t\t} catch (error) {\n\t\t\tthis.logger('Re-trying staging using Git add . as chunking failed : ' + error);\n\t\t\tgitCommit = 'git add . || exit 1';\n\t\t}\n\t} else {\n\t\tgitCommit = 'git add . || exit 1';\n\t}\n\tgitCommit = `\n\t\t${gitCommit}\n\t\tgit commit -m \"${commitMessage}\" ${allowCommitWithNoChanges ? '|| true' : ''}`;\n\tthis.executeCommand(gitCommit, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_COMMIT, true);\n}\n\nfunction configureGit(gitEmail, gitName) {\n\tconst configureGit = `\n        git config feature.manyFiles true || exit 1\n        git update-index --index-version 4 || exit 1\n        git config --local user.email \"${gitEmail}\" || exit 1\n        git config --local user.name \"${gitName}\" || exit 1\n        git config --global diff.renames false || exit 1\n        git config --global merge.renames false || exit 1\n        git config --global status.renames false || exit 1\n        git config --global core.quotePath false\n        `;\n\n\tthis.executeCommand(configureGit, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CONFIG, true);\n}\n\nasync function commitAndUpdateEnvironmentBranches(gitDepth, disableEarlyCommitCompletion) {\n\tconst resultData = {};\n\tconst { commitMessage, sourceEnvironmentBranch } = process.env,\n\t\tgitStatus = this.executeCommand(\n\t\t\t'git status --porcelain',\n\t\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS,\n\t\t\ttrue\n\t\t);\n\n\tif (!gitStatus) {\n\t\tresultData.status = 'No Changes';\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COMMIT_INFO, '', 'No Changes');\n\t\tthis.executeCommand(\n\t\t\t`copado -p \"There are no changes to be committed\" -r '${JSON.stringify(resultData)}'`,\n\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\ttrue\n\t\t);\n\t\tif (resultViewerJson?.length) {\n\t\t\tthis.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n\t\t}\n\t\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.GIT_MERGE_PUSH_FEATURE_BRANCH, processes);\n\t\tprocess.exit(0);\n\t} else {\n\t\tthis.logger('START Commit and Push feature branch');\n\t\tconst filesToStage = this.getFilePaths(COMMIT_CHANGES_FILE_PATH);\n\t\tthis.gitCommit(commitMessage, featureBranch, filesToStage, false);\n\t\tthis.gitPush(featureBranch);\n\t\tthis.logger('END Commit and Push feature branch');\n\n\t\tresultData.commitId = this.getCommitId();\n\t\tdisableEarlyCommitCompletion?.toLowerCase() === 'true'\n\t\t\t? this.updateResultWithCommitDetails(resultData)\n\t\t\t: await this.finishCommit(true, true, 'Commit Completed, Environment branches will be merged in the background', resultData);\n\t\tthis.executeAfterCommitOperations(sourceEnvironmentBranch, featureBranch, gitDepth, 0);\n\t}\n}\n\nfunction finishCommit(isFinished, isSuccess, progressStatus, resultData) {\n\tthis.logger('START Early Finish Commit');\n\treturn new Promise(resolve => {\n\t\tconst CF_SF_SESSIONID = process.env.CF_SF_SESSIONID;\n\t\tconst CF_SF_ENDPOINT = process.env.CF_SF_ENDPOINT.replace('https://', '');\n\n\t\tconst body = JSON.stringify({\n\t\t\tresult_id: process.env.CF_RESULTID,\n\t\t\tis_finished: isFinished,\n\t\t\tis_success: isSuccess,\n\t\t\tstatus: progressStatus,\n\t\t\tresult_data: JSON.stringify(resultData)\n\t\t});\n\n\t\tconst options = {\n\t\t\thostname: CF_SF_ENDPOINT,\n\t\t\tpath: '/services/apexrest/copado/FunctionWebEvent',\n\t\t\tmethod: 'POST',\n\t\t\theaders: {\n\t\t\t\t'Content-Type': 'application/json',\n\t\t\t\tAccept: 'application/json',\n\t\t\t\t'Content-Length': Buffer.byteLength(body),\n\t\t\t\tAuthorization: `Bearer ${CF_SF_SESSIONID}`\n\t\t\t}\n\t\t};\n\n\t\tconst req = https.request(options, res => {\n\t\t\tres.on('data', () => {\n\t\t\t\t// on 'data' listener is mandatory to be added.\n\t\t\t});\n\t\t\tres.on('end', () => {\n\t\t\t\tthis.logger(`Status Code: ${res.statusCode}`);\n\t\t\t\tif (res.statusCode == 200) {\n\t\t\t\t\tthis.logger('END Early Finish Commit');\n\t\t\t\t\tresolve(body);\n\t\t\t\t} else {\n\t\t\t\t\tthis.updateResultWithCommitDetails(resultData);\n\t\t\t\t\tthis.logger('END Early Finish Commit');\n\t\t\t\t\tresolve(body);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\n\t\treq.on('error', error => {\n\t\t\tthis.updateResultWithCommitDetails(resultData);\n\t\t\tthis.logger(`error: ${error}`);\n\t\t\tthis.logger('END Early Finish Commit');\n\t\t\tresolve(body);\n\t\t});\n\n\t\treq.write(body);\n\t\treq.end();\n\t});\n}\n\nfunction executeAfterCommitOperations(sourceEnvironmentBranch, featureBranch, gitDepth, numberOfRetries) {\n\tthis.logger('START Merge feature branch in source environment branch');\n\ttry {\n\t\tthis.executeCommand(\n\t\t\t`\n        git reset --hard || true\n        git clean -fd || true`,\n\t\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_CLEAN,\n\t\t\ttrue\n\t\t);\n\t\tthis.executeCommand(\n\t\t\tthis.fetchCheckoutBranch(sourceEnvironmentBranch, gitDepth, false),\n\t\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_CHECKOUT,\n\t\t\ttrue\n\t\t);\n\t\tthis.mergeFeatureBranchInSource(featureBranch, sourceEnvironmentBranch);\n\t\tthis.checkSFDXProjectJson(sourceEnvironmentBranch, sourceApiVersion);\n\t\tthis.gitPush(sourceEnvironmentBranch);\n\t} catch (error) {\n\t\tif (numberOfRetries < 1) {\n\t\t\tthis.executeAfterCommitOperations(sourceEnvironmentBranch, featureBranch, gitDepth, numberOfRetries + 1);\n\t\t} else {\n\t\t\tthis.executeCommand(this.getErrorCmdString(error.message));\n\t\t}\n\t}\n\n\tthis.logger('END Merge feature branch in source environment branch');\n}\n\nfunction mergeFeatureBranchInSource(featureBranch, sourceEnvironmentBranch) {\n\tif (!sourceEnvironmentBranch) {\n\t\tthrow new Error('No source environment branch provided');\n\t}\n\n\ttry {\n\t\tconst mergeFeatureBranchInSource = `git merge \"${featureBranch}\" -Xignore-space-change`;\n\t\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.GIT_MERGE_PUSH_FEATURE_BRANCH, processes);\n\t\tthis.executeCommand(mergeFeatureBranchInSource, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_MERGE, true);\n\t} catch (error) {\n\t\tconst gitStatus = this.executeCommand(\n\t\t\t'git status --porcelain=v1',\n\t\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS,\n\t\t\ttrue\n\t\t);\n\t\t// Logging git status for debugging\n\t\tthis.logger(gitStatus);\n\t\tfs.writeFileSync(GIT_STATUS_FILE_PATH, gitStatus);\n\t\tif (this.hasConflict()) {\n\t\t\tfs.writeFileSync(OUTPUT_JSON_FILE_PATH, '');\n\t\t\tthis.asyncCopadoLogMessage('Resolving git conflicts');\n\t\t\tthis.executeCommand(\n\t\t\t\t`copado-merge ${TARGET_DIRECTORY} ${COMMIT_CHANGES_FILE_PATH} -p ${GIT_STATUS_FILE_PATH} -t sfdx -c --out ${TEMP_DIRECTORY}/`,\n\t\t\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.COPADO_MERGE\n\t\t\t);\n\t\t} else {\n\t\t\tthrow new Error(error);\n\t\t}\n\t}\n\n\tthis.gitCommit(\n\t\t`Merging ${featureBranch} into ${sourceEnvironmentBranch} after auto conflict resolution`,\n\t\tsourceEnvironmentBranch,\n\t\tundefined,\n\t\ttrue\n\t);\n}\n\nfunction hasConflict() {\n\tlet hasConflict = false;\n\tconst gitStatus = fs.readFileSync(GIT_STATUS_FILE_PATH, 'utf-8');\n\tif (gitStatus) {\n\t\tconst porcelainStatus = gitStatus.split('\\n').map(str => str.split(' ')?.[0]);\n\t\thasConflict = porcelainStatus.some(status => {\n\t\t\tif (\n\t\t\t\t(status[0] && status[1] && status[0] === PORCELAIN_STATUS.ADDED && status[1] === PORCELAIN_STATUS.ADDED) ||\n\t\t\t\t(status[0] === PORCELAIN_STATUS.DELETED && status[1] === PORCELAIN_STATUS.DELETED)\n\t\t\t) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn status[0] === PORCELAIN_STATUS.UNMERGED || status[1] === PORCELAIN_STATUS.UNMERGED;\n\t\t});\n\t}\n\treturn hasConflict;\n}\n\nfunction getCommitId() {\n\treturn this.executeCommand('git rev-parse HEAD', RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_FIND_COMMIT_ID, true);\n}\n\nfunction gitPush(branchName) {\n\tthis.asyncCopadoLogMessage(`Pushing all changes to ${branchName}`);\n\tconst gitPush = `git push origin \"${branchName}\"`;\n\tthis.executeCommand(gitPush, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_PUSH, true);\n}\n\nfunction getErrorCmdString(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `copado -p \"Error\" -e ${JSON.stringify(error?.trim()?.substring(0, 32760) + '; ' + suffix)}`;\n}\n\nfunction readFromPath(filePath) {\n\tif (!fs.existsSync(filePath)) {\n\t\tthrow new Error(`Could not find file at path: ${filePath}`);\n\t}\n\tconst data = fs.readFileSync(filePath, 'utf-8');\n\tlet result;\n\ttry {\n\t\tresult = JSON.parse(data);\n\t} catch (err) {\n\t\tthrow new Error(`Content at ${filePath} is not a valid JSON`);\n\t}\n\treturn result;\n}\n\nfunction getFilePaths(changeFilePath, actions, categories) {\n\tlet changeList = this.readFromPath(changeFilePath);\n\tlet filePaths = new Set();\n\tif (actions?.length || categories?.length) {\n\t\tchangeList = changeList.filter(change => {\n\t\t\tlet isValid = true;\n\t\t\tif (actions?.length) {\n\t\t\t\tisValid = isValid && actions.includes(change.a.toLowerCase());\n\t\t\t}\n\t\t\tif (categories?.length) {\n\t\t\t\tisValid = isValid && categories?.includes(change.c.toLowerCase());\n\t\t\t}\n\t\t\treturn isValid;\n\t\t});\n\t}\n\tchangeList.forEach(change => {\n\t\tif (change.j && change.j !== '') {\n\t\t\tconst jsonAdditionalInfo = JSON.parse(change.j);\n\t\t\tlet filesToBeAdded = jsonAdditionalInfo?.filePath?.filter(file => fs.existsSync(file) && fs.statSync(file).isFile());\n\t\t\tconst deletedFiles = jsonAdditionalInfo?.deleteFilesFromGit;\n\t\t\tif (deletedFiles?.length) {\n\t\t\t\tthis.logger(`Deleted files to be staged : ${deletedFiles}`);\n\t\t\t\tfilesToBeAdded.push(...deletedFiles);\n\t\t\t}\n\n\t\t\tif (change.t.toLowerCase() == TYPES.CUSTOM_OBJECT && change.a.toLowerCase() == ACTIONS.FULL) {\n\t\t\t\tconst filePath = filesToBeAdded[0];\n\t\t\t\tconst dirPath = filePath.substring(0, filePath.lastIndexOf('/'));\n\t\t\t\tfilesToBeAdded = [dirPath];\n\t\t\t}\n\t\t\tif (change.c.toLowerCase() !== CATEGORY.VLOCITY && change.a.toLowerCase() === ACTIONS.DELETE) {\n\t\t\t\tfilesToBeAdded = [\n\t\t\t\t\t...jsonAdditionalInfo.deleteMapping.cascadeLocators,\n\t\t\t\t\t...jsonAdditionalInfo.deleteMapping.nestedComponents.reduce((result, cmp) => {\n\t\t\t\t\t\tresult.push(...cmp.cascadeLocators);\n\t\t\t\t\t\treturn result;\n\t\t\t\t\t}, [])\n\t\t\t\t];\n\t\t\t}\n\t\t\tif (filesToBeAdded) {\n\t\t\t\tfilePaths = new Set([...filePaths, ...filesToBeAdded]);\n\t\t\t}\n\t\t}\n\t});\n\treturn [...filePaths];\n}\n\nfunction discardRetrieveOnlyFiles(commitChanges) {\n\tthis.logger('START Discard retrieve only files');\n\tif (commitChanges.Sfdx.retrieveOnly?.length) {\n\t\tconst addOnlyFiles = this.getFilePaths(COMMIT_CHANGES_FILE_PATH, [ACTIONS.ADD, ACTIONS.SELECTIVE_COMMIT], [CATEGORY.SFDX]);\n\t\tconst retrieveOnlyFiles = this.getFilePaths(COMMIT_CHANGES_FILE_PATH, [ACTIONS.RETRIEVE_ONLY], [CATEGORY.SFDX]);\n\t\tconst filesToDiscard = retrieveOnlyFiles.filter(item => !addOnlyFiles.includes(item));\n\t\tfilesToDiscard.length > 0 ? this.discardFilesInGit(filesToDiscard) : console.debug('No files to discard');\n\t}\n\tthis.logger('END Discard retrieve only files');\n}\n\nfunction getUntrackedFiles() {\n\tconst untrackedFiles = this.executeCommand(\n\t\t'git ls-files --others --exclude-standard',\n\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_LIST_UNTRACKED_FILES\n\t)\n\t\t?.split('\\n')\n\t\t?.map(file => file?.trim())\n\t\t?.filter(file => file != '');\n\treturn untrackedFiles;\n}\n\nfunction executeCommandinChunks(fileList, chunkSize, cmd, cmdInfo) {\n\tif (fileList.length > 0) {\n\t\tlet fileIndex = 0;\n\t\tdo {\n\t\t\tlet endIndex = fileIndex + parseInt(chunkSize) > fileList.length ? fileList.length : fileIndex + parseInt(chunkSize);\n\t\t\tlet fileChunk = fileList.slice(fileIndex, endIndex);\n\t\t\tthis.executeCommand(\n\t\t\t\tcmd.replace(/REPLACE_VALUE/g, fileChunk.map(file => `'${file}'`).join(' ')),\n\t\t\t\tcmdInfo?.category,\n\t\t\t\tcmdInfo?.additionalInfo,\n\t\t\t\ttrue\n\t\t\t);\n\t\t\tfileIndex = endIndex;\n\t\t} while (fileIndex < fileList.length);\n\t}\n}\n\nfunction discardFilesInGit(fileList) {\n\tconst unTrackedFiles = this.getUntrackedFiles();\n\tconst toBeCleanedFiles = fileList.filter(file => unTrackedFiles.includes(file));\n\tconst trackedFiles = fileList.filter(file => !toBeCleanedFiles.includes(file));\n\ttoBeCleanedFiles?.length &&\n\t\tthis.executeCommandinChunks(toBeCleanedFiles, chunkSize, 'git clean -fd REPLACE_VALUE', {\n\t\t\tcategory: RESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\tadditionalInfo: RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CLEAN\n\t\t});\n\ttrackedFiles?.length &&\n\t\tthis.executeCommandinChunks(trackedFiles, chunkSize, '( git checkout HEAD -- REPLACE_VALUE ) || true', {\n\t\t\tcategory: RESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\tadditionalInfo: RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CHECKOUT\n\t\t});\n}\n\nfunction executeCommand(command, category, additionalInfo, disableMetrics, hasJsonResponse, disableLogs) {\n\tif (!disableMetrics) {\n\t\tthis.startWatch(category, additionalInfo, processes);\n\t}\n\tlet errorMessage;\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.log(response, disableLogs);\n\tif (!disableMetrics) {\n\t\tthis.endWatch(additionalInfo, processes);\n\t}\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tif (!disableMetrics) {\n\t\t\tthis.endWatch(additionalInfo, processes);\n\t\t}\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n\t\tconst truncatedError = JSON.stringify(\n\t\t\terrorMessage\n\t\t\t\t.split('\\n')\n\t\t\t\t.filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n\t\t\t\t.join(' ')\n\t\t);\n\t\tthrow new CommandExecutionError(truncatedError, category, additionalInfo);\n\t}\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(maxBuffer)\n\t};\n\treturn options;\n}\n\nfunction getApiVersion(overriddenApiVersion, apiVersion) {\n\tconst finalApiVersion = overriddenApiVersion || apiVersion;\n\tconst regExpApiVersion = /\\d\\d\\.0/;\n\tif (!regExpApiVersion.test(finalApiVersion)) {\n\t\tthis.executeCommand(this.getErrorCmdString(`Invalid API Version: ${finalApiVersion}`));\n\t\tprocess.exit(1);\n\t}\n\treturn finalApiVersion;\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction uploadFile(filePath, name) {\n\tchild_process.exec(`copado --uploadfile ${filePath} ${name ? '--name ' + name : ''}`, this.options(), (error, stdout, stderr) => {\n\t\tthis.handleResponse(\n\t\t\terror,\n\t\t\t{ stdout, stderr },\n\t\t\t{ category: RESULT_INFO.CATEGORY.COPADO_SERVICE, additionalInfo: RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES }\n\t\t);\n\t});\n}\n\nfunction downloadFile(fileId, downloadDir) {\n\treturn `copado --downloadfiles ${fileId} --downloaddir ${downloadDir}`;\n}\n\nfunction validateCommitId(commitId) {\n\tif (commitId) {\n\t\tthis.updateResultWithCommitDetails({ commitId });\n\t\tif (resultViewerJson?.length) {\n\t\t\tthis.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n\t\t}\n\t\tprocess.exit(0);\n\t}\n}\n\nfunction updateResultWithCommitDetails(resultData) {\n\tthis.populateResultViewer(RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COMMIT_INFO, '', `Commit Id : ${resultData?.commitId}`);\n\tthis.executeCommand(`copado -p 'Saving commit details' --result-data '${JSON.stringify(resultData)}'`);\n}\n\nfunction getGitDepth(gitDepth) {\n\tgitDepth = parseInt(gitDepth);\n\treturn gitDepth >= 0 ? gitDepth : 100;\n}\n\nfunction fetchCheckoutBranch(branch, gitDepth, forceCreate) {\n\treturn `( git fetch origin ${branch} --depth ${gitDepth} && git checkout ${branch} )` + (forceCreate ? ` || git checkout -b ${branch}` : '');\n}\n\nfunction log(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tconsole.log(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tconsole.log(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction copyFiles(source, target) {\n\tchild_process.execSync(`cp -R ${source} ${target}`, { stdio: STDIO.INHERIT });\n}\n\nfunction asyncCopadoLogMessage(msg, logLevel) {\n\tif (msg) {\n\t\tthis.populateResultViewer(logLevel ? logLevel : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n\t\tnew Promise(resolve => {\n\t\t\tchild_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, () => {\n\t\t\t\tresolve();\n\t\t\t});\n\t\t});\n\t}\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n\tif (message) {\n\t\tresultViewerJson.push({\n\t\t\tLevel: level,\n\t\t\tCategory: category,\n\t\t\tAdditionalInformation: additionalInfo,\n\t\t\tMessage: message\n\t\t});\n\t}\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n\tconst RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n\tconst fileContent = { data, columns, header, headerIcon };\n\tfs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n\tthis.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n\tnew Promise((resolve, reject) => {\n\t\tchild_process.exec(`copado --uploadfile ${filePath}`, {}, err => {\n\t\t\tif (err) {\n\t\t\t\tthis.populateResultViewer(\n\t\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES,\n\t\t\t\t\terr\n\t\t\t\t);\n\t\t\t\treject(new CommandExecutionError(err, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES));\n\t\t\t} else {\n\t\t\t\tresolve();\n\t\t\t}\n\t\t});\n\t});\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nfunction buildManifest(changesList) {\n\tconst manifestFileName = `${TARGET_DIRECTORY}/${COPADO_RETRIEVE_XML}`;\n\t// Create Map\n\tlet metadataByType = new Map();\n\tchangesList.forEach(change => {\n\t\tif (!metadataByType.has(change.t)) {\n\t\t\tmetadataByType.set(change.t, new Set());\n\t\t}\n\t\tmetadataByType.get(change.t).add(change.n);\n\t});\n\n\t// Create manifest file\n\tlet manifest = [];\n\tmanifest.push('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\" ?>\\n');\n\tmanifest.push('<Package xmlns=\"http://soap.sforce.com/2006/04/metadata\">\\n');\n\tmetadataByType.forEach((value, key) => {\n\t\tif (value && key) {\n\t\t\tmanifest.push('\\t<types>\\n');\n\t\t\tvalue.forEach(item => {\n\t\t\t\tmanifest.push(`\\t\\t<members>${item}</members>\\n`);\n\t\t\t});\n\n\t\t\tmanifest.push(`\\t\\t<name>${key}</name>\\n`);\n\t\t\tmanifest.push('\\t</types>\\n');\n\t\t}\n\t});\n\n\tmanifest.push(`\\t<version>${sourceApiVersion}</version>\\n`);\n\tmanifest.push('</Package>\\n');\n\n\tfs.writeFileSync(manifestFileName, manifest.join(''));\n}\n\nfunction startWatch(processType, processName, processes) {\n\tif (!processName || !processType) {\n\t\treturn;\n\t}\n\tconst startTime = process.hrtime();\n\tif (!totalTimeByType[processType]) {\n\t\ttotalTimeByType[processType] = 0;\n\t}\n\tprocesses.push({ name: processName, type: processType, startTime, endTime: null, elapsedTime: null });\n}\n\nfunction endWatch(processType, processes) {\n\tif (!processType) {\n\t\treturn;\n\t}\n\tconst processIndex = processes.length;\n\tif (!processIndex && processes[processIndex - 1].type !== processType) {\n\t\t// we call endWatch in sync with startwatch for same process & doesnt overlap with others endWatch. additionally checking that it belongs to the same processType in the processes index before we store it.\n\t\tconsole.error(`Process '${processType}' not started.`);\n\t\treturn;\n\t}\n\tconst endTime = process.hrtime();\n\tconst elapsedTime = process.hrtime(processes[processIndex - 1].startTime);\n\tprocesses[processIndex - 1].endTime = endTime;\n\tprocesses[processIndex - 1].elapsedTime = elapsedTime[0] * 1e9 + elapsedTime[1];\n}\n\nfunction printMetrics() {\n\tlet ux = new Ux();\n\tthis.logger('\\n');\n\tux.styledHeader('====================      OVERALL METRICS      ====================');\n\tconst resultData = [];\n\tprocesses.forEach(process => {\n\t\t// store data\n\t\tresultData.push({\n\t\t\tprocessType: '| ' + process.type,\n\t\t\tprocessName: '| ' + process.name,\n\t\t\t'startTime(UTC)': process.startTime ? '| ' + this.formatTime(process.startTime) : '| ' + 'N/A',\n\t\t\t'endTime(UTC)': process.endTime ? '| ' + this.formatTime(process.endTime) : '| ' + 'N/A',\n\t\t\telapseTime: process.elapsedTime ? '| ' + `${(process.elapsedTime / 1e9).toFixed(2)} s` + ' |' : '| ' + 'N/A' + ' |'\n\t\t});\n\t\t// Aggregate total time by type\n\t\tif (process.elapsedTime) {\n\t\t\tif (!totalTimeByType[process.type]) {\n\t\t\t\ttotalTimeByType[process.type] = 0;\n\t\t\t}\n\t\t\ttotalTimeByType[process.type] += process.elapsedTime;\n\t\t}\n\t});\n\n\tux.table(resultData, { processType: {}, processName: {}, 'startTime(UTC)': {}, 'endTime(UTC)': {}, elapseTime: {} });\n\tthis.logger('\\n' + '   ====================       EXECUTION SUMMARY      ====================   ');\n\t// Print total aggregate time by type\n\tObject.entries(totalTimeByType).forEach(([type, totalTime]) => {\n\t\tthis.logger(`${type} Total Time: ${(totalTime / 1e9).toFixed(2)} seconds`);\n\t});\n\tthis.logger('   ====================       EXECUTION SUMMARY      ====================   ' + '\\n');\n}\n\nfunction formatTime(time) {\n\tconst date = new Date(time[0] * 1000 + time[1] / 1e6);\n\tconst hours = date.getUTCHours().toString().padStart(2, '0');\n\tconst minutes = date.getUTCMinutes().toString().padStart(2, '0');\n\tconst seconds = date.getUTCSeconds().toString().padStart(2, '0');\n\tconst milliseconds = date.getUTCMilliseconds().toString().padStart(3, '0');\n\treturn `${hours}:${minutes}:${seconds}.${milliseconds}`;\n}\n\nfunction getMetadataReconcilerRequest(profiles, operation) {\n\tconst request = new CopaReconcilerInput();\n\trequest.repositoryPath = TARGET_DIRECTORY;\n\trequest.accessToken = sourceSessionId;\n\trequest.instanceUrl = this.getInstanceUrl(sourceEndPoint);\n\trequest.jsonOutputPath = TEMP_DIRECTORY;\n\trequest.profiles = profiles;\n\trequest.operation = operation;\n\treturn request;\n}\n\nfunction getInstanceUrl(instanceUrl) {\n\treturn instanceUrl?.substring(0, instanceUrl?.indexOf('/', instanceUrl?.indexOf('/') + 2));\n}\n\nfunction uploadSelectiveCommitFileOnResult(selectiveCommitFilePath, hash) {\n\tconst hashCommitFile = `${hash}_${SELECTIVE_COMMIT_SUFFIX.COMMIT}`;\n\tthis.uploadFile(selectiveCommitFilePath, hashCommitFile);\n}\n\nfunction getSelectiveCommitFile(metadataTypeAndName, selectiveCommitHash) {\n\tlet result = '';\n\tif (fs.existsSync(`${TEMP_DIRECTORY}/${selectiveCommitHash}_${SELECTIVE_COMMIT_SUFFIX.SESSION}`)) {\n\t\tresult = `${TEMP_DIRECTORY}/${selectiveCommitHash}_${SELECTIVE_COMMIT_SUFFIX.SESSION}`;\n\t} else if (fs.existsSync(`${TEMP_DIRECTORY}/${selectiveCommitHash}_${SELECTIVE_COMMIT_SUFFIX.COMMIT}`)) {\n\t\tresult = `${TEMP_DIRECTORY}/${selectiveCommitHash}_${SELECTIVE_COMMIT_SUFFIX.COMMIT}`;\n\t} else {\n\t\tthrow new Error(`Failed to find the Selected Changes for ${metadataTypeAndName}`);\n\t}\n\treturn result;\n}\n\n// INNER CLASS\nclass CommandExecutionError extends Error {\n\tconstructor(message, category, additionalInfo) {\n\t\tsuper(`${category ? category + ' - ' : ''}${additionalInfo ? additionalInfo + ' : ' : ''}${message}`);\n\t\tthis.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n\t}\n}\n\nmodule.exports.encodeFileNames = encodeFileNames;\nmodule.exports.getCommitChanges = getCommitChanges;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.discardFilesInGit = discardFilesInGit;\nmodule.exports.getUntrackedFiles = getUntrackedFiles;\nmodule.exports.executeCommandinChunks = executeCommandinChunks;\nmodule.exports.discardRetrieveOnlyFiles = discardRetrieveOnlyFiles;\nmodule.exports.getFilePaths = getFilePaths;\nmodule.exports.readFromPath = readFromPath;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.gitPush = gitPush;\nmodule.exports.getCommitId = getCommitId;\nmodule.exports.commitAndUpdateEnvironmentBranches = commitAndUpdateEnvironmentBranches;\nmodule.exports.processMetadata = processMetadata;\nmodule.exports.gitCommit = gitCommit;\nmodule.exports.findAndReplace = findAndReplace;\nmodule.exports.execute = execute;\nmodule.exports.fetchCreateFeatureBranch = fetchCreateFeatureBranch;\nmodule.exports.getFilesInScope = getFilesInScope;\nmodule.exports.varReplace = varReplace;\nmodule.exports.retrieveOrgMetadata = retrieveOrgMetadata;\nmodule.exports.retrieveFullProfile = retrieveFullProfile;\nmodule.exports.sfdxRetrieve = sfdxRetrieve;\nmodule.exports.configureSFDXCLI = configureSFDXCLI;\nmodule.exports.checkSFDXProjectJson = checkSFDXProjectJson;\nmodule.exports.setup = setup;\nmodule.exports.checkNestedParentMetadataDeletion = checkNestedParentMetadataDeletion;\nmodule.exports.prepareMetadataChangesList = prepareMetadataChangesList;\nmodule.exports.configureGit = configureGit;\nmodule.exports.getApiVersion = getApiVersion;\nmodule.exports.validateCommittedChanges = validateCommittedChanges;\nmodule.exports.uploadFile = uploadFile;\nmodule.exports.downloadFile = downloadFile;\nmodule.exports.mergeFeatureBranchInSource = mergeFeatureBranchInSource;\nmodule.exports.validateCommitId = validateCommitId;\nmodule.exports.updateResultWithCommitDetails = updateResultWithCommitDetails;\nmodule.exports.initialSetup = initialSetup;\nmodule.exports.handleResponse = handleResponse;\nmodule.exports.createTargetDirectoryAndFetchBaseBranch = createTargetDirectoryAndFetchBaseBranch;\nmodule.exports.options = options;\nmodule.exports.changeWorkingDirectory = changeWorkingDirectory;\nmodule.exports.enrichChangeList = enrichChangeList;\nmodule.exports.getEnrichServiceCommand = getEnrichServiceCommand;\nmodule.exports.getGitDepth = getGitDepth;\nmodule.exports.fetchCheckoutBranch = fetchCheckoutBranch;\nmodule.exports.hasConflict = hasConflict;\nmodule.exports.log = log;\nmodule.exports.copyFiles = copyFiles;\nmodule.exports.getSFChanges = getSFChanges;\nmodule.exports.finishCommit = finishCommit;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.executeAfterCommitOperations = executeAfterCommitOperations;\nmodule.exports.updateCommitChangeFileWithProfilePaths = updateCommitChangeFileWithProfilePaths;\nmodule.exports.getOptions = getOptions;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.logger = logger;\nmodule.exports.buildManifest = buildManifest;\nmodule.exports.startWatch = startWatch;\nmodule.exports.endWatch = endWatch;\nmodule.exports.formatTime = formatTime;\nmodule.exports.printMetrics = printMetrics;\nmodule.exports.getInstanceUrl = getInstanceUrl;\nmodule.exports.getMetadataReconcilerRequest = getMetadataReconcilerRequest;\nmodule.exports.updateSelectiveCommitFiles = updateSelectiveCommitFiles;\nmodule.exports.uploadSelectiveCommitFileOnResult = uploadSelectiveCommitFileOnResult;\nmodule.exports.getSelectiveCommitFile = getSelectiveCommitFile;\n// EXECUTION\n\n!isTest && this.execute(commitChanges);",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0l7Q000000iAiLQAU",
                    "LastReferencedDate": "2023-12-12T07:48:39.000+0000",
                    "LastViewedDate": "2023-12-12T07:48:39.000+0000",
                    "Name": "Commit"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q000000iAiMQAU"
                    },
                    "copado__API_Name__c": "sfdx_promote",
                    "copado__Callback_Type__c": "Flow",
                    "copado__Description__c": "Creation of Promotion Branch and Promotion of user stories",
                    "copado__FlowHandler__c": "cmcSf.Update_Conflict_Resolution_File",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"userStoryBranches\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.userStoryBranches}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"promotionBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.promotionBranchName}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"targetBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.destinationBranchName}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"tag\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.Promotion__r.Release__r.Version__c}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"recreatePromotionBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.Promotion__r.cmcSf__Recreate_Promotion_Branch__c}\"\n}, {\n  \"name\" : \"promotionId\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.Id}\"\n}, {\n  \"name\" : \"fileChangesId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"\n}, {\n  \"name\" : \"conflictResolutionAttachments\",\n  \"defaultValue\" : \"{$Context.apex.GetConflictResolutionAttachments}\"\n}, {\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"name\" : \"repositoryId\",\n  \"defaultValue\" : \"{$Pipeline.Git_Repository__r.Id}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"gitDepth\",\n  \"defaultValue\" : \"{$Pipeline.Property.gitDepth_promote}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"required\" : true,\n  \"name\" : \"fileName\",\n  \"defaultValue\" : \"Copado Promotion changes\"\n}, {\n  \"name\" : \"overriddenApiVersion\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"disableXMLDeDuplication\",\n  \"defaultValue\" : \"{$Pipeline.Property.DisableXMLDeDuplication}\"\n}]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n/**\n * Performs promotion of selected user story metadata changes.\n * Returns (If ACTION success) new peomotion branch in user repo with all the changes\n * (If ACTION failed) Returns details with conflict or error status on promotion record\n * @param userStoryBranches\n * @param promotionBranch\n * @param targetBranch\n * @param tag\n * @param recreatePromotionBranch\n * @param promotionId\n * @param fileChangesId\n * @param conflictResolutionAttachments\n * @param gitName\n * @param gitEmail\n * @param repositoryId\n * @param gitDepth\n * @param maxBuffer\n */\n\nconst child_process = require('child_process'),\n\t{ existsSync, readFileSync, writeFileSync } = require('fs'),\n\tprocess = require('process');\n\nconst {\n\t\tfileChangesId,\n\t\ttargetBranch,\n\t\tpromotionBranch,\n\t\tgitDepth,\n\t\tgitEmail,\n\t\tgitName,\n\t\tpromotionId,\n\t\trepositoryId,\n\t\tconflictResolutionAttachments,\n\t\tuserStoryBranches,\n\t\ttag,\n\t\trecreatePromotionBranch,\n\t\tfileName,\n\t\toverriddenApiVersion,\n\t\tAPI_VERSION,\n\t\tisTest,\n\t\tGIT_BATCH_SIZE,\n\t\tdisableXMLDeDuplication,\n\t\tmaxBuffer\n\t} = process.env,\n\t{ Ux } = isTest ? require('@salesforce/sf-plugins-core') : require('/usr/local/lib/node_modules/@salesforce/sf-plugins-core'),\n\tSTDIO = {\n\t\tINHERIT: 'inherit',\n\t\tPIPE: 'pipe'\n\t},\n\tAPP_DIRECTORY = getPath('/app'),\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tTARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n\tOUTPUT_JSON_PATH = `${TEMP_DIRECTORY}/output.json`,\n\tGIT_STATUS_FILE_PATH = `${TEMP_DIRECTORY}/git_status.txt`,\n\tENRICHED_CHANGE_FILE_PATH = `${TEMP_DIRECTORY}/enrichedPromotionChanges.json`,\n\tVLOCITY_CATEGORY = 'Vlocity',\n\tGIT_DEPTH = getGitDepth(gitDepth),\n\tPORCELAIN_STATUS = {\n\t\tADDED: 'A',\n\t\tDELETED: 'D',\n\t\tUNMERGED: 'U'\n\t},\n\tMETADATA_TYPE = {\n\t\tLAYOUT: 'layout'\n\t},\n\tACTIONS = {\n\t\tADD: 'add',\n\t\tFULL: 'full',\n\t\tSELECTIVE_COMMIT: 'selectivecommit'\n\t},\n\tMAXBUFFER = parseInt(maxBuffer),\n\tCOPADO_INFO_PREFIX = 'CopadoFunction INFO',\n\tRESULT_INFO = {\n\t\tLEVEL: {\n\t\t\tINFO: 'INFO',\n\t\t\tERROR: 'ERROR',\n\t\t\tWARN: 'WARN'\n\t\t},\n\t\tCATEGORY: {\n\t\t\tUNKNOWN_EXCEPTION: 'Unknown Exception',\n\t\t\tCOPADO_INFO: 'Copado Info',\n\t\t\tCOPADO_METADATA_INTELLIGENCE: 'Copado Metadata Intelligence',\n\t\t\tGIT: 'Git',\n\t\t\tCOPADO_SERVICE: 'Copado Service',\n\t\t\tFILE_SYSTEM: 'File System',\n\t\t\tGIT_SERVICE: 'Git Service'\n\t\t},\n\t\tADDITIONAL_INFORMATION: {\n\t\t\tGIT_STATUS: 'Git Status',\n\t\t\tGIT_CONFIG: 'Git Configuration',\n\t\t\tPROMOTION_BRANCH_CHECKOUT: 'Promotion Branch Checkout',\n\t\t\tENRICHER_SERVICE: 'Enricher Service',\n\t\t\tCOPADO_MERGE: 'Copado Merge',\n\t\t\tUPLOAD_FILES: 'Upload Files',\n\t\t\tDOWNLOAD_FILES: 'Download Files',\n\t\t\tGIT_MERGE: 'Git Merge',\n\t\t\tGIT_PUSH: 'Git Push',\n\t\t\tGIT_ADD: 'Git Add',\n\t\t\tGIT_CHECKOUT: 'Git Checkout',\n\t\t\tGIT_FETCH: 'Git Fetch',\n\t\t\tGIT_FETCH_BRANCHES: 'Git Fetch Feature Branches',\n\t\t\tGIT_RESET: 'Git Reset',\n\t\t\tGIT_FIND_COMMIT_ID: 'Git Find Commit Id',\n\t\t\tSETUP_DIRECTORY: 'Setup Directory',\n\t\t\tLIST_REMOTE_REFERENCES: 'List Remote References',\n\t\t\tFILE_CREATE: 'File Create'\n\t\t}\n\t},\n\tCUSTOM_ERROR = {\n\t\tCOMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n\t},\n\tRESULT_TABLE_HEADER = {\n\t\tlabel: 'Promote Result',\n\t\tcustomLabel: 'Promote_Result'\n\t},\n\tHEADER_ICON = 'standard:note',\n\tRESULT_TABLE_COLUMNS = [\n\t\t{\n\t\t\tlabel: 'Level',\n\t\t\tfieldName: 'Level',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Level',\n\t\t\tinitialWidth: 80\n\t\t},\n\t\t{\n\t\t\tlabel: 'Category',\n\t\t\tfieldName: 'Category',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Category',\n\t\t\tinitialWidth: 120\n\t\t},\n\t\t{\n\t\t\tlabel: 'Additional Information',\n\t\t\tfieldName: 'AdditionalInformation',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Additional_Information',\n\t\t\tinitialWidth: 200\n\t\t},\n\t\t{\n\t\t\tlabel: 'Message',\n\t\t\tfieldName: 'Message',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Message'\n\t\t}\n\t];\n\nlet executionError,\n\ttotalTimeByType = {},\n\tprocesses = [],\n\tresultViewerJson = [];\n\n// SCRIPT FUNCTIONS\n\nfunction execute() {\n\ttry {\n\t\tconst promotionChangesFilePath = this.getPromotionChanges(fileChangesId, fileName);\n\t\tthis.setUpDirectory(TARGET_DIRECTORY);\n\t\tthis.fetchTargetBranch(targetBranch);\n\t\tthis.configureGit(gitEmail, gitName);\n\t\tthis.fetchCreatePromotionBranch(promotionBranch, recreatePromotionBranch);\n\t\tthis.checkSFDXProjectJson(overriddenApiVersion, API_VERSION);\n\t\tthis.promote(userStoryBranches, promotionChangesFilePath, promotionBranch, promotionId, repositoryId);\n\t\tthis.deduplicateXMLTags(disableXMLDeDuplication, userStoryBranches, promotionChangesFilePath);\n\n\t\tthis.gitPush(tag, promotionBranch);\n\t\tthis.printMetrics();\n\t} catch (err) {\n\t\tthis.logger(`Error stack: ${err.stack}`);\n\t\tif (!(err instanceof CommandExecutionError)) {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, 'See logs for more info', err.message);\n\t\t}\n\t\texecutionError = err.message || err?.toString() || 'Unknown Error occurred';\n\t} finally {\n\t\tif (resultViewerJson?.length) {\n\t\t\tthis.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n\t\t}\n\t\tif (executionError) {\n\t\t\tthis.executeCommand(this.getErrorCommand(executionError));\n\t\t\tprocess.exit(1);\n\t\t}\n\t}\n}\n\nfunction asyncCopadoLogMessage(msg, logLevel) {\n\tif (msg) {\n\t\tthis.populateResultViewer(logLevel ? logLevel : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n\t\tnew Promise(resolve => {\n\t\t\tchild_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, (err, response, stderr) => {\n\t\t\t\tresolve();\n\t\t\t});\n\t\t});\n\t}\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n\tif (message) {\n\t\tresultViewerJson.push({\n\t\t\tLevel: level,\n\t\t\tCategory: category,\n\t\t\tAdditionalInformation: additionalInfo,\n\t\t\tMessage: message\n\t\t});\n\t}\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDirectory__${filePath}` : filePath;\n}\n\nfunction getPromotionChanges(fileChangesId, fileName) {\n\tconsole.log('START getting promotion changes');\n\tthis.executeCommand(\n\t\t`copado --downloadfiles ${fileChangesId} --downloaddir ${TEMP_DIRECTORY}/`,\n\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILES\n\t);\n\tconsole.log('END getting promotion changes');\n\tif (existsSync(`${TEMP_DIRECTORY}/${fileName}`)) {\n\t\treturn `${TEMP_DIRECTORY}/${fileName}`;\n\t} else if (existsSync(`${TEMP_DIRECTORY}/${fileName}.json`)) {\n\t\treturn `${TEMP_DIRECTORY}/${fileName}.json`;\n\t} else {\n\t\tthrow new Error('Error fetching Promotion Changes');\n\t}\n}\n\nfunction setUpDirectory(dir) {\n\tconst cmd = `\n        mkdir -p ${dir}\n    `;\n\tthis.executeCommand(cmd, RESULT_INFO.CATEGORY.FILE_SYSTEM, RESULT_INFO.ADDITIONAL_INFORMATION.SETUP_DIRECTORY);\n\tprocess.chdir(dir);\n}\n\nfunction fetchTargetBranch(targetBranch) {\n\tconsole.log('START fetching target branch');\n\tthis.executeCommand(\n\t\tthis.getRemoteBranchFetchCommand(targetBranch),\n\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_CHECKOUT\n\t);\n\tconsole.log('END fetching target branch');\n}\n\nfunction getRemoteBranchFetchCommand(branch) {\n\treturn `copado-git-get --depth \"${GIT_DEPTH}\" \"${branch}\"`;\n}\n\nfunction fetchCreatePromotionBranch(promotionBranch, recreatePromotionBranch) {\n\tconsole.log('START fetching / creating promotion branch');\n\tlet cmd = '';\n\tif (!promotionBranch) {\n\t\tthrow new Error('Kindly provide a valid promotion branch');\n\t}\n\tif (recreatePromotionBranch === 'true' && this.remotePromotionBranchExists(promotionBranch)) {\n\t\tthis.asyncCopadoLogMessage(`Removing branch ${promotionBranch}`);\n\t\tcmd = `git push origin --delete \"${promotionBranch}\" || exit 1`;\n\t}\n\tthis.asyncCopadoLogMessage(`Fetching/creating branch ${promotionBranch}`);\n\tcmd += `\n        ${this.fetchCheckoutBranch(promotionBranch, true)}\n    `;\n\tthis.executeCommand(cmd, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.PROMOTION_BRANCH_CHECKOUT);\n\tconsole.log('END fetching / creating promotion branch');\n}\n\nfunction remotePromotionBranchExists(promotionBranch) {\n\tconst cmd = `git ls-remote --heads origin ${promotionBranch}`;\n\treturn this.executeCommand(cmd, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.LIST_REMOTE_REFERENCES);\n}\n\nfunction configureGit(gitEmail, gitName) {\n\tthis.executeCommand(\n\t\t`\n        git config --local user.email \"${gitEmail}\" || exit 1\n        git config --local user.name \"${gitName}\" || exit 1\n        git config --global diff.renames false || exit 1\n        git config --global merge.renames false || exit 1\n        git config --global status.renames false || exit 1\n        git config --global core.quotePath false\n    `,\n\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_CONFIG\n\t);\n}\n\nfunction promote(userStoryBranches, promotionChangesFilePath, promotionBranch, promotionId, repositoryId) {\n\tconsole.log('START promote operation');\n\tconst featureBranches = JSON.parse(userStoryBranches);\n\tthis.fetchFeatureBranches(featureBranches);\n\tlet gitConflictsResolution = [];\n\tconsole.log('START Merging branches into Promotion branch');\n\tfor (let story of featureBranches) {\n\t\tthis.checkoutFeatureAndPromotionBranch(story, promotionBranch);\n\t\ttry {\n\t\t\tthis.mergeFeatureBranchInPromotionBranch(story, promotionBranch);\n\t\t} catch (error) {\n\t\t\twriteFileSync(\n\t\t\t\tGIT_STATUS_FILE_PATH,\n\t\t\t\tthis.executeCommand('git status --porcelain=v1', RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS)\n\t\t\t);\n\t\t\tif (this.hasConflict()) {\n\t\t\t\tthis.asyncCopadoLogMessage('Resolving conflicts');\n\t\t\t\tgitConflictsResolution.push(...this.handleConflicts(promotionChangesFilePath, promotionId, repositoryId, story, promotionBranch));\n\t\t\t} else {\n\t\t\t\tthrow new Error(error);\n\t\t\t}\n\t\t}\n\t}\n\tconsole.log('END Merging branches into Promotion branch');\n\tconsole.log('END promote operation');\n\tthis.uploadGitConflictsResolution(gitConflictsResolution);\n}\n\nfunction fetchFeatureBranches(userStoryBranches) {\n\tconsole.log('START fetch feature branches');\n\tthis.startWatch(RESULT_INFO.CATEGORY.GIT_SERVICE,RESULT_INFO.ADDITIONAL_INFORMATION.GIT_FETCH_BRANCHES,processes);\n\tconst chunkSize = GIT_BATCH_SIZE ? parseInt(GIT_BATCH_SIZE) : 10;\n\tif (userStoryBranches.length > 0) {\n\t\tlet index = 0;\n\t\tdo {\n\t\t\tconst endIndex = index + chunkSize > userStoryBranches.length ? userStoryBranches.length : index + chunkSize;\n\t\t\tconst branches = userStoryBranches.slice(index, endIndex);\n\t\t\tthis.executeCommand(\n\t\t\t\tthis.buildFetchFeatureBranchesCommand(branches),\n\t\t\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_FETCH,true\n\t\t\t);\n\t\t\tindex = endIndex;\n\t\t} while (index < userStoryBranches.length);\n\t}\n\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.GIT_FETCH_BRANCHES,processes);\n\tconsole.log('END fetch feature branches');\n}\n\nfunction buildFetchFeatureBranchesCommand(userStoryBranches) {\n\treturn `git fetch origin ${userStoryBranches.map(branch => `'${branch}'`).join(' ')} --depth ${GIT_DEPTH}`;\n}\n\nfunction checkoutFeatureAndPromotionBranch(userStoryBranch, promotionBranch) {\n\tconst checkoutFeatureAndPromotionBranch = `\n        git checkout \"${userStoryBranch}\" || exit 1\n        git checkout \"${promotionBranch}\"\n    `;\n\tthis.executeCommand(checkoutFeatureAndPromotionBranch, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CHECKOUT);\n}\n\nfunction mergeFeatureBranchInPromotionBranch(userStoryBranch, promotionBranch) {\n\tthis.executeCommand(\n\t\t`git merge -m \"Merging ${userStoryBranch} to ${promotionBranch}\" \"${userStoryBranch}\" -Xignore-space-change`,\n\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_MERGE\n\t);\n}\n\nfunction handleConflicts(promotionChangesFilePath, promotionId, repositoryId, userStoryBranch, promotionBranch) {\n\tlet output;\n\tlet gitConflictsResolution = [];\n\tthis.resolveConflict(userStoryBranch.split('/')[1], promotionChangesFilePath, promotionId, repositoryId);\n\tif (existsSync(OUTPUT_JSON_PATH)) {\n\t\toutput = JSON.parse(readFileSync(OUTPUT_JSON_PATH, 'utf8'));\n\t\tif (output?.some(file => file.strategy === 'ONLINE_CONFLICT_RESOLUTION')) {\n\t\t\tconst CONFLICT_MESSAGE = `Conflict found while merging ${userStoryBranch} to ${promotionBranch}. Conflict needs to be resolved manually.`;\n\t\t\t//reseting the conflicted files to reuse the volume later in the same promotion\n\t\t\tthis.executeCommand('git reset --hard || true', RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_RESET);\n\t\t\tthis.executeCommand(`copado -p '${CONFLICT_MESSAGE}' -r '{\"status\": \"conflicts\"}'`, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_MERGE);\n\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_MERGE, CONFLICT_MESSAGE);\n\t\t\tthrow new CommandExecutionError(CONFLICT_MESSAGE, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_MERGE);\n\t\t}\n\t}\n\tthis.gitCommit(`Merging ${userStoryBranch} to ${promotionBranch} after auto conflict resolution`);\n\tif (output?.length) {\n\t\tgitConflictsResolution.push(...this.saveMergeCommitId(output));\n\t}\n\treturn gitConflictsResolution;\n}\n\nfunction uploadGitConflictsResolution(gitConflictsResolution) {\n\tconsole.log('START Uploading conflict resolution');\n\tif (gitConflictsResolution?.length) {\n\t\tconst conflictResolutionsFilePath = `${TEMP_DIRECTORY}/GitConflictsResolution.json`;\n\t\twriteFileSync(conflictResolutionsFilePath, JSON.stringify(gitConflictsResolution, null, 2));\n\t\tthis.executeCommand(\n\t\t\t`copado --uploadfile ${conflictResolutionsFilePath}`,\n\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES\n\t\t);\n\t}\n\tconsole.log('END Uploading conflict resolution');\n}\n\nfunction hasConflict() {\n\tlet hasConflict = false;\n\tconst gitStatus = readFileSync(GIT_STATUS_FILE_PATH, 'utf-8');\n\tconsole.log(gitStatus);\n\tif (gitStatus) {\n\t\tconst porcelainStatus = gitStatus.split('\\n').map(str => str.split(' ')?.[0]);\n\t\thasConflict = porcelainStatus.some(status => {\n\t\t\tif (\n\t\t\t\t(status[0] && status[1] && status[0] === PORCELAIN_STATUS.ADDED && status[1] === PORCELAIN_STATUS.ADDED) ||\n\t\t\t\t(status[0] === PORCELAIN_STATUS.DELETED && status[1] === PORCELAIN_STATUS.DELETED)\n\t\t\t) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn status[0] === PORCELAIN_STATUS.UNMERGED || status[1] === PORCELAIN_STATUS.UNMERGED;\n\t\t});\n\t}\n\treturn hasConflict;\n}\n\nfunction resolveConflict(userStoryName, promotionChangesFilePath, promotionId, repositoryId) {\n\tconst CONFLICTED_CHANGES = `${TEMP_DIRECTORY}/conflictedChanges`;\n\twriteFileSync(CONFLICTED_CHANGES, this.getConflictingFilePaths().join('\\n'), 'utf-8');\n\tconst promotionChanges = JSON.parse(readFileSync(promotionChangesFilePath, 'utf8'));\n\n\t// We encode Vlocity datapacks name to identify retrieved folder names.\n\tthis.updateVlocityChangesFile(promotionChangesFilePath, promotionChanges);\n\n\tthis.enrichChangeList(promotionChangesFilePath, `${TARGET_DIRECTORY}/`, CONFLICTED_CHANGES, ENRICHED_CHANGE_FILE_PATH);\n\n\tthis.executeCommand(`\n    echo \"${JSON.stringify(conflictResolutionAttachments)}\" > ${TEMP_DIRECTORY}/solvedByUser.json\n    touch ${OUTPUT_JSON_PATH}`, RESULT_INFO.CATEGORY.FILE_SYSTEM, RESULT_INFO.ADDITIONAL_INFORMATION.FILE_CREATE);\n\n\tthis.executeCommand(\n\t\tthis.getResolveConflictCommand(\n\t\t\tpromotionChangesFilePath,\n\t\t\tGIT_STATUS_FILE_PATH,\n\t\t\tENRICHED_CHANGE_FILE_PATH,\n\t\t\tpromotionId,\n\t\t\trepositoryId,\n\t\t\tuserStoryName\n\t\t),\n\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.COPADO_MERGE\n\t);\n}\n\nfunction enrichChangeList(promotionChanges, targetRepository, conflictedChanges, outputFilePath) {\n\tthis.executeCommand(\n\t\t`enricher -p '${promotionChanges}' --repo ${targetRepository} ${conflictedChanges ? '--changefile ' + conflictedChanges : ''} ${\n\t\t\toutputFilePath ? '--out ' + outputFilePath : ''\n\t\t} --quick true`,\n\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.ENRICHER_SERVICE\n\t);\n}\n\nfunction getConflictingFilePaths() {\n\tconst lines = readFileSync(GIT_STATUS_FILE_PATH, 'utf-8')?.split('\\n');\n\tconst conflictedFiles = [];\n\tif (lines?.length) {\n\t\tlines.forEach(line => {\n\t\t\tif (line) {\n\t\t\t\tconst space = line.indexOf(' ');\n\t\t\t\t// AA tmp/filepath\n\t\t\t\tconst conflictType = line.substring(0, space);\n\t\t\t\tconst filePath = line.substring(space + 1).replaceAll(/^\\\"|\\\"$/g, '');\n\t\t\t\tif (filePath && conflictType.length == 2 && !conflictType.includes('?')) {\n\t\t\t\t\tconflictedFiles.push(filePath);\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t}\n\t// throwing an error when the backend service responds that the merge has conflict, but the git status does not provide the paths\n\tif (!conflictedFiles?.length) {\n\t\tthrow new Error('Could not find conflicting files');\n\t}\n\treturn conflictedFiles;\n}\n\nfunction gitCommit(commitMessage) {\n\tthis.executeCommand(\n\t\t`\n        git add . # add all the resolved changes, if any \n        git commit -am \"${commitMessage}\" || true`,\n\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_ADD\n\t);\n}\n\nfunction saveMergeCommitId(output) {\n\tconst cmd = 'git rev-parse HEAD';\n\tconst mergeCommitId = this.executeCommand(cmd, RESULT_INFO.CATEGORY.GIT_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_FIND_COMMIT_ID)?.trim();\n\toutput.map(file => (file.sucessfulPromotion = mergeCommitId));\n\treturn output;\n}\n\nfunction gitPush(tag, promotionBranch) {\n\tconsole.log('START push promotion branch');\n\tconst escapedTag = tag ? this.escapeSpecialCharacters(tag).replace(/[|]/g, \"'\\\\|'\") : null;\n\tconst cmd = escapedTag\n\t\t? `\n            git tag '${escapedTag}' || exit 1\n            git push --all\n        `\n\t\t: `\n            echo 'No tag specified'\n            git push origin \"${promotionBranch}\"\n        `;\n\tthis.asyncCopadoLogMessage('Pushing all changes');\n\tthis.executeCommand(\n\t\t`\n        ${cmd}\n    `,\n\t\tRESULT_INFO.CATEGORY.GIT_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.GIT_PUSH\n\t);\n\tconsole.log('END push promotion branch');\n}\n\nfunction checkSFDXProjectJson(overriddenApiVersion, apiVersion) {\n\tconst SOURCE_API_VERSION = this.getApiVersion(overriddenApiVersion, apiVersion);\n\tconst sfdxProjectJsonPath = `${TARGET_DIRECTORY}/sfdx-project.json`;\n\tif (existsSync(sfdxProjectJsonPath)) {\n\t\tlet fileContent = JSON.parse(readFileSync(sfdxProjectJsonPath, { encoding: 'utf8' }));\n\t\tif (fileContent.sourceApiVersion !== SOURCE_API_VERSION) {\n\t\t\tconst commitMessage = `Updated  sourceApiVersion from ${fileContent.sourceApiVersion} to ${SOURCE_API_VERSION} in sfdx-project.json to align the commit, promote and deploy operations with the latest supported api version of Copado.`;\n\t\t\tfileContent.sourceApiVersion = SOURCE_API_VERSION;\n\t\t\twriteFileSync(sfdxProjectJsonPath, JSON.stringify(fileContent, null, 2));\n\t\t\tthis.gitCommit(commitMessage);\n\t\t}\n\t} else {\n\t\tthrow new Error(\n\t\t\t'Invalid configuration. sfdx-project.json is invalid or missing at project root. Copado Commit and Deploy operations are required to run from within a valid sfdx project.'\n\t\t);\n\t}\n}\n\nfunction getErrorCommand(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `copado -p \"Error\" -e ${JSON.stringify(error?.trim()?.substring(0, 32760) + '; ' + suffix)}`;\n}\n\nfunction executeCommand(command, category, additionalInfo,disableMetrics, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\tif(!disableMetrics){\n\t\tthis.startWatch(category, additionalInfo,processes);\n\t}\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.log(response, disableLogs);\n\tif(!disableMetrics){\n\t\tthis.endWatch(additionalInfo,processes);\n\t}\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\tif(!disableMetrics){\n\t\t\t\tthis.endWatch(additionalInfo,processes);\n\t\t\t}\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n\t\tconst truncatedError = JSON.stringify(\n\t\t\terrorMessage\n\t\t\t\t.split('\\n')\n\t\t\t\t.filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n\t\t\t\t.join(' ')\n\t\t);\n\t\tthrow new CommandExecutionError(truncatedError, category, additionalInfo);\n\t}\n}\n\nfunction getApiVersion(overriddenApiVersion, apiVersion) {\n\tconst finalApiVersion = overriddenApiVersion || apiVersion;\n\tconst regExpApiVersion = /\\d\\d\\.0/;\n\tif (!regExpApiVersion.test(finalApiVersion)) {\n\t\tthis.executeCommand(this.getErrorCommand(`Invalid API Version: ${finalApiVersion}`));\n\t\tprocess.exit(1);\n\t}\n\treturn finalApiVersion;\n}\n\nfunction escapeSpecialCharacters(text) {\n\treturn text.replace(/'/g, \"'\\\\''\");\n}\n\nfunction getGitDepth(gitDepth) {\n\tgitDepth = parseInt(gitDepth);\n\treturn gitDepth >= 0 ? gitDepth : 100;\n}\n\nfunction fetchCheckoutBranch(branch, forceCreate) {\n\treturn `( git fetch origin ${branch} --depth ${GIT_DEPTH} && git checkout ${branch} )` + (forceCreate ? ` || git checkout -b ${branch}` : '');\n}\n\nfunction log(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tconsole.log(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tconsole.log(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction updateVlocityChangesFile(promotionChangesFilePath, promotionChanges) {\n\tconst hasVlocityChanges = promotionChanges.find(changeObj => changeObj.c === VLOCITY_CATEGORY)?.c;\n\tif (hasVlocityChanges) {\n\t\tpromotionChanges.forEach(changeObj => {\n\t\t\tif (changeObj.c === VLOCITY_CATEGORY) {\n\t\t\t\tconst datapackKey = JSON.parse(changeObj.j)?.vk?.split('/');\n\t\t\t\tchangeObj.n = datapackKey[1]\n\t\t\t\t\t?.replace('\\\\', '-')\n\t\t\t\t\t.replace(/[^A-Za-z0-9/_\\-]+/g, '-')\n\t\t\t\t\t.replace(/[-]+/g, '-')\n\t\t\t\t\t.replace(/[-_]+_/g, '_')\n\t\t\t\t\t.replace(/[-]+\\/[-]+/g, '/')\n\t\t\t\t\t.replace(/^[-_\\\\/]+/, '')\n\t\t\t\t\t.replace(/[-_\\\\/]+$/, '');\n\t\t\t}\n\t\t});\n\t\twriteFileSync(promotionChangesFilePath, JSON.stringify(promotionChanges, null, 2));\n\t}\n}\n\nfunction deduplicateXMLTags(disableXMLDeDuplication, userStoryBranches, promotionChangesFilePath) {\n\tconst layoutsInPromotion = this.getLayoutsWithAddOrFullActionInPromotion(promotionChangesFilePath);\n\tif (disableXMLDeDuplication?.toLowerCase() == 'true' || layoutsInPromotion?.length == 0) {\n\t\treturn;\n\t}\n\n\tthis.asyncCopadoLogMessage('Deduplicating XML tags');\n\n\tconst layoutsInPromotionChanges = `${TEMP_DIRECTORY}/LayoutsInPromotionChanges.json`;\n\twriteFileSync(layoutsInPromotionChanges, JSON.stringify(layoutsInPromotion));\n\n\tthis.enrichChangeList(layoutsInPromotionChanges, `${TARGET_DIRECTORY}/`);\n\tthis.executeCommand(\n\t\tthis.getDeduplicateXMLCommand(layoutsInPromotionChanges, userStoryBranches),\n\t\tRESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.COPADO_MERGE\n\t);\n\n\tthis.gitCommit('Copado De-duplication of XML tags');\n}\n\nfunction getResolveConflictCommand(promotionChangesFilePath, gitStatusFilePath, enrichedChangesFilePath, promotionId, repositoryId, userStoryName) {\n\treturn `copado-merge ${TARGET_DIRECTORY} '${promotionChangesFilePath}' --out ${TEMP_DIRECTORY} -t sfdx -p ${gitStatusFilePath} -cp ${promotionId} -rp ${repositoryId} -r ${TEMP_DIRECTORY}/solvedByUser.json  -u ${userStoryName} -v2 --conflictedchanges '${enrichedChangesFilePath}'`;\n}\n\nfunction getDeduplicateXMLCommand(layoutsInPromotionChanges, userStoryBranches) {\n\treturn `copado-merge ${TARGET_DIRECTORY} '${layoutsInPromotionChanges}' --out ${TEMP_DIRECTORY} -t sfdx deduplicate --mergedus ${this.getMergedUserStoriesFilePath(\n\t\tuserStoryBranches\n\t)}  --metadatas 'Layout'`;\n}\nfunction getMergedUserStoriesFilePath(userStoryBranches) {\n\tconst result = `${TEMP_DIRECTORY}/MergedUserStories.json`,\n\t\tfeature = 'feature/';\n\n\twriteFileSync(result, JSON.stringify(JSON.parse(userStoryBranches).map(branch => branch?.substring(feature.length))));\n\treturn result;\n}\nfunction getLayoutsWithAddOrFullActionInPromotion(promotionChangesFilePath) {\n\tconst supportedActions = [ACTIONS.ADD, ACTIONS.FULL, ACTIONS.SELECTIVE_COMMIT];\n\tconst promotionChanges = this.readFromPath(promotionChangesFilePath);\n\tconst result = promotionChanges?.filter(change => {\n\t\treturn change.t?.toLowerCase() === METADATA_TYPE.LAYOUT && supportedActions.includes(change.a?.toLowerCase());\n\t});\n\treturn result;\n}\n\nfunction readFromPath(filePath) {\n\tif (!existsSync(filePath)) {\n\t\tthrow new Error(`Could not find file at path: ${filePath}`);\n\t}\n\tconst data = readFileSync(filePath, 'utf-8');\n\tlet result;\n\ttry {\n\t\tresult = JSON.parse(data);\n\t} catch (err) {\n\t\tthrow new Error(`Content at ${filePath} is not a valid JSON`);\n\t}\n\treturn result;\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n\tconst RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n\tconst fileContent = { data, columns, header, headerIcon };\n\twriteFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n\tthis.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(MAXBUFFER)\n\t};\n\treturn options;\n}\n\nfunction uploadFileAtPath(filePath) {\n    new Promise((resolve, reject) => {\n        child_process.exec(`copado --uploadfile ${filePath}`, {}, (err, stdout, stderr) => {\n            if (err) {\n                this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES, err);\n                reject(new CommandExecutionError(err), RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES);\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\nfunction startWatch(processType,processName,processes) {\n\tif(!processName || !processType){\n\t\treturn;\n\t}\n\tconst startTime = process.hrtime();\n\tif (!totalTimeByType[processType]) {\n\t\ttotalTimeByType[processType] = 0;\n\t}\n\tprocesses.push({ name: processName, type: processType, startTime, endTime: null, elapsedTime: null });\n}\n\nfunction endWatch(processType,processes) {\n\tif(!processType){\n\t\treturn;\n\t}\n\tconst processIndex = processes.length;\n\tif (!processIndex && processes[processIndex-1].type !== processType) {\n\t\tconsole.error(`Process '${processType}' not started.`);\n\t\treturn;\n\t}\n\tconst endTime = process.hrtime();\n\tconst elapsedTime = process.hrtime(processes[processIndex-1].startTime);\n\tprocesses[processIndex-1].endTime = endTime;\n\tprocesses[processIndex-1].elapsedTime = elapsedTime[0] * 1e9 + elapsedTime[1];\n}\n\nfunction printMetrics() {\n\tlet ux = new Ux();\n\tthis.logger('\\n');\n\tux.styledHeader('   ====================      OVERALL METRICS      ====================   ');\n\tconst resultData = [];\n\tprocesses.forEach(process => {\n\t\t// store data\n\t\tresultData.push({\n\t\t\tprocessType: '| ' + process.type,\n\t\t\tprocessName: '| ' + process.name,\n\t\t\t'startTime(UTC)': process.startTime ? '| ' + this.formatTime(process.startTime) : '| ' + 'N/A',\n\t\t\t'endTime(UTC)': process.endTime ? '| ' + this.formatTime(process.endTime) : '| ' + 'N/A',\n\t\t\telapseTime: process.elapsedTime ? '| ' + `${(process.elapsedTime / 1e9).toFixed(2)} s` + ' |' : '| ' + 'N/A' + ' |'\n\t\t});\n\t\t// Aggregate total time by type\n\t\tif (process.elapsedTime) {\n\t\t\tif (!totalTimeByType[process.type]) {\n\t\t\t\ttotalTimeByType[process.type] = 0;\n\t\t\t}\n\t\t\ttotalTimeByType[process.type] += process.elapsedTime;\n\t\t}\n\t});\n\n\tux.table(resultData, { processType: {}, processName: {}, 'startTime(UTC)': {}, 'endTime(UTC)': {}, elapseTime: {}});\n\tthis.logger('\\n'+'   ====================       EXECUTION SUMMARY      ====================   ');\n\t// Print total aggregate time by type\n\tObject.entries(totalTimeByType).forEach(([type, totalTime]) => {\n\t\tthis.logger(`${type} Total Time: ${(totalTime / 1e9).toFixed(2)} seconds`);\n\t});\n\tthis.logger('   ====================       EXECUTION SUMMARY      ====================   '+'\\n');\n}\n\nfunction formatTime(time) {\n\tconst date = new Date(time[0] * 1000 + time[1] / 1e6);\n\tconst hours = date.getUTCHours().toString().padStart(2, '0');\n\tconst minutes = date.getUTCMinutes().toString().padStart(2, '0');\n\tconst seconds = date.getUTCSeconds().toString().padStart(2, '0');\n\tconst milliseconds = date.getUTCMilliseconds().toString().padStart(3, '0');\n\treturn `${hours}:${minutes}:${seconds}.${milliseconds}`;\n}\n\n// INNER CLASS\nclass CommandExecutionError extends Error {\n\tconstructor(message, category, additionalInfo) {\n\t\tsuper(`${category ? category + ' - ' : ''}${additionalInfo ? additionalInfo + ' : ' : ''}${message}`);\n\t\tthis.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n\t}\n}\n\nmodule.exports.execute = execute;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.getPromotionChanges = getPromotionChanges;\nmodule.exports.setUpDirectory = setUpDirectory;\nmodule.exports.fetchTargetBranch = fetchTargetBranch;\nmodule.exports.fetchCreatePromotionBranch = fetchCreatePromotionBranch;\nmodule.exports.configureGit = configureGit;\nmodule.exports.promote = promote;\nmodule.exports.uploadGitConflictsResolution = uploadGitConflictsResolution;\nmodule.exports.hasConflict = hasConflict;\nmodule.exports.resolveConflict = resolveConflict;\nmodule.exports.getConflictingFilePaths = getConflictingFilePaths;\nmodule.exports.gitCommit = gitCommit;\nmodule.exports.saveMergeCommitId = saveMergeCommitId;\nmodule.exports.gitPush = gitPush;\nmodule.exports.checkSFDXProjectJson = checkSFDXProjectJson;\nmodule.exports.getErrorCommand = getErrorCommand;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getApiVersion = getApiVersion;\nmodule.exports.escapeSpecialCharacters = escapeSpecialCharacters;\nmodule.exports.fetchFeatureBranches = fetchFeatureBranches;\nmodule.exports.mergeFeatureBranchInPromotionBranch = mergeFeatureBranchInPromotionBranch;\nmodule.exports.getRemoteBranchFetchCommand = getRemoteBranchFetchCommand;\nmodule.exports.remotePromotionBranchExists = remotePromotionBranchExists;\nmodule.exports.getPath = getPath;\nmodule.exports.handleConflicts = handleConflicts;\nmodule.exports.getGitDepth = getGitDepth;\nmodule.exports.fetchCheckoutBranch = fetchCheckoutBranch;\nmodule.exports.buildFetchFeatureBranchesCommand = buildFetchFeatureBranchesCommand;\nmodule.exports.checkoutFeatureAndPromotionBranch = checkoutFeatureAndPromotionBranch;\nmodule.exports.log = log;\nmodule.exports.updateVlocityChangesFile = updateVlocityChangesFile;\nmodule.exports.deduplicateXMLTags = deduplicateXMLTags;\nmodule.exports.readFromPath = readFromPath;\nmodule.exports.getLayoutsWithAddOrFullActionInPromotion = getLayoutsWithAddOrFullActionInPromotion;\nmodule.exports.enrichChangeList = enrichChangeList;\nmodule.exports.getMergedUserStoriesFilePath = getMergedUserStoriesFilePath;\nmodule.exports.getResolveConflictCommand = getResolveConflictCommand;\nmodule.exports.getDeduplicateXMLCommand = getDeduplicateXMLCommand;\nmodule.exports.logger = logger;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.getOptions = getOptions;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.startWatch = startWatch;\nmodule.exports.endWatch = endWatch;\nmodule.exports.formatTime = formatTime;\nmodule.exports.printMetrics = printMetrics;\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0l7Q000000iAiMQAU",
                    "LastReferencedDate": "2023-12-19T12:42:05.000+0000",
                    "LastViewedDate": "2023-12-19T12:42:05.000+0000",
                    "Name": "Promote"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v55.0/sobjects/copado__Function__c/a0l7Q000000MDYyQAO"
                    },
                    "copado__API_Name__c": "sfdx_encode_file_names",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"name\" : \"file_changes_id\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"\n}, {\n  \"name\" : \"file_name\",\n  \"defaultValue\" : \"Copado Deploy changes\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\nconst execSync = require('child_process').execSync,\n    { existsSync, writeFileSync, readFileSync } = require('fs');\n\nlet deploymentMetadata = [];\n\n// EXECUTION\n\nexecute();\n\nfunction execute() {\n    getDeployChanges();\n    if (deploymentMetadata.length) {\n        encodeFileNames();\n    }\n}\n\n// SCRIPT FUNCTIONS\n\nfunction getDeployChanges() {\n    const { file_name, file_changes_id } = process.env;\n    execSync(`copado --downloadfiles ${file_changes_id} --downloaddir /tmp/`);\n    let downloadedFileName;\n    if (existsSync(`/tmp/${file_name}`)) {\n        downloadedFileName = file_name;\n    } else if (existsSync(`/tmp/${file_name}.json`)) {\n        downloadedFileName = `${file_name}.json`;\n    } else {\n        throw 'Error fetching Deployment Changes';\n    }\n    deploymentMetadata = readFromPath(`/tmp/${downloadedFileName}`);\n\n    //TODO : First condition needs to be removed, adding this now to make sure already committed files do not fail in further operations.\n    deploymentMetadata = deploymentMetadata.filter((element) => !element.c || element.c === 'SFDX');\n}\nfunction encodeFileNames() {\n    for (let change of deploymentMetadata) {\n        switch (change.t) {\n            case 'DashboardFolder':\n            case 'ReportFolder':\n            case 'Document':\n                change.n = change.n.substring(0, change.n.lastIndexOf('.')) ? change.n.substring(0, change.n.lastIndexOf('.')) : change.n;\n                break;\n\n            case 'EmailTemplate':\n                change.n = change.n.replace(/%24/gi, '$').replace(/%2F/gi, '/');\n                break;\n\n            case 'Layout':\n                const regExp = '(?:([a-zA-Z_][a-zA-Z0-9_]{0,14}?(?!__c-))__)?([^-]+)-(?:([a-zA-Z_][a-zA-Z0-9_]{0,14}?_?(?!__c$))__)?(.+)\\n?';\n                const layoutFullName = change.n.match(regExp);\n                let layoutName = layoutFullName[4].replace(/_{2}(?!c)/g, (match) => {\n                    return match.replace(/_/gi, '%5F');\n                });\n                layoutName = layoutName.replace(/\\./, '%2E');\n                change.n = `${layoutFullName[1] ? layoutFullName[1] + '__' : ''}${layoutFullName[2]}-${\n                    layoutFullName[3] ? layoutFullName[3] + '__' : ''\n                }${layoutName}`;\n                break;\n\n            case 'Profile':\n                change.n = change.n.replace(/\\./gi, '%2E').replace(/__/gi, '%5F%5F');\n                break;\n        }\n    }\n    writeFileSync('/app/encoded_changes.json', JSON.stringify(deploymentMetadata));\n}\n\nfunction readFromPath(filePath) {\n    return JSON.parse(readFileSync(filePath, 'utf-8'));\n}",
                    "copado__Type__c": "Standard",
                    "Id": "a0l7Q000000MDYyQAO",
                    "LastReferencedDate": "2022-09-16T10:59:41.000+0000",
                    "LastViewedDate": "2022-09-16T10:59:41.000+0000",
                    "Name": "Encode File Names"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q000000iAiOQAU"
                    },
                    "copado__API_Name__c": "sfdx_package_version_publish",
                    "copado__Description__c": "To publish the package version",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"versionDetails\",\n  \"defaultValue\" : \"{$Job.PrevStep.Result__r.Result_Data__c}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sessionId\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"endpoint\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst { spawnSync } = require('child_process'),\n\t{ versionDetails, endpoint, sessionId, isTest, maxBuffer } = process.env,\n\t{ subscriberId, apiVersion } = JSON.parse(versionDetails),\n\tCHECK_LOG = 'Please check logs for more details',\n\tMAXBUFFER = parseInt(maxBuffer),\n\tTEMP_DIRECTORY = 'temp';\n\n// SCRIPT FUNCTIONS\n\nfunction execute() {\n\ttry {\n\t\tthis.createSFDXProject(TEMP_DIRECTORY);\n\t\tthis.setInstanceURL(endpoint);\n\t\tconst promotionResponse = this.promotePackageVersion(subscriberId, sessionId, apiVersion, TEMP_DIRECTORY);\n\t\tthis.handlePromotionResponse(promotionResponse);\n\n\t\tthis.executeCommand(`\n            copado -p 'Package \"${subscriberId}\" promoted successfully'\n            copado -p 'Updating Results' -r ${subscriberId}`);\n\t} catch (err) {\n\t\t//Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n\t\tif (err?.status === 3) {\n\t\t\tprocess.exit(1);\n\t\t}\n\t\tthis.executeCommand(this.showError(err?.toString()));\n\t}\n}\n\nfunction createSFDXProject(directory) {\n\tthis.executeCommand(`\n\t\tcopado -p 'Creating Temp Project'\n        sf project generate --name ${directory} || (${this.showError(`Error creating SFDX project, ${CHECK_LOG}`)})\n    `);\n\tprocess.chdir(directory);\n}\n\nfunction setInstanceURL(endpoint) {\n\tconst url = endpoint.substring(0, endpoint.indexOf('/', endpoint.indexOf('/') + 2));\n\tthis.executeCommand(`\n        copado -p 'Setting instance url'\n        sf config set org-instance-url=${url} || (${this.showError(`Error setting instance URL, ${CHECK_LOG}`)})\n    `);\n}\n\nfunction promotePackageVersion(subscriberId, sessionId, apiVersion, directory) {\n\tconst promoteCmd = `sf package version promote --package ${subscriberId} --target-dev-hub ${sessionId} ${\n\t\tapiVersion ? `--api-version ${apiVersion}` : ''\n\t} --no-prompt --json || true`;\n\tthis.logger(`Package Version Promotion Command ==> ${promoteCmd}`);\n\n\tconst response = this.executeCommand(\n\t\t`\n\t\tcopado -p 'Promoting package ${subscriberId}'\n\t\t${promoteCmd}\n\t`,\n\t\ttrue\n\t).toString();\n\treturn JSON.parse(response);\n}\n\nfunction handlePromotionResponse(response) {\n\tthis.logger(`Package Version Promotion Response ==> ${JSON.stringify(response)}`);\n\tif (response.status) {\n\t\tthrow `${response.message ? response.message : ''} ${CHECK_LOG}`;\n\t}\n}\n\nfunction showError(error) {\n\tconst refinedErrorMsg = this.maskSensitiveInformation(error);\n\treturn `copado -p 'Error' -e ${JSON.stringify(refinedErrorMsg).replace(/\\\\n/g, '\\n')} ${isTest ? '' : ' && exit 3'}`;\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nfunction maskSensitiveInformation(data) {\n\tconst sensitiveInfo = ['--target-dev-hub', '-u', '-v'],\n\t\tmaskingSequence = '*****';\n\n\tconst arrayOfData = data.split(' ');\n\tsensitiveInfo.forEach(subString => {\n\t\tconst keyIndex = arrayOfData.indexOf(subString);\n\t\tif (keyIndex > -1) {\n\t\t\tarrayOfData[keyIndex + 1] = maskingSequence;\n\t\t\tdata = arrayOfData.join(' ');\n\t\t}\n\t});\n\treturn data;\n}\n\nfunction executeCommand(cmd, disableLogs) {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: MAXBUFFER\n\t};\n\tconst response = spawnSync(cmd, options);\n\tconst { output, error } = this.log(response, disableLogs);\n\tif (response?.status != 0) {\n\t\tif (response?.status == 3) {\n\t\t\tif (isTest) {\n\t\t\t\tthrow output;\n\t\t\t}\n\t\t\tprocess.exit(3);\n\t\t}\n\t\tthrow error ? error : `Error executing the command: ${cmd}`;\n\t}\n\treturn output;\n}\n\nfunction log(response, disableLogs) {\n\tconst output = response?.stdout?.toString().trim();\n\tconst error = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (output) {\n\t\t\tconsole.log(output);\n\t\t}\n\t\tif (error) {\n\t\t\tconsole.log(error);\n\t\t}\n\t}\n\treturn { output, error };\n}\n\nmodule.exports.execute = execute;\nmodule.exports.logger = logger;\nmodule.exports.log = log;\nmodule.exports.handlePromotionResponse = handlePromotionResponse;\nmodule.exports.promotePackageVersion = promotePackageVersion;\nmodule.exports.createSFDXProject = createSFDXProject;\nmodule.exports.showError = showError;\nmodule.exports.setInstanceURL = setInstanceURL;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\nmodule.exports.executeCommand = executeCommand;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1.0",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q000000iAiOQAU",
                    "LastReferencedDate": "2023-12-20T05:08:26.000+0000",
                    "LastViewedDate": "2023-12-20T05:08:26.000+0000",
                    "Name": "Sfdx Package Version Publish"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v56.0/sobjects/copado__Function__c/a0l7Q000000iAiPQAU"
                    },
                    "copado__API_Name__c": "SFDX_Package_Version_Update",
                    "copado__Description__c": "Updates package version",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"devhubSession\",\n  \"defaultValue\" : \"{$Context.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"devhubEndpoint\",\n  \"defaultValue\" : \"{$Context.Credential.Endpoint}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"packageVersion\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.packageVersion}\"\n}, {\n  \"name\" : \"installationKey\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.installationKey}\"\n}, {\n  \"name\" : \"apiVersion\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.apiVersion}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\nconst { execSync } = require('child_process'),\n\t{ devhubEndpoint, devhubSession, installationKey, apiVersion, isTest } = process.env,\n\tbaseUrl = devhubEndpoint.substring(0, devhubEndpoint.indexOf('/', devhubEndpoint.indexOf('/') + 2)),\n\tpackageVersion = JSON.parse(process.env.packageVersion),\n\tCHECK_LOG = 'Please check the logs for details',\n\tTEMP_DIRECTORY = 'temp';\n\n//SCRIPT FUNCTIONS\n\nfunction execute() {\n\ttry {\n\t\tthis.createSFDXProject(TEMP_DIRECTORY);\n\t\tthis.setInstanceURL(baseUrl);\n\n\t\tconst flags = this.buildParameters({\n\t\t\t'target-dev-hub': devhubSession,\n\t\t\tpackage: packageVersion.copado__Subscriber_Version_Id__c,\n\t\t\t'version-name': packageVersion.copado__Version_Name__c,\n\t\t\t'version-description': packageVersion.copado__Version_Description__c,\n\t\t\tbranch: packageVersion.copado__Branch__c,\n\t\t\ttag: packageVersion.copado__Tag__c,\n\t\t\t'installation-key': installationKey,\n\t\t\t'api-version': apiVersion\n\t\t});\n\n\t\tthis.handleVersionPromotionResponse(this.updatePackageVersion(flags));\n\t\tthis.updateResult(packageVersion);\n\t} catch (error) {\n\t\t//Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n\t\tif (error?.status === 3) {\n\t\t\tprocess.exit(1);\n\t\t}\n\t\texecSync(this.showError(error.toString()));\n\t}\n}\n\nfunction updateResult(packageVersion) {\n\tconst updateResultCmd = `copado -p 'Updating result' -r ${JSON.stringify(\n\t\tJSON.stringify({\n\t\t\tpackageVersion\n\t\t})\n\t)}`;\n\t//escaping special characters here, so it can be used in payload\n\texecSync(this.escapeSpecialCharacters(updateResultCmd));\n}\n\nfunction buildParameters(flags) {\n\treturn Object.entries(flags).reduce((parameters, [key, value]) => {\n\t\treturn parameters + (value ? ` --${key} \"${value}\"` : '');\n\t}, '');\n}\n\nfunction setInstanceURL(url) {\n\texecSync(`\n        sf -v\n        copado -p 'Setting instance url'\n        sf config set org-instance-url=${url} || (${this.showError(`Error setting instance URL, ${CHECK_LOG}`)})\n    `);\n}\n\nfunction createSFDXProject(directory) {\n\texecSync(`\n        copado -p 'Creating Temp Project'\n        sf project generate --name ${directory} || (${this.showError(`Error creating SF project, ${CHECK_LOG}`)})\n    `);\n\n\tprocess.chdir(directory);\n}\n\nfunction showError(error) {\n\tconst refinedErrorMsg = this.maskSensitiveInformation(error, { '--targetdevhubusername': devhubSession });\n\treturn `copado -p 'Error' -e ${this.escapeSpecialCharacters(JSON.stringify(refinedErrorMsg)).replace(/\\\\n/g, '\\n')}  ${\n\t\tisTest ? '' : ' && exit 3'\n\t}`;\n}\n\nfunction updatePackageVersion(parameters) {\n\tconst updateCmd = `\n        copado -p 'Updating package version'\n        sf package version update ${parameters} --json || true\n    `;\n\n\tconst logMessage = `Package Version Update Command ==> sf package version update ${parameters} --json`;\n\tthis.logger(installationKey ? maskSensitiveInformation(logMessage, { '--installationkey': installationKey }) : logMessage);\n\n\t//escaping special characters here, so it can be used in payload\n\treturn JSON.parse(execSync(this.escapeSpecialCharacters(updateCmd)).toString());\n}\n\nfunction handleVersionPromotionResponse(response) {\n\tthis.logger(`Package Version Update Response ==> ${JSON.stringify(response)}`);\n\tif (response.status) {\n\t\texecSync(this.showError(`Package Version Update failed. ${response.message}, ${CHECK_LOG}`));\n\t}\n}\n\nfunction escapeSpecialCharacters(text) {\n\treturn text.replace(/`/g, '\\\\`').replace(/\\$/g, '\\\\$');\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nfunction maskSensitiveInformation(data, sensitiveFlags) {\n\tconst maskingSequence = '*****';\n\n\tconst arrayOfData = data.split(' ');\n\tObject.keys(sensitiveFlags).forEach(subStr => {\n\t\tconst keyIndex = arrayOfData.indexOf(subStr);\n\t\tif (keyIndex > -1) {\n\t\t\tarrayOfData[keyIndex + 1] = maskingSequence;\n\t\t\tarrayOfData.splice(keyIndex + 2, sensitiveFlags[subStr].split(' ').length - 1);\n\t\t}\n\t});\n\treturn arrayOfData.join(' ');\n}\n\nmodule.exports.execute = execute;\nmodule.exports.updateResult = updateResult;\nmodule.exports.buildParameters = buildParameters;\nmodule.exports.setInstanceURL = setInstanceURL;\nmodule.exports.createSFDXProject = createSFDXProject;\nmodule.exports.showError = showError;\nmodule.exports.updatePackageVersion = updatePackageVersion;\nmodule.exports.handleVersionPromotionResponse = handleVersionPromotionResponse;\nmodule.exports.escapeSpecialCharacters = escapeSpecialCharacters;\nmodule.exports.logger = logger;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1",
                    "Id": "a0l7Q000000iAiPQAU",
                    "LastReferencedDate": "2022-10-06T09:24:14.000+0000",
                    "LastViewedDate": "2022-10-06T09:24:14.000+0000",
                    "Name": "SFDX Package Version Update"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q000000iAiQQAU"
                    },
                    "copado__API_Name__c": "SFDX_Package_Version_Create",
                    "copado__Description__c": "Create a package version record",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"endPoint\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"session\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"packageId\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"versionName\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"versionNumber\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"description\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : false,\n  \"name\" : \"jsonInformation\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"name\" : \"pollInterval\",\n  \"defaultValue\" : \"{$Property.sfdx_package_version_create_poll_time_in_seconds}\"\n}, {\n  \"name\" : \"retrialTimes\",\n  \"defaultValue\" : \"{$Property.sfdx_package_version_create_retrial_number}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n\n'use strict'\n\nconst { mkdirSync, readFileSync, writeFileSync } = require('fs'),\n    { execSync } = require('child_process'),\n    { packageId, versionName, versionNumber, description, endPoint, session, gitEmail, gitName, retrialTimes, pollInterval, isTest } = process.env,\n    params = JSON.parse(\n        process?.env['jsonInformation']\n            .replace(/(\\\\r\\\\n|\\\\r|\\\\n)/g, '')\n            .replace(/\\\\\"/g, '\"')\n            .replace(/\\\\\\\\/g, '\\\\')\n    ),\n    checkLog = 'Please check the logs for details',\n    baseUrl = endPoint?.substring(0, endPoint?.indexOf('/', endPoint?.indexOf('/') + 2)),\n    fetchReportRetrialTimes = retrialTimes ? parseInt(retrialTimes) : 10,\n    pollIntervalInSec = pollInterval ? parseInt(pollInterval) : 30;\nparams.tag = params.tag ? stripTag(params.tag) : '';\nconst {\n        branch,\n        tag,\n        loglevel,\n        apiversion,\n        path,\n        definitionfile,\n        installationkey,\n        installationkeybypass,\n        codecoverage,\n        releasenotesurl,\n        postinstallurl,\n        postinstallscript,\n        uninstallscript,\n        skipvalidation\n    } = params,\n    ERROR_LIMIT = 32760;\n\n// EXECUTION\n\nfunction execute() {\n    try {\n        mkdirSync('sfProject');\n        process.chdir('sfProject');\n\n        this.cloneRepo();\n        this.setInstanceURL();\n        this.configureGit();\n        this.updatePackageVersion(this.createPackageVersion());\n    } catch (err) {\n        //Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n        if (err?.status === 3) {\n            process.exit(1);\n        }\n        execSync(`${this.getErrorCmd(err.toString())}`);\n    }\n}\n\n// SCRIPT FUNCTIONS\nfunction updatePackageVersion(response) {\n    if (!response.status) {\n        const requestId = response?.result?.Id;\n        this.pollPackageVersionCreateRequest(requestId, 0)\n            .then(({ data, alias }) => {\n                this.commit();\n\n                this.updateTagBranchDetails(data?.result[0]?.SubscriberPackageVersionId, alias);\n                this.setProgressStatus({\n                    progressStatus: 'Package version created successfully',\n                    resultData: JSON.stringify(getLatestVersion(data?.result[0]?.SubscriberPackageVersionId, packageId))\n                });\n            })\n            .catch((error) => {\n                this.setProgressStatus({\n                    progressStatus: 'Package Version creation failed',\n                    errorMessage: `Could not create package. ${error}`\n                });\n            });\n    } else if (response.status) {\n        this.setProgressStatus({ progressStatus: 'Package Version creation failed', errorMessage: `Could not create package. ${response.message}` });\n    }\n}\n\nfunction getLatestVersion(pkgVersionId, packageId) {\n    const versionList = execSync(`sf package version list --target-dev-hub ${session} --packages ${packageId} --verbose --json`).toString();\n    return JSON.parse(versionList)?.result?.find((version) => version.SubscriberPackageVersionId === pkgVersionId);\n}\n\nfunction setSFLogLevel(command, logLevel) {\n    if (logLevel) {\n        return `SF_LOG_LEVEL=${logLevel} ${command}`;\n    }\n    return command;\n\n}\n\nfunction createPackageVersion() {\n\n    const parameters = this.buildParameters({\n        \"target-dev-hub\": session,\n        \"api-version\": apiversion,\n        package: packageId,\n        path,\n        branch,\n        \"definition-file\": definitionfile,\n        tag,\n        \"installation-key\": installationkey,\n        \"installation-key-bypass\": installationkeybypass,\n        \"version-name\": versionName,\n        \"version-number\": versionNumber,\n        \"version-description\": description,\n        \"code-coverage\": codecoverage,\n        \"releasenotes-url\": releasenotesurl,\n        \"post-install-url\": postinstallurl,\n        \"post-install-script\": postinstallscript,\n        \"uninstall-script\": uninstallscript,\n        \"skip-validation\": skipvalidation\n    });\n\n    const logMessage = `Package Version Create Command ==> sf package version create ${parameters} --json`;\n    this.logger(installationkey ? this.maskSensitiveInformation(logMessage, { '--installation-key': installationkey }) : logMessage);\n\n    const versionCreateCmd = `\n        copado -p 'Creating package version'\n        ${this.setSFLogLevel(`sf package version create ${parameters} --json || true`, loglevel)}\n    `;\n\n    const response = execSync(this.escapeSpecialCharacters(versionCreateCmd)).toString();\n    this.logger(`Package Version Create Response ==> ${response}`);\n    return JSON.parse(response);\n}\n\nfunction pollPackageVersionCreateRequest(requestId, counter) {\n    return new Promise(function (resolve, reject) {\n        let timerId = setTimeout(function poll() {\n            const result = execSync(`sf package version create report --package-create-request-id  ${requestId} --target-dev-hub ${session} --json || true`);\n            const data = JSON.parse(result);\n\n            if (!data?.status && data?.result && data?.result[0]?.Status == 'Success') {\n                const alias = this.updateSFProjectFile(data.result[0]);\n                resolve({ data, alias });\n            } else if (data.status && data.message) { \n                counter++;\n                this.logger(`Package Version Creation Report ==> ${JSON.stringify(data)}`);\n                if (counter <= fetchReportRetrialTimes) {\n                    this.logger(`Retrying attempt ${counter} to get status of Package Version creation request: ${requestId}`);\n                    timerId = setTimeout(poll.bind(this), pollIntervalInSec * 1000);\n                } else {\n                    reject(data?.message);\n                }\n            } else if (data.result && data.result[0]?.Status == 'Error') {\n                this.logger(`Package Version Creation Report ==> ${JSON.stringify(data)}`);\n                reject(data.result[0]?.Error);\n            } else {\n                counter = 0;\n                timerId = setTimeout(poll.bind(this), pollIntervalInSec * 1000);\n            }\n        }.bind(this), pollIntervalInSec * 1000);\n    }.bind(this));\n}\n\nfunction updateSFProjectFile(data) {\n    const sfProjectFile = this.readProjectJson();\n    const packageAliases = sfProjectFile?.packageAliases;\n\n    const pkgVersionInfo = this.getVersionInfo(data?.SubscriberPackageVersionId);\n    const alias = this.getVersionAlias(packageAliases, data?.Package2Id, pkgVersionInfo);\n\n    packageAliases[alias] = data?.SubscriberPackageVersionId;\n\n    writeFileSync('sfdx-project.json', JSON.stringify(sfProjectFile, null, 2));\n    this.logger('sfdx-project.json file updated with subscriber package version Id');\n    return alias;\n}\n\nfunction getVersionInfo(versionId) {\n    const query = `SELECT Branch, MajorVersion, MinorVersion, PatchVersion, BuildNumber FROM Package2Version WHERE SubscriberPackageVersionId='${versionId}'`;\n    const response = execSync(`sf data query --use-tooling-api --query \"${query}\" --target-org ${session} --json || true`);\n    const parsedResponse = JSON.parse(response);\n    this.logger(JSON.stringify(parsedResponse));\n    if (parsedResponse?.status || !parsedResponse?.result?.records[0]) {\n        this.setProgressStatus({\n            progressStatus: 'Error in updating sfdx-project.json file. Version Information not found',\n            errorMessage: `Could not create package. ${parsedResponse?.message}`\n        });\n    }\n    return parsedResponse?.result?.records[0];\n}\n\nfunction createTag(tag) {\n    execSync(\n        `\n        git tag '${tag}' HEAD ||\n            (${this.getErrorCmd(`Error creating tag '${tag}' in git, ${checkLog}`)})\n    `,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction deleteTag(tag) {\n    let tagForDeletion = this.escapeCharactersForTagDeletion(tag);\n    execSync(\n        `git push --delete origin refs/tags/${tagForDeletion} || (${this.getErrorCmd(\n            `Error deleting existing tag ${tagForDeletion} in git, ${checkLog}`\n        )})`,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction escapeCharactersForTagDeletion(tag) {\n    return tag\n        .replace(/`/g, '\\\\`')\n        .replace(/\\$/g, '\\\\$')\n        .replace(/\\\"/g, '\\\\\"')\n        .replace(/\\'/g, \"\\\\'\")\n        .replace(/\\(/g, '\\\\(')\n        .replace(/\\)/g, '\\\\)')\n        .replace(/\\|/g, '\\\\|')\n        .replace(/</g, '\\\\<')\n        .replace(/>/g, '\\\\>')\n        .replace(/#/g, '\\\\#')\n        .replace(/&/g, '\\\\&')\n        .replace(/\\\\\"/g, '\"');\n}\n\nfunction commit() {\n    execSync(\n        `\n        git add 'sfdx-project.json' || exit 1\n        git commit -m 'Committing sfdx-project.json' || exit 1\n    `,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction pushTagAndBranchChanges(branch, tag) {\n    if (branch) {\n        execSync(`git push origin ${branch} || (${this.getErrorCmd(`Error pushing changes in git, ${checkLog}`)})`, { stdio: 'inherit' });\n    }\n    if (tag) {\n        execSync(`git push origin '${tag}' || (${this.getErrorCmd(`Error pushing changes in git, ${checkLog}`)})`, { stdio: 'inherit' });\n    }\n}\n\nfunction cloneRepo() {\n    execSync(\n        `\n    copado -p 'Cloning git repository'\n    copado-git-get ${branch} || (${this.getErrorCmd(`Error check out branch, ${checkLog}`)})\n  `,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction setInstanceURL() {\n    execSync(\n        `\n    copado -p 'Setting instance url'\n    sf config set org-instance-url=${baseUrl} || (${this.getErrorCmd(`Error setting instance URL, ${checkLog}`)})\n  `,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction setProgressStatus({ progressStatus, errorMessage, resultData }) {\n    let escapedData = resultData ? JSON.stringify(resultData).replace(/`/g, '\\\\`').replace(/\\$/g, '\\\\$') : '';\n\n    let truncatedError = this.truncateError(errorMessage);\n\n    const resultUpdateCmd = `copado -p '${progressStatus}' ${errorMessage ? `-e \"${truncatedError}\" && exit 3` : ''} ${\n        resultData ? `-r ${escapedData}` : ''\n    }`;\n\n    execSync(resultUpdateCmd);\n}\n\nfunction truncateError(errorMessage) {\n    return errorMessage?.length > ERROR_LIMIT ? errorMessage.substring(0, ERROR_LIMIT) + '...' : errorMessage;\n}\n\nfunction getErrorCmd(error) {\n    let refinedErrorMsg = this.maskSensitiveInformation(error, { '--target-dev-hub': session });\n    return `copado -p 'Error' -e ${this.escapeSpecialCharacters(JSON.stringify(refinedErrorMsg)).replace(/\\\\n/g, '\\n').replace(/\\\\t/g, '\\t')} && exit 3`;\n}\n\nfunction readProjectJson() {\n    return JSON.parse(readFileSync('sfdx-project.json', 'utf-8'));\n}\n\nfunction getVersionAlias(object, value, pkgVersionInfo) {\n    let packageName = Object.keys(object).find((key) => object[key] === value);\n    if (!packageName) {\n        const response = execSync(`sf data query --use-tooling-api --query \"SELECT Name FROM Package2 WHERE Id='${value}'\" --target-org ${session} --json`);\n        packageName = JSON.parse(response).result.records[0].Name;\n    }\n    return `${packageName}@${pkgVersionInfo.MajorVersion}.${pkgVersionInfo.MinorVersion}.${pkgVersionInfo.PatchVersion}-${pkgVersionInfo.BuildNumber}-${pkgVersionInfo.Branch}`;\n}\n\nfunction updateTagBranchDetails(subscriberVersionId, alias) {\n    const gitTag = tag ? tag : this.stripTag(alias);\n    let isTagExist = false;\n\n    if (tag) {\n        const remoteTags = execSync(`git ls-remote --tags --refs origin`).toString();\n        isTagExist = remoteTags\n            .split('\\n')\n            .map((step) => step.substring(step.indexOf('refs/tags/') + 10, step.length))\n            .includes(gitTag.replace(/\\\\\"/g, '\"'));\n    }\n\n    if (isTagExist) {\n        this.deleteTag(gitTag);\n    }\n\n    const escapedGitTag = this.escapeCharactersForTagCreation(gitTag);\n    this.createTag(escapedGitTag);\n\n    if (!tag) {\n        const response = this.updatePackageVersionTag(session, escapedGitTag, subscriberVersionId);\n        if (response.status) {\n            this.setProgressStatus({ progressStatus: 'Package Version tag update failed', errorMessage: response.message });\n        } else {\n            this.setProgressStatus({ progressStatus: `Package Version tag updated to ${escapedGitTag}` });\n        }\n    }\n\n    this.pushTagAndBranchChanges(branch, escapedGitTag);\n}\n\nfunction updatePackageVersionTag(devhubSession, tag, subscriberVersionId) {\n    const parameters = this.buildParameters({\n        \"target-dev-hub\": devhubSession,\n        package: subscriberVersionId,\n        tag: tag\n    });\n    const updateCmd = `\n        copado -p 'Updating package version'\n        sf package version update ${parameters} --json || true\n    `;\n    const response = execSync(updateCmd).toString();\n    this.logger(`Package Version Update Response ==> ${response}`);\n    return JSON.parse(response);\n}\n\nfunction buildParameters(flags) {\n    return Object.entries(flags).reduce((parameters, [key, value]) => {\n        return parameters + (typeof value == 'boolean' ? (value ? ` --${key}` : '') : value ? ` --${key} \"${value}\"` : '');\n    }, '');\n}\n\nfunction escapeCharactersForTagCreation(text) {\n    return text.replace(/\\\\\"/g, '\"').replace(/'/g, \"'\\\\''\").replace(/[|]/g, \"'\\\\|'\");\n}\n\nfunction escapeSpecialCharacters(text) {\n    let result = text.replace(/`/g, '\\\\`').replace(/\\$/g, '\\\\$');\n\n    return result;\n}\n\nfunction stripTag(tag) {\n    //removing ascii characters below 20hex, mentioned sequences, and a few characters such as (?*[~^\\*:)\n    return tag\n        .replace(/[\\u0000-\\u0020]/g, '')\n        .replace(/[~^:?*[\\\\]/g, '')\n        .replace(/(\\/\\/)/g, '')\n        .replace(/(\\.\\.)/g, '')\n        .replace(/(@{)/g, '')\n        .replace(/(\\/\\.)/g, '')\n        .replace(/^[\\/]/g, '')\n        .replace(/(\\.lock)$/g, '')\n        .replace(/[\\/\\.]$/g, '')\n        .replace(/(\\.\\/$)/g, '')\n        .replace(/\\\"/g, '\\\\\"');\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nfunction configureGit() {\n    execSync(\n        `\n        git config --local user.email \"${gitEmail}\" || exit 1\n        git config --local user.name \"${gitName}\" || exit 1`,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction maskSensitiveInformation(data, sensitiveFlags) {\n    const maskingSequence = '*****';\n\n    const arrayOfData = data.split(' ');\n    Object.keys(sensitiveFlags).forEach((subStr) => {\n        const keyIndex = arrayOfData.indexOf(subStr);\n        if (keyIndex > -1) {\n            arrayOfData[keyIndex + 1] = maskingSequence;\n            arrayOfData.splice(keyIndex + 2, sensitiveFlags[subStr].split(' ').length - 1);\n        }\n    });\n    return arrayOfData.join(' ');\n}\n\n\nmodule.exports.execute = execute;\nmodule.exports.updatePackageVersion = updatePackageVersion;\nmodule.exports.getLatestVersion = getLatestVersion;\nmodule.exports.setSFLogLevel = setSFLogLevel;\nmodule.exports.createPackageVersion = createPackageVersion;\nmodule.exports.pollPackageVersionCreateRequest = pollPackageVersionCreateRequest;\nmodule.exports.updateSFProjectFile = updateSFProjectFile;\nmodule.exports.getVersionInfo = getVersionInfo;\nmodule.exports.createTag = createTag;\nmodule.exports.deleteTag = deleteTag;\nmodule.exports.escapeCharactersForTagDeletion = escapeCharactersForTagDeletion;\nmodule.exports.commit = commit;\nmodule.exports.pushTagAndBranchChanges = pushTagAndBranchChanges;\nmodule.exports.cloneRepo = cloneRepo;\nmodule.exports.setInstanceURL = setInstanceURL;\nmodule.exports.setProgressStatus = setProgressStatus;\nmodule.exports.truncateError = truncateError;\nmodule.exports.getErrorCmd = getErrorCmd;\nmodule.exports.readProjectJson = readProjectJson;\nmodule.exports.getVersionAlias = getVersionAlias;\nmodule.exports.updateTagBranchDetails = updateTagBranchDetails;\nmodule.exports.updatePackageVersionTag = updatePackageVersionTag;\nmodule.exports.buildParameters = buildParameters;\nmodule.exports.escapeCharactersForTagCreation = escapeCharactersForTagCreation;\nmodule.exports.escapeSpecialCharacters = escapeSpecialCharacters;\nmodule.exports.stripTag = stripTag;\nmodule.exports.logger = logger;\nmodule.exports.configureGit = configureGit;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0l7Q000000iAiQQAU",
                    "LastReferencedDate": "2023-12-19T15:48:45.000+0000",
                    "LastViewedDate": "2023-12-19T15:48:45.000+0000",
                    "Name": "SFDX Package Version Create"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q000000iAiRQAU"
                    },
                    "copado__API_Name__c": "SFDX_Get_Package_Version_Dependencies",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"endpoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"session\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"subscriberVersionId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.subscriberId}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"installationKey\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.installationKey}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\nconst { execSync } = require('child_process'),\n    { endpoint, session, subscriberVersionId, installationKey } = process.env,\n    baseUrl = endpoint.substring(0, endpoint.indexOf('/', endpoint.indexOf('/') + 2)),\n    checkLog = 'Please check the logs for details',\n    TEMP_DIRECTORY = 'temp';\n\n// EXECUTON\n\nexecute();\n\nfunction execute() {\n    try {\n        createSFDXProject(TEMP_DIRECTORY);\n        setInstanceURL();\n        const dependencies = getVersionDependencies();\n        handleDependenciesResponse(dependencies);\n    } catch (err) {\n        //Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n        if (err?.status === 3) {\n            process.exit(1);\n        }\n        execSync(`${getErrorCmd(err.toString())}`);\n    }\n}\n\n// SCRIPT FUNCTIONS\n\nfunction createSFDXProject(directory) {\n    execSync(`\n\t\tcopado -p 'Creating Temp Project'\n        sf project generate --name ${directory} || (${getErrorCmd(`Error creating SFDX project, ${checkLog}`)})\n    `,\n        { stdio: 'inherit' }\n    );\n    process.chdir(directory);\n}\n\nfunction setInstanceURL() {\n    execSync(\n        `\n\t  copado -p 'Setting instance url'\n\t  sf config set org-instance-url=${baseUrl} || (${getErrorCmd(`Error setting instance URL, ${checkLog}`)})\n\t`,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction getVersionDependencies() {\n    const query = `SELECT MajorVersion, MinorVersion, PatchVersion, BuildNumber, SubscriberPackageId, Dependencies FROM SubscriberPackageVersion WHERE Id='${subscriberVersionId}' ${addFilter()}`;\n\n    const logMessage = `SubscriberPackageVersion Query From Devhub  ==> ${query}`;\n    logger(installationKey ? maskSensitiveInformation(logMessage, { 'InstallationKey=': installationKey }) : logMessage);\n\n    const result = execSync(`\n\t\t\tcopado -p 'Getting dependencies'\n\t\t\tsf data query --query \"${query}\" --use-tooling-api --target-org ${session} --json || true\n\t\t`).toString();\n    logger(`SubscriberPackageVersion Tooling API Response ==> ${JSON.stringify(result)}`);\n\n    return JSON.parse(result);\n}\n\nfunction getErrorCmd(error) {\n    const refinedErrorMsg = installationKey\n        ? maskSensitiveInformation(error, { '--target-org': session, 'InstallationKey=': installationKey })\n        : maskSensitiveInformation(error, { '--target-org': session });\n    return `copado -p 'Error' -e ${JSON.stringify(refinedErrorMsg).replace(/\\\\n/g, '\\n').replace(/\\\\t/g, '\\t')} && exit 3`;\n}\n\nfunction addFilter() {\n    return installationKey ? `AND InstallationKey= '${installationKey}'` : '';\n}\n\nfunction handleDependenciesResponse(response) {\n    let updateResult;\n    if (!response.status) {\n        const apiResponse = response?.result?.totalSize && response?.result?.records[0];\n        const result = getResult(apiResponse);\n\n        updateResult = `copado -p 'Updating dependencies' -r '${JSON.stringify(result)}'`;\n    } else {\n        updateResult = getErrorCmd(`${response.name}: ${response.message}`);\n    }\n    if (updateResult) {\n        execSync(updateResult, {\n            stdio: 'inherit'\n        });\n    }\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nfunction mapDependencies(response) {\n    let dependencies = [];\n    if (response?.Dependencies?.ids?.length) {\n        dependencies = response.Dependencies.ids.map((dependency) => dependency.subscriberPackageVersionId);\n    }\n    return dependencies;\n}\n\nfunction getResult(apiResponse) {\n    return {\n        subscriberVersionId: subscriberVersionId,\n        dependencies: apiResponse && mapDependencies(apiResponse),\n        versionNumber:\n            apiResponse && `${apiResponse.MajorVersion}.${apiResponse.MinorVersion}.${apiResponse.PatchVersion}.${apiResponse.BuildNumber}`,\n        subscriberPackageId: apiResponse && apiResponse.SubscriberPackageId\n    };\n}\n\nfunction maskSensitiveInformation(data, sensitiveFlags) {\n    const maskingSequence = '*****';\n\n    const arrayOfData = data.split(' ');\n    Object.keys(sensitiveFlags).forEach((subStr) => {\n        const keyIndex = arrayOfData.indexOf(subStr);\n        if (keyIndex > -1) {\n            arrayOfData[keyIndex + 1] = maskingSequence;\n            arrayOfData.splice(keyIndex + 2, sensitiveFlags[subStr].split(' ').length - 1);\n        }\n    });\n    return arrayOfData.join(' ');\n}",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q000000iAiRQAU",
                    "LastReferencedDate": "2023-12-20T05:14:11.000+0000",
                    "LastViewedDate": "2023-12-20T05:14:11.000+0000",
                    "Name": "SFDX Get Package Version Dependencies"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v55.0/sobjects/copado__Function__c/a0k09000000qQSoAAM"
                    },
                    "copado__API_Name__c": "sfdx_execute_apex",
                    "copado__Description__c": "Run sfdx force:apex:execute to execute Apex Job Steps.",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"destination_sessionid\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destination_endpoint\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"script\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destination_env_var\",\n  \"defaultValue\" : \"{$Destination.apex.EnvironmentVariables}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"isValidation\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.deploymentDryRun}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n/**\n * Performs execution of apex script using sfdx cli command.\n * @param destination_sessionid\n * @param destination_endpoint\n * @param script\n * @param destination_env_var\n * @param isValidation\n */\n\nconst { mkdirSync, writeFileSync } = require('fs'),\n    { execSync, exec } = require('child_process'),\n    { destination_sessionid, destination_endpoint, script, destination_env_var, isValidation, isTest, API_VERSION } = process.env,\n    destination_base_url = getBaseUrl(destination_endpoint),\n    scriptName = 'script.apex',\n    validationModeMessage = 'This step will not be executed for validate changes',\n    TEMP_DIRECTORY = getPath('/tmp'),\n    SFDX_PROJECT_DIRECTORY = `${TEMP_DIRECTORY}/sfdx-project`,\n    STDIO = {\n        INHERIT: 'inherit',\n        PIPE: 'pipe',\n        IGNORE: 'ignore'\n    };\n\n// EXECUTION\n\nfunction execute() {\n    try {\n        this.validateExecutionMode();\n        this.createSfdxProject(SFDX_PROJECT_DIRECTORY);\n        this.writeScriptContent(scriptName, script);\n        this.performVarreplace();\n        this.setupSFConfig();\n        this.executeApexScript();\n    } catch (error) {\n        this.logError(error);\n    }\n}\n\n// SCRIPT FUNCTIONS\n\nfunction createSfdxProject(projectDirectory) {\n    this.asyncCopadoLogMessage('Creating SFDX Project');\n    mkdirSync(projectDirectory, { recursive: true, force: true });\n    const projectJSON = {\n        packageDirectories: [\n            {\n                path: 'force-app',\n                default: true\n            }\n        ],\n        name: 'sfdx-project',\n        namespace: '',\n        sfdcLoginUrl: 'https://login.salesforce.com',\n        sourceApiVersion: API_VERSION\n    };\n    writeFileSync(`${projectDirectory}/sfdx-project.json`, JSON.stringify(projectJSON));\n    process.chdir(projectDirectory);\n}\n\nfunction writeScriptContent(scriptName, script) {\n    const content = script.replace('\\\\n', ' ');\n    writeFileSync(scriptName, content);\n}\n\nfunction performVarreplace() {\n    this.asyncCopadoLogMessage('Replacing environment variables, if any');\n    const cmd = `\n\t  varreplace '${destination_env_var}' '${scriptName}' --valuename=false\n  `;\n    execSync(cmd, { stdio: STDIO.INHERIT });\n}\n\nfunction setupSFConfig() {\n    this.asyncCopadoLogMessage('Configuring sf cli');\n    const cmd = `\n      sf config set org-instance-url=${destination_base_url}\n    `;\n    execSync(cmd, { stdio: STDIO.INHERIT });\n}\n\nfunction executeApexScript() {\n    /* \n        TODO: In sfdx(v7) version the sf apex run fails abruptly in case of error (so error handling cannot be done, but it works fine in case of success)\n        but it doesn't happen in case of sf(v2). Once we switch to sf(v2) then we will be using it as illustrated below\n    */\n    /*const cmd = `\n        copado -p 'Executing apex script'\n        sf apex run --target-org ${destination_sessionid} --file '${scriptName}' --json\n    `;*/\n    this.asyncCopadoLogMessage('Executing apex script');\n    const cmd = `\n        sfdx force:apex:execute --targetusername ${destination_sessionid} --apexcodefile '${scriptName}' --json\n    `;\n    const response = execSync(cmd, { maxBuffer: 50 * 1024 * 1024 });\n    this.validateResponse(response);\n}\n\nfunction validateResponse(response) {\n    if (!response) {\n        throw 'Apex script execution failed';\n    }\n    const formattedResponse = JSON.parse(response.toString());\n    if (formattedResponse.status != 0) {\n        throw formattedResponse?.message;\n    } else if (!formattedResponse?.result?.compiled || !formattedResponse?.result?.success) {\n        throw `Error occured: \"${JSON.stringify(formattedResponse?.result)}\". Please check logs for more details.`;\n    } else {\n        execSync(`copado -p 'Apex script execution completed successfully'`);\n    }\n}\n\nfunction logError(error) {\n    execSync(`copado -p 'Error' -e \"${error.toString()}\" && exit 1`);\n}\n\nfunction validateExecutionMode() {\n    if (isValidation === 'true') {\n        execSync(`copado -p '${validationModeMessage}' --result-data '${validationModeMessage}'`);\n        process.exit(0);\n    }\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname}/__tests__/__mockDirectory__${filePath}` : filePath;\n}\n\nfunction getBaseUrl(endpoint) {\n    return endpoint.substring(0, endpoint.indexOf('/', endpoint.indexOf('/') + 2));\n}\n\nfunction asyncCopadoLogMessage(msg) {\n    new Promise(resolve => {\n        exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, (err, response, stderr) => {\n            resolve();\n        });\n    });\n}\n\nmodule.exports.execute = execute;\nmodule.exports.validateExecutionMode = validateExecutionMode;\nmodule.exports.performVarreplace = performVarreplace;\nmodule.exports.setupSFConfig = setupSFConfig;\nmodule.exports.executeApexScript = executeApexScript;\nmodule.exports.logError = logError;\nmodule.exports.validateResponse = validateResponse;\nmodule.exports.getPath = getPath;\nmodule.exports.createSfdxProject = createSfdxProject;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.writeScriptContent = writeScriptContent;\n!isTest && this.execute();",
                    "copado__Timeout__c": 60,
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0k09000000qQSoAAM",
                    "LastReferencedDate": "2022-06-27T07:54:21.000+0000",
                    "LastViewedDate": "2022-06-27T07:54:21.000+0000",
                    "Name": "SFDX Execute Apex"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q000000iAiTQAU"
                    },
                    "copado__API_Name__c": "SFDXPackageCreate",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"devhubEndpoint\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"devhubSession\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"packageName\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"path\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"jsonInformation\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"description\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"name\" : \"branch\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\nconst { mkdirSync, readFileSync } = require('fs'),\n    { execSync } = require('child_process'),\n    { gitEmail, gitName, devhubEndpoint, branch, devhubSession, packageName, path, description, isTest } = process.env,\n    { loglevel, apiversion, packagetype, nonamespace, orgdependent, errornotificationusername, namespaceprefix } = JSON.parse(\n        process.env['jsonInformation']?.replace(/\\\\/g, '')\n    ),\n    baseUrl = devhubEndpoint?.substring(0, devhubEndpoint?.indexOf('/', devhubEndpoint?.indexOf('/') + 2)),\n    DIR_NAME = 'sfProject',\n    CHECK_LOG = 'Please check the logs for details',\n    SFDX_PROJECT_JSON = 'sfdx-project.json';\n\n// SCRIPT FUNCTIONS\n\nfunction execute() {\n    try {\n        this.setupDirectory(DIR_NAME);\n        this.prepareAndCloneRepo(branch);\n        this.setInstanceUrl(baseUrl);\n        this.configureGit(gitEmail, gitName);\n        this.validateNamespace(namespaceprefix, nonamespace);\n        const flags = this.buildParameters({\n            loglevel,\n            'target-dev-hub': devhubSession,\n            'api-version': apiversion,\n            name: packageName,\n            path,\n            'package-type': packagetype,\n            'no-namespace': nonamespace,\n            'org-dependent': orgdependent,\n            description,\n            'error-notification-username': errornotificationusername\n        });\n        this.createPackage(flags);\n    } catch (err) {\n        //Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n        if (err?.status === 3) {\n            process.exit(1);\n        }\n        execSync(`${this.getErrorCmd(err.toString())}`);\n    }\n}\n\nfunction setupDirectory(dirName) {\n    mkdirSync(dirName);\n    process.chdir(dirName);\n}\n\nfunction buildParameters(flags) {\n    return Object.entries(flags).reduce((parameters, [key, value]) => {\n        return parameters + (typeof value == 'boolean' ? (value ? ` --${key}` : '') : value ? ` --${key} \"${value}\"` : '');\n    }, '');\n}\n\nfunction getPackagesList(sessionId) {\n    return JSON.parse(execSync(`sf package list --target-dev-hub ${sessionId} --json || true`).toString());\n}\n\nfunction prepareAndCloneRepo(branchName) {\n    execSync(`\n        copado -p 'Cloning git repository'\n        copado-git-get '${branchName}' || (${this.getErrorCmd(`Could not checkout branch ${branchName}, ${CHECK_LOG}`)})\n    `);\n}\n\nfunction setInstanceUrl(baseUrl) {\n    execSync(`\n        copado -p 'Setting instance url'\n        sf config set org-instance-url=${baseUrl} || (${this.getErrorCmd(`Failed setting an instance URL, ${CHECK_LOG}`)})\n    `);\n}\n\nfunction createPackage(pkgCreateParam) {\n    const createCmd = `sf package create ${pkgCreateParam} --json`,\n        createCmdExec = `\n            copado -p 'Creating package'\n            ${createCmd} || true\n            copado -p 'Finishing'\n        `;\n    this.logger(`Package Create Command ==> ${createCmd}`);\n\n    //escaping special characters here, so it can be used in payload\n    const response = JSON.parse(execSync(this.escapeSpecialCharacters(createCmdExec)).toString());\n    this.logger(`Package Create Command Response ==> ${JSON.stringify(response)}`);\n\n    if (!response?.status && response?.result?.Id) {\n        this.commit();\n        const packageId = response.result.Id,\n            packagesDetails = this.getPackagesList(devhubSession);\n\n        if (packagesDetails?.status) {\n            this.setProgressStatus({\n                progressStatus: 'Error',\n                errorMessage: `Error fetching package version list from devhub, ${packagesDetails.message}`\n            });\n        } else {\n            const namespace = packagesDetails.result.find(pkg => pkg.Id === packageId)?.NamespacePrefix,\n                resultData = { packageId: packageId, namespace: namespace ? namespace : '' };\n            this.setProgressStatus({ progressStatus: 'Package created successfully', resultData: JSON.stringify(resultData) });\n        }\n    } else {\n        this.setProgressStatus({\n            progressStatus: 'Package creation failed',\n            errorMessage: `Could not create package, ${response.message}`\n        });\n    }\n}\n\nfunction commit() {\n    execSync(\n        `\n        git add '${SFDX_PROJECT_JSON}' || (${this.getErrorCmd(`Error adding git change, ${CHECK_LOG}`)})\n        git commit -m 'Committing sfdx-project.json' || (${this.getErrorCmd(`Error commiting git change, ${CHECK_LOG}`)})\n        git push origin ${branch} || (${this.getErrorCmd(`Error pushing changes in git, ${CHECK_LOG}`)})`,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction setProgressStatus({ progressStatus, errorMessage, resultData }) {\n    execSync(`copado -p '${progressStatus}' ${errorMessage ? `-e '${errorMessage}'` : ''} ${resultData ? `-r '${resultData}'` : ''}`);\n    if (errorMessage) {\n        throw errorMessage;\n    }\n}\n\nfunction getErrorCmd(error) {\n    const refinedErrorMsg = this.maskSensitiveInformation(error);\n    return `copado -p 'Error' -e ${this.escapeSpecialCharacters(JSON.stringify(refinedErrorMsg).replace(/\\\\n/g, '\\n'))} ${isTest ? '' : '&& exit 3'}`;\n}\n\nfunction readProjectJson(fileName) {\n    try {\n        return JSON.parse(readFileSync(fileName, 'utf-8'));\n    } catch (err) {\n        throw `Issue while parsing sfdx-project.json file. \\n${err.toString()}`;\n    }\n}\n\nfunction escapeSpecialCharacters(text) {\n    return text?.replace(/`/g, '\\\\`')?.replace(/\\$/g, '\\\\$');\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nfunction configureGit(gitEmail, gitName) {\n    execSync(\n        `\n        git config --local user.email \"${gitEmail}\" || (${this.getErrorCmd(`Issue configuring git email, ${CHECK_LOG}`)})\n        git config --local user.name \"${gitName}\" || (${this.getErrorCmd(`Issue configuring git name, ${CHECK_LOG}`)})`,\n        { stdio: 'inherit' }\n    );\n}\n\nfunction validateNamespace(namespaceprefix, nonamespace) {\n    if (namespaceprefix && !nonamespace && this.readProjectJson(SFDX_PROJECT_JSON)?.namespace !== namespaceprefix) {\n        this.setProgressStatus({\n            progressStatus: 'Error',\n            errorMessage: `Namespace in package record does not match with sfdx-project.json file in git repository.`\n        });\n    }\n}\n\nfunction maskSensitiveInformation(data) {\n    const sensitiveInfo = ['--target-dev-hub', '-u', '-v'],\n        maskingSequence = '*****';\n\n    const arrayOfData = data.split(' ');\n    sensitiveInfo.forEach(subString => {\n        const keyIndex = arrayOfData.indexOf(subString);\n        if (keyIndex > -1) {\n            arrayOfData[keyIndex + 1] = maskingSequence;\n            data = arrayOfData.join(' ');\n        }\n    });\n    return data;\n}\n\nmodule.exports.configureGit = configureGit;\nmodule.exports.logger = logger;\nmodule.exports.escapeSpecialCharacters = escapeSpecialCharacters;\nmodule.exports.readProjectJson = readProjectJson;\nmodule.exports.getErrorCmd = getErrorCmd;\nmodule.exports.setProgressStatus = setProgressStatus;\nmodule.exports.commit = commit;\nmodule.exports.createPackage = createPackage;\nmodule.exports.prepareAndCloneRepo = prepareAndCloneRepo;\nmodule.exports.setInstanceUrl = setInstanceUrl;\nmodule.exports.getPackagesList = getPackagesList;\nmodule.exports.buildParameters = buildParameters;\nmodule.exports.execute = execute;\nmodule.exports.setupDirectory = setupDirectory;\nmodule.exports.validateNamespace = validateNamespace;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q000000iAiTQAU",
                    "LastReferencedDate": "2023-12-19T15:49:30.000+0000",
                    "LastViewedDate": "2023-12-19T15:49:30.000+0000",
                    "Name": "SFDX Package Create"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v57.0/sobjects/copado__Function__c/a0l7Q000000MDZ5QAO"
                    },
                    "copado__ApexClass__c": null,
                    "copado__API_Name__c": "SFDXRunApexTests",
                    "copado__Callback_Type__c": null,
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEndpoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"name\" : \"testMinutesTimeout\",\n  \"defaultValue\" : \"1440\"\n}, {\n  \"name\" : \"testResultIds\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.resultIds}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"testSuiteAndTestClassFileVersionDetails\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.GetFileVersionIdOfTestClassTestSuite}\"\n}, {\n  \"name\" : \"consolidatedResultId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.resultId}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n\t{ mkdirSync, writeFileSync, existsSync, readFile } = require('fs'),\n\t{\n\t\tsourceSessionId,\n\t\tsourceEndpoint,\n\t\ttestMinutesTimeout,\n\t\ttestResultIds,\n\t\ttestSuiteAndTestClassFileVersionDetails,\n\t\tconsolidatedResultId,\n\t\tmaxBuffer,\n\t\tisTest,\n\t\tAPI_VERSION\n\t} = process.env,\n\t{ Ux } = isTest ? require('@salesforce/sf-plugins-core') : require('/usr/local/lib/node_modules/@salesforce/sf-plugins-core'),\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tSFDX_PROJECT_DIRECTORY = `${TEMP_DIRECTORY}/sfdx-project`,\n\tSTDIO = {\n\t\tINHERIT: 'inherit',\n\t\tPIPE: 'pipe',\n\t\tIGNORE: 'ignore'\n\t},\n\tNUMBER_OF_RUN_APEX_TESTS_RETRIES = 10,\n\tCONSTANTS = {\n\t\tTEST_SUITE_FILE_NAME: 'cmcSf_TestSuites',\n\t\tTEST_CLASS_FILE_NAME: 'cmcSf_TestClasses'\n\t},\n\t{ cpus } = require('os'),\n\tRESULT_INFO = {\n\t\t\tCATEGORY: {\n\t\t\t\tSFDX_CLI: 'Salesforce CLI'\n\t\t\t},\n\t\t\tADDITIONAL_INFORMATION: {\n\t\t\t\tINSTANCE_URL :'INSTANCE URL',\n\t\t\t\tRUN_APEX_TEST: 'RUN APEX TEST'\n\t\t\t}\n\t};\n\nlet totalTimeByType = {},\n\tprocesses = [];\n\n// SCRIPT FUNCTIONS\n\nasync function execute() {\n\ttry {\n\t\tthis.asyncCopadoLogMessage('Preparing sfdx project configuration');\n\t\tthis.setup(SFDX_PROJECT_DIRECTORY);\n\t\tthis.switchToDirectory(SFDX_PROJECT_DIRECTORY);\n\t\tthis.setInstanceUrl(sourceEndpoint);\n\t\tconst contentVersionIdsOfTestClassesAndTestSuites = this.getContentVersionIdsOfTestClassesAndTestSuites(\n\t\t\ttestSuiteAndTestClassFileVersionDetails\n\t\t);\n\t\tconst testClasses = await this.getTestClasses(contentVersionIdsOfTestClassesAndTestSuites);\n\t\tthis.asyncCopadoLogMessage('Running apex tests in the source environment');\n\t\tconst testResult = await this.executeApexTest(sourceSessionId, testClasses, testMinutesTimeout, 0);\n\t\tthis.switchToDirectory(TEMP_DIRECTORY);\n\t\tthis.asyncCopadoLogMessage('Uploading apex tests execution result');\n\t\tawait Promise.all(this.uploadTestResult(testResult, TEMP_DIRECTORY, consolidatedResultId, testResultIds));\n\t} catch (error) {\n\t\tconst executionError = error.message || error?.toString() || 'Unknown Error occurred';\n\t\tthis.executeCommand(this.getErrorCmdString(executionError));\n\t\t!isTest && process.exit(1);\n\t}\n\tfinally {\n\t\tthis.printMetrics();\n\t}\n}\n\nfunction setup(projectDirectory) {\n\tmkdirSync(projectDirectory, { recursive: true, force: true });\n\tconst projectJSON = {\n\t\tpackageDirectories: [\n\t\t\t{\n\t\t\t\tpath: 'force-app',\n\t\t\t\tdefault: true\n\t\t\t}\n\t\t],\n\t\tname: 'sfdx-project',\n\t\tnamespace: '',\n\t\tsfdcLoginUrl: 'https://login.salesforce.com',\n\t\tsourceApiVersion: API_VERSION\n\t};\n\twriteFileSync(`${projectDirectory}/sfdx-project.json`, JSON.stringify(projectJSON));\n}\n\nfunction setInstanceUrl(sourceEndpoint) {\n\tthis.startWatch(RESULT_INFO.CATEGORY.SFDX_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.INSTANCE_URL, processes);\n\tconst baseUrl = sourceEndpoint?.substring(0, sourceEndpoint?.indexOf('/', sourceEndpoint?.indexOf('/') + 2));\n\tconst command = `\n        sf config set org-instance-url ${baseUrl}\n    `;\n\tthis.executeCommand(command);\n\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.INSTANCE_URL, processes);\n}\n\nasync function executeApexTest(sourceSessionId, testClasses, testMinutesTimeout, retryCount) {\n\tif (!testClasses) {\n\t\tthrow new Error('There is no test class available for execution');\n\t}\n\tthis.startWatch(RESULT_INFO.CATEGORY.SFDX_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.RUN_APEX_TEST, processes);\n\tconst testsParam = testClasses?.map(testClass => `--class-names ${testClass}`)?.join(' ');\n\tconst command = `sf apex run test --target-org ${sourceSessionId} ${testsParam} --result-format json --detailed-coverage --code-coverage --wait ${testMinutesTimeout}`;\n\ttry {\n\t\tconst response = await this.executeCommandAsync(command, true, true);\n\t\treturn response;\n\t} catch (error) {\n\t\tif ((error?.includes('ETIMEDOUT') || error?.message?.includes('ETIMEDOUT')) && retryCount < NUMBER_OF_RUN_APEX_TESTS_RETRIES) {\n\t\t\tthis.messageLogger(`Retrying attempt ${retryCount + 1}`);\n\t\t\treturn await this.executeApexTest(sourceSessionId, testClasses, testMinutesTimeout, ++retryCount);\n\t\t} else {\n\t\t\tthrow error;\n\t\t}\n\t} finally {\n\t\tthis.endWatch(RESULT_INFO.ADDITIONAL_INFORMATION.RUN_APEX_TEST, processes);\n\t}\n}\n\nfunction uploadTestResult(testResult, TEMP_DIRECTORY, consolidatedResultId, testResultIds) {\n\tlet promises = [];\n\tpromises.concat(this.uploadTestResultToFunctionResult(testResult, TEMP_DIRECTORY));\n\tpromises.concat(this.uploadTestResultToConsolidatedAndTestResult(testResult, TEMP_DIRECTORY, consolidatedResultId, testResultIds));\n\treturn promises;\n}\n\nfunction uploadTestResultToFunctionResult(testResult, tmpDirectory) {\n\tconst promises = [];\n\tthis.removeUsernameFromTestResult(testResult);\n\tconst testResultFileName = `${tmpDirectory}/apex-tests-output.json`;\n\twriteFileSync(testResultFileName, JSON.stringify(testResult));\n\tconst command = `\n        copado --uploadfile ${testResultFileName} --name \"apex-tests-output.json\"\n    `;\n\tpromises.push(this.executeCommandAsync(command));\n\treturn promises;\n}\n\nfunction uploadTestResultToConsolidatedAndTestResult(testResult, tmpDirectory, consolidatedResultId, testResultIds) {\n\tif (!consolidatedResultId && !testResultIds) {\n\t\tthrow new Error('No appropriate result record found');\n\t}\n\tconst promises = [];\n\tthis.removeUsernameFromTestResult(testResult);\n\tthis.removeCoveredLinesFromTestResult(testResult);\n\tthis.removeSummaryAndRecordDetailsFromTestResult(testResult);\n\tconst testResultFileName = `${tmpDirectory}/apex-tests-truncated-output.json`;\n\twriteFileSync(testResultFileName, JSON.stringify(testResult));\n\n\tconst resultIds = testResultIds ? JSON.parse(testResultIds) : [];\n\tconsolidatedResultId && resultIds.push(consolidatedResultId);\n\n\tresultIds.forEach(resultId => {\n\t\tconst command = `\n            copado --uploadfile ${testResultFileName} --name \"apex-tests-output.json\" --parentid ${resultId}\n        `;\n\t\tpromises.push(this.executeCommandAsync(command));\n\t});\n\treturn promises;\n}\n\nfunction asyncCopadoLogMessage(msg) {\n\tnew Promise(resolve => {\n\t\tchild_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, (err, response, stderr) => {\n\t\t\tresolve();\n\t\t});\n\t});\n}\n\nfunction switchToDirectory(workingDirectory) {\n\tprocess.chdir(workingDirectory);\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDirectory__${filePath}` : filePath;\n}\n\nfunction executeCommand(command, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.log(response, disableLogs);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthrow new Error(errorMessage);\n\t}\n}\n\nfunction executeCommandAsync(command, hasJsonResponse, disableLog) {\n\treturn new Promise((resolve, reject) => {\n\t\tlet output = '',\n\t\t\terror = '';\n\t\tconst childProcess = child_process.spawn(command, [], { shell: true });\n\n\t\tchildProcess.stdout.on('data', data => {\n\t\t\toutput += data?.toString();\n\t\t});\n\n\t\tchildProcess.stderr.on('data', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('close', code => {\n\t\t\tlet rejected = false;\n\t\t\tif (code !== 0) {\n\t\t\t\tlet errorMessage = '';\n\t\t\t\tif (hasJsonResponse) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tresolve(JSON.parse(output));\n\t\t\t\t\t} catch (ex) {\n\t\t\t\t\t\terrorMessage = error;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\terrorMessage = error;\n\t\t\t\t}\n\t\t\t\terrorMessage = errorMessage ? errorMessage : `Error executing the command ${command}`;\n\t\t\t\treject(errorMessage);\n\t\t\t\trejected = true;\n\t\t\t}\n\t\t\tif (!disableLog) {\n\t\t\t\tthis.messageLogger(code?.toString());\n\t\t\t\tthis.messageLogger(output);\n\t\t\t\tthis.messageLogger(error);\n\t\t\t}\n\t\t\tif (!rejected) {\n\t\t\t\tresolve(hasJsonResponse ? JSON.parse(output) : output);\n\t\t\t}\n\t\t});\n\n\t\tchildProcess.on('error', error => {\n\t\t\treject(error);\n\t\t});\n\t});\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(maxBuffer)\n\t};\n\treturn options;\n}\n\nfunction log(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tthis.messageLogger(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tthis.messageLogger(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction messageLogger(message) {\n\tconsole.log(message);\n}\n\nfunction getErrorCmdString(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `copado -p \"Error\" -e \"${error.trim()?.substring(0, 32760)}; ${suffix}\"`;\n}\n\nfunction removeUsernameFromTestResult(testResult) {\n\tif (testResult?.result?.summary?.username) {\n\t\tdelete testResult.result.summary.username;\n\t}\n}\n\nfunction removeCoveredLinesFromTestResult(testResult) {\n\ttestResult?.result?.coverage?.coverage?.forEach(element => {\n\t\tdelete element.lines;\n\t});\n}\n\nfunction removeSummaryAndRecordDetailsFromTestResult(testResult) {\n\tif (testResult?.result?.coverage?.summary) {\n\t\tdelete testResult.result.coverage.summary;\n\t}\n\n\tif (testResult?.result?.coverage?.records) {\n\t\tdelete testResult.result.coverage.records;\n\t}\n}\n\nasync function getTestClasses(contentVersionIdsOfTestClassesAndTestSuites) {\n\tthis.asyncCopadoLogMessage('Finding test classes for execution');\n\tconst commands = [];\n\tcontentVersionIdsOfTestClassesAndTestSuites.forEach(contentVersionId => {\n\t\tconst command = {};\n\t\tcommand.value = `\n\t\t\t  mkdir -p ${TEMP_DIRECTORY}/${contentVersionId}\n\t\t\t  copado --downloadfiles \"${contentVersionId}\" --downloaddir ${TEMP_DIRECTORY}/${contentVersionId}\n\t\t  `;\n\t\tcommands.push(command);\n\t});\n\n\tconst totalCpus = cpus().length;\n\tconst parallelCommandExecutor = new this.ParallelCommandExecutor(commands, totalCpus == 1 ? 1 : totalCpus - 1);\n\tawait Promise.all(parallelCommandExecutor.startExecution());\n\n\tlet testClasses = new Set();\n\tconst testSuitesAndTestClassesFileContent = await Promise.all(\n\t\tthis.getPromisesToReadTestSuitesAndTestClassesFile(contentVersionIdsOfTestClassesAndTestSuites)\n\t);\n\ttestSuitesAndTestClassesFileContent.forEach(fileContent => {\n\t\ttestClasses = new Set([...testClasses, ...this.getSelectedTestClasses(fileContent)]);\n\t});\n\n\tmessageLogger(`Test classes found for execution ${[...testClasses]}`);\n\n\tif (!testClasses.size) {\n\t\tthrow new Error('No test classes were found for execution');\n\t}\n\treturn [...testClasses];\n}\n\nfunction getPromisesToReadTestSuitesAndTestClassesFile(contentVersionIdsOfTestClassesAndTestSuites) {\n\tconst promises = [];\n\tcontentVersionIdsOfTestClassesAndTestSuites.forEach(contentVersionId => {\n\t\tconst testSuiteFilePath = `${TEMP_DIRECTORY}/${contentVersionId}/${CONSTANTS.TEST_SUITE_FILE_NAME}`;\n\t\tconst testClassFilePath = `${TEMP_DIRECTORY}/${contentVersionId}/${CONSTANTS.TEST_CLASS_FILE_NAME}`;\n\t\tif (existsSync(testSuiteFilePath)) {\n\t\t\tpromises.push(this.readFileAsync(testSuiteFilePath, true));\n\t\t}\n\t\tif (existsSync(testClassFilePath)) {\n\t\t\tpromises.push(this.readFileAsync(testClassFilePath, true));\n\t\t}\n\t});\n\treturn promises;\n}\n\nfunction getSelectedTestClasses(testClassesAndTestSuitesFileContent) {\n\tlet result = new Set();\n\ttestClassesAndTestSuitesFileContent?.forEach(data => {\n\t\tif (data.children) {\n\t\t\tresult = new Set([...result, ...this.getSelectedTestClasses(data.children)]);\n\t\t} else if (data.s) {\n\t\t\tresult.add(data.n);\n\t\t}\n\t});\n\treturn result;\n}\n\nfunction getContentVersionIdsOfTestClassesAndTestSuites(testSuiteAndTestClassFileVersionDetails) {\n\tlet result;\n\ttry {\n\t\tresult = testSuiteAndTestClassFileVersionDetails ? JSON.parse(testSuiteAndTestClassFileVersionDetails) : [];\n\t} catch (error) {\n\t\tthrow new Error(`Error finding test suite and test class file ids, ${error.toString()}`);\n\t}\n\treturn result;\n}\n\nclass ParallelCommandExecutor {\n\tcommands;\n\tmaxAllowedChildProcesses;\n\n\tconstructor(commands, maxAllowedChildProcesses) {\n\t\tthis.commands = commands;\n\t\tthis.maxAllowedChildProcesses = maxAllowedChildProcesses;\n\t}\n\n\tstartExecution() {\n\t\tconst promises = [];\n\t\tlet totalConsumedChildProcesses = 0;\n\t\tconst totalCommands = this.commands?.length;\n\t\tif (!totalCommands || totalCommands < 1) {\n\t\t\tthrow new Error('No commands supplied to the command processor');\n\t\t}\n\n\t\twhile (this.commands.length && this.maxAllowedChildProcesses > totalConsumedChildProcesses) {\n\t\t\tpromises.push(\n\t\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\t\tthis._executeCommand(this.commands.shift(), resolve, reject);\n\t\t\t\t})\n\t\t\t);\n\t\t\ttotalConsumedChildProcesses++;\n\t\t}\n\t\tmessageLogger(`Parallel command executor started ${promises.length} child process(es) for processing ${totalCommands} command(s)`);\n\t\treturn promises;\n\t}\n\n\t_executeCommand(command, resolve, reject) {\n\t\tlet output = '',\n\t\t\terror = '';\n\t\tconst childProcess = child_process.spawn(command.value, [], {\n\t\t\tshell: true\n\t\t});\n\n\t\tchildProcess.stdout.on('data', data => {\n\t\t\toutput += data?.toString();\n\t\t});\n\n\t\tchildProcess.stderr.on('data', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('error', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('close', code => {\n\t\t\tif (!command.disableLogs) {\n\t\t\t\tmessageLogger(`command: ${command.value}, \\ncode: ${code}`);\n\t\t\t\tif (output) {\n\t\t\t\t\tmessageLogger(output);\n\t\t\t\t}\n\t\t\t\tif (error) {\n\t\t\t\t\tmessageLogger(error);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (code !== 0) {\n\t\t\t\tlet errorMessage = '';\n\t\t\t\tif (command.hasJsonResponse) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\terrorMessage = JSON.parse(output);\n\t\t\t\t\t} catch (err) {\n\t\t\t\t\t\terrorMessage = err.toString();\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\terrorMessage = error;\n\t\t\t\t}\n\t\t\t\terrorMessage = errorMessage ? errorMessage : `Error executing the command ${command.value}`;\n\t\t\t\treject(errorMessage);\n\t\t\t} else {\n\t\t\t\tthis._handleNextExecution(resolve, reject);\n\t\t\t}\n\t\t});\n\t}\n\n\t_handleNextExecution(resolve, reject) {\n\t\tif (this.commands.length) {\n\t\t\tthis._executeCommand(this.commands.shift(), resolve, reject);\n\t\t} else {\n\t\t\tmessageLogger('Parallel command executor resolved a child process');\n\t\t\tresolve('Parallel command executor resolved a child process');\n\t\t}\n\t}\n}\n\nfunction readFileAsync(filePath, isJsonContent) {\n\treturn new Promise((resolve, reject) => {\n\t\treadFile(filePath, (error, data) => {\n\t\t\tif (error) {\n\t\t\t\treject(error);\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tresolve(isJsonContent ? JSON.parse(data.toString()) : data.toString());\n\t\t\t\t} catch (err) {\n\t\t\t\t\treject(err.toString());\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t});\n}\n\nfunction startWatch(processType, processName, processes) {\n\tif (!processName || !processType) {\n\t\treturn;\n\t}\n\tconst startTime = process.hrtime();\n\tif (!totalTimeByType[processType]) {\n\t\ttotalTimeByType[processType] = 0;\n\t}\n\tprocesses.push({ name: processName, type: processType, startTime, endTime: null, elapsedTime: null });\n}\n\nfunction endWatch(processType, processes) {\n\tif (!processType) {\n\t\treturn;\n\t}\n\tconst processIndex = processes.length;\n\tif (!processIndex && processes[processIndex - 1].type !== processType) {\n\t\t// we call endWatch in sync with startwatch for same process & doesnt overlap with others endWatch. additionally checking that it belongs to the same processType in the processes index before we store it.\n\t\tconsole.error(`Process '${processType}' not started.`);\n\t\treturn;\n\t}\n\tconst endTime = process.hrtime();\n\tconst elapsedTime = process.hrtime(processes[processIndex - 1].startTime);\n\tprocesses[processIndex - 1].endTime = endTime;\n\tprocesses[processIndex - 1].elapsedTime = elapsedTime[0] * 1e9 + elapsedTime[1];\n}\n\nfunction printMetrics() {\n\tlet ux = new Ux();\n\tthis.messageLogger('\\n');\n\tux.styledHeader('====================      OVERALL METRICS      ====================');\n\tconst resultData = [];\n\tprocesses.forEach(process => {\n\t\t// store data\n\t\tresultData.push({\n\t\t\tprocessType: '| ' + process.type,\n\t\t\tprocessName: '| ' + process.name,\n\t\t\t'startTime(UTC)': process.startTime ? '| ' + this.formatTime(process.startTime) : '| ' + 'N/A',\n\t\t\t'endTime(UTC)': process.endTime ? '| ' + this.formatTime(process.endTime) : '| ' + 'N/A',\n\t\t\telapseTime: process.elapsedTime ? '| ' + `${(process.elapsedTime / 1e9).toFixed(2)} s` + ' |' : '| ' + 'N/A' + ' |'\n\t\t});\n\t\t// Aggregate total time by type\n\t\tif (process.elapsedTime) {\n\t\t\tif (!totalTimeByType[process.type]) {\n\t\t\t\ttotalTimeByType[process.type] = 0;\n\t\t\t}\n\t\t\ttotalTimeByType[process.type] += process.elapsedTime;\n\t\t}\n\t});\n\n\tux.table(resultData, { processType: {}, processName: {}, 'startTime(UTC)': {}, 'endTime(UTC)': {}, elapseTime: {} });\n\tthis.messageLogger('\\n' + '   ====================       EXECUTION SUMMARY      ====================   ');\n\t// Print total aggregate time by type\n\tObject.entries(totalTimeByType).forEach(([type, totalTime]) => {\n\t\tthis.messageLogger(`${type} Total Time: ${(totalTime / 1e9).toFixed(2)} seconds`);\n\t});\n\tthis.messageLogger('   ====================       EXECUTION SUMMARY      ====================   ' + '\\n');\n}\n\nfunction formatTime(time) {\n\tconst date = new Date(time[0] * 1000 + time[1] / 1e6);\n\tconst hours = date.getUTCHours().toString().padStart(2, '0');\n\tconst minutes = date.getUTCMinutes().toString().padStart(2, '0');\n\tconst seconds = date.getUTCSeconds().toString().padStart(2, '0');\n\tconst milliseconds = date.getUTCMilliseconds().toString().padStart(3, '0');\n\treturn `${hours}:${minutes}:${seconds}.${milliseconds}`;\n}\n\nmodule.exports.setup = setup;\nmodule.exports.setInstanceUrl = setInstanceUrl;\nmodule.exports.executeApexTest = executeApexTest;\nmodule.exports.uploadTestResult = uploadTestResult;\nmodule.exports.uploadTestResultToFunctionResult = uploadTestResultToFunctionResult;\nmodule.exports.uploadTestResultToConsolidatedAndTestResult = uploadTestResultToConsolidatedAndTestResult;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.switchToDirectory = switchToDirectory;\nmodule.exports.getPath = getPath;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.executeCommandAsync = executeCommandAsync;\nmodule.exports.getOptions = getOptions;\nmodule.exports.log = log;\nmodule.exports.messageLogger = messageLogger;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.removeUsernameFromTestResult = removeUsernameFromTestResult;\nmodule.exports.removeCoveredLinesFromTestResult = removeCoveredLinesFromTestResult;\nmodule.exports.removeSummaryAndRecordDetailsFromTestResult = removeSummaryAndRecordDetailsFromTestResult;\nmodule.exports.execute = execute;\nmodule.exports.getTestClasses = getTestClasses;\nmodule.exports.getSelectedTestClasses = getSelectedTestClasses;\nmodule.exports.getContentVersionIdsOfTestClassesAndTestSuites = getContentVersionIdsOfTestClassesAndTestSuites;\nmodule.exports.getPromisesToReadTestSuitesAndTestClassesFile = getPromisesToReadTestSuitesAndTestClassesFile;\nmodule.exports.ParallelCommandExecutor = ParallelCommandExecutor;\nmodule.exports.readFileAsync = readFileAsync;\nmodule.exports.startWatch = startWatch;\nmodule.exports.endWatch = endWatch;\nmodule.exports.formatTime = formatTime;\nmodule.exports.printMetrics = printMetrics;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Timeout__c": 1440,
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q000000MDZ5QAO",
                    "LastReferencedDate": "2023-03-29T04:19:26.000+0000",
                    "LastViewedDate": "2023-03-29T04:19:26.000+0000",
                    "Name": "SFDX Run Apex Tests"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v56.0/sobjects/copado__Function__c/a0l7Q000000iFzHQAU"
                    },
                    "copado__API_Name__c": "SFDX_Package_Version_Git_Config",
                    "copado__Description__c": "SFDX Package Version Git Config",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"packageVersion\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.packageVersion}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"name\" : \"dxNamespace\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.GetDxNamespace}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n// IMPORTS\nconst fs = require('fs'),\n    { execSync } = require('child_process'),\n    process = require('process'),\n    { packageVersion, isTest, dxNamespace } = process.env,\n    versionDetail = JSON.parse(packageVersion);\n\n// CONSTANTS\n\nconst STDIO = {\n        INHERIT: 'inherit'\n    },\n    CHECK_LOG = 'Please check the logs for details',\n    PROJECT_DIRECTORY = 'sfProject',\n    PROJECT_JSON = 'sfdx-project.json';\n\n// SCRIPT FUNCTIONS\n\nfunction cloneRepo(branchName) {\n    if (!branchName) {\n        throw `Could not find branch name.`;\n    }\n\n    execSync(\n        `\n\t\tcopado -p 'Cloning git repository'\n\t\tcopado-git-get ${branchName} --depth 1 || (${this.getErrorCmd(`Error check out branch ${branchName}, ${CHECK_LOG}`)})`,\n        { stdio: STDIO.INHERIT }\n    );\n}\n\nfunction readProjectJson(file) {\n    try {\n        return JSON.parse(fs.readFileSync(file, 'utf-8'));\n    } catch (error) {\n        throw `Error parsing ${file}. ${error?.toString()}`;\n    }\n}\n\nfunction escapeSpecialCharacters(text) {\n    return text.replace(/`/g, '\\\\`').replace(/\\$/g, '\\\\$');\n}\n\nfunction getErrorCmd(error) {\n    return `copado -p 'Error' -e ${this.escapeSpecialCharacters(JSON.stringify(error))} ${isTest ? '' : '&& exit 3'}`;\n}\n\nfunction getDetailsFromProjectJson(projectJson, version, dxNamespace) {\n    const packageId = version?.copado__Artifact__r?.copado__Package_Id__c,\n        packageAliases = projectJson?.packageAliases,\n        recordNamespace = version?.copado__Artifact__r?.copado__Package_Namespace__c,\n        projectJsonNamespace = projectJson?.namespace,\n        pkgName = packageAliases ? Object.keys(packageAliases)?.find(pckgId => packageAliases[pckgId] === packageId) : undefined;\n\n    this.checkAttributesAndHandleErrors({ packageAliases, packageId, pkgName, recordNamespace, projectJsonNamespace });\n\n    const {\n        versionNumber,\n        versionDescription,\n        versionName,\n        postInstallUrl,\n        ancestorVersion,\n        ancestorId,\n        postInstallScript,\n        releaseNotesUrl,\n        uninstallScript,\n        definitionFile\n    } = this.getPackageDirectory(projectJson, pkgName);\n\n    return JSON.stringify({\n        packageVersion: {\n            Id: version.Id,\n            copado__Version_number__c: versionNumber,\n            copado__Version_Description__c: versionDescription,\n            copado__Version_Name__c: versionName,\n            [`${dxNamespace}Post_Install_URL__c`]: postInstallUrl,\n            [`${dxNamespace}Post_Install_Script__c`]: postInstallScript,\n            [`${dxNamespace}Release_Notes_URL__c`]: releaseNotesUrl,\n            [`${dxNamespace}Uninstall_Script__c`]: uninstallScript,\n            copado__DefinitionFile__c: definitionFile,\n            [`${dxNamespace}Ancestor_Version__c`]: ancestorVersion,\n            [`${dxNamespace}Ancestor_Id__c`]: ancestorId ? (packageAliases[ancestorId] ? packageAliases[ancestorId] : ancestorId) : undefined\n        }\n    });\n}\n\nfunction checkAttributesAndHandleErrors({ packageAliases, packageId, pkgName, recordNamespace, projectJsonNamespace }) {\n    if (!packageAliases) {\n        throw `Missing attribute packageAliases from project JSON file`;\n    }\n\n    if (!packageId || !pkgName) {\n        throw `Missing associated package either in Salesforce record or project JSON file.`;\n    }\n\n    if (recordNamespace && projectJsonNamespace && recordNamespace != projectJsonNamespace) {\n        throw `Mismatch of namespace in Package record and repository.`;\n    }\n}\n\nfunction setupDirectory(directory) {\n    fs.mkdirSync(directory);\n    process.chdir(directory);\n}\n\nfunction execute() {\n    try {\n        this.setupDirectory(PROJECT_DIRECTORY);\n        this.cloneRepo(versionDetail.copado__Branch__c);\n        execSync(\n            `\n            copado -p 'Fetching details from repository'`,\n            { stdio: STDIO.INHERIT }\n        );\n        const projectJson = this.readProjectJson(PROJECT_JSON);\n        const versionDetails = this.getDetailsFromProjectJson(projectJson, versionDetail, dxNamespace);\n        const result = this.escapeSpecialCharacters(JSON.stringify(versionDetails));\n        execSync(`copado -p 'Fetch Successful' -r ${result}`, { stdio: STDIO.INHERIT });\n    } catch (err) {\n        //Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n        if (err?.status === 3) {\n            process.exit(1);\n        }\n        execSync(`${this.getErrorCmd(err?.toString())}`);\n    }\n}\n\nfunction getPackageDirectory(projectJson, pkgName) {\n    const pkgDirectory = projectJson?.packageDirectories?.find(dir => dir.package === pkgName);\n    if (!pkgDirectory) {\n        throw `Could not find directory for package '${pkgName}' in packageDirectories attribute in project JSON file.`;\n    }\n    return pkgDirectory;\n}\n\nmodule.exports.cloneRepo = cloneRepo;\nmodule.exports.escapeSpecialCharacters = escapeSpecialCharacters;\nmodule.exports.readProjectJson = readProjectJson;\nmodule.exports.getErrorCmd = getErrorCmd;\nmodule.exports.getDetailsFromProjectJson = getDetailsFromProjectJson;\nmodule.exports.checkAttributesAndHandleErrors = checkAttributesAndHandleErrors;\nmodule.exports.execute = execute;\nmodule.exports.setupDirectory = setupDirectory;\nmodule.exports.getPackageDirectory = getPackageDirectory;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Timeout__c": 120,
                    "copado__Type__c": "Standard",
                    "Id": "a0l7Q000000iFzHQAU",
                    "LastReferencedDate": "2023-01-30T10:18:48.000+0000",
                    "LastViewedDate": "2023-01-30T10:18:48.000+0000",
                    "Name": "SFDX Package Version Git Config"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v55.0/sobjects/copado__Function__c/a0k09000000rbjMAAQ"
                    },
                    "copado__API_Name__c": "SFDX_Deploy_Custom_Setting",
                    "copado__Description__c": "This function is used to create custom setting records",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEndpoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEnvVar\",\n  \"defaultValue\" : \"{$Source.apex.EnvironmentVariables}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationEnvVar\",\n  \"defaultValue\" : \"{$Destination.apex.EnvironmentVariables}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationSessionId\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationEndpoint\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"records\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : false,\n  \"name\" : \"customSettingName\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : false,\n  \"name\" : \"profiles\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : false,\n  \"name\" : \"users\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : false,\n  \"name\" : \"organizations\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : false,\n  \"name\" : \"keyPrefix\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"isValidation\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.deploymentDryRun}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"name\" : \"pollInterval\",\n  \"defaultValue\" : \"{$Pipeline.Property.customSettingPollInterval}\"\n}, {\n  \"name\" : \"maxRetrials\",\n  \"defaultValue\" : \"{$Pipeline.Property.customSettingMaxRetrials}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n/**\n * Performs deployment of custom setting records.\n * @param sourceSessionId\n * @param sourceEndpoint\n * @param sourceEnvVar\n * @param destinationEnvVar\n * @param destinationSessionId\n * @param destinationEndpoint\n * @param records\n * @param customSettingName\n * @param profiles\n * @param users\n * @param organizations\n * @param keyPrefix\n * @param isValidation\n */\n\nconst fs = require('fs'),\n\t{ exec, spawnSync, spawn } = require('child_process'),\n\t{\n\t\tsourceSessionId,\n\t\tsourceEndpoint,\n\t\tsourceEnvVar,\n\t\tdestinationEnvVar,\n\t\tdestinationSessionId,\n\t\tdestinationEndpoint,\n\t\tcustomSettingName,\n\t\tisValidation,\n\t\tisTest,\n\t\tAPI_VERSION,\n\t\tmaxBuffer,\n\t\tpollInterval,\n\t\tmaxRetrials\n\t} = process.env,\n\tsourceApiVersion = API_VERSION,\n\tsourceBaseUrl = getBaseUrl(sourceEndpoint),\n\tdestinationBaseUrl = getBaseUrl(destinationEndpoint),\n\tsourceEnvironment = 'source',\n\tdestinationEnvironment = 'destination',\n\tAPP_DIRECTORY = getPath('/app'),\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tMAX_BUFFER = parseInt(maxBuffer),\n\tSTDIO = {\n\t\tINHERIT: 'inherit',\n\t\tPIPE: 'pipe',\n\t\tIGNORE: 'ignore'\n\t},\n\tSFDX_PROJECT = 'sfdx_project',\n\tRECORDS_FILE = 'records.csv',\n\tRESULT_FILE = 'result.json',\n\tDEPLOYMENT_STATUS = {\n\t\tPENDING: 'Pending',\n\t\tINPROGRESS: 'InProgress'\n\t},\n\tPOLL_TIME = parseInt(pollInterval) >= 0 ? parseInt(pollInterval) : 1000,\n\tMAX_RETRIALS = parseInt(maxRetrials) >= 0 ? parseInt(maxRetrials) : 10;\n\n\nlet { records, profiles, users, organizations, keyPrefix } = process.env,\n\tprofileQuery,\n\tuserQuery,\n\torganizationQuery,\n\trecordNames,\n\tsourceCustomSetting = {},\n\tsourceRecords = {\n\t\tprofileMapping: {},\n\t\tuserMapping: {},\n\t\torganizationMapping: {},\n\t\trecords: []\n\t},\n\tdestinationRecords = {\n\t\tprofileMapping: {},\n\t\tuserMapping: {},\n\t\torganizationMapping: {},\n\t\trecords: {}\n\t};\n\n// FUNCTIONS\n\nfunction execute() {\n\ttry {\n\t\tthis.validateExecutionMode();\n\t\tthis.setup();\n\t\tthis.validateSource();\n\t\tthis.prepareQueryForDependentRecords();\n\t\tPromise.all(this.getCustomSettingDependentData(sourceSessionId, `Retrieve records from ${sourceEnvironment}`))\n\t\t\t.then(data => {\n\t\t\t\tthis.queryCustomSettingInSource(data);\n\t\t\t\tthis.validateDestination();\n\t\t\t\tPromise.all(this.getCustomSettingDependentData(destinationSessionId, `Retrieve records from ${destinationEnvironment}`))\n\t\t\t\t\t.then(async (data) => {\n\t\t\t\t\t\tthis.queryCustomSettingInDestination(data);\n\t\t\t\t\t\tawait this.mergeAndDeployRecords();\n\t\t\t\t\t})\n\t\t\t\t\t.catch(error => {\n\t\t\t\t\t\tthis.handleError(error);\n\t\t\t\t\t});\n\t\t\t})\n\t\t\t.catch(error => {\n\t\t\t\tthis.handleError(error);\n\t\t\t});\n\t} catch (error) {\n\t\tthis.handleError(error);\n\t}\n}\n\nfunction getBaseUrl(endpoint) {\n\treturn endpoint.substring(0, endpoint.indexOf('/', endpoint.indexOf('/') + 2));\n}\n\nfunction validateExecutionMode() {\n\tconst validationModeMessage = 'This step will not be executed for validate changes';\n\tif (isValidation === 'true') {\n\t\tconst command = `copado -p '${validationModeMessage}' --result-data '${validationModeMessage}'`;\n\t\tthis.executeCommand(command);\n\t\tprocess.exit(0);\n\t}\n}\n\nfunction handleError(error) {\n\tthis.executeCommand(this.getErrorCommandString(error.message || error?.toString()));\n\tprocess.exit(1);\n}\n\nfunction setup() {\n\tthis.asyncCopadoLogMessage('Preparing sfdx project configuration');\n\tconst cmd = `\n        cd ${APP_DIRECTORY}\n        sf project generate --name '${SFDX_PROJECT}'\n    `;\n\tthis.executeCommand(cmd);\n\n\tif (!fs.existsSync(`${APP_DIRECTORY}/${SFDX_PROJECT}/sfdx-project.json`)) {\n\t\tthrow new Error('There was some issue creating SFDX Project');\n\t}\n\n\tlet projectJson = fs.readFileSync(`${APP_DIRECTORY}/${SFDX_PROJECT}/sfdx-project.json`)?.toString();\n\tif (projectJson) {\n\t\tprojectJson = JSON.parse(projectJson);\n\t\tif (projectJson.sourceApiVersion !== sourceApiVersion) {\n\t\t\tprojectJson = { ...projectJson, sourceApiVersion };\n\t\t\tfs.writeFileSync(`${APP_DIRECTORY}/${SFDX_PROJECT}/sfdx-project.json`, JSON.stringify(projectJson));\n\t\t}\n\t}\n}\n\nfunction setInstanceUrl(url, message) {\n\tthis.asyncCopadoLogMessage(message);\n\tconst cmd = `\n        cd ${APP_DIRECTORY}/${SFDX_PROJECT}\n        sf config set org-instance-url=${url}\n    `;\n\tthis.executeCommand(cmd);\n}\n\nfunction retrieveCustomSettingMetadata(sessionid, message, environment, customSettingName) {\n\tlet result;\n\tif (!customSettingName) {\n\t\tthrow new Error(`Error occured (${environment}), invalid custom setting name`);\n\t}\n\tthis.asyncCopadoLogMessage(message);\n\tconst cmd = `\n        cd ${APP_DIRECTORY}/${SFDX_PROJECT}\n        sf project retrieve start --metadata CustomObject:${customSettingName} --target-org ${sessionid} --ignore-conflicts --json\n    `;\n\tconst response = this.executeCommand(cmd, true);\n\n\tif (!response) {\n\t\tthrow new Error(`Error occured (${environment}), custom setting metadata retrieval failed`);\n\t} else {\n\t\tresult = this.extractCustomSettingMetadata(response, environment, customSettingName);\n\t}\n\treturn result;\n}\n\nfunction extractCustomSettingMetadata(metadataResponse, environment, customSettingName) {\n\tconst result = { fields: [], filePath: '' };\n\tconst metadata = metadataResponse?.result?.files;\n\tif (metadataResponse.status != 0 || !metadata) {\n\t\tthrow new Error(`Error occured (${environment}), ${JSON.stringify(metadataResponse)}`);\n\t} else {\n\t\tmetadata.forEach(element => {\n\t\t\tif (element.error) {\n\t\t\t\tthrow new Error(`Error occured (${environment}), ${element.error}`);\n\t\t\t} else if (element.type === 'CustomField') {\n\t\t\t\tresult.fields.push(element.fullName.replace(`${customSettingName}.`, ''));\n\t\t\t} else if (element.type === 'CustomObject') {\n\t\t\t\tresult.filePath = element.filePath;\n\t\t\t}\n\t\t});\n\t}\n\treturn result;\n}\n\nfunction checkCustomSettingTypeAndVisibility(customSettingPath, message, environment) {\n\tconst result = { isHierarchy: false };\n\tif (!customSettingPath) {\n\t\tthrow new Error(`Error occured (${environment}), invalid custom setting filePath`);\n\t}\n\tthis.asyncCopadoLogMessage(message);\n\tconst cmd = `\n        cd ${APP_DIRECTORY}/${SFDX_PROJECT}\n        cat ${customSettingPath}\n    `;\n\tlet response = this.executeCommand(cmd);\n\tif (!response) {\n\t\tthrow new Error(`Error occured (${environment}), custom setting details not found`);\n\t} else {\n\t\tif (!response.includes('<visibility>Public</visibility>')) {\n\t\t\tthrow new Error(`Error occured (${environment}). Only public custom setting records can be moved from source org to destination org`);\n\t\t}\n\t\tresult.isHierarchy = response.includes('<customSettingsType>Hierarchy</customSettingsType>');\n\t}\n\treturn result;\n}\n\nfunction validateSource() {\n\tthis.setInstanceUrl(sourceBaseUrl, `Setting instance url to ${sourceEnvironment}`);\n\tconst metadata = this.retrieveCustomSettingMetadata(\n\t\tsourceSessionId,\n\t\t`Retrieve and validate custom setting in ${sourceEnvironment}`,\n\t\tsourceEnvironment,\n\t\tcustomSettingName\n\t);\n\tObject.assign(sourceCustomSetting, metadata);\n\tconst type = this.checkCustomSettingTypeAndVisibility(\n\t\tsourceCustomSetting.filePath,\n\t\t`Checking custom setting type and visibility in ${sourceEnvironment}`,\n\t\tsourceEnvironment\n\t);\n\tObject.assign(sourceCustomSetting, type);\n}\n\nfunction prepareQueryForDependentRecords() {\n\tconst hierarchyCustomSettingError = `Error occured, for hierarchy custom setting we need profile, user or organization record(s) to deploy the custom setting data`;\n\tconst listCustomSettingError = `Error occured, no custom setting record(s) found for deployment`;\n\tif (sourceCustomSetting.isHierarchy) {\n\t\tif (!profiles && !users && !organizations) {\n\t\t\tthrow new Error(hierarchyCustomSettingError);\n\t\t}\n\t\tprofiles = JSON.parse(profiles);\n\t\tusers = JSON.parse(users);\n\t\torganizations = JSON.parse(organizations);\n\t\tif (profiles?.length) {\n\t\t\tprofileQuery = `SELECT Id, Name FROM Profile WHERE Name IN ('${profiles.map(profile => profile.Name).join(\"','\")}')`;\n\t\t}\n\t\tif (users?.length) {\n\t\t\tconst userNames = [];\n\t\t\tconst userProfileNames = [];\n\t\t\tusers.forEach(user => {\n\t\t\t\tuserNames.push(user.Name);\n\t\t\t\tuserProfileNames.push(user.Profile.Name);\n\t\t\t});\n\t\t\tuserQuery = `SELECT Id, Name FROM User WHERE Name IN ('${userNames.join(\"','\")}') AND Profile.Name IN ('${userProfileNames.join(\n\t\t\t\t\"','\"\n\t\t\t)}')`;\n\t\t}\n\t\tif (organizations?.length) {\n\t\t\torganizationQuery = `SELECT Id, Name FROM Organization WHERE Name IN ('${organizations\n\t\t\t\t.map(organization => organization.Name)\n\t\t\t\t.join(\"','\")}')`;\n\t\t}\n\t\tif (!profileQuery && !userQuery && !organizationQuery) {\n\t\t\tthrow new Error(hierarchyCustomSettingError);\n\t\t}\n\t} else if (!records) {\n\t\tthrow new Error(listCustomSettingError);\n\t} else {\n\t\trecords = JSON.parse(records);\n\t\tif (!records?.length) {\n\t\t\tthrow new Error(listCustomSettingError);\n\t\t} else {\n\t\t\trecordNames = records.map(record => record.Name);\n\t\t}\n\t}\n}\n\nfunction queryCustomSettingInSource(data) {\n\tconst filterResponse = this.prepareCustomSettingQueryFilter(data, sourceCustomSetting.isHierarchy, 'Id', 'Name', sourceEnvironment);\n\tObject.assign(sourceRecords, filterResponse);\n\tdelete sourceRecords.customSettingNames;\n\tconst queryResponse = this.queryCustomSettingRecords(\n\t\tsourceCustomSetting.isHierarchy,\n\t\tObject.keys(sourceRecords.profileMapping),\n\t\tObject.keys(sourceRecords.userMapping),\n\t\tObject.keys(sourceRecords.organizationMapping),\n\t\tfilterResponse.customSettingNames,\n\t\t`Error occured, no filters avaliable to query custom seting records in ${sourceEnvironment}`,\n\t\tsourceCustomSetting.fields,\n\t\tsourceSessionId,\n\t\tsourceEnvironment\n\t);\n\tsourceRecords.records = this.getCustomSettingRecords(\n\t\tJSON.parse(queryResponse),\n\t\tsourceEnvironment,\n\t\t`Error occured, there are no custom setting records available in ${sourceEnvironment} as per the mentioned filters`\n\t);\n}\n\nfunction getCustomSettingRecords(data, environment, noRecordsError) {\n\tlet result;\n\tif (data.status != 0) {\n\t\tthrow new Error(`Error occured (${environment}), '${JSON.stringify(data)}'`);\n\t} else {\n\t\tresult = data?.result?.records;\n\t\tif (!records?.length && noRecordsError) {\n\t\t\tthrow new Error(noRecordsError);\n\t\t}\n\t}\n\treturn result;\n}\n\nfunction prepareCustomSettingQueryFilter(data, isHierarchy, key, value, environment) {\n\tconst result = { profileMapping: {}, userMapping: {}, organizationMapping: {}, customSettingNames: null };\n\tdata.forEach(response => {\n\t\tif (isHierarchy) {\n\t\t\tresponse = JSON.parse(response);\n\t\t\tif (response.status != 0) {\n\t\t\t\tthrow new Error(`Error occured (${environment}), '${JSON.stringify(response)}'`);\n\t\t\t} else {\n\t\t\t\tconst records = response?.result?.records;\n\t\t\t\tif (records?.length) {\n\t\t\t\t\tthis.mapRecords(records, result, key, value);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tresult.customSettingNames = response;\n\t\t}\n\t});\n\treturn result;\n}\n\nfunction queryCustomSettingRecords(\n\tisHierarchy,\n\tprofileIds,\n\tuserIds,\n\torgIds,\n\tcustomSettingNames,\n\tnoFilterError,\n\tfieldsToQuery,\n\tsessionid,\n\tenvironment\n) {\n\tlet response;\n\tlet filters = [];\n\tif (isHierarchy) {\n\t\tfilters = filters.concat(profileIds, userIds, orgIds);\n\t} else {\n\t\tfilters = filters.concat(customSettingNames);\n\t}\n\n\tif (!filters?.length) {\n\t\tif (noFilterError) {\n\t\t\tthrow new Error(noFilterError);\n\t\t}\n\t} else {\n\t\tconst filterIds = `('${filters.join(\"','\")}')`;\n\t\tconst query = `SELECT Id, Name, SetupOwnerId ${fieldsToQuery?.length ? ',' + fieldsToQuery.join(',') : ''} FROM ${customSettingName} WHERE ${\n\t\t\tisHierarchy ? 'SetupOwnerId IN ' : 'Name IN '\n\t\t} ${filterIds}`;\n\t\tresponse = this.doSoqlSyncQuery(query, sessionid);\n\t}\n\n\tif (!response) {\n\t\tthrow new Error(`Error occured (${environment}), sf data query command failed`);\n\t}\n\treturn response;\n}\n\nfunction mapRecords(records, dataSet, key, value) {\n\trecords.forEach(record => {\n\t\tswitch (record?.attributes?.type) {\n\t\t\tcase 'Profile':\n\t\t\t\tdataSet.profileMapping[record[key]] = record[value];\n\t\t\t\tbreak;\n\t\t\tcase 'User':\n\t\t\t\tdataSet.userMapping[record[key]] = record[value];\n\t\t\t\tbreak;\n\t\t\tcase 'Organization':\n\t\t\t\tdataSet.organizationMapping[record[key]] = record[value];\n\t\t\t\tbreak;\n\t\t}\n\t});\n}\n\nfunction getCustomSettingDependentData(sessionId, message) {\n\tthis.asyncCopadoLogMessage(message);\n\tconst promises = [];\n\tif (sourceCustomSetting.isHierarchy) {\n\t\t[profileQuery, userQuery, organizationQuery].forEach(query => {\n\t\t\tif (query) {\n\t\t\t\tpromises.push(this.executeCommandAsync(this.getQueryCmd(query, sessionId), false, true));\n\t\t\t}\n\t\t});\n\t} else {\n\t\tpromises.push(\n\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\tresolve(recordNames);\n\t\t\t})\n\t\t);\n\t}\n\treturn promises;\n}\n\nfunction doSoqlSyncQuery(query, sessionId) {\n\tconst response = this.executeCommand(this.getQueryCmd(query, sessionId));\n\tif (!response) {\n\t\tthrow new Error(`Error occured, sf data query (${query}) command failed`);\n\t} else {\n\t\treturn response;\n\t}\n}\n\nfunction getQueryCmd(query, sessionId) {\n\treturn `\n        cd ${APP_DIRECTORY}/${SFDX_PROJECT}\n        sf data query --query \"${query}\" --json --target-org ${sessionId}\n    `;\n}\n\nfunction validateDestination() {\n\tthis.setInstanceUrl(destinationBaseUrl, `Setting instance url to ${destinationEnvironment}`);\n\tconst metadata = this.retrieveCustomSettingMetadata(\n\t\tdestinationSessionId,\n\t\t`Retrieve and validate custom setting in ${destinationEnvironment}`,\n\t\tdestinationEnvironment,\n\t\tcustomSettingName\n\t);\n\tconst missingFields = sourceCustomSetting.fields.filter(field => metadata.fields.indexOf(field) === -1);\n\tif (missingFields?.length) {\n\t\tthrow new Error(`Error occured, fields missing in ${destinationEnvironment} ${missingFields.join(',')}`);\n\t}\n\tconst type = this.checkCustomSettingTypeAndVisibility(\n\t\tmetadata.filePath,\n\t\t`Checking custom setting type and visibility in ${destinationEnvironment}`,\n\t\tdestinationEnvironment\n\t);\n\tif (sourceCustomSetting.isHierarchy != type.isHierarchy) {\n\t\tthrow new Error(`Error occured, there is a mismatch in the custom setting type for source and destination`);\n\t}\n}\n\nfunction queryCustomSettingInDestination(data) {\n\tconst filterResponse = this.prepareCustomSettingQueryFilter(data, sourceCustomSetting.isHierarchy, 'Name', 'Id', destinationEnvironment);\n\tObject.assign(destinationRecords, filterResponse);\n\tdelete destinationRecords.customSettingNames;\n\tconst queryResponse = this.queryCustomSettingRecords(\n\t\tsourceCustomSetting.isHierarchy,\n\t\tObject.values(destinationRecords.profileMapping),\n\t\tObject.values(destinationRecords.userMapping),\n\t\tObject.values(destinationRecords.organizationMapping),\n\t\tfilterResponse.customSettingNames,\n\t\tnull,\n\t\tnull,\n\t\tdestinationSessionId,\n\t\tdestinationEnvironment\n\t);\n\tconst records = this.getCustomSettingRecords(JSON.parse(queryResponse), destinationEnvironment, null);\n\trecords.forEach(record => {\n\t\tdestinationRecords.records[sourceCustomSetting.isHierarchy ? record.SetupOwnerId : record.Name] = record.Id;\n\t});\n}\n\nasync function mergeAndDeployRecords() {\n\tconst finalRecords = this.mergeRecords();\n\tthis.createCSV(finalRecords);\n\tthis.varreplace();\n\tconst result = await this.deployRecords(customSettingName);\n\tlet deployResult;\n\tif (result?.result?.jobInfo?.id) {\n\t\tdeployResult = await this.checkDeploymentStatus(result?.result?.jobInfo?.id, 0);\n\t}\n\tthis.uploadFile(deployResult ? deployResult : result);\n\tthis.validateDeployResult(deployResult ? deployResult : result);\n}\n\nfunction mergeRecords() {\n\tconst finalRecords = [];\n\tkeyPrefix = JSON.parse(keyPrefix);\n\tlet destinationSetupOwnerId;\n\tsourceRecords.records.forEach(record => {\n\t\tif (sourceCustomSetting.isHierarchy) {\n\t\t\tdestinationSetupOwnerId = null;\n\t\t\tswitch (keyPrefix[record.SetupOwnerId.substring(0, 3)]) {\n\t\t\t\tcase 'Profile':\n\t\t\t\t\tdestinationSetupOwnerId = destinationRecords.profileMapping[sourceRecords.profileMapping[record.SetupOwnerId]];\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'User':\n\t\t\t\t\tdestinationSetupOwnerId = destinationRecords.userMapping[sourceRecords.userMapping[record.SetupOwnerId]];\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'Organization':\n\t\t\t\t\tdestinationSetupOwnerId = destinationRecords.organizationMapping[sourceRecords.organizationMapping[record.SetupOwnerId]];\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!destinationSetupOwnerId) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else {\n\t\t\tdestinationSetupOwnerId = null;\n\t\t}\n\t\tdelete record.attributes;\n\t\trecord.SetupOwnerId = destinationSetupOwnerId;\n\t\trecord.Id = sourceCustomSetting.isHierarchy ? destinationRecords.records[destinationSetupOwnerId] : destinationRecords.records[record.Name];\n\t\tfinalRecords.push(record);\n\t});\n\treturn finalRecords;\n}\n\nfunction createCSV(finalRecords) {\n\tif (!finalRecords?.length) {\n\t\tthrow new Error(`No custom setting records avaliable for deployment in ${destinationEnvironment}`);\n\t} else {\n\t\tconst csvData = this.arrayToCSV(finalRecords);\n\t\tfs.writeFileSync(`${TEMP_DIRECTORY}/${RECORDS_FILE}`, csvData);\n\t}\n}\n\nfunction arrayToCSV(data) {\n\tlet csv = data.map(row => Object.values(row));\n\tcsv.unshift(Object.keys(data[0]));\n\treturn `\"${csv.join('\"\\n\"').replace(/,/g, '\",\"')}\"`;\n}\n\nfunction varreplace() {\n\tthis.asyncCopadoLogMessage('Replacing environment variables, if any');\n\tconst cmd = `\n        varreplace '${sourceEnvVar}' '${TEMP_DIRECTORY}/${RECORDS_FILE}' --valuename=true || exit 1\n        varreplace '${destinationEnvVar}' '${TEMP_DIRECTORY}/${RECORDS_FILE}' --valuename=false || exit 1\n    `;\n\tthis.executeCommand(cmd);\n}\n\nasync function deployRecords(customSettingName) {\n\tsourceCustomSetting = sourceRecords = destinationRecords = profileQuery = userQuery = organizationQuery = recordNames = null;\n\tthis.asyncCopadoLogMessage(`Deploying custom setting records in ${destinationEnvironment}`);\n\tconst cmd = `\n        cd ${APP_DIRECTORY}/${SFDX_PROJECT} \n        sf data upsert bulk --sobject ${customSettingName} --file ${TEMP_DIRECTORY}/${RECORDS_FILE} --external-id Id --target-org ${destinationSessionId} --async --json\n    `;\n\treturn await this.executeCommandAsync(cmd, true, true);\n}\n\nasync function checkDeploymentStatus(jobId, numberOfRetries) {\n\tthis.logger(`Job Id : ${jobId}`);\n\tprocess.chdir(`${APP_DIRECTORY}/${SFDX_PROJECT}`);\n\treturn new Promise((resolve, reject) => {\n\t\tsetTimeout(\n\t\t\tasync function pollDeploymentStatus(jobId, numberOfRetries) {\n\t\t\t\tconst cmd = `\n                    sf data upsert resume --job-id ${jobId} --target-org ${destinationSessionId} --json\n                `;\n\t\t\t\tconst response = await this.executeCommandAsync(cmd, true, true);\n\t\t\t\tif (response?.status) {\n\t\t\t\t\tif (response?.message?.includes('ETIMEDOUT') || response?.message === 'Metadata API request failed: The client has timed out.') {\n\t\t\t\t\t\tif (numberOfRetries < MAX_RETRIALS) {\n\t\t\t\t\t\t\tthis.logger(`Fetching Data Upsert Job Details failed : ${response?.message} Retrying Attempt ${numberOfRetries}`);\n\t\t\t\t\t\t\tnumberOfRetries++;\n\t\t\t\t\t\t\tsetTimeout(pollDeploymentStatus.bind(this, jobId, numberOfRetries), POLL_TIME);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tresolve(response);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresolve(response);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (response?.result?.state == DEPLOYMENT_STATUS.INPROGRESS || response?.result?.status == DEPLOYMENT_STATUS.PENDING) {\n\t\t\t\t\tnumberOfRetries = 0;\n\t\t\t\t\tsetTimeout(pollDeploymentStatus.bind(this, jobId, numberOfRetries), POLL_TIME);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(response);\n\t\t\t\t}\n\t\t\t}.bind(this, jobId, numberOfRetries),\n\t\t\tPOLL_TIME\n\t\t);\n\t});\n}\n\nfunction validateDeployResult(deployResult) {\n\tif (deployResult.status && deployResult.message) {\n\t\tthrow new Error(deployResult.message);\n\t} else if (deployResult?.result?.records?.failedResults?.length) {\n\t\tthrow new Error(\n\t\t\t`Error occured while deploying custom setting records, kindly check the result.json file on the result record for more details`\n\t\t);\n\t}\n}\n\nfunction uploadFile(deployResult) {\n\tfs.writeFileSync(`${TEMP_DIRECTORY}/${RESULT_FILE}`, JSON.stringify(deployResult));\n\tconst cmd = `\n        copado --uploadfile ${TEMP_DIRECTORY}/${RECORDS_FILE} --name \"records.csv\" || exit 1\n        copado --uploadfile ${TEMP_DIRECTORY}/${RESULT_FILE} --name \"result.json\" || exit 1\n    `;\n\tthis.executeCommand(cmd);\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction asyncCopadoLogMessage(messge) {\n\tnew Promise(resolve => {\n\t\texec(`copado -p \"${messge}\"`, { stdio: STDIO.INHERIT }, (err, response, stderr) => {\n\t\t\tresolve();\n\t\t});\n\t});\n}\n\nfunction executeCommand(command, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\tconst response = spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.log(response, disableLogs);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthrow new Error(errorMessage);\n\t}\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: MAX_BUFFER\n\t};\n\treturn options;\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nfunction log(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tconsole.log(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tconsole.log(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction getErrorCommandString(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `copado -p \"Error\" -e \"${error.trim()?.substring(0, 32760)}; ${suffix}\"`;\n}\n\nfunction executeCommandAsync(command, hasJsonResponse, disableLog) {\n\treturn new Promise((resolve, reject) => {\n\t\tlet output = '',\n\t\t\terror = '';\n\t\tconst childProcess = spawn(command, [], { shell: true });\n\n\t\tchildProcess.stdout.on('data', data => {\n\t\t\toutput += data?.toString();\n\t\t});\n\n\t\tchildProcess.stderr.on('data', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('close', code => {\n\t\t\tif (code !== 0) {\n\t\t\t\tlet errorMessage = '';\n\t\t\t\tif (hasJsonResponse) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tresolve(JSON.parse(output));\n\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\terrorMessage = error;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\terrorMessage = error;\n\t\t\t\t}\n\t\t\t\terrorMessage = errorMessage ? errorMessage : `Error executing the command ${command}`;\n\t\t\t\treject(errorMessage);\n\t\t\t}\n\t\t\tif (!disableLog) {\n\t\t\t\tif (code?.toString()) {\n\t\t\t\t\tthis.logger(`code: ${code?.toString()}`);\n\t\t\t\t}\n\t\t\t\tif (output) {\n\t\t\t\t\tthis.logger(`stdout: ${output}`);\n\t\t\t\t}\n\t\t\t\tif (error) {\n\t\t\t\t\tthis.logger(`stderr: ${error}`);\n\t\t\t\t}\n\t\t\t}\n\t\t\tresolve(hasJsonResponse ? JSON.parse(output) : output);\n\t\t});\n\n\t\tchildProcess.on('error', error => {\n\t\t\treject(error);\n\t\t});\n\t});\n}\n\nmodule.exports.execute = execute;\nmodule.exports.validateExecutionMode = validateExecutionMode;\nmodule.exports.handleError = handleError;\nmodule.exports.setup = setup;\nmodule.exports.setInstanceUrl = setInstanceUrl;\nmodule.exports.retrieveCustomSettingMetadata = retrieveCustomSettingMetadata;\nmodule.exports.extractCustomSettingMetadata = extractCustomSettingMetadata;\nmodule.exports.checkCustomSettingTypeAndVisibility = checkCustomSettingTypeAndVisibility;\nmodule.exports.validateSource = validateSource;\nmodule.exports.prepareQueryForDependentRecords = prepareQueryForDependentRecords;\nmodule.exports.queryCustomSettingInSource = queryCustomSettingInSource;\nmodule.exports.getCustomSettingRecords = getCustomSettingRecords;\nmodule.exports.prepareCustomSettingQueryFilter = prepareCustomSettingQueryFilter;\nmodule.exports.queryCustomSettingRecords = queryCustomSettingRecords;\nmodule.exports.mapRecords = mapRecords;\nmodule.exports.getCustomSettingDependentData = getCustomSettingDependentData;\nmodule.exports.doSoqlSyncQuery = doSoqlSyncQuery;\nmodule.exports.getQueryCmd = getQueryCmd;\nmodule.exports.validateDestination = validateDestination;\nmodule.exports.queryCustomSettingInDestination = queryCustomSettingInDestination;\nmodule.exports.mergeAndDeployRecords = mergeAndDeployRecords;\nmodule.exports.mergeRecords = mergeRecords;\nmodule.exports.createCSV = createCSV;\nmodule.exports.arrayToCSV = arrayToCSV;\nmodule.exports.varreplace = varreplace;\nmodule.exports.deployRecords = deployRecords;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getOptions = getOptions;\nmodule.exports.logger = logger;\nmodule.exports.log = log;\nmodule.exports.getErrorCommandString = getErrorCommandString;\nmodule.exports.executeCommandAsync = executeCommandAsync;\nmodule.exports.checkDeploymentStatus = checkDeploymentStatus;\nmodule.exports.validateDeployResult = validateDeployResult;\nmodule.exports.uploadFile = uploadFile;\nmodule.exports.getBaseUrl = getBaseUrl;\nmodule.exports.getPath = getPath;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Timeout__c": 60,
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0k09000000rbjMAAQ",
                    "LastReferencedDate": "2022-06-27T07:34:47.000+0000",
                    "LastViewedDate": "2022-06-27T07:34:47.000+0000",
                    "Name": "SFDX Deploy Custom Setting"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v56.0/sobjects/copado__Function__c/a0k0900000C7opaAAB"
                    },
                    "copado__ApexClass__c": "cmcSf.RefreshMetadataCallback",
                    "copado__API_Name__c": "SFDX_Refresh_Metadata",
                    "copado__Callback_Type__c": "ApexClass",
                    "copado__Description__c": "This function generates metadata and deleted metadata files for the Salesforce org",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"sessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"endpoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"metadataFileId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.metadataFileId}\"\n}, {\n  \"name\" : \"ignoredType\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.ignoredType}\"\n}, {\n  \"name\" : \"typeFilter\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.typeFilter}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n/**\n * Generates metadata and deleted metadata files for the Salesforce org\n * @param sessionId\n * @param endpoint\n * @param metadataFileId\n * @param ignoredType\n * @param typeFilter\n * @param maxBuffer\n */\nconst { writeFileSync } = require('fs'),\n    { env, chdir, exit } = require('process'),\n    { spawnSync } = require('child_process'),\n    { sessionId, endpoint, metadataFileId, ignoredType, typeFilter, maxBuffer } = env,\n    MAX_BUFFER_SIZE = parseInt(maxBuffer),\n    METADATA_FILE = 'MetaData',\n    NEW_METADATA_FILE = 'NewMetaData',\n    DELETED_METADATA_FILE = 'DeletedMetaData',\n    IGNORED_TYPE_FILE = 'IgnoredType.json',\n    TYPE_FILTER_FILE = 'TypeFilter.json',\n    STDIO = {\n        INHERIT: 'inherit'\n    };\n\n// EXECUTION\n\nexecute();\n\n// FUNCTIONS\n\nfunction execute() {\n    try {\n        chdir('/tmp');\n        createFile(IGNORED_TYPE_FILE, ignoredType ? ignoredType : '[]');\n        createFile(TYPE_FILTER_FILE, typeFilter ? typeFilter : '[]');\n        generateMetadataFile(sessionId, endpoint);\n        findDeletedMetadata(metadataFileId);\n    } catch (error) {\n        logError(error);\n    }\n}\n\nfunction logError(error) {\n    executeCommand(getErrorCmdString(error.toString()));\n}\n\nfunction createFile(fileName, data) {\n    writeFileSync(fileName, data);\n}\n\nfunction generateMetadataFile(sessionId, endpoint) {\n    const metadataRetrieveCmd =\n        'metadata-retrieve ' +\n        buildParameters({\n            ignoredTypes: IGNORED_TYPE_FILE,\n            output: NEW_METADATA_FILE,\n            typeFilter: TYPE_FILTER_FILE\n        }) +\n        ' refresh ' +\n        buildParameters({\n            endpointUrl: sessionId,\n            sessionId: getBaseUrl(endpoint)\n        }) +\n        ' || ' +\n        getErrorCmdString('Error in generating metadata file');\n    generateFile('Generating Metadata File', metadataRetrieveCmd, NEW_METADATA_FILE, METADATA_FILE, 'Error in uploading metadata file');\n}\n\nfunction generateDeletedMetadataFile() {\n    const metadataRetrieveCmd =\n        'metadata-retrieve ' +\n        buildParameters({\n            ignoredTypes: IGNORED_TYPE_FILE,\n            output: DELETED_METADATA_FILE,\n            typeFilter: TYPE_FILTER_FILE\n        }) +\n        ` difference ${METADATA_FILE} ${NEW_METADATA_FILE}  || ` +\n        getErrorCmdString('Error in generating deleted metadata file');\n    generateFile(\n        'Generating Deleted Metadata File',\n        metadataRetrieveCmd,\n        DELETED_METADATA_FILE,\n        DELETED_METADATA_FILE,\n        'Error in uploading deleted metadata file'\n    );\n}\n\nfunction generateFile(progressMessage, metadataRetrieveCmd, filePath, fileName, fileUploadErrorMessage) {\n    const cmd = `\n         copado -p '${progressMessage}'\n         ${metadataRetrieveCmd}\n         copado -u ${filePath} -n ${fileName} || ${getErrorCmdString(fileUploadErrorMessage)}\n  `;\n    executeCommand(cmd, STDIO.INHERIT);\n}\n\nfunction getBaseUrl(endpoint) {\n    return endpoint.substring(0, endpoint.indexOf('/', endpoint.indexOf('/') + 2));\n}\n\nfunction findDeletedMetadata(metadataFileId) {\n    if (metadataFileId) {\n        downloadCredentialMetadataFile(metadataFileId);\n        generateDeletedMetadataFile();\n    }\n}\n\nfunction downloadCredentialMetadataFile(metadataFileId) {\n    executeCommand(\n        `copado --downloadfiles ${metadataFileId} || ${getErrorCmdString('Error in downloading credential metadata file')}`,\n        STDIO.INHERIT\n    );\n}\n\nfunction buildParameters(data) {\n    return Object.entries(data).reduce((parameters, [key, value]) => {\n        return parameters + (value ? ` --${key} ${value}` : '');\n    }, '');\n}\n\nfunction executeCommand(cmd, ioconfig) {\n    const options = {\n        shell: true,\n        maxBuffer: MAX_BUFFER_SIZE\n    };\n    if (ioconfig) {\n        options.stdio = ioconfig;\n    }\n    const response = spawnSync(cmd, options);\n    if (response?.stderr) {\n        throw response?.stderr;\n    } else if (response?.status === 1) {\n        exit(1);\n    }\n}\n\nfunction getErrorCmdString(error) {\n    const suffix = 'Please check the logs for details.';\n    return `{ copado -p 'Error' -e \"${error}. ${suffix}\"; exit 1; }`;\n}",
                    "copado__Type__c": "Standard",
                    "Id": "a0k0900000C7opaAAB",
                    "LastReferencedDate": "2022-12-20T06:35:41.000+0000",
                    "LastViewedDate": "2022-12-20T06:35:41.000+0000",
                    "Name": "SFDX Refresh Metadata"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v60.0/sobjects/copado__Function__c/a0l7Q000000Og66QAC"
                    },
                    "copado__API_Name__c": "Initialize_Git_With_SFDX_Project",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : false,\n  \"name\" : \"dataJson\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson__c}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"name\" : \"overriddenApiVersion\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.GetGitJson}\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n\n'use strict';\n\nconst {\n\t\tisTest,\n\t\tdataJson,\n\t\tgit_json,\n\t\tmaxBuffer,\n\t\tgitEmail,\n\t\tgitName,\n\t\tAPI_VERSION,\n\t\toverriddenApiVersion\n\t} = process.env,\n\tchild_process = require('child_process'),\n\tMAXBUFFER = parseInt(maxBuffer),\n\t{ existsSync, writeFileSync, readFileSync } = require('fs'),\n\tSTDIO = {\n\t\tINHERIT: 'inherit',\n\t\tPIPE: 'pipe',\n\t\tIGNORE: 'ignore'\n\t},\n\tAPP_DIRECTORY = getPath('/app'),\n\t{\n\t\tbranch,\n\t\trecreateProject,\n\t\tprojectName,\n\t\ttemplate,\n\t\tdefaultDirectory,\n\t\tforceBranchCreation\n\t} = JSON.parse(dataJson),\n\tTARGET_DIRECTORY = `${APP_DIRECTORY}/${projectName}`;\n\nfunction execute() {\n\ttry {\n\t\tthis.setUpWorkingDirectory(TARGET_DIRECTORY);\n\t\tthis.switchToWorkingDirectory(TARGET_DIRECTORY);\n\t\tthis.fetchRemoteGitBranch(branch);\n\t\tthis.validateExistingSFDXProject(recreateProject);\n\t\tthis.configureGit(gitEmail, gitName);\n\t\tthis.createSFDXProject(APP_DIRECTORY, projectName, template, defaultDirectory);\n\t\tthis.createExcludeAutoResolveFile();\n\t\tthis.updateGitIgnore();\n\t\tconst sourceApiVersion = this.getApiVersion(overriddenApiVersion, API_VERSION);\n\t\tconst isSourceApiVersionUpdated = this.updateSourceApiVersion(branch, sourceApiVersion);\n\t\tthis.validateGitStatus();\n\t\tthis.pushChangesToRemoteBranch(branch, isSourceApiVersionUpdated, sourceApiVersion);\n\t\tthis.uploadProjectInitializedJson();\n\t} catch (error) {\n\t\tthis.executeCommand(this.getErrorCommand(error.toString()), STDIO.INHERIT);\n\t}\n}\n\nfunction setUpWorkingDirectory(workingDirectory) {\n\tthis.executeCommand(`\n        copado -p 'Setting up working directory'\n    \tmkdir -p '${workingDirectory}'\n    `);\n}\n\nfunction switchToWorkingDirectory(workingDirectory) {\n\tprocess.chdir(workingDirectory);\n}\n\nfunction fetchRemoteGitBranch(branchName) {\n\tlet fetchGitBranch = `copado -p 'Fetching git branch'\n        copado-git-get '${branchName}'`;\n\n\tif (forceBranchCreation) {\n\t\tfetchGitBranch += ' --create';\n\t}\n\n\tfetchGitBranch += ` || ${this.getErrorCommand(`Error fetching git branch ${branchName}`)}`;\n\tthis.executeCommand(fetchGitBranch);\n}\n\nfunction validateExistingSFDXProject(recreateProject) {\n\tif (existsSync('sfdx-project.json') && !recreateProject) {\n\t\t//upload the result with projectInitialized = true since the repository already has an SFDX project\n\t\tthis.uploadProjectInitializedJson();\n\t\tthrow 'An existing SFDX project was found in your repository, initialization canceled';\n\t}\n}\n\nfunction configureGit(gitEmail, gitName) {\n\tconst cmd = `\n    git config --local user.email \"${gitEmail}\" || ${this.getErrorCommand('Failure in configuring git user email')}\n    git config --local user.name \"${gitName}\" || ${this.getErrorCommand('Failure in configuring git user name')}\n    git config --global diff.renames false || ${this.getErrorCommand('Failure in disabling git rename detection from diff.renames')}\n    git config --global merge.renames false || ${this.getErrorCommand('Failure in disabling git rename detection from merge.renames')}\n    git config --global status.renames false || ${this.getErrorCommand('Failure in disabling git rename detection from status.renames')}\n    `;\n\tthis.executeCommand(cmd, STDIO.INHERIT);\n}\n\nfunction createSFDXProject(appDirectory, projectName, template, defaultDirectory) {\n\tthis.executeCommand(`copado -p 'Creating SFDX project'`);\n\tconst sfProjectCreateCmd = `sf project generate --name \"${projectName}\" --default-package-dir \"${defaultDirectory}\" --template \"${template}\"`;\n\tthis.logger(sfProjectCreateCmd);\n\tthis.executeCommand(`\n        cd '${appDirectory}'\n        ${sfProjectCreateCmd}\n    `);\n}\n\nfunction createExcludeAutoResolveFile() {\n\tconst fileContent =\n\t\t'# Files matching patterns in this file will be excluded from auto-resolve during merge conflicts\\n' +\n\t\t'# The pattern syntax is the same as for .gitignore files\\n' +\n\t\t'# here is more documentation:\\n' +\n\t\t'# Copado Docs & Samples: https://docs.copado.com/articles/copado-ci-cd-publication/conflict-resolution-in-copado-devops-platform\\n' +\n\t\t'# Sample statements for metadata which is frequently excluded.\\n' +\n\t\t'# please remove comment (#) to \"activate\" a statement and start resolving conflicts for specific metadata manually in Copado:\\n' +\n\t\t'#**/classes/*.cls\\n' +\n\t\t'#**/pages/*.page\\n' +\n\t\t'#**/layouts/*.layout-meta.xml';\n\twriteFileSync('.copado_exclude_autoresolve', fileContent);\n}\n\nfunction updateGitIgnore() {\n\tlet fileContent = readFileSync('.gitignore', 'utf-8')?.toString();\n\tfileContent = `${fileContent}\\n.copado`;\n\twriteFileSync('.gitignore', fileContent);\n}\n\nfunction getApiVersion(overriddenApiVersion, apiVersion) {\n\tconst finalApiVersion = overriddenApiVersion || apiVersion;\n\tconst regExpApiVersion = /\\d\\d\\.0/;\n\tif (!regExpApiVersion.test(finalApiVersion)) {\n\t\tthis.executeCommand(this.getErrorCommand(`Invalid API Version: ${finalApiVersion}`));\n\t}\n\treturn finalApiVersion;\n}\n\nfunction updateSourceApiVersion(branchName, sourceApiVersion) {\n\tlet result = false;\n\tconst sfdxProjectJsonPath = `sfdx-project.json`;\n\tif (!existsSync(sfdxProjectJsonPath)) {\n\t\tthrow `Invalid configuration in ${branchName}. sfdx-project.json is invalid or missing at project root`;\n\t}\n\tlet fileContent = JSON.parse(readFileSync(sfdxProjectJsonPath, 'utf-8'));\n\tif (fileContent.sourceApiVersion !== sourceApiVersion) {\n\t\tfileContent.sourceApiVersion = sourceApiVersion;\n\t\twriteFileSync(sfdxProjectJsonPath, JSON.stringify(fileContent, null, 2));\n\t\tresult = true;\n\t}\n\treturn result;\n}\n\nfunction validateGitStatus() {\n\tconst gitStatus = this.executeCommand(`git status --porcelain`);\n\tif (!gitStatus) {\n\t\tthis.executeCommand(`copado -p 'There are no changes to be committed' -r 'No changes to be committed'`);\n\t\tif (!isTest) {\n\t\t\tprocess.exit(0);\n\t\t}\n\t}\n}\n\nfunction pushChangesToRemoteBranch(branchName, isSourceApiVersionUpdated, sourceApiVersion) {\n\tlet cmd = isSourceApiVersionUpdated\n\t\t? `copado -p 'Pushing changes in git' -r 'SourceApiVersion in sfdx-project.json is set as ${sourceApiVersion} to support Copado operations'`\n\t\t: `copado -p 'Pushing changes in git'`;\n\tcmd += `\n    git add . || ${this.getErrorCommand('There was some issue when staging changes')}\n    git commit -m 'Initialize SFDX Project' || ${this.getErrorCommand('There was some issue when committing changes')}\n    git push origin '${branchName}' ||  ${this.getErrorCommand('Could not push the changes to remote branch')}\n    `;\n\tthis.executeCommand(cmd, STDIO.INHERIT);\n}\n\nfunction uploadProjectInitializedJson() {\n\tconst projectInitialized = true;\n\tconst resultJson = { projectInitialized };\n\tthis.executeCommand(`copado -p \"Uploading result data\" --result-data '${JSON.stringify(resultJson)}'`);\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDirectory__${filePath}` : filePath;\n}\n\nfunction getErrorCommand(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `{ copado -p 'Error' -e '${error}. ${suffix}'; exit 2; }`;\n}\n\nfunction executeCommand(cmd, ioconfig) {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: MAXBUFFER\n\t};\n\tif (ioconfig) {\n\t\toptions.stdio = ioconfig;\n\t}\n\tconst response = child_process.spawnSync(cmd, options);\n\tconst { output, error } = this.log(response);\n\tif (response?.status != 0) {\n\t\tif (response?.status == 2) {\n\t\t\tif (isTest) {\n\t\t\t\tthrow output;\n\t\t\t}\n\t\t\tprocess.exit(2);\n\t\t}\n\t\tthrow error ? error : `Error executing the command: ${cmd}`;\n\t}\n\treturn output;\n}\n\nfunction log(response) {\n\tconst output = response?.stdout?.toString().trim();\n\tconst error = response?.stderr?.toString().trim();\n\tif (output) {\n\t\tthis.logger(output);\n\t}\n\tif (error) {\n\t\tthis.logger(error);\n\t}\n\treturn { output, error };\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nmodule.exports.execute = execute;\nmodule.exports.setUpWorkingDirectory = setUpWorkingDirectory;\nmodule.exports.switchToWorkingDirectory = switchToWorkingDirectory;\nmodule.exports.fetchRemoteGitBranch = fetchRemoteGitBranch;\nmodule.exports.configureGit = configureGit;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.log = log;\nmodule.exports.getPath = getPath;\nmodule.exports.getErrorCommand = getErrorCommand;\nmodule.exports.validateExistingSFDXProject = validateExistingSFDXProject;\nmodule.exports.createSFDXProject = createSFDXProject;\nmodule.exports.createExcludeAutoResolveFile = createExcludeAutoResolveFile;\nmodule.exports.updateGitIgnore = updateGitIgnore;\nmodule.exports.updateSourceApiVersion = updateSourceApiVersion;\nmodule.exports.getApiVersion = getApiVersion;\nmodule.exports.validateGitStatus = validateGitStatus;\nmodule.exports.pushChangesToRemoteBranch = pushChangesToRemoteBranch;\nmodule.exports.logger = logger;\nmodule.exports.uploadProjectInitializedJson = uploadProjectInitializedJson;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q000000Og66QAC",
                    "LastReferencedDate": "2024-03-01T11:56:20.000+0000",
                    "LastViewedDate": "2024-03-01T11:56:20.000+0000",
                    "Name": "Initialize Git With SFDX Project"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v58.0/sobjects/copado__Function__c/a0l7Q00000D1gMjQAJ"
                    },
                    "copado__API_Name__c": "vlocity_retrieve",
                    "copado__Image_Name__c": "copado-multicloud-vlocity:v1",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : false,\n  \"name\" : \"fileChangesId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEndPoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceDirectory\",\n  \"defaultValue\" : \"vlocity\"\n}, {\n  \"required\" : true,\n  \"name\" : \"copadoCommitFileName\",\n  \"defaultValue\" : \"Copado Commit changes\"\n}, {\n  \"name\" : \"maxDepth\",\n  \"defaultValue\" : \"0\"\n}, {\n  \"name\" : \"selectedDataPacks\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"vlocitySettingsDocumentId\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.VlocitySettingsSourceId}\"\n}, {\n  \"name\" : \"commitId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.commitId}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n\t{\n\t\tsourceEndPoint,\n\t\tsourceSessionId,\n\t\tisTest,\n\t\tfileChangesId,\n\t\tsourceDirectory,\n\t\tcopadoCommitFileName,\n\t\tmaxDepth,\n\t\tselectedDataPacks,\n\t\tvlocitySettingsDocumentId,\n\t\tcommitId,\n        maxBuffer\n\t} = process.env,\n\tfs = require('fs'),\n\tunidecode = isTest ? require('unidecode') :require('/usr/local/lib/node_modules/vlocity/node_modules/unidecode'),\n\tjs_yaml = isTest ? require('js-yaml') : require('/usr/local/lib/node_modules/js-yaml'),\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tRETRIEVE_RESULT_JSON = 'retrieveResult.json',\n\tRETRIEVE_RESULT_PATH = `${TEMP_DIRECTORY}/${RETRIEVE_RESULT_JSON}`,\n\tCOMMIT_CHANGES_FILE_PATH = 'encoded_changes.json',\n\tVLOCITY_CATEGORY = 'Vlocity',\n\tADD_ACTION = 'Add',\n\tJOB_FILE = 'jobfile.yaml',\n\tVLOCITY_SETTINGS_YAML_FILE = 'vlocity-settings',\n\tmaxDepthPackExport = parseInt(maxDepth),\n\tbaseUrl = sourceEndPoint?.substring(0, sourceEndPoint?.indexOf('/', sourceEndPoint?.indexOf('/') + 2)),\n\tRESULT_TABLE_COLUMNS = [\n\t\t{\n\t\t\tlabel: 'Level',\n\t\t\tfieldName: 'Level',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Level',\n\t\t\tinitialWidth: 80\n\t\t},\n\t\t{\n\t\t\tlabel: 'Category',\n\t\t\tfieldName: 'Category',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Category', // api name of the custom label of the header\n\t\t\tinitialWidth: 120\n\t\t},\n\t\t{\n\t\t\tlabel: 'Additional Information',\n\t\t\tfieldName: 'AdditionalInformation',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Additional_Information',\n\t\t\tinitialWidth: 200\n\t\t},\n\t\t{\n\t\t\tlabel: 'Message',\n\t\t\tfieldName: 'Message',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Message'\n\t\t}\n\t],\n\tRESULT_TABLE_HEADER = {\n\t\tlabel: 'Vlocity Retrieve Result', // header label\n\t\tcustomLabel: 'Vlocity_Retrieve_Result' // customLabel of the header Label\n\t},\n\tHEADER_ICON = 'standard:note',\n\tRESULT_INFO = {\n\t\tLEVEL: {\n\t\t\tINFO: 'INFO',\n\t\t\tERROR: 'ERROR',\n\t\t\tWARN: 'WARN'\n\t\t},\n\t\tCATEGORY: {\n\t\t\tUNKNOWN_EXCEPTION: 'Unknown Exception',\n\t\t\tCOPADO_INFO: 'Copado Info',\n\t\t\tCOPADO_SERVICE: 'Copado Service',\n\t\t\tVBT: 'VBT Command'\n\t\t},\n\t\tADDITIONAL_INFORMATION: {\n\t\t\tDOWNLOAD_FILE: 'Download file',\n            UPLOAD_FILES: 'Upload file',\n\t\t\tVLOCITY_RETRIEVE: 'Vlocity Retrieve'\n\t\t}\n\t},\n\tCUSTOM_ERROR = {\n\t\tCOMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n\t};\n\nlet executionError,\n\tresultViewerJson = [];\n\n// SCRIPT FUNCTIONS\n\nasync function execute() {\n\ttry {\n\t\tthis.displayVersions();\n\t\tthis.validateCommitId(commitId);\n\t\tconst changes = this.getCommitChanges(selectedDataPacks);\n\t\tthis.createEncodedChanges(changes, COMMIT_CHANGES_FILE_PATH);\n\t\tconst vlocitySelections = this.getVlocitySelections(changes);\n\t\tif (vlocitySelections?.length) {\n\t\t\tthis.createJobFile(JOB_FILE, vlocitySelections);\n\t\t\tthis.updateJobFileFromSettings(vlocitySettingsDocumentId, JOB_FILE, selectedDataPacks);\n\t\t\tawait this.retrieveVlocityDataPacks(JOB_FILE);\n\t\t} else if (selectedDataPacks && !vlocitySelections?.length) {\n\t\t\tthrow new Error('Select at least one vlocity datapack to get dependencies');\n\t\t} else {\n\t\t\tthis.asyncCopadoLogMessage('No vlocity changes');\n\t\t}\n\t} catch (err) {\n\t\tconsole.log('Error stack: ', err.stack);\n\t\tif (!(err instanceof CommandExecutionError)) {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, 'See logs for more info', err.message);\n\t\t}\n\t\texecutionError = err.message || err?.toString() || 'Unknown Error occurred';\n\t} finally {\n\t\tif (resultViewerJson?.length) {\n\t\t\tthis.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n\t\t}\n\t\tif (executionError) {\n\t\t\tthis.executeCommand(this.getErrorCmdString(executionError));\n\t\t\tprocess.exit(1);\n\t\t}\n\t}\n}\n\nfunction validateCommitId(commitId) {\n\tif (commitId) {\n\t\tthis.asyncCopadoLogMessage('Commit done through CLI');\n\t\tprocess.exit(0);\n\t}\n}\n\nfunction downloadFile(fileId, downloadDir, fileName) {\n\tthis.asyncCopadoLogMessage('Retrieve vlocity selections');\n\tthis.executeCommand(\n\t\t`copado --downloadfiles ${fileId} --downloaddir ${downloadDir}`,\n\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILE\n\t);\n}\n\nasync function retrieveVlocityDataPacks(jobFile) {\n\tconst vlocityCmd = `vlocity -sf.instanceUrl ${baseUrl} -sf.sessionId ${sourceSessionId} -job ${jobFile} packExport --json-pretty || true`;\n\tthis.logger('Vlocity Command: ' + vlocityCmd);\n\tthis.logger('jobfile.yaml: ' + fs.readFileSync(jobFile, 'utf-8'));\n    this.asyncCopadoLogMessage('Retrieving Vlocity components');\n\n\tconst retrievedDataPacks = await this.executeCommandAsync(vlocityCmd, true, true, true);\n\tthis.asyncCopadoLogMessage(\n\t\t`To check status of retrieved Vlocity datapacks, go to result record of Vlocity retrieve step and find file attached with name ${RETRIEVE_RESULT_JSON}`\n\t);\n\n\tfs.writeFileSync(RETRIEVE_RESULT_PATH, JSON.stringify(retrievedDataPacks, null, 2));\n\tthis.uploadFileAtPath(RETRIEVE_RESULT_PATH);\n\n\tif (retrievedDataPacks?.status === 'error') {\n\t\tthis.populateResultViewer(\n\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\tRESULT_INFO.CATEGORY.VBT,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_RETRIEVE,\n\t\t\tretrievedDataPacks?.message\n\t\t);\n\t\tif (!selectedDataPacks) {\n\t\t\tthrow new CommandExecutionError(\n\t\t\t\tretrievedDataPacks?.message,\n\t\t\t\tRESULT_INFO.CATEGORY.VBT,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_RETRIEVE\n\t\t\t);\n\t\t}\n\t}\n\tthis.updateResult(selectedDataPacks, retrievedDataPacks);\n}\n\nfunction createJobFile(jobFile, vlocityDataPacks) {\n    this.asyncCopadoLogMessage('Creating Job File');\n\tconst jobFileParameters = this.defaultJobParameters(vlocityDataPacks);\n\tfs.writeFileSync(jobFile, js_yaml.dump(jobFileParameters), 'utf8');\n}\n\nfunction displayVersions() {\n\tthis.executeCommand(\n\t\t`\n            echo \"Node version: \"\n            node -v\n            echo \"VBT version: \"\n            vlocity -v\n        `\n\t);\n}\n\nfunction defaultJobParameters(vlocityDataPacks) {\n\treturn {\n\t\tprojectPath: `./${sourceDirectory}`,\n\t\toauthConnection: true,\n\t\tautoUpdateSettings: true,\n\t\tseparateMatrixVersions: true,\n\t\tseparateCalculationProcedureVersions: true,\n\t\tmaxDepth: parseInt(maxDepthPackExport),\n\t\tmanifest: vlocityDataPacks.map(currentData => {\n\t\t\treturn JSON.parse(currentData.j)?.vk;\n\t\t})\n\t};\n}\n\nfunction updateJobFileFromSettings(vlocitySettingsDocumentId, jobFileName, isRetrievingDependencies) {\n\tif (vlocitySettingsDocumentId) {\n\t\tthis.downloadFile(vlocitySettingsDocumentId, TEMP_DIRECTORY, VLOCITY_SETTINGS_YAML_FILE);\n\t\tconst vlocitySettings = js_yaml.load(fs.readFileSync(`${TEMP_DIRECTORY}/${VLOCITY_SETTINGS_YAML_FILE}`, 'utf-8'));\n\n\t\tlet settings = [];\n\t\tif (isRetrievingDependencies) {\n\t\t\tsettings = vlocitySettings?.dependencies ? Object.keys(vlocitySettings?.dependencies) : [];\n\t\t} else {\n\t\t\tsettings = vlocitySettings?.retrieve ? Object.keys(vlocitySettings.retrieve) : [];\n\t\t}\n\n\t\tif (settings.length) {\n\t\t\tconst jobYaml = js_yaml.load(fs.readFileSync(jobFileName, 'utf-8'));\n\n\t\t\tsettings.forEach(setting => {\n\t\t\t\tif (setting !== 'manifest' && setting !== 'projectPath' && setting !== 'maxDepth') {\n\t\t\t\t\tjobYaml[setting] = isRetrievingDependencies ? vlocitySettings?.dependencies[setting] : vlocitySettings.retrieve[setting];\n\t\t\t\t}\n\t\t\t\tif (setting === 'maxDepth' && isRetrievingDependencies) {\n\t\t\t\t\tjobYaml[setting] = vlocitySettings?.dependencies[setting];\n\t\t\t\t}\n\t\t\t});\n\t\t\tfs.writeFileSync(jobFileName, js_yaml.dump(jobYaml), 'utf8');\n\t\t\tthis.asyncCopadoLogMessage('Vlocity Settings has been applied');\n\t\t} else {\n\t\t\tthis.asyncCopadoLogMessage('Vlocity Settings aren\\'t present');\n\t\t}\n\t}\n    else {\n        this.asyncCopadoLogMessage('Vlocity Settings file not found');\n    }\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nfunction maskSensitiveInformation(data, sensitiveFlags) {\n\tconst maskingSequence = '*****';\n\n\tconst arrayOfData = data.split(' ');\n\tObject.keys(sensitiveFlags).forEach(subStr => {\n\t\tconst keyIndex = arrayOfData.indexOf(subStr);\n\t\tif (keyIndex > -1) {\n\t\t\tarrayOfData[keyIndex + 1] = maskingSequence;\n\t\t\tarrayOfData.splice(keyIndex + 2, sensitiveFlags[subStr].split(' ').length - 1);\n\t\t}\n\t});\n\treturn arrayOfData.join(' ');\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction getFileDetails(dir, fileName) {\n\tlet downloadedFileName;\n\tif (fs.existsSync(`${dir}/${fileName}`)) {\n\t\tdownloadedFileName = fileName;\n\t} else if (fs.existsSync(`${dir}/${fileName}.json`)) {\n\t\tdownloadedFileName = `${fileName}.json`;\n\t} else {\n\t\tthrow new Error('Error fetching Commit Changes');\n\t}\n\treturn this.readFromPath(`${dir}/${downloadedFileName}`);\n}\n\nfunction getCommitChanges(selectedDataPacks) {\n\tlet changes;\n\tif (selectedDataPacks) {\n\t\tchanges = JSON.parse(selectedDataPacks);\n\t} else {\n\t\tthis.downloadFile(fileChangesId, TEMP_DIRECTORY, copadoCommitFileName);\n\t\tchanges = this.getFileDetails(TEMP_DIRECTORY, copadoCommitFileName);\n\t}\n\treturn changes;\n}\n\nfunction updateResult(selectedDataPacks, retrievedDataPacks) {\n\tif (selectedDataPacks) {\n\t\tconst success = [];\n\t\tlet errors = [];\n\t\tconst hasError = retrievedDataPacks?.status === 'error';\n\n\t\tretrievedDataPacks?.records.forEach(record => {\n\t\t\tif (record.VlocityDataPackStatus === 'Success') {\n\t\t\t\tsuccess.push({\n                    Operation: ADD_ACTION,\n                    MemberName: record?.VlocityDataPackDisplayLabel,\n                    MemberType: record?.VlocityDataPackType,\n                    OtherInformation: JSON.stringify({ vk: record?.VlocityDataPackKey })\n                });\n\t\t\t}\n\t\t});\n\t\tif (hasError) {\n            errors = retrievedDataPacks?.message.split('\\n');\n        }\n        this.executeCommand(`copado -p 'Updating results' -r '${JSON.stringify({ success, errors })}'`);\n\t}\n}\n\nfunction readFromPath(filePath) {\n\tif (!fs.existsSync(filePath)) {\n\t\tthrow new Error(`Could not find file at path: ${filePath}`);\n\t}\n\tconst data = fs.readFileSync(filePath, 'utf-8');\n\tlet result;\n\ttry {\n\t\tresult = JSON.parse(data);\n\t} catch (err) {\n\t\tthrow new Error(`Content at ${filePath} is not a valid JSON`);\n\t}\n\treturn result;\n}\n\nfunction getVlocitySelections(changes) {\n\treturn changes?.filter(selected => selected.c === VLOCITY_CATEGORY && selected.a === ADD_ACTION);\n}\n\nfunction executeCommandAsync(command, category, additionalInfo, hasJsonResponse, disableLog) {\n\treturn new Promise((resolve, reject) => {\n\t\tlet output = '',\n\t\t\terror = '';\n\t\tconst childProcess = child_process.spawn(command, [], { shell: true });\n\n\t\tchildProcess.stdout.on('data', data => {\n\t\t\toutput += data?.toString();\n\t\t});\n\n\t\tchildProcess.stderr.on('data', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('close', code => {\n\t\t\tif (code !== 0) {\n\t\t\t\tlet errorMessage = '';\n\t\t\t\tif (hasJsonResponse) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tresolve(JSON.parse(output));\n\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\terrorMessage = error;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\terrorMessage = error;\n\t\t\t\t}\n\t\t\t\terrorMessage = errorMessage ? errorMessage : `Error executing the command ${command}`;\n\t\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n\t\t\t\treject(new CommandExecutionError(errorMessage, category, additionalInfo));\n\t\t\t}\n\t\t\tif (!disableLog) {\n\t\t\t\tthis.logger(`code: ${code?.toString()}`);\n\t\t\t\tthis.logger(`stdout: ${output}`);\n\t\t\t\tthis.logger(`stderr: ${error}`);\n\t\t\t}\n\t\t\tresolve(hasJsonResponse ? JSON.parse(output) : output);\n\t\t});\n\n\t\tchildProcess.on('error', error => {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, error);\n\t\t\treject(new CommandExecutionError(error, category, additionalInfo));\n\t\t});\n\t});\n}\n\nfunction uploadFileAtPath(filePath) {\n\tnew Promise((resolve, reject) => {\n\t\tchild_process.exec(`copado --uploadfile ${filePath}`, {}, err => {\n\t\t\tif (err) {\n\t\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES, err);\n\t\t\t\treject(new CommandExecutionError(err, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES));\n\t\t\t} else {\n\t\t\t\tresolve();\n\t\t\t}\n\t\t});\n\t});\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n\tif (message) {\n\t\tresultViewerJson.push({\n\t\t\tLevel: level,\n\t\t\tCategory: category,\n\t\t\tAdditionalInformation: additionalInfo,\n\t\t\tMessage: message\n\t\t});\n\t}\n}\n\nfunction getErrorCmdString(error) {\n\tconst suffix = 'Please check the logs for details.';\n    const refinedErrorMsg = maskSensitiveInformation(error, { '-sf.sessionId': '*****' });\n\tconst errorMessage = JSON.stringify(refinedErrorMsg + `; ${suffix}`).trim()?.substring(0, 32760);\n\treturn `copado -p \"Error\" -e ${errorMessage}`;\n} \n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n\tconst RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n\tconst fileContent = { data, columns, header, headerIcon };\n\tfs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n\tthis.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction executeCommand(command, category, additionalInfo, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.log(response, disableLogs);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n\t\tthrow new CommandExecutionError(errorMessage, category, additionalInfo);\n\t}\n}\n\nfunction log(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tconsole.log(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tconsole.log(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction asyncCopadoLogMessage(msg, logLevel) {\n\tif (msg) {\n\t\tthis.populateResultViewer(logLevel ? logLevel : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n\t\tnew Promise(resolve => {\n\t\t\tchild_process.exec(`copado -p \"${msg}\"`, { stdio: 'inherit' }, () => {\n\t\t\t\tresolve();\n\t\t\t});\n\t\t});\n\t}\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(maxBuffer)\n\t};\n\treturn options;\n}\n\nfunction createEncodedChanges(committedMetadata, filePath) {\n\tfor (let commitChange of committedMetadata) {\n\t\tif (commitChange.c?.toLowerCase() == VLOCITY_CATEGORY?.toLowerCase()) {\n\t\t\tconst datapackKey = JSON.parse(commitChange.j)?.vk?.split('/');\n\t\t\tcommitChange.n = unidecode(datapackKey[1])\n\t\t\t\t?.replace('\\\\', '-')\n\t\t\t\t.replace(/[^A-Za-z0-9/_\\-]+/g, '-')\n\t\t\t\t.replace(/[-]+/g, '-')\n\t\t\t\t.replace(/[-_]+_/g, '_')\n\t\t\t\t.replace(/[-]+\\/[-]+/g, '/')\n\t\t\t\t.replace(/^[-_\\\\/]+/, '')\n\t\t\t\t.replace(/[-_\\\\/]+$/, '');\n\t\t}\n\t}\n\tfs.writeFileSync(filePath, JSON.stringify(committedMetadata, null, 2));\n}\n\n// INNER CLASS\n\nclass CommandExecutionError extends Error {\n\tconstructor(message, category, additionalInfo) {\n\t\tsuper(`${category ? category + ' - ' : ''}${additionalInfo ? additionalInfo + ' : ' : ''}${message}`);\n\t\tthis.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n\t}\n}\n\nmodule.exports.execute = execute;\nmodule.exports.logger = logger;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\nmodule.exports.downloadFile = downloadFile;\nmodule.exports.getPath = getPath;\nmodule.exports.getFileDetails = getFileDetails;\nmodule.exports.readFromPath = readFromPath;\nmodule.exports.retrieveVlocityDataPacks = retrieveVlocityDataPacks;\nmodule.exports.getVlocitySelections = getVlocitySelections;\nmodule.exports.getCommitChanges = getCommitChanges;\nmodule.exports.updateResult = updateResult;\nmodule.exports.createJobFile = createJobFile;\nmodule.exports.defaultJobParameters = defaultJobParameters;\nmodule.exports.updateJobFileFromSettings = updateJobFileFromSettings;\nmodule.exports.validateCommitId = validateCommitId;\nmodule.exports.executeCommandAsync = executeCommandAsync;\nmodule.exports.displayVersions = displayVersions;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.log = log;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.getOptions = getOptions;\nmodule.exports.createEncodedChanges = createEncodedChanges;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0l7Q00000D1gMjQAJ",
                    "LastReferencedDate": "2023-08-22T11:33:16.000+0000",
                    "LastViewedDate": "2023-08-22T11:33:16.000+0000",
                    "Name": "Vlocity Retrieve"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v58.0/sobjects/copado__Function__c/a0l7Q00000D28NjQAJ"
                    },
                    "copado__ApexClass__c": "cmcSf.RefreshVlocityCallback",
                    "copado__API_Name__c": "vlocity_refresh_index",
                    "copado__Callback_Type__c": "ApexClass",
                    "copado__Description__c": "Function to refresh Vlocity Index from Source Org",
                    "copado__Image_Name__c": "copado-multicloud-vlocity:v1",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"sessionId\",\n  \"defaultValue\" : \"{$Context.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"endpoint\",\n  \"defaultValue\" : \"{$Context.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"credentialId\",\n  \"defaultValue\" : \"\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\nconst { execSync } = require('child_process'),\n    { writeFileSync } = require('fs'),\n    { sessionId, endpoint, credentialId, isTest } = process.env,\n    url = endpoint.substring(0, endpoint.indexOf('/', endpoint.indexOf('/') + 2)),\n    CHECK_LOG = 'Please check the logs for details',\n    VLOCITY_CATEGORY = 'Vlocity',\n    VLOCITY_FILE = 'Vlocity.json',\n    js_yaml = isTest ? require('js-yaml') : require('/usr/local/lib/node_modules/js-yaml'),\n    JOB_FILE = 'jobfile.yaml';\n\nfunction execute() {\n    try {\n        this.displayVersions();\n        this.createJobFile(JOB_FILE);\n        const packGetAllAvailable = this.retrieveVlocityAllAvailableExports(JOB_FILE);\n        const records = JSON.parse(packGetAllAvailable)?.records;\n\n        const formattedOutput = this.parseOutputToValidFormat(records);\n\n        this.writeAndUploadFile(formattedOutput, VLOCITY_FILE);\n    } catch (error) {\n        if (error?.status === 3) {\n            process.exit(1);\n        }\n        execSync(this.showError(error.toString()));\n    }\n}\n\nfunction retrieveVlocityAllAvailableExports(jobFile) {\n    const packGetAllAvailableCmd = `vlocity -sf.sessionId ${sessionId} -sf.instanceUrl ${url} -job ${jobFile} packGetAllAvailableExports --json-pretty || (${this.showError(\n        `Error in refreshing Vlocity. ${CHECK_LOG}`\n    )})`;\n\n    this.logger(`Vlocity Get All Available Export Command ==> ${packGetAllAvailableCmd}`);\n\n    const result = execSync(packGetAllAvailableCmd, { maxBuffer: 50 * 1024 * 1024 });\n\n    return result;\n}\n\nfunction createJobFile(jobFile) {\n    const jobFileParameters = this.defaultJobParameters();\n\n    writeFileSync(jobFile, js_yaml.dump(jobFileParameters), 'utf8');\n}\n\nfunction defaultJobParameters() {\n    return { separateMatrixVersions: true, separateCalculationProcedureVersions: true };\n}\n\nfunction parseOutputToValidFormat(records) {\n    return records.map((record) => ({\n        t: record.VlocityDataPackType,\n        n: record.VlocityDataPackDisplayLabel,\n        j: JSON.stringify({ vk: record.VlocityDataPackKey }),\n        b: record.LastModifiedByName,\n        d: record.LastModifiedDate,\n        cb: record.CreatedByName,\n        cd: record.CreatedDate,\n        c: VLOCITY_CATEGORY\n    }));\n}\n\nfunction writeAndUploadFile(output, filePath) {\n    writeFileSync(filePath, JSON.stringify(output));\n    execSync(`copado -u '${filePath}' --parentid '${credentialId}' || (${this.showError(`Error uploading file. ${CHECK_LOG}`)})`);\n}\n\nfunction showError(error) {\n    const refinedErrorMsg = this.maskSensitiveInformation(error, { '-sf.sessionId': sessionId });\n    return `copado -p 'Error' -e ${JSON.stringify(refinedErrorMsg).replace(/\\\\n/g, '\\n')}  ${isTest ? '' : '&&  exit 3'}`;\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nfunction maskSensitiveInformation(data, sensitiveFlags) {\n    const maskingSequence = '*****';\n\n    const arrayOfData = data.split(' ');\n    Object.keys(sensitiveFlags).forEach((subStr) => {\n        const keyIndex = arrayOfData.indexOf(subStr);\n        if (keyIndex > -1) {\n            arrayOfData[keyIndex + 1] = maskingSequence;\n            arrayOfData.splice(keyIndex + 2, sensitiveFlags[subStr].split(' ').length - 1);\n        }\n    });\n    return arrayOfData.join(' ');\n}\n\nfunction displayVersions() {\n    execSync(\n        `\n            echo \"Node version: \"\n            node -v\n            echo \"VBT version: \"\n            vlocity -v\n        `,\n        { stdio: 'inherit' }\n    );\n}\n\nmodule.exports.execute = execute;\nmodule.exports.retrieveVlocityAllAvailableExports = retrieveVlocityAllAvailableExports;\nmodule.exports.parseOutputToValidFormat = parseOutputToValidFormat;\nmodule.exports.writeAndUploadFile = writeAndUploadFile;\nmodule.exports.createJobFile = createJobFile;\nmodule.exports.defaultJobParameters = defaultJobParameters;\nmodule.exports.showError = showError;\nmodule.exports.logger = logger;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\nmodule.exports.displayVersions = displayVersions;\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q00000D28NjQAJ",
                    "LastReferencedDate": "2023-07-21T02:22:19.000+0000",
                    "LastViewedDate": "2023-07-21T02:22:19.000+0000",
                    "Name": "Vlocity Refresh Index"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q00000D2yXGQAZ"
                    },
                    "copado__API_Name__c": "deploy_vlocity",
                    "copado__Image_Name__c": "copado-multicloud-vlocity:v1",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"name\" : \"promotionBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.promotionBranchName}\"\n}, {\n  \"name\" : \"targetBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.destinationBranchName}\"\n}, {\n  \"name\" : \"destinationInstanceUrl\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"name\" : \"destinationSessionid\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"name\" : \"validationId\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.Promotion__r.cmcSf__Validate_Deploy_Request_Id__c}\"\n}, {\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"name\" : \"gitDepth\",\n  \"defaultValue\" : \"100\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"name\" : \"hasVlocityChanges\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.HasVlocityChanges}\"\n}, {\n  \"name\" : \"isValidation\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.deploymentDryRun}\"\n}, {\n  \"name\" : \"vlocityDirectory\",\n  \"defaultValue\" : \"vlocity\"\n}, {\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"name\" : \"repository_id\",\n  \"defaultValue\" : \"{$Pipeline.Git_Repository__r.Id}\"\n}, {\n  \"name\" : \"file_changes_id\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"\n}, {\n  \"name\" : \"file_name\",\n  \"defaultValue\" : \"Copado Deploy changes\"\n}, {\n  \"name\" : \"attachVlocityLogFile\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.Promotion__r.cmcSf__Attach_Vlocity_Build_File__c}\"\n}, {\n  \"name\" : \"vlocitySettingsDocumentId\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.VlocitySettingsDestinationId}\"\n}, {\n  \"name\" : \"rollBackEnabled\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.IsRollBackEnabled}\"\n}, {\n  \"name\" : \"findAndReplaceRules\",\n  \"defaultValue\" : \"{$Context.apex.GlobalFindAndReplaceDestinationId}\"\n}, {\n  \"name\" : \"destinationEnv\",\n  \"defaultValue\" : \"{$Destination.apex.EnvironmentVariables}\"\n}, {\n  \"name\" : \"prevResult\",\n  \"defaultValue\" : \"{$Job.PrevStep.Result__r.Result_Data__c}\"\n}, {\n  \"name\" : \"promotionId\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.Promotion__r.Id}\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n/**\n* Performs deploy of selected user story metadata changes.\n* Returns (If ACTION success) destination branch with merged changes of the user story metadata\n* (If ACTION failed) Returns details with error status on the job execution\n\n\n* @param promotionBranch\n* @param targetBranch\n* @param destinationInstanceUrl\n* @param destinationSessionid\n* @param isValidation\n* @param gitName\n* @param gitEmail\n* @param maxBuffer\n* @param vlocityDirectory\n* @param hasVlocityChanges\n* @param file_changes_id\n* @param file_name\n*/\n\nconst child_process = require('child_process'),\n    fs = require('fs'),\n    path = require('path'),\n    { env } = require('process'),\n    {\n        destinationSessionid,\n        promotionBranch,\n        targetBranch,\n        destinationInstanceUrl,\n        gitDepth,\n        isTest,\n        hasVlocityChanges,\n        isValidation,\n        vlocityDirectory,\n        file_changes_id,\n        file_name,\n        attachVlocityLogFile,\n        vlocitySettingsDocumentId,\n        rollBackEnabled,\n        findAndReplaceRules,\n        destinationEnv,\n        prevResult,\n        promotionId\n    } = env,\n    url = destinationInstanceUrl.substring(0, destinationInstanceUrl.indexOf('/', destinationInstanceUrl.indexOf('/') + 2)),\n    APP_DIRECTORY = getPath('/app'),\n    js_yaml = isTest ? require('js-yaml') : require('/usr/local/lib/node_modules/js-yaml'),\n    TEMP_DIRECTORY = getPath('/tmp'),\n    TARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n    ENCODED_CHANGES_FILE = 'encoded_changes.json',\n    JOB_FILE = 'jobfile.yaml',\n    ROLLBACK_RETRIEVAL_PATH = `${TEMP_DIRECTORY}/vlocityRollback`,\n    DEPLOYMENT_RESULT_JSON = 'DeploymentResult.json',\n    DEPLOYMENT_RESULT_PATH = `${TEMP_DIRECTORY}/${DEPLOYMENT_RESULT_JSON}`,\n    STDIO = {\n        INHERIT: 'inherit',\n        PIPE: 'pipe',\n        IGNORE: 'ignore'\n    },\n    ACTIONS = {\n        ADD: 'add',\n        RETRIEVE_ONLY: 'retrieveonly',\n        FULL: 'full',\n        DELETE: 'delete'\n    },\n    ROLLBACK_ACTION = {\n        UNCHANGED: 'Unchanged',\n        DELETE: 'Delete',\n        CREATE: 'Create',\n        UPDATE: 'Update',\n        DELETE_NOT_SUPPORTED: 'Delete (Not Supported)',\n        CREATE_NOT_SUPPORTED: 'Create (Not Supported)'\n    },\n    GIT_DEPTH = getGitDepth(gitDepth),\n    VLOCITY_BUILD_LOG = 'VlocityBuildLog.yaml',\n    VLOCITY_SETTINGS_YAML_FILE = 'vlocity-settings',\n    VLOCITY_TEMP = 'vlocity-temp',\n    VLOCITY_ROLLBACK_JSON = `${TEMP_DIRECTORY}/CopadoVlocityRollbackChanges.json`,\n    isRollBack = isRollBackEnabled(isValidation, rollBackEnabled),\n    RESULT_INFO = {\n        LEVEL: {\n            INFO: 'INFO',\n            ERROR: 'ERROR',\n            WARN: 'WARN'\n        },\n        CATEGORY: {\n            UNKNOWN_EXCEPTION: 'Unknown Exception',\n            COPADO_INFO: 'Copado Info',\n            COPADO_SERVICE: 'Copado Service',\n            VBT_CLI: 'VBT CLI',\n            GIT: 'Git',\n            FILE_SYSTEM: 'File System',\n            COPADO_METADATA_INTELLIGENCE: 'Copado Metadata Intelligence'\n        },\n        ADDITIONAL_INFORMATION: {\n            CONSOLIDATED_RESULT: `Consolidated ${isValidation === 'true' ? 'Validation' : 'Deployment'} Result`,\n            GIT_STATUS: 'Git Status',\n            ROLLBACK_BRANCH_CHECKOUT: 'Rollback Branch Checkout',\n            GIT_COMMIT: 'Git Commit',\n            GIT_CONFIG: 'Git Configuration',\n            PROMOTION_BRANCH_CHECKOUT: 'Promotion Branch Checkout',\n            TARGET_BRANCH_CHECKOUT: 'Target Branch Checkout',\n            DEBUG_BRANCH_CHECKOUT: 'Debug Branch Checkout',\n            POPULATE_INFO_ON_RESULT: 'Populate Information on the result record',\n            ENV_VARIABLE_REPLACEMENT: 'Environment Variable Replacement',\n            GLOBAL_FIND_AND_REPLACE: 'Global Find and Replace',\n            UPLOAD_FILES: 'Upload Files',\n            DOWNLOAD_FILES: 'Download Files',\n            VALIDATE_DATAPACKS: 'Validate Vlocity Deployment',\n            VLOCITY_DEPLOYMENT: 'Datapacks Deployment',\n            GIT_MERGE: 'Git Merge',\n            GIT_PUSH: 'Git Push',\n            GIT_ADD: 'Git Add'\n        }\n    },\n    resultViewerJson = [],\n    CUSTOM_ERROR = {\n        COMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n    },\n    RESULT_TABLE_COLUMNS = [\n        {\n            label: 'Level',\n            fieldName: 'Level',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Level',\n            initialWidth: 80\n        },\n        {\n            label: 'Category',\n            fieldName: 'Category',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Category',\n            initialWidth: 120\n        },\n        {\n            label: 'Additional Information',\n            fieldName: 'AdditionalInformation',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Additional_Information',\n            initialWidth: 200\n        },\n        {\n            label: 'Message',\n            fieldName: 'Message',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Message'\n        }\n    ],\n    RESULT_TABLE_HEADER = {\n        label: 'Deployment Result',\n        customLabel: 'Deployment_Result'\n    },\n    HEADER_ICON = 'standard:note';\n\nlet isSfMetadataPresent, isVlocityDataPackPresent, executionError;\n\n// EXECUTION\n\nasync function execute() {\n    const { targetBranch, gitEmail, gitName } = env;\n    try {\n        this.displayVersions();\n        this.checkChangesWrtCategory(`${APP_DIRECTORY}/${ENCODED_CHANGES_FILE}`);\n        const { allChanges, addChanges } = this.getVlocityChanges(file_name, file_changes_id);\n\n        //TODO: Promotion and merge to be improved to run conditionally.\n        this.fetchPromotionBranch(promotionBranch, GIT_DEPTH);\n        this.configureGit(gitEmail, gitName);\n\n        const rollBackBranchName = this.getRollBackBranchName(promotionBranch);\n        const { retrieveResult, filePaths } = await this.executeRollBackLogic(addChanges, rollBackBranchName, findAndReplaceRules);\n        this.logger('retrieveResult' + JSON.stringify(retrieveResult));\n\n        this.gitMergePromotionToTarget(promotionBranch, targetBranch, GIT_DEPTH);\n        this.writeJobFile(JOB_FILE, addChanges);\n        this.updateJobFileFromSettings(vlocitySettingsDocumentId, JOB_FILE);\n\n        // Apply Find and replace\n        this.varReplace(destinationEnv, TARGET_DIRECTORY, false);\n        this.yamlFindAndReplace(addChanges, TARGET_DIRECTORY, findAndReplaceRules, targetBranch);\n\n        this.validateVlocityData(JOB_FILE);\n        const deployResult = this.deployVlocity(JOB_FILE, attachVlocityLogFile === 'true');\n        this.logger('deployResult' + JSON.stringify(deployResult));\n\n        await Promise.all([this.pushChangesToRemote(targetBranch), this.cleanDeploymentFiles()]);\n        if (isRollBack) {\n            await Promise.all([\n                this.pushChangesToRemote(rollBackBranchName),\n                this.createCopadoRollbackChangesFile(allChanges, retrieveResult, filePaths)\n            ]);\n        }\n    } catch (err) {\n        this.logger('Error stack: ', err.stack);\n        executionError = err.message || err?.toString() || 'Unknown Error occurred';\n        if (!(err instanceof CommandExecutionError)) {\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, `See logs for more info`, executionError);\n        }\n    } finally {\n        if (resultViewerJson?.length) {\n            this.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n        }\n        if (executionError) {\n            this.executeCommand(\n                this.getErrorCmdString(executionError),\n                RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                RESULT_INFO.ADDITIONAL_INFORMATION.POPULATE_INFO_ON_RESULT\n            );\n            process.exit(1);\n        }\n    }\n}\n\n// SCRIPT FUNCTIONS\n\nfunction checkChangesWrtCategory(sfdxFilePath) {\n    isSfMetadataPresent = fs.existsSync(sfdxFilePath);\n    isVlocityDataPackPresent = hasVlocityChanges?.toLowerCase() === 'true';\n\n    if (isSfMetadataPresent) {\n        this.logger('Salesforce changes found.');\n    } else {\n        this.logger('Salesforce changes not found.');\n    }\n\n    if (isVlocityDataPackPresent) {\n        this.logger('Vlocity changes found.');\n    } else {\n        this.logger('Vlocity changes not found.');\n        this.asyncCopadoLogMessage(`No Vlocity datapacks`);\n    }\n\n    if (!isVlocityDataPackPresent || isValidation === 'true') {\n        this.asyncCopadoLogMessage(`Exiting Vlocity Deployment Step`);\n        if (resultViewerJson?.length) {\n            this.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n        }\n        process.exit(0);\n    }\n}\n\nfunction getVlocityChanges(fileName, fileChangesId) {\n    this.executeCommand(\n        `copado --downloadfiles ${fileChangesId} --downloaddir /tmp/`,\n        RESULT_INFO.CATEGORY.COPADO_SERVICE,\n        RESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILES\n    );\n    let downloadedFileName;\n    if (fs.existsSync(`/tmp/${fileName}`)) {\n        downloadedFileName = fileName;\n    } else if (fs.existsSync(`/tmp/${fileName}.json`)) {\n        downloadedFileName = `${fileName}.json`;\n    } else {\n        throw new Error('Error fetching Deployment Changes');\n    }\n    const deploymentMetadata = this.readFromPath(`/tmp/${downloadedFileName}`);\n    return {\n        allChanges: deploymentMetadata.filter((element) => element.c === 'Vlocity'),\n        addChanges: deploymentMetadata.filter((element) => element.c === 'Vlocity' && element.a?.toLowerCase() === ACTIONS.ADD)\n    };\n}\n\nfunction writeJobFile(jobFile, vlocityChanges) {\n    const jobFileParameters = this.defaultJobParameters(vlocityChanges);\n    fs.writeFileSync(jobFile, js_yaml.dump(jobFileParameters), 'utf8');\n}\n\nfunction defaultJobParameters(vlocityDataPacks) {\n    return {\n        projectPath: `./${vlocityDirectory}`,\n        oauthConnection: true,\n        autoUpdateSettings: true,\n        maxDepth: 0,\n        separateMatrixVersions: true,\n        separateCalculationProcedureVersions: true,\n        reactivateOmniScriptsWhenEmbeddedTemplateFound: true,\n        manifest: vlocityDataPacks.map((currentData) => {\n            return JSON.parse(currentData.j)?.vk;\n        })\n    };\n}\n\nfunction updateJobFileFromSettings(vlocitySettingsDocumentId, jobFileName) {\n    if (vlocitySettingsDocumentId) {\n        this.downloadFile(vlocitySettingsDocumentId, TEMP_DIRECTORY, VLOCITY_SETTINGS_YAML_FILE);\n        const vlocitySettings = js_yaml.load(fs.readFileSync(`${TEMP_DIRECTORY}/${VLOCITY_SETTINGS_YAML_FILE}`, 'utf-8'));\n        let settings = vlocitySettings?.deploy ? Object.keys(vlocitySettings.deploy) : [];\n\n        if (settings.length) {\n            const jobYaml = js_yaml.load(fs.readFileSync(jobFileName, 'utf-8'));\n            settings.forEach((setting) => {\n                if (setting !== 'manifest' && setting !== 'projectPath' && setting !== 'maxDepth') {\n                    jobYaml[setting] = vlocitySettings.deploy[setting];\n                }\n            });\n            fs.writeFileSync(jobFileName, js_yaml.dump(jobYaml), 'utf8');\n            this.asyncCopadoLogMessage('Vlocity Settings would be applied');\n        } else {\n            this.asyncCopadoLogMessage('Vlocity Settings not found');\n        }\n    }\n}\n\nfunction downloadFile(fileId, downloadDir, fileName) {\n    this.asyncCopadoLogMessage('Retrieve vlocity selections');\n    this.executeCommand(\n        `\n        copado --downloadfiles ${fileId} --downloaddir ${downloadDir}\n    `,\n        RESULT_INFO.CATEGORY.COPADO_SERVICE,\n        RESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILES\n    );\n}\n\nfunction validateVlocityData(jobFile) {\n    this.asyncCopadoLogMessage('Validating Vlocity DataPacks');\n    const validateVlocityDataPacks = `vlocity -sf.sessionId ${destinationSessionid} -sf.instanceUrl ${url} -job ${jobFile} validateLocalData --json-pretty`;\n\n    const response = this.executeCommand(\n        validateVlocityDataPacks,\n        RESULT_INFO.CATEGORY.VBT_CLI,\n        RESULT_INFO.ADDITIONAL_INFORMATION.VALIDATE_DATAPACKS\n    );\n    this.evaluateResponse(response);\n}\n\nfunction deployVlocity(jobFile, attachFile) {\n    this.asyncCopadoLogMessage('Deploying Vlocity DataPacks');\n    const deployVlocityCommand = `\n        vlocity -sf.sessionId ${destinationSessionid} -sf.instanceUrl ${url} -job ${jobFile} packDeploy --verbose --json-pretty`;\n\n    this.logger('Deploy Command: ' + deployVlocityCommand);\n    this.logger('jobfile.yaml \\n' + fs.readFileSync(jobFile, 'utf-8'));\n\n    const response = this.executeCommand(\n        deployVlocityCommand,\n        RESULT_INFO.CATEGORY.VBT_CLI,\n        RESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_DEPLOYMENT,\n        true,\n        true\n    );\n    this.logger(\n        `To check status of deployed Vlocity datapacks, go to result record of Vlocity Deploy step and find file attached with name ${DEPLOYMENT_RESULT_JSON}`\n    );\n\n    fs.writeFileSync(DEPLOYMENT_RESULT_PATH, JSON.stringify(response, null, 2));\n    this.uploadFile(DEPLOYMENT_RESULT_PATH);\n\n    if (attachFile || response?.status === 'error') {\n        this.maskSensitiveInfo(VLOCITY_BUILD_LOG, [destinationSessionid]);\n        this.uploadFile(VLOCITY_BUILD_LOG);\n    }\n    return this.evaluateResponse(response);\n}\n\nfunction maskSensitiveInfo(filePath, sensitiveInfo) {\n    let fileContent = fs.readFileSync(filePath, 'utf-8'),\n        updatedContent;\n    sensitiveInfo.forEach((detail) => {\n        updatedContent = fileContent?.replaceAll(detail, '****');\n    });\n\n    if (updatedContent && fileContent !== updatedContent) {\n        fs.writeFileSync(filePath, updatedContent, 'utf-8');\n    }\n}\n\nfunction fetchPromotionBranch(promotion, gitDepth) {\n    console.log('START Fetching promotion branch');\n    fs.mkdirSync(TARGET_DIRECTORY, { recursive: true });\n    process.chdir(TARGET_DIRECTORY);\n    this.asyncCopadoLogMessage(`Fetching ${promotion}`);\n    this.executeCommand(\n        `\n            copado-git-get \"${promotion}\" --depth \"${gitDepth}\"\n        `,\n        RESULT_INFO.CATEGORY.GIT,\n        RESULT_INFO.ADDITIONAL_INFORMATION.PROMOTION_BRANCH_CHECKOUT\n    );\n    console.log('END Fetching promotion branch');\n}\n\nfunction configureGit(gitEmail, gitName) {\n    const configureGit = `\n        git config --local user.email \"${gitEmail}\" || exit 1\n        git config --local user.name \"${gitName}\" || exit 1\n        git config --global diff.renames false || exit 1\n        git config --global merge.renames false || exit 1\n        git config --global status.renames false || exit 1\n    `;\n    this.executeCommand(`${configureGit}`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CONFIG);\n}\n\nfunction cleanDeploymentFiles() {\n    const cleanUp = `\n        git reset --hard\n    `;\n    return new Promise((resolve, reject) => {\n        child_process.exec(cleanUp, this.getOptions(), (error, stdout, stderr) => {\n            this.handleResponse(error, stdout, stderr, reject);\n            resolve();\n        });\n    });\n}\n\nfunction gitMergePromotionToTarget(promotionBranch, targetBranch, gitDepth) {\n    this.asyncCopadoLogMessage(`Locally merging ${promotionBranch} into ${targetBranch}`);\n    let checkoutTargetBranch = `\n        git reset --hard || exit 2\n        ${this.fetchCheckoutBranch(targetBranch, gitDepth, false)}\n    `;\n\n    this.executeCommand(checkoutTargetBranch, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.TARGET_BRANCH_CHECKOUT);\n\n    try {\n        const merge = `git merge \"${promotionBranch}\" --no-commit -Xignore-space-change`;\n        this.executeCommand(merge, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_MERGE);\n    } catch (error) {\n        this.evaluateMergeStatus();\n        throw error;\n    }\n    this.commitGit(`Merging ${promotionBranch} into ${targetBranch} after auto conflict resolution`);\n}\n\nfunction commitGit(commitMessage) {\n    this.executeCommand(\n        `\n        git add . ':!${VLOCITY_BUILD_LOG}' ':!${JOB_FILE}' ':!${VLOCITY_TEMP}/*' || exit 1\n        git commit -am \"${commitMessage}\" || true\n    `,\n        RESULT_INFO.CATEGORY.GIT,\n        RESULT_INFO.ADDITIONAL_INFORMATION.GIT_COMMIT\n    );\n}\n\nfunction evaluateMergeStatus() {\n    const gitStatus = this.executeCommand('git status --porcelain=v1 -uno', RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS),\n        porcelainStatus = gitStatus.split('\\n').map((str) => str.split(' ')?.[0]),\n        isConflict = porcelainStatus.length ? ['AA', 'UU', 'DD', 'UA', 'UD', 'DU', 'AU'].some((s) => porcelainStatus.includes(s)) : false;\n    let infoMessage;\n\n    if (isConflict) {\n        this.populateResultViewer(\n            RESULT_INFO.LEVEL.ERROR,\n            RESULT_INFO.CATEGORY.GIT,\n            RESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS,\n            `Changes detected in target branch '${targetBranch}' after promotion branch '${promotionBranch}' was created, please recreate promotion branch out of the new target branch state.`\n        );\n        throw new Error(\n            `Changes detected in target branch '${targetBranch}' after promotion branch '${promotionBranch}' was created, please recreate promotion branch out of the new target branch state.`\n        );\n    } else if (!gitStatus) {\n        infoMessage = 'Already up to date';\n    } else {\n        infoMessage = `Changes detected in target branch '${targetBranch}' after promotion branch '${promotionBranch}' was created.`;\n    }\n    infoMessage && this.asyncCopadoLogMessage(infoMessage);\n}\n\nfunction pushChangesToRemote(remoteBranchName) {\n    this.asyncCopadoLogMessage(`Push changes into remote ${targetBranch} branch`);\n    const push = `git push origin \"${remoteBranchName}\" || exit 1`;\n    const deploymentSuccessMessage =\n        'Important Information: Be aware that the contents of your deployment were successfully deployed to the target org and have not been removed based on this error';\n    return new Promise((resolve, reject) => {\n        child_process.exec(push, this.getOptions(), (error, stdout, stderr) => {\n            this.handleResponse(error, stdout, stderr, reject, deploymentSuccessMessage);\n            resolve();\n        });\n    });\n}\n\nfunction getErrorCmdString(error) {\n    const suffix = 'Please check the logs for details.';\n    return `{ copado -p \"Error\" -e \"${error.trim()}; ${suffix}\"; }`;\n}\n\nfunction executeCommand(command, category, additionalInfo, hasJsonResponse, disableLogs) {\n    let errorMessage;\n    const response = child_process.spawnSync(command, this.getOptions());\n    const { outputStream, errorStream } = this.log(response, disableLogs);\n    if (response?.status == 0) {\n        return hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n    }\n    if (!hasJsonResponse) {\n        errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n    } else {\n        try {\n            return JSON.parse(outputStream);\n        } catch (error) {\n            errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n        }\n    }\n    if (errorMessage) {\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n        throw new CommandExecutionError(errorMessage);\n    }\n}\n\nfunction evaluateResponse(response) {\n    if (response?.status === 'error' && response?.message) {\n        this.handleDeploymentErrors(response);\n    }\n\n    if (response?.status === 'success' && response?.message === '0 Completed') {\n        this.asyncCopadoLogMessage('No Vlocity datapack deployed');\n    }\n    return response;\n}\n\nfunction handleDeploymentErrors(response) {\n    let errorCount = 0,\n        successCount = 0,\n        warningCount = 0;\n    response?.records.forEach((record) => {\n        if (record?.VlocityDataPackStatus === 'Success') {\n            this.logger(`INFO: Deployment was successful for ${record?.VlocityDataPackDisplayLabel}`);\n            successCount++;\n        } else if (record?.VlocityDataPackStatus === 'Error') {\n            if (record?.ErrorMessage.includes('Activation Error >>')) {\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.WARN,\n                    RESULT_INFO.CATEGORY.VBT_CLI,\n                    RESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_DEPLOYMENT,\n                    record?.ErrorMessage\n                );\n                this.logger(`WARNING: ${record?.ErrorMessage}`);\n                warningCount++;\n                return;\n            }\n            this.populateResultViewer(\n                RESULT_INFO.LEVEL.ERROR,\n                RESULT_INFO.CATEGORY.VBT_CLI,\n                RESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_DEPLOYMENT,\n                record?.ErrorMessage\n            );\n            this.logger(`ERROR: ${record?.ErrorMessage}`);\n            errorCount++;\n        }\n    });\n\n    if (warningCount > 0) {\n        this.asyncCopadoLogMessage(`copado -p 'Warnings during deployment'`);\n    }\n\n    if (successCount > 0 && errorCount > 0) {\n        this.asyncCopadoLogMessage('Git merge aborted due to errors', RESULT_INFO.LEVEL.ERROR);\n        this.logger(`ERROR: Some datapacks were successfully deployed but the changes were not merged into the destination branch.`);\n    }\n\n    if ((response?.status === 'error' && response?.records?.length === 0) || errorCount > 0) {\n        this.populateResultViewer(\n            RESULT_INFO.LEVEL.ERROR,\n            RESULT_INFO.CATEGORY.VBT_CLI,\n            RESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_DEPLOYMENT,\n            `Deployment for following DataPacks failed : ${response.message}`\n        );\n        throw new Error(`Deployment for following DataPacks failed : ${response.message}`);\n    }\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction getGitDepth(gitDepth) {\n    gitDepth = parseInt(gitDepth);\n    return gitDepth >= 0 ? gitDepth : 100;\n}\n\nfunction fetchCheckoutBranch(branch, gitDepth, forceCreate) {\n    return `( git fetch origin ${branch} --depth ${gitDepth} && git checkout ${branch} )` + (forceCreate ? ` || git checkout -b ${branch}` : '');\n}\n\nfunction handleResponse(error, stdout, stderr, reject, deploymentSuccessMessage) {\n    if (stdout) {\n        console.log(stdout);\n    }\n    if (stderr) {\n        console.log(stderr);\n    }\n    if (error?.code) {\n        const errorResponse = stderr ? (deploymentSuccessMessage ? `${stderr} ${deploymentSuccessMessage}` : stderr) : `Error executing the command ${error.cmd}`;\n        if (reject) {\n            reject(new Error(errorResponse));\n            return;\n        }\n        throw new Error(errorResponse);\n    }\n}\n\nfunction getOptions(ioconfig) {\n    const { maxBuffer } = env;\n    const options = {\n        shell: true,\n        maxBuffer: parseInt(maxBuffer)\n    };\n    if (ioconfig) {\n        options.stdio = ioconfig;\n    }\n    return options;\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nfunction log(response, disableLogs) {\n    const outputStream = response?.stdout?.toString().trim();\n    const errorStream = response?.stderr?.toString().trim();\n    if (!disableLogs) {\n        if (outputStream) {\n            console.log(outputStream);\n        }\n        if (errorStream) {\n            console.log(errorStream);\n        }\n    }\n    return { outputStream, errorStream };\n}\n\nfunction readFromPath(filePath) {\n    return JSON.parse(fs.readFileSync(filePath, 'utf-8'));\n}\n\nfunction uploadFile(fileName, name, parentId) {\n    const command = `copado -u ${fileName} ${name ? `--name '${name}'` : ''} ${parentId ? `--parentid '${parentId}'` : ''}`;\n    this.logger(command);\n    this.executeCommand(command, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES);\n}\n\nfunction isRollBackEnabled(isValidation, rollBackEnabled) {\n    return isValidation?.toLowerCase() !== 'true' && rollBackEnabled?.toLowerCase() === 'true';\n}\n\nasync function executeRollBackLogic(changes, rollBackBranchName, findAndReplaceRules) {\n    let result = [],\n        filePaths = [];\n    if (isRollBack && changes?.length) {\n        this.checkoutRollBackBranch(rollBackBranchName, targetBranch);\n        this.writeJobFile(JOB_FILE, changes);\n        const retrieveResult = this.retrieveVlocityDataPacks();\n\n        filePaths = this.getFilePaths(retrieveResult);\n\n        if (filePaths.length && !hasOnlyDestructiveChanges(changes)) {\n            this.varReplace(destinationEnv, ROLLBACK_RETRIEVAL_PATH, true);\n            this.yamlFindAndReplace(changes, ROLLBACK_RETRIEVAL_PATH, findAndReplaceRules, rollBackBranchName);\n        }\n\n        retrieveResult?.records?.length &&\n            this.copyFiles(`${ROLLBACK_RETRIEVAL_PATH}/${vlocityDirectory}/.`, `${TARGET_DIRECTORY}/${vlocityDirectory}/`);\n        const gitStatus = this.executeCommand(`git status --porcelain=v1`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS);\n\n        const changedFiles = gitStatus.split('\\n').map((str) => str.trim().split(' ')?.[1]);\n\n        result = filePaths.filter((filePath) =>\n            changedFiles?.some((changedFile) => changedFile?.includes(filePath) || changedFile?.includes(path.dirname(filePath)))\n        );\n\n        this.commitChangesInRollbackBranch(result, filePaths, rollBackBranchName);\n    }\n\n    return { filePaths, retrieveResult: result };\n}\n\nfunction hasOnlyDestructiveChanges(changes) {\n    return changes.filter((change) => change.a === 'delete').length === changes.length;\n}\n\nasync function commitChangesInRollbackBranch(changes, filepathsList, rollBackBranchName) {\n    if (changes?.length) {\n        this.asyncCopadoLogMessage(`Committing backup to ${rollBackBranchName}`);\n        this.gitCommit('Committing Vlocity files to rollback branch', rollBackBranchName, filepathsList, true);\n    } else {\n        this.logger(`INFO: No changes in ${rollBackBranchName}`);\n    }\n}\n\nfunction getRollBackBranchName(promotion) {\n    return 'rollback/' + promotion.split('/')[1];\n}\n\nfunction checkoutRollBackBranch(rollBackBranch, targetBranch) {\n    let checkoutRollbackBranch;\n    const rollbackBranchCreated = prevResult && JSON.parse(prevResult)?.rollbackBranchCreated;\n    this.asyncCopadoLogMessage(rollbackBranchCreated ? `Switching to branch ${rollBackBranch}` : `Creating ${rollBackBranch} from ${targetBranch}`);\n\n    if (rollbackBranchCreated) {\n        checkoutRollbackBranch = `\n            git reset --hard || true\n            git fetch origin ${targetBranch} || exit 1\n            git checkout ${rollBackBranch}`;\n    } else {\n        checkoutRollbackBranch = `\n            git reset --hard || true\n            git fetch origin ${targetBranch} || exit 1\n            git branch -D ${rollBackBranch} || true\n            git checkout -b ${rollBackBranch} origin/${targetBranch}`;\n    }\n\n    this.executeCommand(checkoutRollbackBranch, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.ROLLBACK_BRANCH_CHECKOUT);\n}\n\nfunction retrieveVlocityDataPacks() {\n    const vlocityCmd = `\n        mkdir ${ROLLBACK_RETRIEVAL_PATH} || exit 1\n        cd ${ROLLBACK_RETRIEVAL_PATH} || exit 1\n        vlocity -sf.instanceUrl ${url} -sf.sessionId ${destinationSessionid} -job ${TARGET_DIRECTORY + '/' + JOB_FILE} packExport --json || true \n    `;\n    this.logger('Vlocity Command: ' + vlocityCmd);\n    this.logger('jobfile.yaml \\n' + fs.readFileSync(JOB_FILE, 'utf-8'));\n\n    const retrievedDataPacks = this.executeCommand(vlocityCmd, RESULT_INFO.CATEGORY.VBT_CLI, '', true, true);\n    this.logger('Destination Org Retrieval status: ', JSON.stringify(retrievedDataPacks, null, 2));\n    return retrievedDataPacks;\n}\n\nfunction varReplace(environmentVariables, targetFolder, valueName) {\n    if (environmentVariables && JSON.parse(environmentVariables)?.length) {\n        this.logger('START varReplace');\n        let command = `varreplace '${environmentVariables}' '${targetFolder}' ${valueName ? '--valuename=true' : ''}`;\n        this.executeCommand(command, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.ENV_VARIABLE_REPLACEMENT);\n        this.logger('END varReplace');\n    }\n}\n\nfunction yamlFindAndReplace(changes, targetFolder, findAndReplaceRules, branch) {\n    this.logger('START Yaml Replace');\n    if (changes?.length > 0 && findAndReplaceRules) {\n        let command = `\n            copado --downloadfiles \"${findAndReplaceRules}\" --downloaddir ${TEMP_DIRECTORY}/ || exit 1\n            yamlreplace \"${TEMP_DIRECTORY}/Copado\" \"${targetFolder}\" -b \"${branch}\"\n        `;\n        this.executeCommand(command, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.GLOBAL_FIND_AND_REPLACE);\n    }\n    this.logger('END Yaml Replace');\n}\n\nfunction getFilePaths(retrieveResult) {\n    let filePaths = [];\n    retrieveResult?.records?.forEach((record) => {\n        if (record?.VlocityDataPackStatus === 'Success' && record?.VlocityDataPackKey) {\n            filePaths.push(convertVlocityKeyToFolderName(`${vlocityDirectory}/${record.VlocityDataPackKey}`));\n        }\n    });\n    return filePaths;\n}\n\nfunction asyncCopadoLogMessage(msg, logLevel) {\n    if (msg) {\n        this.populateResultViewer(logLevel ? logLevel : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n        new Promise((resolve) => {\n            child_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, (err, response, stderr) => {\n                resolve();\n            });\n        });\n    }\n}\n\nfunction executeCommandinChunks(fileList, chunkSize, cmd) {\n    if (fileList.length > 0) {\n        let fileIndex = 0;\n        do {\n            let endIndex = fileIndex + parseInt(chunkSize) > fileList.length ? fileList.length : fileIndex + parseInt(chunkSize);\n            let fileChunk = fileList.slice(fileIndex, endIndex);\n            this.executeCommand(\n                cmd.replace(/REPLACE_VALUE/g, fileChunk.map((file) => `'${file}'`).join(' ')),\n                RESULT_INFO.CATEGORY.GIT,\n                RESULT_INFO.ADDITIONAL_INFORMATION.GIT_ADD\n            );\n            fileIndex = endIndex;\n        } while (fileIndex < fileList.length);\n    }\n}\n\nfunction gitCommit(commitMessage, branchName, filePaths, allowCommitWithNoChanges) {\n    console.log(`Committing ${commitMessage} in ${branchName}`);\n    this.executeCommand('rm -f .git/index.lock', RESULT_INFO.CATEGORY.FILE_SYSTEM);\n    this.executeCommandinChunks(filePaths, 10, `git add -f REPLACE_VALUE`);\n    const gitCommit = `git commit -m \"${commitMessage}\" ${allowCommitWithNoChanges ? ' || true' : ''}`;\n    this.executeCommand(gitCommit, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_COMMIT);\n}\n\nfunction createCopadoRollbackChangesFile(changeList, retrieveResult, exportedFilePaths) {\n    return new Promise((resolve, reject) => {\n        const rollbackChanges = JSON.parse(JSON.stringify(changeList));\n        rollbackChanges.forEach((record) => {\n            if (record.a?.toLowerCase() === ACTIONS.ADD) {\n                record.a = ROLLBACK_ACTION.DELETE_NOT_SUPPORTED;\n            } else if (record.a?.toLowerCase() === ACTIONS.DELETE) {\n                record.a = ROLLBACK_ACTION.CREATE_NOT_SUPPORTED;\n            } else if (record.a?.toLowerCase() === ACTIONS.RETRIEVE_ONLY) {\n                record.a = ROLLBACK_ACTION.UNCHANGED;\n            }\n            record.s = true;\n        });\n\n        exportedFilePaths?.forEach((path) => {\n            const updatedNode = rollbackChanges.find(\n                (change) => change.j && convertVlocityKeyToFolderName(JSON.parse(change.j)?.vk) === path.substring(path.indexOf('/') + 1)\n            );\n            if (updatedNode) {\n                updatedNode.a = ROLLBACK_ACTION.UPDATE;\n            }\n        });\n\n        retrieveResult?.forEach((result) => {\n            const updatedNode = rollbackChanges.find(\n                (change) => change.j && convertVlocityKeyToFolderName(JSON.parse(change.j)?.vk) === result.substring(result.indexOf('/') + 1)\n            );\n            if (updatedNode) {\n                updatedNode.a = ROLLBACK_ACTION.UPDATE;\n            }\n        });\n\n        this.asyncCopadoLogMessage('Uploading Rollback Changes File');\n        fs.writeFileSync(VLOCITY_ROLLBACK_JSON, JSON.stringify(rollbackChanges));\n        this.uploadFile(VLOCITY_ROLLBACK_JSON, 'Copado Vlocity Rollback changes', promotionId);\n        resolve();\n    });\n}\n\nfunction copyFiles(source, target) {\n    this.logger(`cp -R ${source} ${target}`);\n    this.executeCommand(\n        `\n        cp -R ${source} ${target}\n        `,\n        RESULT_INFO.CATEGORY.FILE_SYSTEM\n    );\n}\n\nfunction convertVlocityKeyToFolderName(vk) {\n    let result;\n    if (vk) {\n        result = vk\n            .replace('\\\\', '-')\n            .replace(/[^A-Za-z0-9/_\\-]+/g, '-')\n            .replace(/[-]+/g, '-')\n            .replace(/[-_]+_/g, '_')\n            .replace(/[-]+\\/[-]+/g, '/')\n            .replace(/^[-_\\\\/]+/, '')\n            .replace(/[-_\\\\/]+$/, '');\n    }\n    return result;\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n    if (message) {\n        resultViewerJson.push({\n            Level: level,\n            Category: category,\n            Message: message,\n            AdditionalInformation: additionalInfo\n        });\n    }\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n    const RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n    const fileContent = { data, columns, header, headerIcon };\n    fs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n    this.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n    new Promise((resolve, reject) => {\n        child_process.exec(`copado --uploadfile ${filePath}`, {}, (error, stdout, stderr) => {\n            if (error?.code) {\n                const errorResponse = stderr ? stderr : `Error executing the command : ${error?.cmd}`;\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.ERROR,\n                    RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                    `Uploading file at ${filePath}`,\n                    errorResponse\n                );\n                reject(new CommandExecutionError(errorResponse));\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\nfunction displayVersions() {\n    child_process.execSync(\n        `\n            echo \"Node version: \"\n            node -v\n            echo \"VBT version: \"\n            vlocity -v\n        `,\n        { stdio: 'inherit' }\n    );\n}\n\nclass CommandExecutionError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n    }\n}\n\nmodule.exports.execute = execute;\nmodule.exports.fetchPromotionBranch = fetchPromotionBranch;\nmodule.exports.configureGit = configureGit;\nmodule.exports.gitMergePromotionToTarget = gitMergePromotionToTarget;\nmodule.exports.getGitDepth = getGitDepth;\nmodule.exports.handleResponse = handleResponse;\nmodule.exports.defaultJobParameters = defaultJobParameters;\nmodule.exports.writeJobFile = writeJobFile;\nmodule.exports.getVlocityChanges = getVlocityChanges;\nmodule.exports.validateVlocityData = validateVlocityData;\nmodule.exports.handleResponse = handleResponse;\nmodule.exports.pushChangesToRemote = pushChangesToRemote;\nmodule.exports.cleanDeploymentFiles = cleanDeploymentFiles;\nmodule.exports.getOptions = getOptions;\nmodule.exports.deployVlocity = deployVlocity;\nmodule.exports.commitGit = commitGit;\nmodule.exports.evaluateMergeStatus = evaluateMergeStatus;\nmodule.exports.fetchCheckoutBranch = fetchCheckoutBranch;\nmodule.exports.checkChangesWrtCategory = checkChangesWrtCategory;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.evaluateResponse = evaluateResponse;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.log = log;\nmodule.exports.logger = logger;\nmodule.exports.readFromPath = readFromPath;\nmodule.exports.uploadFile = uploadFile;\nmodule.exports.updateJobFileFromSettings = updateJobFileFromSettings;\nmodule.exports.downloadFile = downloadFile;\nmodule.exports.handleDeploymentErrors = handleDeploymentErrors;\nmodule.exports.isRollBackEnabled = isRollBackEnabled;\nmodule.exports.executeRollBackLogic = executeRollBackLogic;\nmodule.exports.getRollBackBranchName = getRollBackBranchName;\nmodule.exports.checkoutRollBackBranch = checkoutRollBackBranch;\nmodule.exports.commitChangesInRollbackBranch = commitChangesInRollbackBranch;\nmodule.exports.retrieveVlocityDataPacks = retrieveVlocityDataPacks;\nmodule.exports.varReplace = varReplace;\nmodule.exports.yamlFindAndReplace = yamlFindAndReplace;\nmodule.exports.getFilePaths = getFilePaths;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.gitCommit = gitCommit;\nmodule.exports.executeCommandinChunks = executeCommandinChunks;\nmodule.exports.createCopadoRollbackChangesFile = createCopadoRollbackChangesFile;\nmodule.exports.copyFiles = copyFiles;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.displayVersions = displayVersions;\nmodule.exports.maskSensitiveInfo = maskSensitiveInfo;\n\n!isTest && this.execute();",
                    "copado__Timeout__c": 120,
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0l7Q00000D2yXGQAZ",
                    "LastReferencedDate": "2023-11-07T07:55:48.000+0000",
                    "LastViewedDate": "2023-11-07T07:55:48.000+0000",
                    "Name": "Deploy Vlocity"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v58.0/sobjects/copado__Function__c/a0l7Q000000OyrMQAS"
                    },
                    "copado__API_Name__c": "SFDX_Data_Deploy",
                    "copado__Callback_Type__c": "ApexClass",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__ApexClass__c": "cmcSf.DataDeployFunctionCallback",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"sourceOrgId\",\n  \"defaultValue\" : \"{$Source.Id}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceInstanceUrl\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationOrgId\",\n  \"defaultValue\" : \"{$Destination.Id}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationInstanceUrl\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationSessionId\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"required\" : true,\n  \"name\" : \"pollInterval\",\n  \"defaultValue\" : \"5000\"\n}, {\n  \"required\" : true,\n  \"name\" : \"isValidation\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.deploymentDryRun}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"dataTemplateFileId\",\n  \"defaultValue\" : \"\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewerForDataDeploy",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n/**\n * Performs deployment of data based on the data template details provided as input\n * Returns (If ACTION success) the data records are successfully inserted/upserted from the source to the destination org\n * (If ACTION failed) Returns details with error status on the result record\n * @param sourceOrgId\n * @param sourceInstanceUrl\n * @param sourceSessionId\n * @param destinationOrgId\n * @param destinationInstanceUrl\n * @param destinationSessionId\n * @param maxBuffer\n * @param dataTemplateFileId\n */\n\nconst child_process = require('child_process'),\n\tfs = require('fs'),\n\t{\n\t\tsourceOrgId,\n\t\tsourceInstanceUrl,\n\t\tsourceSessionId,\n\t\tdestinationOrgId,\n\t\tdestinationInstanceUrl,\n\t\tdestinationSessionId,\n\t\tmaxBuffer,\n\t\tCF_BACKEND_ENDPOINT,\n\t\tpollInterval,\n\t\tisTest,\n\t\tisValidation,\n\t\tdataTemplateFileId\n\t} = process.env,\n\tresponse = {\n\t\tSTATUS: {\n\t\t\tREQUEST_ACCEPTED: 'REQUEST_ACCEPTED',\n\t\t\tFAILED: 'FAILED',\n\t\t\tCOMPLETED: 'COMPLETED'\n\t\t},\n\t\tTYPE: {\n\t\t\tJSON: 'json',\n\t\t\tBUFFER: 'buffer'\n\t\t}\n\t},\n\trequest = {\n\t\tGET: 'GET',\n\t\tPOST: 'POST'\n\t},\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tRESULT_ZIP_FILE_PATH = `${TEMP_DIRECTORY}/deploymentResult.zip`,\n\tDATA_DEPLOYMENT_RESULT_DIR = `${TEMP_DIRECTORY}/result`,\n\tDATA_TEMPLATE_DIR = `${TEMP_DIRECTORY}`,\n\tMAXBUFFER = parseInt(maxBuffer),\n\tDATA_TEMPLATE_FILENAME = 'DataTemplatePayload',\n\tVALIDATION_MODE_MESSAGE = 'This step will not be executed for validate changes',\n\tRESULT_INFO = {\n\t\tLEVEL: {\n\t\t\tINFO: 'INFO',\n\t\t\tERROR: 'ERROR',\n\t\t\tWARN: 'WARN'\n\t\t},\n\t\tCATEGORY: {\n\t\t\tUNKNOWN_EXCEPTION: 'Unknown Exception',\n\t\t\tCOPADO_INFO: 'Copado Info',\n\t\t\tCOPADO_SERVICE: 'Copado Service',\n\t\t\tFILE_SYSTEM: 'File System'\n\t\t},\n\t\tADDITIONAL_INFORMATION: {\n\t\t\tPOPULATE_INFO_ON_RESULT: 'Populate Information on the result record',\n\t\t\tEXTRACT_DATA_DEPLOYMENT_RESULT: 'Extract Data Deployment Result',\n\t\t\tUPLOAD_FILES: 'Upload Files'\n\t\t}\n\t},\n\tSTDIO = {\n\t\tINHERIT: 'inherit'\n\t},\n\tTABLE_COLUMNS = {\n\t\tRESULT_VIEWER: [\n\t\t\t{\n\t\t\t\tlabel: 'Level',\n\t\t\t\tfieldName: 'Level',\n\t\t\t\ttype: 'text',\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'Level',\n\t\t\t\tinitialWidth: 80\n\t\t\t},\n\t\t\t{\n\t\t\t\tlabel: 'Category',\n\t\t\t\tfieldName: 'Category',\n\t\t\t\ttype: 'text',\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'Category',\n\t\t\t\tinitialWidth: 120\n\t\t\t},\n\t\t\t{\n\t\t\t\tlabel: 'Additional Information',\n\t\t\t\tfieldName: 'AdditionalInformation',\n\t\t\t\ttype: 'text',\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'Additional_Information',\n\t\t\t\tinitialWidth: 200\n\t\t\t},\n\t\t\t{\n\t\t\t\tlabel: 'Message',\n\t\t\t\tfieldName: 'Message',\n\t\t\t\ttype: 'text',\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'Message'\n\t\t\t}\n\t\t],\n\t\tDEPLOYMENT_SUMMARY_VIEWER: [\n\t\t\t{\n\t\t\t\tlabel: 'Template Name',\n\t\t\t\tfieldName: 'templateUrl',\n\t\t\t\ttype: 'url',\n\t\t\t\ttypeAttributes: {\n\t\t\t\t\tlabel: {\n\t\t\t\t\t\tfieldName: 'templateName'\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tcustomLabel: 'Template_Name',\n\t\t\t\thideDefaultActions: true\n\t\t\t},\n\t\t\t{\n\t\t\t\tlabel: 'SObject',\n\t\t\t\tfieldName: 'objectName',\n\t\t\t\ttype: 'text',\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'SObject',\n\t\t\t\thideDefaultActions: true\n\t\t\t},\n\t\t\t{\n\t\t\t\tlabel: 'Success',\n\t\t\t\tfieldName: 'deployedRecords',\n\t\t\t\ttype: 'number',\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'Success',\n\t\t\t\thideDefaultActions: true,\n\t\t\t\tinitialWidth: 100\n\t\t\t},\n\t\t\t{\n\t\t\t\tlabel: 'Failed',\n\t\t\t\tfieldName: 'failedRecords',\n\t\t\t\ttype: 'number',\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'Failed',\n\t\t\t\thideDefaultActions: true,\n\t\t\t\tinitialWidth: 100\n\t\t\t},\n\t\t\t{\n\t\t\t\tlabel: 'Generated Ids',\n\t\t\t\tfieldName: 'generatedIds',\n\t\t\t\ttype: 'number',\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'Generated_Ids',\n\t\t\t\thideDefaultActions: true,\n\t\t\t\tinitialWidth: 120\n\t\t\t},\n\t\t\t{\n\t\t\t\tlabel: 'CSV File',\n\t\t\t\tfieldName: 'csvFileLink',\n\t\t\t\ttype: 'button-icon',\n\t\t\t\ttypeAttributes: {\n\t\t\t\t\ticonName: {\n\t\t\t\t\t\tfieldName: 'csvFileIcon'\n\t\t\t\t\t},\n\t\t\t\t\tdisabled: {\n\t\t\t\t\t\tfieldName: 'isCsvFileIconDisabled'\n\t\t\t\t\t},\n\t\t\t\t\ttype: 'url',\n\t\t\t\t\tfieldName: 'csvFileLink',\n\t\t\t\t\tvariant: 'bare'\n\t\t\t\t},\n\t\t\t\twrapText: true,\n\t\t\t\tcustomLabel: 'CSV_File',\n\t\t\t\thideDefaultActions: true,\n\t\t\t\tinitialWidth: 80\n\t\t\t}\n\t\t]\n\t},\n\tHEADER = {\n\t\tRESULT_VIEWER: {\n\t\t\tlabel: 'Execution Details',\n\t\t\tcustomLabel: 'Execution_Details'\n\t\t},\n\t\tDEPLOYMENT_SUMMARY_VIEWER: {\n\t\t\tlabel: 'Data Deployment Result',\n\t\t\tcustomLabel: 'Data_Deployment_Result'\n\t\t}\n\t},\n\tFILE_NAMES = {\n\t\tRESULT_VIEWER: 'ResultViewer.json',\n\t\tDEPLOYMENT_SUMMARY_JSON: 'deployment_summary.json',\n\t\tDEPLOYMENT_SUMMARY_VIEWER: 'DeploymentSummaryViewer.json'\n\t},\n\tHEADER_ICON = {\n\t\tRESULT_VIEWER: 'standard:note',\n\t\tDEPLOYMENT_SUMMARY_VIEWER: 'standard:picklist_type'\n\t},\n\tresultViewerJson = [];\n\nlet executionError;\n\nasync function execute() {\n\ttry {\n\t\tthis.validateExecutionMode(isTest, isValidation, VALIDATION_MODE_MESSAGE);\n\t\tconst dataTemplateDetail = dataTemplateFileId ? this.getDataTemplateContent(dataTemplateFileId) : '';\n\t\tif (!dataTemplateDetail) {\n\t\t\tthrow new Error('Data template content is empty');\n\t\t}\n\n\t\tconst dataTemplatePayload = this.parseDatatemplate(dataTemplateDetail);\n\t\tconst apiPayload = this.populateCredentialsValues(dataTemplatePayload);\n\t\tconst deploymentId = await this.initiateDataDeployment(apiPayload);\n\t\tawait this.pollDataDeploymentStatus(deploymentId);\n\t\tawait this.downloadDataDeploymentResult(deploymentId);\n\t\tthis.uploadDataDeploymentInfoOnResult();\n\t} catch (err) {\n\t\tconsole.log('Error stack: ', err.stack);\n\t\tif (!(err instanceof CommandExecutionError)) {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, `See logs for more info`, err.message);\n\t\t}\n\t\texecutionError = err.message || err?.toString() || `Unknown Error occurred`;\n\t} finally {\n\t\tif (resultViewerJson?.length) {\n\t\t\tthis.uploadResultTableJson(\n\t\t\t\tresultViewerJson,\n\t\t\t\tTABLE_COLUMNS.RESULT_VIEWER,\n\t\t\t\tFILE_NAMES.RESULT_VIEWER,\n\t\t\t\tHEADER.RESULT_VIEWER,\n\t\t\t\tHEADER_ICON.RESULT_VIEWER\n\t\t\t);\n\t\t}\n\t\tif (executionError) {\n\t\t\tthis.executeCommand(\n\t\t\t\tthis.getErrorCmdString(executionError),\n\t\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.POPULATE_INFO_ON_RESULT\n\t\t\t);\n\t\t\tprocess.exit(1);\n\t\t}\n\t}\n}\n\nfunction validateExecutionMode(isTest, isValidation, validationModeMessage) {\n\tconst isValidationDeployment = isValidation === 'true';\n\tif (isTest) {\n\t\treturn isValidationDeployment;\n\t} else if (isValidationDeployment) {\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', validationModeMessage);\n\t\tthis.executeCommand(\n\t\t\t`copado -p '${validationModeMessage}' --result-data '${validationModeMessage}'`,\n\t\t\tRESULT_INFO.CATEGORY.COPADO_INFO,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.POPULATE_INFO_ON_RESULT\n\t\t);\n\t\tprocess.exit(0);\n\t}\n}\n\nfunction getDataTemplateContent(dataTemplateFileId) {\n\tthis.downloadFile(dataTemplateFileId, DATA_TEMPLATE_DIR);\n\tconst filePath = `${DATA_TEMPLATE_DIR}/${DATA_TEMPLATE_FILENAME}`;\n\tconst dataTemplateContent = fs.readFileSync(filePath, 'utf-8');\n\treturn dataTemplateContent;\n}\n\nfunction downloadFile(fileId, downloadDirectory) {\n\tconst command = `copado --downloadfiles ${fileId} --downloaddir ${downloadDirectory}`;\n\tthis.executeCommand(command);\n}\n\nfunction parseDatatemplate(dataTemplateDetail) {\n\ttry {\n\t\tconst payload = JSON.parse(dataTemplateDetail);\n\t\tthis.setPayloadDataLimit(payload);\n\t\t// Added logs to debug the payload in case of an error\n\t\tthis.logger(payload);\n\t\treturn payload;\n\t} catch (error) {\n\t\tthrow new Error('The input data template information is not a valid JSON');\n\t}\n}\n\nfunction setPayloadDataLimit(payload) {\n\tpayload.main_template['limit'] = payload.main_template['limitValue'];\n\tdelete payload.main_template['limitValue'];\n\tpayload.related_templates?.forEach(template => {\n\t\ttemplate['limit'] = template['limitValue'];\n\t\tdelete template['limitValue'];\n\t});\n}\n\nfunction populateCredentialsValues(dataTemplateDetail) {\n\tconst result = {\n\t\t...dataTemplateDetail,\n\t\torg_credentials: {\n\t\t\tsource: {\n\t\t\t\torganizationId: sourceOrgId,\n\t\t\t\tinstance: sourceInstanceUrl,\n\t\t\t\ttoken: sourceSessionId\n\t\t\t},\n\t\t\tdestination: {\n\t\t\t\torganizationId: destinationOrgId,\n\t\t\t\tinstance: destinationInstanceUrl,\n\t\t\t\ttoken: destinationSessionId\n\t\t\t}\n\t\t}\n\t};\n\treturn result;\n}\n\nasync function initiateDataDeployment(payload) {\n\tconst result = await this.sendRequest('/ddapi/data_deploy', request.POST, response.TYPE.JSON, payload);\n\t// Added logs to debug in case of unprecedented response from the api\n\tthis.asyncCopadoLogMessage('Initiate Data Deployment');\n\tthis.logger(result);\n\tif (!result?.deploymentId) {\n\t\tthrow new Error(`${result.status} - ${result.errorMessage ? result.errorMessage : result.error}`);\n\t}\n\treturn result.deploymentId;\n}\n\nfunction pollDataDeploymentStatus(deploymentId) {\n\treturn new Promise((resolve, reject) => {\n\t\tthis.asyncCopadoLogMessage('Polling data deployment status');\n\t\tconst pollDeploymentStatus = setInterval(async () => {\n\t\t\ttry {\n\t\t\t\tconst result = await this.sendRequest(`/ddapi/data_job/${deploymentId}/status`, request.GET, response.TYPE.JSON);\n\t\t\t\t// Adding debug to track progress in logs\n\t\t\t\tswitch (result.status) {\n\t\t\t\t\tcase response.STATUS.FAILED:\n\t\t\t\t\t\tclearInterval(pollDeploymentStatus);\n\t\t\t\t\t\treject(new Error(result.step));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase response.STATUS.COMPLETED:\n\t\t\t\t\t\tthis.asyncCopadoLogMessage(result.step);\n\t\t\t\t\t\tclearInterval(pollDeploymentStatus);\n\t\t\t\t\t\tresolve();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tthis.asyncCopadoLogMessage(result.step);\n\t\t\t\t}\n\t\t\t} catch (error) {\n\t\t\t\treject(error);\n\t\t\t}\n\t\t}, pollInterval);\n\t});\n}\n\nasync function downloadDataDeploymentResult(deploymentId) {\n\tthis.asyncCopadoLogMessage('Downloading Data Deployment Result');\n\tconst result = await this.sendRequest(`/ddapi/data_job/${deploymentId}/result`, request.GET, response.TYPE.BUFFER);\n\tfs.writeFileSync(RESULT_ZIP_FILE_PATH, result);\n\tthis.executeCommand(\n\t\t`unzip -d ${DATA_DEPLOYMENT_RESULT_DIR} ${RESULT_ZIP_FILE_PATH}`,\n\t\tRESULT_INFO.CATEGORY.FILE_SYSTEM,\n\t\tRESULT_INFO.ADDITIONAL_INFORMATION.EXTRACT_DATA_DEPLOYMENT_RESULT\n\t);\n}\n\nasync function sendRequest(path, method, responseType, payload) {\n\tlet result;\n\ttry {\n\t\tconst apiResponse = await fetch(CF_BACKEND_ENDPOINT + path, this.getOptions(method, payload));\n\t\tswitch (responseType) {\n\t\t\tcase response.TYPE.BUFFER:\n\t\t\t\tresult = Buffer.from(await apiResponse.arrayBuffer());\n\t\t\t\tbreak;\n\t\t\tcase response.TYPE.JSON:\n\t\t\t\tresult = await apiResponse.json();\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tresult = await apiResponse.text();\n\t\t}\n\t} catch (error) {\n\t\tthrow new Error(`ERROR: ${method} ${path} : ${error}`);\n\t}\n\treturn result;\n}\n\nfunction getOptions(method, payload) {\n\tconst options = {\n\t\tmethod: method,\n\t\theaders: {\n\t\t\t'Content-Type': 'application/json'\n\t\t}\n\t};\n\tif (method === request.POST) {\n\t\toptions.body = JSON.stringify(payload);\n\t}\n\treturn options;\n}\n\nfunction uploadDataDeploymentInfoOnResult() {\n\tthis.asyncCopadoLogMessage('Uploading data deployment detail files on the result record');\n\n\tfs.readdirSync(DATA_DEPLOYMENT_RESULT_DIR, { encoding: 'utf-8' })?.forEach(file => {\n\t\tthis.populateResultViewer(\n\t\t\tRESULT_INFO.LEVEL.INFO,\n\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES,\n\t\t\t`${DATA_DEPLOYMENT_RESULT_DIR}/${file}`\n\t\t);\n\t\tthis.executeCommand(`copado --uploadfile '${DATA_DEPLOYMENT_RESULT_DIR}/${file}'`);\n\t});\n\n\tconst deploymentSummary = this.getDeploymentSummary(`${DATA_DEPLOYMENT_RESULT_DIR}/${FILE_NAMES.DEPLOYMENT_SUMMARY_JSON}`);\n\n\tthis.uploadResultTableJson(\n\t\tdeploymentSummary,\n\t\tTABLE_COLUMNS.DEPLOYMENT_SUMMARY_VIEWER,\n\t\tFILE_NAMES.DEPLOYMENT_SUMMARY_VIEWER,\n\t\tHEADER.DEPLOYMENT_SUMMARY_VIEWER,\n\t\tHEADER_ICON.DEPLOYMENT_SUMMARY_VIEWER\n\t);\n\n\tconst resultData = this.getResultData(deploymentSummary);\n\n\tif (resultData) {\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_SERVICE, 'Updating Data deployment info', resultData);\n\t\tthis.executeCommand(\n\t\t\t`copado -p 'Updating Data deployment info' -r '${resultData}'`,\n\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.POPULATE_INFO_ON_RESULT\n\t\t);\n\t}\n}\n\nfunction getDeploymentSummary(filePath) {\n\tlet result = '';\n\tif (fs.existsSync(filePath)) {\n\t\tconst fileData = fs.readFileSync(filePath, 'utf-8');\n\t\tif (fileData) {\n\t\t\tresult = JSON.parse(fileData);\n\t\t}\n\t}\n\treturn result;\n}\nfunction getResultData(deploymentSummary) {\n\tlet result = '';\n\tif (deploymentSummary) {\n\t\tresult = deploymentSummary\n\t\t\t.map(templateDeploymentResult =>\n\t\t\t\tObject.keys(templateDeploymentResult)\n\t\t\t\t\t.map(key => `${key} : ${templateDeploymentResult[key]}`)\n\t\t\t\t\t.join('\\n')\n\t\t\t)\n\t\t\t.join('\\n------------------------\\n');\n\t\tresult =\n\t\t\t'To find more info related to the data deployment result, please look at the deployment_summary.json attached to this result record\\n' +\n\t\t\tresult;\n\t}\n\treturn result?.substring(0, 131070); // truncating the string to prevent the length from exceeding Long Text Area(131072) size limit\n}\n\nfunction getErrorCmdString(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `copado -p 'Error' -e \"${error?.substring(0, 32765)}. ${suffix}\"`;\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction executeCommand(command, category, additionalnfo, hasJsonResponse) {\n\tlet errorMessage;\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: MAXBUFFER\n\t};\n\tconst response = child_process.spawnSync(command, options);\n\tconst { outputStream, errorStream } = this.log(response);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalnfo, errorMessage);\n\t\tthrow new CommandExecutionError(errorMessage);\n\t}\n}\n\nfunction log(response) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (outputStream) {\n\t\tthis.logger(outputStream);\n\t}\n\tif (errorStream) {\n\t\tthis.logger(errorStream);\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction asyncCopadoLogMessage(msg, level) {\n\tthis.populateResultViewer(level ? level : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n\tnew Promise(resolve => {\n\t\tchild_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, () => {\n\t\t\tresolve();\n\t\t});\n\t});\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n\tresultViewerJson.push({\n\t\tLevel: level,\n\t\tCategory: category,\n\t\tMessage: message,\n\t\tAdditionalInformation: additionalInfo\n\t});\n}\n\nfunction uploadResultTableJson(data, columns, fileName, header, headerIcon) {\n\tconst RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/${fileName}`;\n\n\tconst fileContent = {\n\t\tdata,\n\t\tcolumns,\n\t\theader,\n\t\theaderIcon\n\t};\n\tfs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n\tthis.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n\tnew Promise((resolve, reject) => {\n\t\tchild_process.exec(`copado --uploadfile ${filePath}`, {}, (error, stdout, stderr) => {\n\t\t\tif (error?.code) {\n\t\t\t\tconst errorResponse = stderr ? stderr : `Error executing the command : ${error?.cmd}`;\n\t\t\t\tthis.populateResultViewer(\n\t\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\t\t\t`Uploading file at ${filePath}`,\n\t\t\t\t\terrorResponse\n\t\t\t\t);\n\t\t\t\treject(new CommandExecutionError(errorResponse));\n\t\t\t} else {\n\t\t\t\tresolve();\n\t\t\t}\n\t\t});\n\t});\n}\n\nfunction logger(value) {\n\tconsole.log(value);\n}\n\nclass CommandExecutionError extends Error {\n\tconstructor(message) {\n\t\tsuper(message);\n\t\tthis.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n\t}\n}\n\nmodule.exports.initiateDataDeployment = initiateDataDeployment;\nmodule.exports.pollDataDeploymentStatus = pollDataDeploymentStatus;\nmodule.exports.populateCredentialsValues = populateCredentialsValues;\nmodule.exports.downloadDataDeploymentResult = downloadDataDeploymentResult;\nmodule.exports.sendRequest = sendRequest;\nmodule.exports.getOptions = getOptions;\nmodule.exports.uploadDataDeploymentInfoOnResult = uploadDataDeploymentInfoOnResult;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.getPath = getPath;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.log = log;\nmodule.exports.execute = execute;\nmodule.exports.getResultData = getResultData;\nmodule.exports.parseDatatemplate = parseDatatemplate;\nmodule.exports.validateExecutionMode = validateExecutionMode;\nmodule.exports.setPayloadDataLimit = setPayloadDataLimit;\nmodule.exports.logger = logger;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadResultTableJson = uploadResultTableJson;\nmodule.exports.getDeploymentSummary = getDeploymentSummary;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.getDataTemplateContent = getDataTemplateContent;\nmodule.exports.downloadFile = downloadFile;\nmodule.exports.CommandExecutionError = CommandExecutionError;\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q000000OyrMQAS",
                    "LastReferencedDate": "2023-06-06T04:39:46.000+0000",
                    "LastViewedDate": "2023-06-06T04:39:46.000+0000",
                    "Name": "SFDX Data Deploy"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v58.0/sobjects/copado__Function__c/a0l7Q00000DF2LhQAL"
                    },
                    "copado__API_Name__c": "sfdx_git_snapshot",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEndpoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"branch\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.copado__Branch__c}\"\n}, {\n  \"name\" : \"selectedMetadata\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.copado__Scope__c}\"\n}, {\n  \"name\" : \"snapshotInformation\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.copado__Other_Information__c}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"metadataRefreshResult\",\n  \"defaultValue\" : \"{$Job.PrevStep.Result__r.Result_Data__c}\"\n}, {\n  \"name\" : \"overriddenApiVersion\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"maximumRetryCount\",\n  \"defaultValue\" : \"1\"\n}, {\n  \"required\" : true,\n  \"name\" : \"commitMessage\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.message}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"processesUsedForRetrieval\",\n  \"defaultValue\" : \"8\"\n}, {\n  \"name\" : \"environmentVariables\",\n  \"defaultValue\" : \"{$Source.apex.EnvironmentVariables}\"\n}, {\n  \"name\" : \"findAndReplaceFileId\",\n  \"defaultValue\" : \"{$Context.apex.GlobalFindAndReplaceSourceId}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"required\" : true,\n  \"name\" : \"metadataChunkInfo\",\n  \"defaultValue\" : \"{\\\"staticresource\\\": 10, \\\"contentasset\\\": 10}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"defaultMetadataChunkInfo\",\n  \"defaultValue\" : \"5000\"\n}, {\n  \"name\" : \"vlocityFolder\",\n  \"defaultValue\" : \"vlocity\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n/**\n * This function takes a snapshot of the salesforce org and pushes its content in git\n * @param gitName,\n * @param gitEmail,\n * @param sourceEndpoint,\n * @param sourceSessionId,\n * @param branch,\n * @param selectedMetadata,\n * @param snapshotInformation,\n * @param metadataRefreshResult,\n * @param maximumRetryCount,\n * @param processesUsedForRetrieval,\n * @param commitMessage,\n * @param environmentVariables,\n * @param overriddenApiVersion,\n * @param findAndReplaceFileId,\n * @param maxBuffer,\n * @param API_VERSION\n */\n\nconst child_process = require('child_process'),\n{\n    isTest,\n    gitName,\n    gitEmail,\n    sourceEndpoint,\n    sourceSessionId,\n    branch,\n    selectedMetadata,\n    snapshotInformation,\n    metadataRefreshResult,\n    maximumRetryCount,\n    processesUsedForRetrieval,\n    commitMessage,\n    environmentVariables,\n    overriddenApiVersion,\n    findAndReplaceFileId,\n    maxBuffer,\n    API_VERSION,\n    metadataChunkInfo,\n    defaultMetadataChunkInfo,\n    vlocityFolder\n} = process.env,\n    { spawnSync, spawn, exec } = require('child_process'),\n    { cpus } = require('os'),\n    { Retriever, CopaReconcilerInput, Operation } = isTest ? require('../common/__mocks__/modules/copado-metadata-reconciler') : require('/usr/local/lib/node_modules/@mcdx/copado-metadata-reconciler'),\n    STDIO = {\n        INHERIT: 'inherit',\n        PIPE: 'pipe',\n        IGNORE: 'ignore'\n    },\n    COPADO_INFO_PREFIX = 'CopadoFunction INFO',\n    CUSTOM_ERROR = {\n        COMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n    },\n    APP_DIRECTORY = getPath('/app'),\n    TEMP_DIRECTORY = getPath('/tmp'),\n    TARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n    { existsSync, writeFileSync, readFileSync } = require('fs'),\n    CREDENTIAL_FILE_NAME = 'MetaData',\n    PROFILE = 'Profile',\n    retryLimit = parseInt(maximumRetryCount) ? parseInt(maximumRetryCount) : 1,\n    maxAllowedProcesses = parseInt(processesUsedForRetrieval) ? parseInt(processesUsedForRetrieval) : 8,\n    additionalInfoForSnapshot = snapshotInformation ? getParsedData(snapshotInformation) : {},\n    MAXBUFFER = parseInt(maxBuffer),\n    nestedMetadataToBeBypassed = [\n        'workflowfieldupdate',\n        'workflowknowledgepublish',\n        'workflowtask',\n        'workflowalert',\n        'workflowsend',\n        'workflowoutboundmessage',\n        'workflowrule',\n        'sharingownerrule',\n        'sharingcriteriarule',\n        'sharingguestrule',\n        'sharingterritoryrule',\n        'customlabel',\n        'assignmentrule',\n        'autoresponserule',\n        'matchingrule',\n        'customfield',\n        'index',\n        'businessprocess',\n        'recordtype',\n        'compactlayout',\n        'weblink',\n        'validationrule',\n        'sharingreason',\n        'listview',\n        'fieldset'\n    ],\n    ignoredMetadata = ['document'],\n    metadataChunkSize = getParsedData(metadataChunkInfo),\n    defaultMetadataChunkSize = parseInt(defaultMetadataChunkInfo) ? parseInt(defaultMetadataChunkInfo) : 5000;\n\nlet apiVersion;\n\n// SCRIPT FUNCTIONS\n\nasync function execute() {\n    try {\n        apiVersion = this.getApiVersion(overriddenApiVersion, API_VERSION),\n        this.asyncCopadoLogMessage('Downloading metadata details of the source environment');\n        const selectedMetadatas = this.getSelectedMetadatas(selectedMetadata);\n        let metadatas, profiles;\n        if (selectedMetadatas.length) {\n            const metadataNamesByType = this.getMetadataNamesByType(metadataRefreshResult, TEMP_DIRECTORY, CREDENTIAL_FILE_NAME);\n            const metadatasSupportedByCli = this.getMetadataSupportedByCli();\n            profiles = this.getProfilesForRetrieval(\n                metadataNamesByType,\n                selectedMetadatas,\n                metadatasSupportedByCli,\n                PROFILE,\n                apiVersion,\n                ignoredMetadata,\n                metadataChunkSize,\n                defaultMetadataChunkSize,\n                nestedMetadataToBeBypassed\n            );\n            metadatas = this.getMetadataItemsForRetrieval(\n                metadataNamesByType,\n                selectedMetadatas,\n                metadatasSupportedByCli,\n                apiVersion,\n                TEMP_DIRECTORY,\n                ignoredMetadata,\n                metadataChunkSize,\n                defaultMetadataChunkSize,\n                nestedMetadataToBeBypassed\n            );\n            if (!profiles.length && !metadatas.length) {\n                this.exitProcess('No metadata available for snapshot');\n            }\n        }\n\n        this.asyncCopadoLogMessage('Setting up working directory');\n        this.setUpWorkingDirectory(TARGET_DIRECTORY);\n        this.switchToWorkingDirectory(TARGET_DIRECTORY);\n        this.asyncCopadoLogMessage('Fetching remote branch');\n        this.fetchRemoteGitBranch(branch);\n        this.copyVlocityFiles(`${APP_DIRECTORY}/${vlocityFolder}`, TARGET_DIRECTORY);\n        const previousCommitId = this.getCommitId();\n        this.configureGit(gitEmail, gitName);\n\n        let errorsMsg;\n        if (selectedMetadatas.length) {\n            await this.updateSourceApiVersion(`${TARGET_DIRECTORY}/sfdx-project.json`, apiVersion);\n            this.configureSFDXCli(apiVersion, sourceEndpoint);\n            const processUsedForRetrieval = this.getMaxAllowedProcesses(maxAllowedProcesses);\n            const { errors } = await this.runMetadataRetrieval(processUsedForRetrieval, metadatas, profiles, TEMP_DIRECTORY);\n            errorsMsg = errors;\n        }\n        this.runVarReplace(additionalInfoForSnapshot, environmentVariables, TARGET_DIRECTORY);\n        this.runFindAndReplace(additionalInfoForSnapshot, findAndReplaceFileId, branch, TEMP_DIRECTORY, TARGET_DIRECTORY, 'Copado');\n        await this.pushChangesToRemoteBranch(branch, commitMessage);\n        const newCommitId = this.getCommitId();\n        if (newCommitId !== previousCommitId) {\n            this.updateResultStatus(errorsMsg, newCommitId);\n        } else {\n            this.updateResultStatus(errorsMsg, undefined, 'No changes');\n        }\n    } catch (error) {\n        this.executeCommand(this.getErrorCommand(error.toString()), STDIO.INHERIT);\n    }\n}\n\nfunction asyncCopadoLogMessage(msg) {\n    new Promise(resolve => {\n        exec(`copado -p '${msg}'`, { shell: true, stdio: STDIO.INHERIT }, (error, stdout, stderr) => {\n            resolve();\n        });\n    });\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname}/__tests__/__mockDirectory__${filePath}` : filePath;\n}\n\nfunction getApiVersion(overriddenApiVersion, apiVersion) {\n    const finalApiVersion = overriddenApiVersion || apiVersion;\n    const regExpApiVersion = /\\d\\d\\.0/;\n    if (!regExpApiVersion.test(finalApiVersion)) {\n        this.executeCommand(this.getErrorCommand(`Invalid API Version: ${finalApiVersion}`));\n    }\n    return finalApiVersion;\n}\n\nfunction getSelectedMetadatas(selectedMetadata) {\n    let result;\n    try {\n        const selection = JSON.parse(selectedMetadata);\n        result = selection?.SFDX?.included?.map(element => element.toLowerCase());\n        if(!result) {\n            const message = JSON.stringify(\"Snapshot doesn't contain any Salesforce Metadata\");\n            this.executeCommand(`copado -p ${message}`, STDIO.IGNORE);\n        }\n    } catch (error) {\n        result = selectedMetadata.split(';').map(element => element.toLowerCase());\n    }\n    return result?.length ? result : [];\n}\n\nfunction getParsedData(data) {\n    let result = {};\n    try {\n        result = JSON.parse(data);\n    } catch (error) {\n        logger(`Error occurred while parsing data : ${error}`);\n    }\n    return result;\n}\n\nfunction copyVlocityFiles(source, target) {\n    if (existsSync(`${APP_DIRECTORY}/${vlocityFolder}`)) {\n        this.executeCommand(`\n                cp -R ${source} ${target} || ${this.getErrorCommand(\n            `Error copying ${source}`\n        )}\n        `);\n    }\n}\n\nfunction getMetadataNamesByType(metadataRefreshResult, downloadDirectory, fileName) {\n    const result = new Map();\n    let fileDetails;\n    try {\n        fileDetails = JSON.parse(metadataRefreshResult);\n    } catch (error) {\n        throw 'Failure while parsing the metadata refresh resul';\n    }\n    if (!fileDetails.contentVersionId) {\n        throw 'Content version id missing from the metadata refresh job step';\n    }\n    this.executeCommand(`\n        copado --downloadfiles '${fileDetails.contentVersionId}' --downloaddir '${downloadDirectory}' || ${this.getErrorCommand(\n        `Error downloading file ${fileName}`\n    )}\n    `);\n    const metadatas = this.getMetaDataFileContent(downloadDirectory, fileName);\n    metadatas.forEach(metadata => {\n        // In the below condition we want to make sure that we do not retrieve\n        // the vlocity and managed packaged static resources in the snapshot process\n        if (!metadata.vk && !(metadata.t?.toLowerCase() === 'staticresource' && metadata.n?.includes('__'))) {\n            if (result.has(metadata.t)) {\n                result.get(metadata.t)?.push(metadata.n);\n            } else {\n                result.set(metadata.t, [metadata.n]);\n            }\n        }\n    });\n    return result;\n}\n\nfunction getMetaDataFileContent(downloadDirectory, fileName) {\n    const file = `${downloadDirectory}/${fileName}`;\n    if (!existsSync(file)) {\n        throw `Error fetching ${fileName} file`;\n    }\n    return JSON.parse(readFileSync(`${file}`, 'utf-8'));\n}\n\nfunction isValidMetadata(ignoredMetadata, metadata, selectedMetadatas, metadatasSupportedByCli, nestedMetadataToBeBypassed) {\n    const metadataName = metadata?.toLowerCase();\n    return (\n        !ignoredMetadata.includes(metadataName) &&\n        (selectedMetadatas.length\n            ? selectedMetadatas.includes(metadataName)\n            : (metadatasSupportedByCli.includes(metadataName) && !nestedMetadataToBeBypassed.includes(metadataName)))\n    );\n}\n\nfunction getProfilesForRetrieval(\n    metadataNamesByType,\n    selectedMetadatas,\n    metadatasSupportedByCli,\n    profileMetadata,\n    apiVersion,\n    ignoredMetadata,\n    metadataChunkSize,\n    defaultMetadataChunkSize,\n    nestedMetadataToBeBypassed\n) {\n    let result = [];\n    if (\n        metadataNamesByType.has(profileMetadata) &&\n        this.isValidMetadata(ignoredMetadata, profileMetadata, selectedMetadatas, metadatasSupportedByCli, nestedMetadataToBeBypassed)\n    ) {\n        const profileNames = metadataNamesByType.get(profileMetadata);\n        metadataNamesByType.delete(profileMetadata);\n        result = [...result, ...this.getMetadataItemForRetrieval(profileNames, profileMetadata, profileNames.length, apiVersion)];\n    }\n    return result;\n}\n\nfunction getMetadataItemForRetrieval(metadataNames, metadataType, maxAllowedItemsPerType, apiVersion, directory) {\n    const result = [];\n    const metadatas = [];\n    while (metadataNames.length > maxAllowedItemsPerType) {\n        metadatas.push(metadataNames.splice(0, maxAllowedItemsPerType));\n    }\n    metadatas.push(metadataNames);\n    metadatas.forEach(metadata => {\n        result.push({\n            metadataType,\n            metadataNames: metadata,\n            retryCount: 0,\n            path: metadataType.toLowerCase() === 'profile' ? '' : getPackageXMLfilePath(metadata, metadataType, apiVersion, directory)\n        });\n    });\n    return result;\n}\n\nfunction getMetadataItemsForRetrieval(\n    metadataNamesByType,\n    selectedMetadatas,\n    metadatasSupportedByCli,\n    apiVersion,\n    directory,\n    ignoredMetadata,\n    metadataChunkSize,\n    defaultMetadataChunkSize,\n    nestedMetadataToBeBypassed\n) {\n    let result = [];\n    for (const [metadataType, metadataNames] of metadataNamesByType.entries()) {\n        if (this.isValidMetadata(ignoredMetadata, metadataType, selectedMetadatas, metadatasSupportedByCli, nestedMetadataToBeBypassed)) {\n            result = [\n                ...result,\n                ...this.getMetadataItemForRetrieval(\n                    metadataNames,\n                    metadataType,\n                    this.getMetadataChunkSize(metadataType, metadataChunkSize, defaultMetadataChunkSize),\n                    apiVersion,\n                    directory\n                )\n            ];\n        }\n    }\n    return result;\n}\n\nfunction getMetadataChunkSize(metadata, metadataChunkSize, defaultMetadataChunkSize) {\n    const metadataName = metadata?.toLowerCase();\n    return metadataChunkSize[metadataName] ? metadataChunkSize[metadataName] : defaultMetadataChunkSize;\n}\n\nfunction setUpWorkingDirectory(workingDirectory) {\n    this.executeCommand(`\n    \tmkdir -p '${workingDirectory}'\n    `);\n}\n\nfunction switchToWorkingDirectory(workingDirectory) {\n    process.chdir(workingDirectory);\n}\n\nfunction fetchRemoteGitBranch(branch) {\n    this.executeCommand(`\n        copado-git-get --depth '1' '${branch}' || ${this.getErrorCommand(`Error fetching git branch ${branch}`)}\n    `);\n}\n\nfunction configureGit(gitEmail, gitName) {\n    const command = `\n        git config --local user.email \"${gitEmail}\" || ${this.getErrorCommand('Failure in configuring git user email')}\n        git config --local user.name \"${gitName}\" || ${this.getErrorCommand('Failure in configuring git user name')}\n        git config --global diff.renames false || ${this.getErrorCommand('Failure in disabling git rename detection from diff.renames')}\n        git config --global status.renames false || ${this.getErrorCommand('Failure in disabling git rename detection from status.renames')}\n        `;\n    this.executeCommand(`${command}`, STDIO.INHERIT);\n}\n\nfunction configureSFDXCli(sourceApiVersion, sourceEndPoint) {\n    const baseUrl = this.getInstanceUrl(sourceEndPoint);\n    const command = `\n    sf config set org-instance-url=${baseUrl} || ${this.getErrorCommand('Error setting org-instance-url : ' + baseUrl)}\n    sf config set org-api-version=${sourceApiVersion} || ${this.getErrorCommand('Error setting org-api-version : ' + sourceApiVersion)}`;\n    this.executeCommand(command, STDIO.INHERIT);\n}\n\nasync function runMetadataRetrieval(maxAllowedProcesses, metadatas, profiles, directory) {\n    let result, errorMessage, pool;\n    try {\n        pool = new this.SpawnPool(maxAllowedProcesses, metadatas, profiles);\n        await Promise.all(pool.execute());\n    } catch (error) {\n        errorMessage = error?.toString();\n    } finally {\n\n        result = { errors: pool.getErrors(), sfCommandLogs: pool.getSfCommandLogs() };\n        this.uploadExecutionDetails(result.errors, result.sfCommandLogs, directory);\n        if (errorMessage) {\n            this.executeCommand(this.getErrorCommand(errorMessage), STDIO.INHERIT);\n        }\n    }\n    return result;\n}\n\nfunction getPackageXMLfilePath(metadataNames, metadataType, apiVersion, directory) {\n    const manifest = [];\n    manifest.push('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\" ?>\\n');\n    manifest.push('<Package xmlns=\"http://soap.sforce.com/2006/04/metadata\">\\n');\n    manifest.push('\\t<types>\\n');\n    metadataNames.forEach(metadataName => {\n        manifest.push(`\\t\\t<members>${metadataName}</members>\\n`);\n    });\n    manifest.push(`\\t\\t<name>${metadataType}</name>\\n`);\n    manifest.push('\\t</types>\\n');\n    manifest.push(`\\t<version>${apiVersion}</version>\\n`);\n    manifest.push('</Package>\\n');\n    const path = directory + '/' + Math.random() + '.xml';\n    writeFileSync(path, manifest.join(' '));\n    return path;\n}\n\nasync function pushChangesToRemoteBranch(branchName, commitMessage) {\n    this.asyncCopadoLogMessage(`Committing ${commitMessage} in ${branchName}`);\n    logger('Commit process started');\n    await this.commitGit(commitMessage);\n    const command = `git push origin \"${branchName}\" --force || ${this.getErrorCommand('Could not push the changes')}`;\n    this.executeCommand(command, STDIO.IGNORE);\n    logger('Commit process ended');\n}\n\nfunction getCommitId() {\n    return this.executeCommand(`git rev-parse HEAD || ${this.getErrorCommand('There was some issue finding the commitid')}`);\n}\n\nfunction runVarReplace(additionalInfoForSnapshot, environmentVariables, targetDirectory) {\n    if (additionalInfoForSnapshot.applyEnvVars && environmentVariables && JSON.parse(environmentVariables)?.length) {\n        this.asyncCopadoLogMessage('Running Var replace');\n        const command = `\n            varreplace '${environmentVariables}' '${targetDirectory}' --valuename=true || ${this.getErrorCommand(\n            'Error replacing environment variables'\n        )}\n\t\t`;\n        this.executeCommand(command, STDIO.INHERIT);\n    }\n}\n\nfunction runFindAndReplace(additionalInfoForSnapshot, findAndReplaceFileId, branch, tempDirectory, targetDirectory, copadoYml) {\n    if (additionalInfoForSnapshot.ymlReplacement && findAndReplaceFileId) {\n        this.asyncCopadoLogMessage('Running YML replace');\n        const PATH_TO_YAML = `${tempDirectory}/${copadoYml}`;\n        const command = `\n        \tcopado --downloadfiles '${findAndReplaceFileId}' --downloaddir \"${tempDirectory}/\" || ${this.getErrorCommand(\n            `Error downloading file ${copadoYml}`\n        )}`;\n        this.executeCommand(command);\n        if (!existsSync(PATH_TO_YAML)) {\n            throw 'Could not find the Copado.yml file';\n        }\n        const findAndReplace = `yamlreplace \"${PATH_TO_YAML}\" \"${targetDirectory}\" -b \"${branch}\" || ${this.getErrorCommand(\n            'Error applying find and replace rules'\n        )}`;\n        this.executeCommand(findAndReplace, STDIO.INHERIT);\n    }\n}\n\nfunction uploadExecutionDetails(errors, sfCommandLogs, tempDirectory) {\n    let command = '';\n\n    if (Object.keys(errors).length) {\n        const errorFilePath = `${tempDirectory}/RetrievalError.json`;\n\n        writeFileSync(errorFilePath, JSON.stringify(errors));\n        command += `copado --uploadfile \"${errorFilePath}\" --name \"Retrieval Error.json\" || true`;\n    }\n\n    if (Object.keys(sfCommandLogs).length) {\n        const sfCommandLogFilePath = `${tempDirectory}/SalesforceRetrieveResult.json`;\n        writeFileSync(sfCommandLogFilePath, JSON.stringify(sfCommandLogs));\n        command += `\n            copado --uploadfile \"${sfCommandLogFilePath}\" --name \"Salesforce Retrieve Result.json\" || true\n        `;\n    }\n\n    if (command) {\n        this.executeCommand(command, STDIO.INHERIT);\n\n    }\n}\n\nfunction exitProcess(message, commitId, status) {\n    const resultData = { message, commitId, status };\n\n    const command = `copado -p \"${message}\" --result-data '${JSON.stringify(resultData)}'`;\n    this.executeCommand(command);\n    process.exit(0);\n}\n\nfunction updateResultStatus(errors, commitId, status) {\n    let message = '';\n    const hasRetrievalError = errors && Object.keys(errors).length;\n\n    if (hasRetrievalError) {\n        if (commitId) {\n            message =\n                'Snapshot execution successful, but some metadata types could not be retrieved. Please view the Retrieval Error.json for details.';\n        } else {\n            message =\n                'There are no changes to be committed. Some metadata types could not be retrieved. Please view the Retrieval Error.json for details';\n        }\n    } else if (commitId) {\n        message = 'Git snapshot completed successfully';\n    } else {\n        message = 'There are no changes to be committed';\n    }\n\n    this.exitProcess(message, commitId, status);\n}\n\nfunction executeCommand(cmd, ioconfig) {\n    const options = {\n        shell: true,\n        maxBuffer: MAXBUFFER\n    };\n    if (ioconfig) {\n        options.stdio = ioconfig;\n    }\n    const response = spawnSync(cmd, options);\n    const { output, error } = this.log(response);\n    if (response?.status != 0) {\n        if (response?.status == 2) {\n            if (isTest) {\n                throw output;\n            }\n            process.exit(2);\n        }\n        throw error ? error : `Error executing the command: ${cmd}`;\n    }\n    return output;\n}\n\n\nfunction executeCommandAsync(command, hasJsonResponse, disableLog) {\n\n    return new Promise((resolve, reject) => {\n        let output = '',\n            error = '';\n        const childProcess = child_process.spawn(command, [], { shell: true });\n\n        childProcess.stdout.on('data', data => {\n            output += data?.toString();\n        });\n\n\n        childProcess.stderr.on('data', data => {\n            error += data?.toString();\n        });\n\n        childProcess.on('close', code => {\n            if (code !== 0) {\n                let errorMessage = '';\n                if (hasJsonResponse) {\n                    try {\n                        resolve(JSON.parse(output));\n                    } catch (error) {\n                        errorMessage = error;\n                    }\n                } else {\n                    errorMessage = error;\n                }\n                errorMessage = errorMessage ? errorMessage : `Error executing the command ${command}`;\n\n                const truncatedError = JSON.stringify(\n                    errorMessage\n                        .split('\\n')\n                        .filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n                        .join(' ')\n                );\n                reject(new CommandExecutionError(truncatedError));\n            }\n            if (!disableLog) {\n                this.logger(`code: ${code?.toString()}`);\n                this.logger(`stdout: ${output}`);\n                this.logger(`stderr: ${error}`);\n            }\n            resolve(hasJsonResponse ? JSON.parse(output) : output);\n        });\n\n        childProcess.on('error', error => {\n            const truncatedError = JSON.stringify(\n                error\n                    .split('\\n')\n                    .filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n                    .join(' ')\n            );\n            reject(new CommandExecutionError(truncatedError));\n        });\n    });\n}\n\nfunction log(response) {\n    const output = response?.stdout?.toString().trim();\n    const error = response?.stderr?.toString().trim();\n    if (output) {\n        this.logger(output);\n    }\n    if (error) {\n        this.logger(error);\n    }\n    return { output, error };\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nfunction getErrorCommand(error) {\n    const suffix = 'Please check the logs for details.';\n    return `{ copado -p 'Error' -e '${error}. ${suffix}'; exit 2; }`;\n}\n\nfunction getMaxAllowedProcesses(neededCpus) {\n    const totalCpus = cpus().length;\n    if (totalCpus === 1) {\n        return 1;\n    }\n    const maxAvailableCpus = totalCpus - 1;\n    if (neededCpus < maxAvailableCpus) {\n        return neededCpus;\n    }\n    logger(`Due to system limitation we will be using ${maxAvailableCpus} child process for metadata retrieval`);\n    return maxAvailableCpus;\n}\n\nclass SpawnPool {\n    maxAllowedProcesses;\n    totalRunningProcesses;\n    metadatas;\n    profiles;\n    errors;\n    sfCommandLogs;\n\n    constructor(maxAllowedProcesses, metadatas, profiles) {\n        this.maxAllowedProcesses = maxAllowedProcesses;\n        this.totalRunningProcesses = 0;\n        this.metadatas = metadatas;\n        this.profiles = profiles;\n        this.errors = {};\n        this.sfCommandLogs = {};\n    }\n\n    execute() {\n        const promises = [];\n        while (this.totalRunningProcesses < this.maxAllowedProcesses && (this.metadatas.length || this.profiles.length)) {\n            this.totalRunningProcesses++;\n            if (this.totalRunningProcesses === 1 && this.profiles.length) {\n                promises.push(new Promise((resolve, reject) => {\n                    this.retrieveFullProfile(this.profiles.shift(), resolve, reject);\n                }));\n            } else {\n                promises.push(\n                    new Promise((resolve, reject) => {\n                        this.handleNextExecution(resolve, reject);\n                    }));\n            }\n        }\n        logger(`Total promises : ${promises.length}`);\n        return promises;\n    }\n\n    executeProcess(metadata, resolve, reject) {\n        let command = `\ncopado -p 'Retrieving Metadata : ${metadata.metadataNames.length} ${metadata.metadataType}(s)'\n            sf project retrieve start --target-org \"${sourceSessionId}\" --manifest \"${metadata.path}\" --wait 60 --json\n        `;\n\n        logger(`Metadata retrieval starting for ${metadata.metadataType} - ${metadata.path}`);\n        const childProcess = spawn(command, [], { shell: true });\n        let stdoutData = '';\n        let stderrData = '';\n        let errorData;\n\n        childProcess.stdout.on('data', data => {\n            stdoutData += data?.toString();\n            childProcess.stdout.resume();\n        });\n\n        childProcess.stderr.on('data', data => {\n            stderrData += data.toString();\n            childProcess.stderr.resume();\n        });\n\n        childProcess.on('error', error => {\n            errorData = error;\n            childProcess.error.resume();\n        });\n\n        childProcess.on('close', code => {\n            const response = { code, stdoutData, stderrData, errorData };\n            this.handleExecutionResultForMetadata(response, metadata, resolve, reject);\n            logger(\n                `Metadata retrieval completed for ${metadata.metadataType} - ${metadata.path}`\n            );\n            logger(`Remaining Retrieval for metadata : ${this.metadatas.length}`);\n        });\n    }\n\n    handleExecutionResultForMetadata(response, metadata, resolve, reject) {\n        const data = getParsedData(response.stdoutData);\n        const error = this.getErrorsFromExecutionResult(data);\n        this.sfCommandLogs[`${metadata.metadataType} : ${metadata.metadataNames.toString()}`] = data;\n        this.validateUnhandledException(data, reject);\n        if (data?.result?.errorStatusCode === 'LIMIT_EXCEEDED' && metadata.metadataNames?.length > 1) {\n            logger(`LIMIT_EXCEEDED for ${metadata.metadataType}, dividing the metadata in chunks`);\n            this.metadatas = [\n                ...this.metadatas,\n                ...getMetadataItemForRetrieval(\n                    metadata.metadataNames,\n                    metadata.metadataType,\n                    parseInt(metadata.metadataNames.length / 2),\n                    apiVersion,\n                    TEMP_DIRECTORY\n                )\n            ];\n        } else if (data?.result?.success === false || response.code === 1 || response.errorData || error) {\n            if (metadata.retryCount < retryLimit) {\n                logger(`Error occured for ${metadata.metadataType}, retrying retrieval`);\n                this.addToMetadata(metadata);\n            } else {\n                logger(\n                    `Error occured for ${metadata.metadataType}, handling error - ${data?.result?.errorMessage || data?.message || response.errorData || error\n                    }`\n                );\n                this.handleErrors(metadata, `${data?.result?.errorMessage || data?.message || response.errorData || error}`);\n            }\n        }\n        if (this.metadatas.length) {\n            this.executeProcess(this.metadatas.shift(), resolve, reject);\n        } else {\n            this.handleNextExecution(resolve, reject);\n        }\n    }\n\n    validateUnhandledException(response, reject) {\n        if (response.status === 1 && response.name === 'UnexpectedForceIgnore') {\n            reject(response.message);\n        }\n    }\n\n    getErrorsFromExecutionResult(response) {\n        const errors = [];\n        response?.result?.files?.forEach(file => {\n            if (file.state === 'Failed' && file.error) {\n                errors.push(file.error);\n            }\n        });\n        return errors.length ? errors.toString() : null;\n    }\n\n    addToMetadata(metadata) {\n        metadata.retryCount += 1;\n        this.metadatas.push(metadata);\n    }\n\n    addToProfile(profile) {\n        profile.retryCount += 1;\n        this.profiles.push(profile);\n    }\n\n    handleErrors(metadata, error) {\n        this.errors[`Error occured while retrieving ${metadata.metadataType} (${metadata.metadataNames.toString()})`] = error;\n    }\n\n    handleNextExecution(resolve, reject) {\n        let currentProcessableMetadata;\n        if (this.metadatas.length) {\n            currentProcessableMetadata = this.metadatas.shift();\n        }\n        if (currentProcessableMetadata) {\n            this.executeProcess(currentProcessableMetadata, resolve, reject);\n        } else {\n            logger('Thread successfully completed');\n            resolve('Thread successfully completed');\n        }\n    }\n\n    getErrors() {\n        return this.errors;\n    }\n\n    getSfCommandLogs() {\n        return this.sfCommandLogs;\n    }\n\n\n    retrieveFullProfile(profiles, resolve, reject) {\n        const request = this.getMetadataReconcilerRequest(profiles?.metadataNames);\n        new Retriever().run(request)?.then(() => {\n\n            const OUTPUT_JSON_FILE_PATH = `${TEMP_DIRECTORY}/output.json`;\n            const profileResult = JSON.parse(readFileSync(OUTPUT_JSON_FILE_PATH, 'utf-8'));\n\n            const data = getParsedData(profileResult);\n            this.sfCommandLogs[`${profiles.metadataType} : ${profiles.metadataNames.toString()}`] = data;\n        }).catch((error) => {\n            const errorMessage = error.message || error?.toString() || 'Unknown Error occurred';\n            if (errorMessage) {\n                if (profiles.retryCount < retryLimit) {\n                    this.addToProfile(profiles);\n                } else {\n                    this.handleErrors(profiles, errorMessage);\n                }\n            }\n        }).finally(() => {\n            if (this.profiles?.length) {\n                this.retrieveFullProfile(this.profiles.shift(), resolve, reject);\n            } else {\n                this.handleNextExecution(resolve, reject);\n            }\n        });\n    }\n\n    getMetadataReconcilerRequest(profiles) {\n        const request = new CopaReconcilerInput();\n        request.repositoryPath = TARGET_DIRECTORY;\n        request.accessToken = sourceSessionId;\n        request.instanceUrl = sourceEndpoint?.substring(0, sourceEndpoint?.indexOf('/', sourceEndpoint?.indexOf('/') + 2));\n        request.jsonOutputPath = TEMP_DIRECTORY;\n        request.profiles = profiles;\n        request.operation = Operation.FULL_PROFILE;\n        return request;\n    }\n\n}\n\nasync function updateSourceApiVersion(sfdxProjectJsonPath, sourceApiVersion) {\n    let fileContent = this.readFromPath(sfdxProjectJsonPath);\n    if (fileContent.sourceApiVersion !== sourceApiVersion) {\n        const commitMessage = `Updated sourceApiVersion from ${fileContent.sourceApiVersion} to ${sourceApiVersion} in sfdx-project.json to align the commit, promote and deploy operations with the latest supported api version of Copado`;\n        fileContent.sourceApiVersion = sourceApiVersion;\n        writeFileSync(sfdxProjectJsonPath, JSON.stringify(fileContent, null, 2));\n        await this.commitGit(commitMessage);\n    }\n}\n\nfunction readFromPath(filePath) {\n    if (!existsSync(filePath)) {\n        throw `Could not find file at path: ${filePath}`;\n    }\n    const data = readFileSync(filePath, 'utf-8');\n    let result;\n    try {\n        result = JSON.parse(data);\n    } catch (err) {\n        throw `Content at ${filePath} is not a valid JSON`;\n    }\n    return result;\n}\n\nasync function commitGit(commitMessage) {\n    await this.executeCommandAsync(`\n        git add . || ${this.getErrorCommand('There was some issue when staging changes')}\n        git commit -m \"${commitMessage}\" || true`, false, true\n    );\n}\n\n\nfunction getInstanceUrl(instanceUrl) {\n    return instanceUrl?.substring(0, instanceUrl?.indexOf('/', instanceUrl?.indexOf('/') + 2));\n}\n\nfunction getMetadataSupportedByCli() {\n    return [\n        'dashboard',\n        'document',\n        'emailtemplate',\n        'profile',\n        'report',\n        'staticresource',\n        'accesscontrolpolicy',\n        'accountforecastsettings',\n        'accountingfieldmapping',\n        'accountingmodelconfig',\n        'accountingsettings',\n        'accountinsightssettings',\n        'accountintelligencesettings',\n        'accountrelationshipsharerule',\n        'accountsettings',\n        'acctmgrtargetsettings',\n        'actionablelistdefinition',\n        'actionlauncheritemdef',\n        'actionlinkgrouptemplate',\n        'actionplantemplate',\n        'actionssettings',\n        'activationplatform',\n        'activitiessettings',\n        'addresssettings',\n        'advaccountforecastset',\n        'advacctforecastdimsource',\n        'advacctforecastperiodgroup',\n        'ai4msettings',\n        'aiapplication',\n        'aiapplicationconfig',\n        'aiassistanttemplate',\n        'aireplyrecommendationssettings',\n        'aiscoringmodeldefinition',\n        'aiscoringmodeldefversion',\n        'aiusecasedefinition',\n        'analyticsnapshot',\n        'analyticssettings',\n        'animationrule',\n        'apexclass',\n        'apexcomponent',\n        'apexemailnotifications',\n        'apexpage',\n        'apexsettings',\n        'apextestsuite',\n        'apextrigger',\n        'appanalyticssettings',\n        'appexperiencesettings',\n        'applicationrecordtypeconfig',\n        'applicationsubtypedefinition',\n        'appmenu',\n        'appointmentassignmentpolicy',\n        'appointmentschedulingpolicy',\n        'approvalprocess',\n        'assessmentquestion',\n        'assessmentquestionset',\n        'assignmentrules',\n        'assistantcontextitem',\n        'assistantdefinition',\n        'assistantrecommendationtype',\n        'assistantskillquickaction',\n        'assistantskillsobjectaction',\n        'assistantversion',\n        'associationenginesettings',\n        'audience',\n        'auradefinitionbundle',\n        'authprovider',\n        'automatedcontactssettings',\n        'autoresponserules',\n        'batchcalcjobdefinition',\n        'batchprocessjobdefinition',\n        'benefitaction',\n        'blacklistedconsumer',\n        'bldgenrgyintensitycnfg',\n        'blockchainsettings',\n        'bot',\n        'botblock',\n        'botsettings',\n        'bottemplate',\n        'botversion',\n        'branchmanagementsettings',\n        'brandingset',\n        'briefcasedefinition',\n        'businesshourssettings',\n        'businessprocess',\n        'businessprocessfeedbackconfiguration',\n        'businessprocessgroup',\n        'businessprocesstypedefinition',\n        'callcenter',\n        'callcenterroutingmap',\n        'callcoachingmediaprovider',\n        'callctragentfavtrfrdest',\n        'campaigninfluencemodel',\n        'campaignsettings',\n        'canvasmetadata',\n        'carebenefitverifysettings',\n        'carelimittype',\n        'careproviderafflroleconfig',\n        'careprovidersearchconfig',\n        'carerequestconfiguration',\n        'caresystemfieldmapping',\n        'casesettings',\n        'casesubjectparticle',\n        'certificate',\n        'channellayout',\n        'channelobjectlinkingrule',\n        'chatteranswerssettings',\n        'chatteremailsmdsettings',\n        'chatterextension',\n        'chattersettings',\n        'claimfinancialsettings',\n        'claimmgmtfoundationenabledsettings',\n        'clausecatgconfiguration',\n        'cleandataservice',\n        'cmsconnectsource',\n        'codebuildersettings',\n        'collectionsdashboardsettings',\n        'commandaction',\n        'commercesettings',\n        'communitiessettings',\n        'community',\n        'communitytemplatedefinition',\n        'communitythemedefinition',\n        'compactlayout',\n        'companysettings',\n        'connectedapp',\n        'connectedappsettings',\n        'contentasset',\n        'contentsettings',\n        'contextdefinition',\n        'contractsettings',\n        'conversationalintelligencesettings',\n        'conversationchanneldefinition',\n        'conversationvendorfielddef',\n        'conversationvendorinfo',\n        'corswhitelistorigin',\n        'csptrustedsite',\n        'currencysettings',\n        'customaddressfieldsettings',\n        'customapplication',\n        'customapplicationcomponent',\n        'customdatatype',\n        'customerdataplatformsettings',\n        'customexperience',\n        'customfeedfilter',\n        'customfield',\n        'customhelpmenusection',\n        'customindex',\n        'customizablepropensityscoringsettings',\n        'customlabels',\n        'custommetadata',\n        'customnotificationtype',\n        'customobject',\n        'customobjecttranslation',\n        'custompageweblink',\n        'custompermission',\n        'customsite',\n        'customtab',\n        'dashboardfolder',\n        'datacalcinsighttemplate',\n        'datacategorygroup',\n        'dataconnectoringestapi',\n        'dataconnectors3',\n        'datadotcomsettings',\n        'dataimportmanagementsettings',\n        'datakitobjecttemplate',\n        'datapackagekitdefinition',\n        'datapackagekitobject',\n        'datapipeline',\n        'datasource',\n        'datasourcebundledefinition',\n        'datasourceobject',\n        'datasourcetenant',\n        'datasrcdatamodelfieldmap',\n        'datastreamdefinition',\n        'datastreamtemplate',\n        'dataweaveresource',\n        'decisionmatrixdefinition',\n        'decisionmatrixdefinitionversion',\n        'decisiontable',\n        'decisiontabledatasetlink',\n        'delegategroup',\n        'deploymentsettings',\n        'devhubsettings',\n        'digitalexperience',\n        'digitalexperiencebundle',\n        'digitalexperienceconfig',\n        'disclosuredefinition',\n        'disclosuredefinitionversion',\n        'disclosuretype',\n        'discoveryaimodel',\n        'discoverygoal',\n        'discoverysettings',\n        'discoverystory',\n        'documentcategory',\n        'documentcategorydocumenttype',\n        'documentchecklistsettings',\n        'documentfolder',\n        'documentgenerationsetting',\n        'documenttype',\n        'duplicaterule',\n        'dynamicformssettings',\n        'dynamictrigger',\n        'eacsettings',\n        'eclairgeodata',\n        'einsteinagentsettings',\n        'einsteinassistantsettings',\n        'einsteindealinsightssettings',\n        'einsteindocumentcapturesettings',\n        'emailadministrationsettings',\n        'emailfolder',\n        'emailintegrationsettings',\n        'emailservicesfunction',\n        'emailtemplatefolder',\n        'emailtemplatesettings',\n        'embeddedservicebranding',\n        'embeddedserviceconfig',\n        'embeddedservicefieldservice',\n        'embeddedserviceflowconfig',\n        'embeddedserviceliveagent',\n        'embeddedservicemenusettings',\n        'employeefieldaccesssettings',\n        'employeeusersettings',\n        'enhancednotessettings',\n        'entitlementprocess',\n        'entitlementsettings',\n        'entitlementtemplate',\n        'entityimplements',\n        'escalationrules',\n        'esignatureconfig',\n        'esignatureenvelopeconfig',\n        'essentialssettings',\n        'eventdelivery',\n        'eventrelayconfig',\n        'eventsettings',\n        'eventsubscription',\n        'eventtype',\n        'experiencebundle',\n        'experiencebundlesettings',\n        'explainabilityactiondefinition',\n        'explainabilityactionversion',\n        'explainabilitymsgtemplate',\n        'expressionsetdefinition',\n        'expressionsetdefinitionversion',\n        'expressionsetmessagetoken',\n        'expressionsetobjectalias',\n        'extdatatranobjecttemplate',\n        'externalaimodel',\n        'externalclientapplication',\n        'externalclientappsettings',\n        'externalcredential',\n        'externaldataconnector',\n        'externaldatasource',\n        'externalserviceregistration',\n        'extlclntappconfigurablepolicies',\n        'extlclntappglobaloauthsettings',\n        'extlclntappmobileconfigurablepolicies',\n        'extlclntappmobilesettings',\n        'extlclntappnotificationsettings',\n        'extlclntappoauthconfigurablepolicies',\n        'extlclntappoauthsettings',\n        'extlclntappsampleconfigurablepolicies',\n        'extlclntappsamplesettings',\n        'featureparameterboolean',\n        'featureparameterdate',\n        'featureparameterinteger',\n        'fieldrestrictionrule',\n        'fieldservicemobileextension',\n        'fieldservicesettings',\n        'fieldset',\n        'fieldsrctrgtrelationship',\n        'filesconnectsettings',\n        'fileuploadanddownloadsecuritysettings',\n        'flexipage',\n        'flow',\n        'flowcategory',\n        'flowdefinition',\n        'flowsettings',\n        'flowtest',\n        'forecastingfilter',\n        'forecastingfiltercondition',\n        'forecastingobjectlistsettings',\n        'forecastingsettings',\n        'forecastingsourcedefinition',\n        'forecastingtype',\n        'forecastingtypesource',\n        'form',\n        'formulasettings',\n        'fueltype',\n        'fueltypesustnuom',\n        'functionreference',\n        'fundraisingconfig',\n        'gatewayproviderpaymentmethodtype',\n        'genaiprompttemplate',\n        'genaiprompttemplateactv',\n        'globalpicklist',\n        'globalvalueset',\n        'globalvaluesettranslation',\n        'googleappssettings',\n        'group',\n        'highvelocitysalessettings',\n        'homepagecomponent',\n        'homepagelayout',\n        'icon',\n        'ideassettings',\n        'identityprovidersettings',\n        'identityverificationprocdef',\n        'iframewhitelisturlsettings',\n        'inboundcertificate',\n        'inboundnetworkconnection',\n        'incidentmgmtsettings',\n        'includeesttaxinquotesettings',\n        'index',\n        'industriesautomotivesettings',\n        'industrieseinsteinfeaturesettings',\n        'industriesloyaltysettings',\n        'industriesmanufacturingsettings',\n        'industriessettings',\n        'insighttype',\n        'installedpackage',\n        'integrationhubsettings',\n        'integrationhubsettingstype',\n        'integrationproviderdef',\n        'interesttaggingsettings',\n        'internaldataconnector',\n        'internalorganization',\n        'inventorysettings',\n        'invlatepymntriskcalcsettings',\n        'invocableactionsettings',\n        'iotsettings',\n        'ipaddressrange',\n        'keywordlist',\n        'knowledgesettings',\n        'languagesettings',\n        'layout',\n        'leadconfigsettings',\n        'leadconvertsettings',\n        'letterhead',\n        'licensedefinition',\n        'licensingsettings',\n        'lightningbolt',\n        'lightningcomponentbundle',\n        'lightningexperiencesettings',\n        'lightningexperiencetheme',\n        'lightningmessagechannel',\n        'lightningonboardingconfig',\n        'listview',\n        'liveagentsettings',\n        'livechatagentconfig',\n        'livechatbutton',\n        'livechatdeployment',\n        'livechatsensitivedatarule',\n        'livemessagesettings',\n        'locationuse',\n        'loyaltyprogramsetup',\n        'macrosettings',\n        'mailmergesettings',\n        'managedcontenttype',\n        'managedtopics',\n        'mapsandlocationsettings',\n        'marketingappextension',\n        'marketingresourcetype',\n        'marketsegmentdefinition',\n        'matchingrules',\n        'mediaadsalessettings',\n        'meetingssettings',\n        'messagingchannel',\n        'mfgprogramtemplate',\n        'mfgserviceconsolesettings',\n        'milestonetype',\n        'mktcalcinsightobjectdef',\n        'mktdatatranobject',\n        'mldatadefinition',\n        'mldomain',\n        'mlpredictiondefinition',\n        'mlrecommendationdefinition',\n        'mobileapplicationdetail',\n        'mobilesecurityassignment',\n        'mobilesecuritypolicy',\n        'mobilesecuritypolicyset',\n        'mobilesettings',\n        'mobsecuritycertpinconfig',\n        'moderationrule',\n        'mutingpermissionset',\n        'mydomaindiscoverablelogin',\n        'mydomainsettings',\n        'namedcredential',\n        'namesettings',\n        'navigationmenu',\n        'network',\n        'networkbranding',\n        'notificationssettings',\n        'notificationtypeconfig',\n        'oauthcustomscope',\n        'oauthoidcsettings',\n        'objecthierarchyrelationship',\n        'objectlinkingsettings',\n        'objectsourcetargetmap',\n        'ocrsampledocument',\n        'ocrtemplate',\n        'omnichannelpricingsettings',\n        'omnichannelsettings',\n        'omnidatatransform',\n        'omniintegrationprocedure',\n        'omniinteractionaccessconfig',\n        'omniinteractionconfig',\n        'omniscript',\n        'omnisupervisorconfig',\n        'omniuicard',\n        'onlinesalessettings',\n        'opportunityinsightssettings',\n        'opportunityscoresettings',\n        'opportunitysettings',\n        'orchestration',\n        'orchestrationcontext',\n        'ordermanagementsettings',\n        'ordersettings',\n        'orgsettings',\n        'outboundnetworkconnection',\n        'pardoteinsteinsettings',\n        'pardotsettings',\n        'participantrole',\n        'partydatamodelsettings',\n        'pathassistant',\n        'pathassistantsettings',\n        'paymentgatewayprovider',\n        'paymentsmanagementenabledsettings',\n        'paymentssettings',\n        'permissionset',\n        'permissionsetgroup',\n        'permissionsetlicensedefinition',\n        'personaccountownerpoweruser',\n        'picklistsettings',\n        'pipelineinspmetricconfig',\n        'platformcachepartition',\n        'platformeventchannel',\n        'platformeventchannelmember',\n        'platformeventsettings',\n        'platformeventsubscriberconfig',\n        'platformslacksettings',\n        'portal',\n        'portalssettings',\n        'posttemplate',\n        'predictionbuildersettings',\n        'presencedeclinereason',\n        'presenceuserconfig',\n        'pricingrecipe',\n        'privacysettings',\n        'processflowmigration',\n        'productattributeset',\n        'productsettings',\n        'productspecificationtypedefinition',\n        'profilepasswordpolicy',\n        'profilesessionsetting',\n        'prompt',\n        'queue',\n        'queueroutingconfig',\n        'quickaction',\n        'quicktextsettings',\n        'quotesettings',\n        'realtimeeventsettings',\n        'recommendationbuildersettings',\n        'recommendationstrategy',\n        'recordactiondeployment',\n        'recordaggregationdefinition',\n        'recordalertcategory',\n        'recordalertdatasource',\n        'recordpagesettings',\n        'recordtype',\n        'redirectwhitelisturl',\n        'registeredexternalservice',\n        'relationshipgraphdefinition',\n        'remotesitesetting',\n        'reportfolder',\n        'reporttype',\n        'restrictionrule',\n        'retailexecutionsettings',\n        'role',\n        'salesagreementsettings',\n        'salesworkqueuesettings',\n        'samlssoconfig',\n        'sandboxsettings',\n        'schedulingobjective',\n        'schedulingrule',\n        'schemasettings',\n        'scontrol',\n        'scorecategory',\n        'searchableobjdatasyncinfo',\n        'searchcriteriaconfiguration',\n        'searchsettings',\n        'securitysettings',\n        'serviceaisetupdefinition',\n        'serviceaisetupfield',\n        'servicechannel',\n        'servicecloudvoicesettings',\n        'servicepresencestatus',\n        'serviceprocess',\n        'servicesetupassistantsettings',\n        'settings',\n        'sharingcriteriarule',\n        'sharingguestrule',\n        'sharingownerrule',\n        'sharingreason',\n        'sharingrules',\n        'sharingset',\n        'sharingsettings',\n        'sharingterritoryrule',\n        'sitedotcom',\n        'sitesettings',\n        'skill',\n        'skilltype',\n        'slackapp',\n        'socialcustomerservicesettings',\n        'socialprofilesettings',\n        'sourcetrackingsettings',\n        'standardvalueset',\n        'standardvaluesettranslation',\n        'stnryassetenvsrccnfg',\n        'streamingappdataconnector',\n        'subscriptionmanagementsettings',\n        'surveysettings',\n        'sustainabilityuom',\n        'sustnuomconversion',\n        'svccatalogcategory',\n        'svccatalogfiltercondition',\n        'svccatalogfiltercriteria',\n        'svccatalogfulfillmentflow',\n        'svccatalogitemdef',\n        'svccatalogitemdeffiltrcrit',\n        'synonymdictionary',\n        'systemnotificationsettings',\n        'territory',\n        'territory2',\n        'territory2model',\n        'territory2rule',\n        'territory2settings',\n        'territory2type',\n        'timelineobjectdefinition',\n        'timesheettemplate',\n        'topicsforobjects',\n        'trailheadsettings',\n        'transactionsecuritypolicy',\n        'translations',\n        'trialorgsettings',\n        'uiobjectrelationconfig',\n        'uiplugin',\n        'uiviewdefinition',\n        'userauthcertificate',\n        'usercriteria',\n        'userengagementsettings',\n        'userinterfacesettings',\n        'usermanagementsettings',\n        'userprofilesearchscope',\n        'userprovisioningconfig',\n        'validationrule',\n        'vehicleassetemssnsrccnfg',\n        'viewdefinition',\n        'visualizationplugin',\n        'voicesettings',\n        'warrantylifecyclemgmtsettings',\n        'waveapplication',\n        'wavecomponent',\n        'wavedashboard',\n        'wavedataflow',\n        'wavedataset',\n        'wavelens',\n        'waverecipe',\n        'wavetemplatebundle',\n        'wavexmd',\n        'web3settings',\n        'weblink',\n        'webstorebundle',\n        'webstoretemplate',\n        'webtoxsettings',\n        'workdotcomsettings',\n        'workflow',\n        'workflowalert',\n        'workflowfieldupdate',\n        'workflowknowledgepublish',\n        'workflowoutboundmessage',\n        'workflowrule',\n        'workflowsend',\n        'workflowtask',\n        'workforceengagementsettings',\n        'workskillrouting',\n        'xorghub'\n    ];\n}\n\nclass CommandExecutionError extends Error {\n    constructor(message) {\n        super(`${message}`);\n        this.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n    }\n}\n\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.getPath = getPath;\nmodule.exports.getApiVersion = getApiVersion;\nmodule.exports.getParsedData = getParsedData;\nmodule.exports.execute = execute;\nmodule.exports.getMetadataNamesByType = getMetadataNamesByType;\nmodule.exports.getMetaDataFileContent = getMetaDataFileContent;\nmodule.exports.getMetadataSupportedByCli = getMetadataSupportedByCli;\nmodule.exports.isValidMetadata = isValidMetadata;\nmodule.exports.getProfilesForRetrieval = getProfilesForRetrieval;\nmodule.exports.getMetadataItemForRetrieval = getMetadataItemForRetrieval;\nmodule.exports.getMetadataItemsForRetrieval = getMetadataItemsForRetrieval;\nmodule.exports.setUpWorkingDirectory = setUpWorkingDirectory;\nmodule.exports.switchToWorkingDirectory = switchToWorkingDirectory;\nmodule.exports.fetchRemoteGitBranch = fetchRemoteGitBranch;\nmodule.exports.configureGit = configureGit;\nmodule.exports.configureSFDXCli = configureSFDXCli;\nmodule.exports.runMetadataRetrieval = runMetadataRetrieval;\nmodule.exports.getPackageXMLfilePath = getPackageXMLfilePath;\nmodule.exports.pushChangesToRemoteBranch = pushChangesToRemoteBranch;\nmodule.exports.uploadExecutionDetails = uploadExecutionDetails;\nmodule.exports.runVarReplace = runVarReplace;\nmodule.exports.runFindAndReplace = runFindAndReplace;\nmodule.exports.exitProcess = exitProcess;\nmodule.exports.updateResultStatus = updateResultStatus;\nmodule.exports.logger = logger;\nmodule.exports.log = log;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getErrorCommand = getErrorCommand;\nmodule.exports.getMaxAllowedProcesses = getMaxAllowedProcesses;\nmodule.exports.getSelectedMetadatas = getSelectedMetadatas;\nmodule.exports.getMetadataChunkSize = getMetadataChunkSize;\nmodule.exports.getCommitId = getCommitId;\nmodule.exports.updateSourceApiVersion = updateSourceApiVersion;\nmodule.exports.readFromPath = readFromPath;\nmodule.exports.commitGit = commitGit;\nmodule.exports.SpawnPool = SpawnPool;\nmodule.exports.copyVlocityFiles = copyVlocityFiles;\nmodule.exports.getInstanceUrl = getInstanceUrl;\nmodule.exports.executeCommandAsync = executeCommandAsync;\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0l7Q00000DF2LhQAL",
                    "LastReferencedDate": "2023-09-18T13:23:22.000+0000",
                    "LastViewedDate": "2023-09-18T13:23:22.000+0000",
                    "Name": "Git Snapshot"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0k0900000Isk2EAAR"
                    },
                    "copado__API_Name__c": "SFDX_Rollback",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : false,\n  \"name\" : \"rollbackFileId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.rollbackFileId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"isValidation\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.isValidation}\"\n}, {\n  \"name\" : \"testLevel\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.testLevel}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"promotion\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.promotion}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"targetBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.targetBranch}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationInstanceUrl\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationSessionid\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"name\" : \"waitTime\",\n  \"defaultValue\" : \"220\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : false,\n  \"name\" : \"destinationEnvVariables\",\n  \"defaultValue\" : \"{$Destination.apex.EnvironmentVariables}\"\n}, {\n  \"name\" : \"findAndReplaceFileId\",\n  \"defaultValue\" : \"{$Context.apex.GlobalFindAndReplaceDestinationId}\"\n}, {\n  \"name\" : \"isProductionEnvironment\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.IdentifyProductionEnvironment}\"\n}, {\n  \"name\" : \"serviceLogLevel\",\n  \"defaultValue\" : \"{$Pipeline.Property.service_log_level}\"\n}, {\n  \"name\" : \"prevResult\",\n  \"defaultValue\" : \"{$Job.PrevStep.Result__r.Result_Data__c}\"\n}, {\n  \"name\" : \"testSuiteAndTestClassFileVersionDetails\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.GetFileVersionIdOfTestClassTestSuite}\"\n}, {\n  \"name\" : \"fetchRollbackReportRetrialTimes\",\n  \"defaultValue\" : \"{$Pipeline.Property.fetchRollbackReportRetrialTimes}\"\n}, {\n  \"name\" : \"rollbackPollTime\",\n  \"defaultValue\" : \"{$Pipeline.Property.rollbackPollTime}\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n/**\n * Performs complete or partial rollback of the selected promotion changes\n * @param rollbackFileId\n * @param isValidation\n * @param testLevel\n * @param promotion (or rollback branch name)\n * @param targetBranch\n * @param destinationInstanceUrl\n * @param destinationSessionid\n * @param gitName\n * @param gitEmail\n * @param maxBuffer\n * @param waitTime\n * @param destinationEnvVariables\n * @param findAndReplaceFileId\n */\n\nconst child_process = require('child_process'),\n    fs = require('fs'),\n    {\n        rollbackFileId,\n        isValidation,\n        testLevel,\n        isProductionEnvironment,\n        promotion,\n        gitEmail,\n        gitName,\n        targetBranch,\n        destinationInstanceUrl,\n        destinationSessionid,\n        waitTime,\n        isTest,\n        findAndReplaceFileId,\n        destinationEnvVariables,\n        overriddenApiVersion,\n        API_VERSION,\n        maxBuffer,\n        serviceLogLevel,\n        prevResult,\n        testSuiteAndTestClassFileVersionDetails,\n        fetchRollbackReportRetrialTimes,\n        rollbackPollTime\n    } = process.env,\n    rollbackBranch = `rollback/${promotion}`,\n    TEMP_DIRECTORY = getPath('/tmp'),\n    APP_DIRECTORY = getPath('/app'),\n    sourceApiVersion = getApiVersion(overriddenApiVersion, API_VERSION),\n    SOURCE_DIRECTORY = `${APP_DIRECTORY}/source`,\n    TARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n    ROLLBACK_CHANGES_JSON = 'Copado Rollback changes',\n    SELECTED_ROLLBACK_CHANGES_JSON = 'Selected_RollbackChanges.json',\n    SELECTED_ROLLBACK_CHANGES_FILEPATH = `${TEMP_DIRECTORY}/${SELECTED_ROLLBACK_CHANGES_JSON}`,\n    FILES_TO_INCLUDE = `${TEMP_DIRECTORY}/filesToInclude.json`,\n    ACTIONS = {\n        UPDATE: 'update',\n        UNCHANGED: 'unchanged',\n        CREATE: 'create',\n        DELETE: 'delete',\n        FULL: 'full',\n        RETRIEVEONLY: 'retrieveonly'\n    },\n    CATEGORY = {\n        SFDX: 'sfdx'\n    },\n    STDIO = {\n        INHERIT: 'inherit'\n    },\n    PACKAGE_XML = 'package.xml',\n    DESTRUCTIVE_CHANGES_XML = 'destructiveChanges.xml',\n    TEST_LEVEL = {\n        RUN_SPECIFIED_TESTS: 'RunSpecifiedTests',\n        NO_TEST_RUN: 'NoTestRun'\n    },\n    CONSTANTS = {\n        COMPONENT_TYPE: 'componentType',\n        FULL_NAME: 'fullName',\n        PROBLEM: 'problem',\n        TEST_SUITE_FILE_NAME:'cmcSf_TestSuites',\n\t\tTEST_CLASS_FILE_NAME:'cmcSf_TestClasses'\n    },\n    DEPLOYMENT_STATUS = {\n        CANCELED: 'Canceled',\n        PENDING: 'Pending',\n        INPROGRESS: 'InProgress'\n    },\n    ROLLBACK_CATEGORY = {\n        UPSERT: 'UPSERT',\n        DELETE: 'DELETE',\n        RETRIEVEONLY: 'RETRIEVEONLY'\n    },\n    MAXBUFFER = parseInt(maxBuffer),\n    RESULT_INFO = {\n        LEVEL: {\n            INFO: 'INFO',\n            ERROR: 'ERROR',\n            WARN: 'WARN'\n        },\n        CATEGORY: {\n            UNKNOWN_EXCEPTION: 'Unknown Exception',\n            COPADO_INFO: 'Copado Info',\n            METADATA_ROLLBACK: 'Metadata Rollback',\n            APEX_TEST_RUN: 'Apex Test Run',\n            CODE_COVERAGE_ERROR: 'Code Coverage Error',\n            FLOW_TEST_FAILURE: 'Flow Test Failure',\n            FLOW_TEST_RUN: 'Flow Test Run',\n            APEX_TEST_FAILURE: 'Apex Test Failure',\n            COPADO_METADATA_INTELLIGENCE: 'Copado Metadata Intelligence',\n            GIT: 'Git',\n            COPADO_SERVICE: 'Copado Service',\n            SFDX_CLI: 'SFDX CLI',\n            METADATA_EXECUTION: `Metadata ${isValidation === 'true' ? 'Validation' : 'Deployment'}`\n        },\n        ADDITIONAL_INFORMATION: {\n            APEX_TEST_FAILURE: 'Apex Test Failure',\n            CODE_COVERAGE_ERROR: 'Code Coverage Error',\n            FLOW_TEST_FAILURE: 'Flow Test Failure',\n            APEX_TEST_RUN_SUMMARY: 'Test Run Summary',\n            CONSOLIDATED_RESULT: `Consolidated ${isValidation === 'true' ? 'Validation' : 'Deployment'} Result`,\n            GIT_STATUS: 'Git Status',\n            ROLLBACK_BRANCH_CHECKOUT: 'Rollback Branch Checkout',\n            GIT_COMMIT: 'Git Commit',\n            GIT_RESET: 'Git Reset',\n            GIT_CONFIGURATION: 'Git configuration',\n            COPADO_GIT_AUTHENTICATION: 'Copado Git Authentication',\n            METADATA_FILE_PATH_CALCULATION: 'Metadata File Path Calculation',\n            METADATA_PROCESSOR: 'Metadata Processor',\n            SFDX_CONFIGURATION: 'SFDX Configuration',\n            GIT_PUSH: 'Git Push',\n            POPULATE_INFO_ON_RESULT: 'Populate Information on the result record',\n            ENV_VARIABLE_REPLACEMENT: 'Environment Variable Replacement',\n            GLOBAL_FIND_AND_REPLACE: 'Global Find and Replace',\n            POLL_STATUS: `Poll ${isValidation === 'true' ? 'Validation' : 'Deployment'} Status`\n        }\n    },\n    resultViewerJson = [],\n    CUSTOM_ERROR = {\n        COMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n    },\n    RESULT_TABLE_COLUMNS = [\n        {\n            label: 'Level',\n            fieldName: 'Level',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Level',\n            initialWidth: 80\n        },\n        {\n            label: 'Category',\n            fieldName: 'Category',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Category',\n            initialWidth: 120\n        },\n        {\n            label: 'Additional Information',\n            fieldName: 'AdditionalInformation',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Additional_Information',\n            initialWidth: 200\n        },\n        {\n            label: 'Message',\n            fieldName: 'Message',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Message'\n        }\n    ],\n    RESULT_TABLE_HEADER = {\n        label: 'Rollback Result',\n        customLabel: 'Rollback_Result'\n    },\n    HEADER_ICON = 'standard:note',\n    NUMBER_OF_REPORT_RETRIALS = parseInt(fetchRollbackReportRetrialTimes) >= 0 ? parseInt(fetchRollbackReportRetrialTimes) : 10,\n    ROLLBACK_REPORT_POLL_TIME = parseInt(rollbackPollTime) >= 0 ? parseInt(rollbackPollTime) : 1,\n    { cpus } = require('os');\n\nlet executionError;\n\n// EXECUTION\n\nasync function execute() {\n    try {\n        if (!rollbackFileId) {\n            this.executeCommand(`copado -p 'Copado Rollback changes.json file not found.'`);\n            process.exit(0);\n        }\n        this.downloadFile(rollbackFileId, TEMP_DIRECTORY, ROLLBACK_CHANGES_JSON);\n        const selectedChanges = this.readFileContent(`${TEMP_DIRECTORY}/${ROLLBACK_CHANGES_JSON}`);\n        this.hasSelectedSFDXChanges(selectedChanges);\n\n        this.setServiceLogLevel(serviceLogLevel);\n        this.fetchBranch(SOURCE_DIRECTORY, rollbackBranch);\n\n        const selectedRollbackChanges = this.getSelectedRollbackChanges(selectedChanges);\n        if (selectedRollbackChanges[ROLLBACK_CATEGORY.UPSERT]?.length) {\n            this.findFilePaths(\n                selectedRollbackChanges,\n                [ROLLBACK_CATEGORY.UPSERT, ROLLBACK_CATEGORY.RETRIEVEONLY],\n                SELECTED_ROLLBACK_CHANGES_FILEPATH\n            );\n            this.getFilesInScope();\n            this.varReplace(destinationEnvVariables);\n            this.findAndReplace(findAndReplaceFileId, `rollback/${promotion}`);\n            // Perform TRIM operation on the rollback branch\n            this.callMetadataProcessor(SELECTED_ROLLBACK_CHANGES_FILEPATH, 'TRIM', false, SOURCE_DIRECTORY);\n            const parentMetadataFile = this.getParentMetadataFile(SELECTED_ROLLBACK_CHANGES_FILEPATH);\n            if (fs.existsSync(parentMetadataFile)) {\n                this.addParentMetadataToOriginalChangeList(selectedRollbackChanges, this.readFileContent(parentMetadataFile));\n            }\n        }\n\n        await Promise.all([\n            new Promise((resolve, reject) => {\n                this.rollback(selectedRollbackChanges, resolve, reject);\n            }),\n            new Promise((resolve, reject) => {\n                try {\n                    this.fetchTargetBranch(TARGET_DIRECTORY, targetBranch).then(() => {\n                        process.chdir(TARGET_DIRECTORY);\n                        this.configureGit(gitEmail, gitName);\n                        this.updateSelectedRollBackChangesFile(selectedRollbackChanges, SELECTED_ROLLBACK_CHANGES_FILEPATH, [ROLLBACK_CATEGORY.DELETE]);\n                        resolve();\n                    });\n                } catch (err) {\n                    reject(err);\n                }\n            })\n        ]);\n        if (selectedRollbackChanges[ROLLBACK_CATEGORY.UPSERT]?.length) {\n            process.chdir(SOURCE_DIRECTORY);\n            this.resetChangesInCurrentBranch();\n            process.chdir(TARGET_DIRECTORY);\n        }\n        // Copy files from the rollback branch to the target branch along with nested handling\n        this.callMetadataProcessor(SELECTED_ROLLBACK_CHANGES_FILEPATH, 'ROLLBACK', true, SOURCE_DIRECTORY, TARGET_DIRECTORY);\n        if (isValidation !== 'true') {\n            this.gitCommit(`Copado Rollback for promotion ${promotion}`);\n            this.gitPush(targetBranch);\n        }\n    } catch (err) {\n        console.log('Error stack: ', err.stack);\n        if (!(err instanceof CommandExecutionError)) {\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, `See logs for more info`, err.message);\n        }\n        executionError = err.message || err?.toString() || 'Unknown Error occurred';\n    } finally {\n        if (resultViewerJson?.length) {\n            this.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n        }\n        if (executionError) {\n            this.executeCommand(\n                this.getErrorCmdString(executionError),\n                RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                RESULT_INFO.ADDITIONAL_INFORMATION.POPULATE_INFO_ON_RESULT\n            );\n            process.exit(1);\n        }\n    }\n}\n\n// SCRIPT FUNCTIONS\n\nfunction hasSelectedSFDXChanges(selectedChanges) {\n    if (!selectedChanges.some(change => change.s)) {\n        this.executeCommand(`copado -p 'No SFDX selected changes found.'`);\n        process.exit(0);\n    }\n}\n\nfunction fetchBranch(directory, branch) {\n    fs.mkdirSync(directory, { recursive: true });\n    process.chdir(directory);\n\n    this.asyncCopadoLogMessage(`Fetching ${branch}`);\n    this.executeCommand(\n        `copado-git-get ${branch} --depth 1`,\n        RESULT_INFO.CATEGORY.COPADO_SERVICE,\n        RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_GIT_AUTHENTICATION\n    );\n}\n\nfunction configureGit(gitEmail, gitName) {\n    const configureGit = `\ngit config --local user.email \"${gitEmail}\" || exit 1\ngit config --local user.name \"${gitName}\" || exit 1\ngit config --global diff.renames false || exit 1\ngit config --global merge.renames false || exit 1\ngit config --global status.renames false || exit 1\n`;\n    this.executeCommand(`${configureGit}`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CONFIGURATION);\n}\n\nfunction enrichChangeList(repository, filePath) {\n    this.executeCommand(\n        `enricher -p ${filePath} --repo ${repository}/ --quick true --loglevel DEBUG`,\n        RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE,\n        RESULT_INFO.ADDITIONAL_INFORMATION.METADATA_FILE_PATH_CALCULATION\n    );\n}\n\nfunction getSelectedRollbackChanges(selectedChanges) {\n    // Initializing the result object with empty arrays\n    const result = {};\n    Object.values(ROLLBACK_CATEGORY).forEach(category => {\n        result[category] = [];\n    });\n\n    selectedChanges.forEach(change => {\n        if (change.s) {\n            // The service understands the action FULL and not the property f..hence setting action to FULL where property f is true\n            if (change.f && change.a.toLowerCase() !== ACTIONS.DELETE) {\n                change.a = ACTIONS.FULL;\n            }\n            if (change.a.toLowerCase() === ACTIONS.DELETE) {\n                result[ROLLBACK_CATEGORY.DELETE].push(change);\n            } else if (change.a.toLowerCase() === ACTIONS.RETRIEVEONLY) {\n                result[ROLLBACK_CATEGORY.RETRIEVEONLY].push(change);\n            } else {\n                result[ROLLBACK_CATEGORY.UPSERT].push(change);\n            }\n        }\n    });\n\n    return result;\n}\n\nfunction executeCommand(command, category, additionalinfo, hasJsonResponse) {\n    let errorMessage;\n    const options = {\n        shell: true,\n        maxBuffer: MAXBUFFER\n    };\n    const response = child_process.spawnSync(command, options);\n    const { outputStream, errorStream } = this.log(response);\n    if (response?.status == 0) {\n        return hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n    }\n    if (!hasJsonResponse) {\n        errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n    } else {\n        try {\n            return JSON.parse(outputStream);\n        } catch (error) {\n            errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n        }\n    }\n    if (errorMessage) {\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalinfo, errorMessage);\n        throw new CommandExecutionError(errorMessage);\n    }\n}\n\nfunction getErrorCmdString(error) {\n    const suffix = 'Please check the logs for details.';\n    return `copado -p \"Error\" -e \"${error.trim()?.substring(0, 32760)}; ${suffix}\"`;\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction getFilePaths(changeFilePath, actions, categories) {\n    let changeList = this.readFileContent(changeFilePath);\n    let filePaths = new Set();\n\n    changeList.forEach(change => {\n        const isValid =\n            (!actions?.length || (actions.length && actions.includes(change.a?.toLowerCase()))) &&\n            (!categories?.length || (categories.length && categories.includes(change.c?.toLowerCase())));\n        if (isValid && change.j && change.j !== '') {\n            const jsonAdditionalInfo = JSON.parse(change.j);\n            let filesToBeAdded = jsonAdditionalInfo?.filePath?.filter(file => fs.existsSync(file) && fs.statSync(file).isFile());\n            if (filesToBeAdded) {\n                filePaths = new Set([...filePaths, ...filesToBeAdded]);\n            }\n        }\n    });\n    return [...filePaths];\n}\n\nfunction log(response) {\n    const outputStream = response?.stdout?.toString().trim();\n    const errorStream = response?.stderr?.toString().trim();\n    if (outputStream) {\n        this.logger(outputStream);\n    }\n    if (errorStream) {\n        this.logger(errorStream);\n    }\n    return { outputStream, errorStream };\n}\n\nfunction downloadFile(fileId, downloadDir, fileName) {\n    return this.executeCommand(\n        `copado --downloadfiles ${fileId} --downloaddir ${downloadDir}`,\n        RESULT_INFO.CATEGORY.COPADO_SERVICE,\n        `File: ${fileId} download in directory ${downloadDir}`\n    );\n}\n\nfunction readFileContent(filePath) {\n    if (!fs.existsSync(filePath)) {\n        throw `Could not find file at path: ${filePath} `;\n    }\n    const data = fs.readFileSync(filePath, 'utf-8');\n\n    try {\n        return JSON.parse(data);\n    } catch (err) {\n        throw `Content at ${filePath} is not a valid JSON`;\n    }\n}\n\nfunction getFilesInScope() {\n    const filesInScope = [];\n    if (fs.existsSync(`${TEMP_DIRECTORY}/${SELECTED_ROLLBACK_CHANGES_JSON}`)) {\n        filesInScope.push(\n            ...this.getFilePaths(\n                `${TEMP_DIRECTORY}/${SELECTED_ROLLBACK_CHANGES_JSON}`,\n                [ACTIONS.CREATE, ACTIONS.UNCHANGED, ACTIONS.UPDATE, ACTIONS.FULL, ACTIONS.RETRIEVEONLY],\n                [CATEGORY.SFDX]\n            )\n        );\n        if (filesInScope?.length) {\n            fs.writeFileSync(FILES_TO_INCLUDE, JSON.stringify(filesInScope));\n        }\n    }\n    return filesInScope;\n}\n\nfunction varReplace(destinationEnvVariables) {\n    if (fs.existsSync(FILES_TO_INCLUDE) && destinationEnvVariables && JSON.parse(destinationEnvVariables)?.length) {\n        this.asyncCopadoLogMessage('Replacing environment variables');\n        const varreplace = `\nvarreplace '${destinationEnvVariables}' '${SOURCE_DIRECTORY}' --include=${FILES_TO_INCLUDE}`;\n        this.executeCommand(varreplace, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.ENV_VARIABLE_REPLACEMENT);\n    }\n}\n\nfunction findAndReplace(findAndReplaceFileId, branch) {\n    const COPADO_YML = 'Copado',\n        PATH_TO_YAML = `${TEMP_DIRECTORY}/${COPADO_YML}`;\n    if (findAndReplaceFileId && fs.existsSync(FILES_TO_INCLUDE)) {\n        this.asyncCopadoLogMessage('Applying global find and replace rules');\n        this.downloadFile(findAndReplaceFileId, `${TEMP_DIRECTORY}/`, COPADO_YML);\n        if (fs.existsSync(PATH_TO_YAML)) {\n            const findAndReplace = `yamlreplace \"${PATH_TO_YAML}\" \"${SOURCE_DIRECTORY}\" -b \"${branch}\" --include=${FILES_TO_INCLUDE}`;\n            this.executeCommand(findAndReplace, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GLOBAL_FIND_AND_REPLACE);\n        } else {\n            throw 'Could not find the Copado.yml file';\n        }\n    }\n}\n\nfunction asyncCopadoLogMessage(msg, level) {\n    this.populateResultViewer(level ? level : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n    new Promise(resolve => {\n        child_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, () => {\n            resolve();\n        });\n    });\n}\n\nfunction callMetadataProcessor(changeFile, operationType, copyFiles, sourceDirectory, targetDirectory) {\n    this.logger('START Metadata processor');\n    this.asyncCopadoLogMessage('Processing metadata');\n    const processMetadata = `metadata-processor ${changeFile} ${sourceDirectory ? sourceDirectory : ''} ${\n        targetDirectory ? '--target ' + targetDirectory + ' -denrich' : ''\n    } -o ${operationType} ${copyFiles ? '--copy' : ''}`;\n    this.executeCommand(processMetadata, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.METADATA_PROCESSOR);\n    this.logger('END Metadata processor');\n}\n\nfunction addParentMetadataToOriginalChangeList(selectedRollbackChanges, parentMetadataList) {\n    if (parentMetadataList?.length) {\n        selectedRollbackChanges[ROLLBACK_CATEGORY.UPSERT].push(...parentMetadataList);\n    }\n}\n\nasync function rollback(selectedRollbackChanges, resolve, reject) {\n    const { addMetadataTypesByName, deleteMetadataTypesByName } = this.getMetadataTypeToNames(selectedRollbackChanges);\n\n    this.buildManifest(SOURCE_DIRECTORY, addMetadataTypesByName, false);\n    if (deleteMetadataTypesByName.size > 0) {\n        this.buildManifest(SOURCE_DIRECTORY, deleteMetadataTypesByName, true);\n    }\n    this.setInstanceUrl(destinationInstanceUrl);\n    this.asyncCopadoLogMessage('Rolling back changes on the destination environment');\n    child_process.exec(\n        await this.getSFDeployCmd(deleteMetadataTypesByName.size > 0, isValidation, testLevel, isProductionEnvironment, waitTime),\n        { cwd: SOURCE_DIRECTORY, maxBuffer: MAXBUFFER },\n        async (error, stdout, stderr) => {\n            try {\n                const deploymentRequest = JSON.parse(stdout?.toString());\n                this.logger(deploymentRequest?.result?.id);\n                const response = await this.checkDeploymentStatus(deploymentRequest?.result?.id, 0);\n                this.handleRollbackResult(response, isValidation, reject);\n                resolve();\n            } catch (err) {\n                if (error?.code) {\n                    const errorMessage = stderr ? stderr : `Error executing the command ${error.cmd}`;\n                    this.populateResultViewer(\n                        RESULT_INFO.LEVEL.ERROR,\n                        RESULT_INFO.CATEGORY.METADATA_ROLLBACK,\n                        RESULT_INFO.ADDITIONAL_INFORMATION,\n                        errorMessage\n                    );\n                    reject(new CommandExecutionError(stderr));\n                    return;\n                }\n            }\n        }\n    );\n}\nasync function checkDeploymentStatus(jobId, numberOfRetries) {\n    this.setInstanceUrl(destinationInstanceUrl);\n    let response = await this.executeCommandAsync(`sf project deploy report --wait ${ROLLBACK_REPORT_POLL_TIME} --job-id ${jobId} --json --target-org ${destinationSessionid}`, RESULT_INFO.CATEGORY.METADATA_EXECUTION, RESULT_INFO.ADDITIONAL_INFORMATION.POLL_STATUS, true, true);\n\n    if (response?.status && (response?.message?.includes('ETIMEDOUT') || response?.message?.includes('Metadata API request failed'))) {\n        if (numberOfRetries < NUMBER_OF_REPORT_RETRIALS) {\n            this.logger(`Fetching Deployment Report failed : ${response?.message}\n\t\t\tRetrying Attempt ${++numberOfRetries}`);\n            return await this.checkDeploymentStatus(jobId, ++numberOfRetries);\n        } else {\n            return response;\n        }\n    }\n    if (response?.result?.status == DEPLOYMENT_STATUS.INPROGRESS || response?.result?.status == DEPLOYMENT_STATUS.PENDING) {\n        numberOfRetries = 0;\n        if (response?.result?.status == DEPLOYMENT_STATUS.INPROGRESS) {\n            this.asyncCopadoLogMessage(response?.result?.stateDetail);\n        }\n        return await this.checkDeploymentStatus(jobId, numberOfRetries);\n    } else {\n        return response;\n    }\n}\n\n\nfunction executeCommandAsync(command, category, additionalInfo, hasJsonResponse, disableLog) {\n    return new Promise((resolve, reject) => {\n        let output = '', error = '';\n        const childProcess = child_process.spawn(command, [], { shell: true });\n\n        childProcess.stdout.on('data', (data) => {\n            output += (data?.toString());\n        });\n\n        childProcess.stderr.on('data', (data) => {\n            error += (data?.toString());\n        });\n\n        childProcess.on('close', (code) => {\n            if (code !== 0) {\n                let errorMessage = '';\n                if (hasJsonResponse) {\n                    try {\n                        resolve(JSON.parse(output))\n                    } catch (error) {\n                        errorMessage = error;\n                    }\n                } else {\n                    errorMessage = error;\n                }\n                errorMessage = errorMessage ? errorMessage : `Error executing the command ${command}`;\n                this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n                reject(new CommandExecutionError(errorMessage));\n            }\n            if (!disableLog) {\n                this.logger(`code: ${code?.toString()}`);\n                this.logger(`stdout: ${output}`);\n                this.logger(`stderr: ${error}`);\n            }\n            resolve((hasJsonResponse ? JSON.parse(output) : output));\n        });\n\n        childProcess.on('error', (error) => {\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, error);\n            reject(new CommandExecutionError(error));\n        });\n    });\n}\n\nasync function getSFDeployCmd(hasDestructiveChanges, isValidation, testLevel, isProductionEnvironment, waitTime) {\n    let sfDeployCommand = `sf project deploy start --json --ignore-conflicts ${\n        waitTime ? '--wait ' + waitTime : ''\n    } --target-org ${destinationSessionid}`;\n\n    if (isValidation == 'true') {\n        sfDeployCommand += ' --dry-run';\n    }\n\n    sfDeployCommand += await this.getTestRunParam(testLevel, isProductionEnvironment);\n\n    sfDeployCommand += ` --manifest ${SOURCE_DIRECTORY}/${PACKAGE_XML} ${hasDestructiveChanges ? `--post-destructive-changes ${SOURCE_DIRECTORY}/${DESTRUCTIVE_CHANGES_XML} --ignore-warnings` : ''}`;\n    this.logger(`Deploy command: ${sfDeployCommand}`);\n    return `${sfDeployCommand}`;\n}\n\nasync function getTestRunParam(testLevel, isProductionEnvironment) {\n    let testRunParam = '';\n    if (testLevel) {\n        const testRun = testLevel?.split(' ')?.join('');\n        if (testRun && !(testRun === TEST_LEVEL.NO_TEST_RUN && isProductionEnvironment === 'true')) {\n            testRunParam += ` --test-level ${testRun}`;\n            if (testRun === TEST_LEVEL.RUN_SPECIFIED_TESTS) {\n                const contentVersionIdsOfTestClassesAndTestSuites = this.getContentVersionIdsOfTestClassesAndTestSuites(\n\t\t\t\t\ttestSuiteAndTestClassFileVersionDetails\n\t\t\t\t);\n\t\t\t\tconst apexTestClasses = await this.getDeploymentTestClasses(contentVersionIdsOfTestClassesAndTestSuites);\n\t\t\t\ttestRunParam = testRunParam + ' --tests ' + apexTestClasses;\n            }\n        }\n    }\n    return testRunParam;\n}\n\nfunction getMetadataTypeToNames(selectedRollbackChanges) {\n    const addMetadataTypesByName = new Map(),\n        deleteMetadataTypesByName = new Map();\n\n    selectedRollbackChanges[ROLLBACK_CATEGORY.DELETE].forEach(change => this.updateMap(deleteMetadataTypesByName, change.t, change.n));\n    selectedRollbackChanges[ROLLBACK_CATEGORY.UPSERT].forEach(change => this.updateMap(addMetadataTypesByName, change.t, change.n));\n    return { addMetadataTypesByName, deleteMetadataTypesByName };\n}\n\nfunction updateMap(typeToNamesMap, key, value) {\n    if (!typeToNamesMap.has(key)) {\n        typeToNamesMap.set(key, []);\n    }\n    typeToNamesMap.get(key).push(value);\n}\n\nfunction buildManifest(directory, metadataByType, isDestructiveManifest) {\n    const manifestFileName = isDestructiveManifest ? `${directory}/${DESTRUCTIVE_CHANGES_XML}` : `${directory}/${PACKAGE_XML}`;\n\n    let manifest = [];\n    manifest.push('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\" ?>\\n');\n    manifest.push('<Package xmlns=\"http://soap.sforce.com/2006/04/metadata\">\\n');\n    metadataByType.forEach((value, key) => {\n        manifest.push('\\t<types>\\n');\n        value.forEach(item => {\n            manifest.push(`\\t\\t<members>${item}</members>\\n`);\n        });\n\n        manifest.push(`\\t\\t<name>${key}</name>\\n`);\n        manifest.push('\\t</types>\\n');\n    });\n\n    manifest.push(`\\t<version>${sourceApiVersion}</version>\\n`);\n    manifest.push('</Package>\\n');\n\n    fs.writeFileSync(manifestFileName, manifest.join(''));\n}\n\nfunction handleRollbackResult(rollbackResult, isValidation, reject) {\n    this.uploadRollbackResult(rollbackResult);\n\n    let errorResponse = '';\n    const details = rollbackResult?.result?.details,\n        componentFailures = details?.componentFailures,\n        componentSuccesses = details?.componentSuccesses,\n        failures = details?.runTestResult?.failures,\n        codeCoverageWarnings = details?.runTestResult?.codeCoverageWarnings,\n        flowCoverageWarnings = details?.runTestResult?.flowCoverageWarnings;\n\n    // If any errors or warning, display to progress indicator and fail the job execution\n    if (rollbackResult?.status == 1) {\n        if (rollbackResult?.message) {\n            errorResponse = rollbackResult?.message;\n        } else if (rollbackResult?.result?.errorMessage) {\n            errorResponse = rollbackResult?.result?.errorMessage;\n        } else if (rollbackResult?.result.status == DEPLOYMENT_STATUS.CANCELED) {\n            errorResponse = `The ${isValidation === 'true' ? 'validation' : 'deployment'} was cancelled on the target org.`;\n        }\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.METADATA_EXECUTION, '', errorResponse);\n    }\n    // apex test failures\n    if (failures) {\n        const failureMessage = this.getFailedTestsErrorMessage(failures);\n        failureMessage &&\n            this.populateResultViewer(\n                RESULT_INFO.LEVEL.ERROR,\n                RESULT_INFO.CATEGORY.APEX_TEST_RUN,\n                RESULT_INFO.ADDITIONAL_INFORMATION.APEX_TEST_FAILURE,\n                failureMessage\n            );\n        errorResponse = this.populateErrorResponse(failureMessage, errorResponse);\n    }\n    // code coverage errors\n    if (codeCoverageWarnings) {\n        const failureMessage = this.getFailedTestsErrorMessage(codeCoverageWarnings);\n        this.populateResultViewer(\n            RESULT_INFO.LEVEL.ERROR,\n            RESULT_INFO.CATEGORY.APEX_TEST_RUN,\n            RESULT_INFO.ADDITIONAL_INFORMATION.CODE_COVERAGE_ERROR,\n            failureMessage\n        );\n        errorResponse = this.populateErrorResponse(failureMessage, errorResponse);\n    }\n\n    // flow coverage errors\n\n    if (flowCoverageWarnings) {\n        const failureMessage = this.getFailedTestsErrorMessage(flowCoverageWarnings);\n        this.populateResultViewer(\n            RESULT_INFO.LEVEL.ERROR,\n            RESULT_INFO.CATEGORY.FLOW_TEST_RUN,\n            RESULT_INFO.ADDITIONAL_INFORMATION.FLOW_TEST_FAILURE,\n            failureMessage\n        );\n        errorResponse = this.populateErrorResponse(failureMessage, errorResponse);\n    }\n    // metadata component deployment failures\n    if (componentFailures) {\n        const errorMetadata = this.filterFailedMedataByProblemType(componentFailures, 'Error');\n        if (errorMetadata.length) {\n            const failureMessage = this.getFailedComponentsErrorMessage(errorMetadata);\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.METADATA_EXECUTION, '', failureMessage);\n            errorResponse = this.populateErrorResponse(failureMessage, errorResponse);\n        }\n    }\n\n    // deployment warnings\n    if (componentSuccesses?.length) {\n        const warningMetadata = this.filterFailedMedataByProblemType(componentSuccesses, 'Warning');\n        if (warningMetadata?.length) {\n            const message = `WARNING deploying Metadata: ${this.getFailedComponentsErrorMessage(warningMetadata)}`;\n            this.asyncCopadoLogMessage(message.substring(0, 254), RESULT_INFO.LEVEL.WARN);\n            this.logger(message);\n        }\n    }\n\n    if (rollbackResult?.status || errorResponse) {\n        if (errorResponse) {\n            reject(new CommandExecutionError(errorResponse.substring(0, 131072)));\n        } else {\n            reject(new Error('There was some issue deploying the changes'));\n        }\n    }\n\n    if (!rollbackResult.status) {\n        this.populateResultViewer(\n            RESULT_INFO.LEVEL.INFO,\n            RESULT_INFO.CATEGORY.APEX_TEST_RUN,\n            RESULT_INFO.ADDITIONAL_INFORMATION.APEX_TEST_RUN_SUMMARY,\n            `Total Tests : ${rollbackResult.result.numberTestsCompleted} | Completed Tests : ${rollbackResult.result.numberTestsTotal}`\n        );\n        const message = componentSuccesses?.reduce((metadataInfo, component) => {\n            return component.componentType\n                ? metadataInfo\n                    ? `${metadataInfo}, ${component.componentType} : ${component.fullName}`\n                    : `${component.componentType} : ${component.fullName}`\n                : metadataInfo;\n        }, '');\n        this.populateResultViewer(\n            RESULT_INFO.LEVEL.INFO,\n            RESULT_INFO.CATEGORY.METADATA_EXECUTION,\n            RESULT_INFO.ADDITIONAL_INFORMATION.CONSOLIDATED_RESULT,\n            message\n        );\n    }\n}\n\nfunction filterFailedMedataByProblemType(failedComponents, problemType) {\n    let result = [];\n    if (Array.isArray(failedComponents)) {\n        result = failedComponents.filter(component => component.problemType == problemType);\n    } else if (failedComponents.problemType == problemType) {\n        result = [failedComponents];\n    }\n    return result;\n}\n\nfunction getFailedComponentsErrorMessage(failedComponents) {\n    let result = '';\n    if (Array.isArray(failedComponents)) {\n        result = failedComponents\n            .map(failure => failure[CONSTANTS.COMPONENT_TYPE].concat(':', failure[CONSTANTS.FULL_NAME], ':', failure[CONSTANTS.PROBLEM]))\n            .join('\\n');\n    } else {\n        result = failedComponents[CONSTANTS.COMPONENT_TYPE]\n            .concat(':', failedComponents[CONSTANTS.FULL_NAME], ':', failedComponents[CONSTANTS.PROBLEM])\n            .toString();\n    }\n    return result;\n}\n\nfunction getFailedTestsErrorMessage(failedTests) {\n    let result = '';\n    if (Array.isArray(failedTests)) {\n        let failedTestsError = failedTests.map(failedTest => {\n            let error = '';\n            error = failedTest.name ? (error ? error.concat('-', failedTest.name) : error.concat(failedTest.name)) : error;\n            error = failedTest.methodName ? (error ? error.concat('-', failedTest.methodName) : error.concat(failedTest.methodName)) : error;\n            error = error ? error.concat('-', failedTest.message) : error.concat(failedTest.message);\n            return error;\n        });\n        if (failedTestsError?.length) {\n            result = failedTestsError.join('\\n');\n        }\n    } else {\n        if (typeof failedTests.name != 'object') {\n            result = result.concat(`${failedTests.name}`);\n        }\n        result = failedTests.methodName ? (result ? result.concat('-', failedTests.methodName) : result.concat(failedTests.methodName)) : result;\n        result = result ? result.concat('-', failedTests.message) : result.concat(failedTests.message);\n    }\n    return result;\n}\n\nfunction populateErrorResponse(errorMessage, errorResponse) {\n    const delimiter = '\\n';\n    errorResponse = (errorResponse && errorResponse?.trim().concat(`${delimiter}`, errorMessage.trim())) || errorResponse.concat(errorMessage.trim());\n    return errorResponse;\n}\n\nfunction setInstanceUrl(instanceUrl) {\n    const baseUrl = instanceUrl?.substring(0, instanceUrl?.indexOf('/', instanceUrl?.indexOf('/') + 2));\n    this.executeCommand(\n        `sf config set org-instance-url=${baseUrl}`,\n        RESULT_INFO.CATEGORY.SFDX_CLI,\n        RESULT_INFO.ADDITIONAL_INFORMATION.SFDX_CONFIGURATION\n    );\n}\n\nfunction getApiVersion(overriddenApiVersion, apiVersion) {\n    const finalApiVersion = overriddenApiVersion || apiVersion;\n    const regExpApiVersion = /\\d\\d\\.0/;\n    if (!regExpApiVersion.test(finalApiVersion)) {\n        throw new Error(`Invalid API Version: ${finalApiVersion}`);\n    }\n    return finalApiVersion;\n}\n\nfunction gitCommit(commitMessage) {\n    if (!this.hasChange()) {\n        this.asyncCopadoLogMessage('There are no changes to be committed');\n        const vlocityChangesToBePushed = prevResult && JSON.parse(prevResult)?.vlocityChangesToBePushed;\n        if (!vlocityChangesToBePushed) {\n            process.exit(0);\n        }\n        return;\n    }\n    this.asyncCopadoLogMessage(`Committing Changes`);\n    this.executeCommand(\n        `\ngit add . || exit 1\ngit commit -m \"${commitMessage}\"\n`,\n        RESULT_INFO.CATEGORY.GIT,\n        RESULT_INFO.ADDITIONAL_INFORMATION.GIT_COMMIT\n    );\n}\n\nfunction gitPush(branchName) {\n    this.asyncCopadoLogMessage(`Pushing all changes to ${branchName}`);\n    this.executeCommand(`git push origin \"${branchName}\"`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_PUSH);\n}\n\nfunction hasChange() {\n    const gitStatus = this.executeCommand(`git status --porcelain`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS);\n    return gitStatus ? true : false;\n}\n\nfunction resetChangesInCurrentBranch() {\n    this.executeCommand(`git reset --hard || true`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_RESET);\n}\n\nfunction findFilePaths(selectedChanges, rollbackCategories, outputFilePath) {\n    const changes = this.getChanges(selectedChanges, rollbackCategories);\n    if (changes?.length) {\n        fs.writeFileSync(outputFilePath, JSON.stringify(changes));\n\n        // Enrich change json for selected actions\n        this.enrichChangeList(SOURCE_DIRECTORY, outputFilePath);\n    }\n}\n\nfunction getChanges(changes, rollbackCategories) {\n    const result = [];\n    rollbackCategories.forEach(category => {\n        result.push(...changes[category]);\n    });\n    return result;\n}\n\nfunction updateSelectedRollBackChangesFile(selectedChanges, filePath, rollbackCategories) {\n    let content = [];\n    if (fs.existsSync(filePath)) {\n        content = [...this.readFileContent(filePath)];\n    }\n    content = [...content, ...this.getChanges(selectedChanges, rollbackCategories)];\n    fs.writeFileSync(filePath, JSON.stringify(content));\n}\n\nfunction fetchTargetBranch(targetDirectory, branch) {\n    return new Promise((resolve, reject) => {\n        const fetchBranch = `\n        mkdir -p ${targetDirectory} || exit 1\n        cd ${TARGET_DIRECTORY} || exit 1\n        copado-git-get ${branch} --depth 1\n        `;\n\n        child_process.exec(fetchBranch, {}, (error, stdout, stderr) => {\n            if (error?.code) {\n                const errorResponse = stderr ? stderr : `Error executing the command : ${error?.cmd}`;\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.ERROR,\n                    RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_GIT_AUTHENTICATION,\n                    errorResponse\n                );\n                reject(new CommandExecutionError(errorResponse));\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\nfunction uploadRollbackResult(rollbackResult) {\n    const resultFilePath = '/tmp/RollbackResult.json';\n    fs.writeFileSync(resultFilePath, JSON.stringify(rollbackResult, null, 2));\n    this.uploadFileAtPath(resultFilePath);\n}\n\nfunction uploadFileAtPath(filePath) {\n    new Promise((resolve, reject) => {\n        child_process.exec(`copado --uploadfile ${filePath}`, {}, (error, stdout, stderr) => {\n            if (error?.code) {\n                const errorResponse = stderr ? stderr : `Error executing the command : ${error?.cmd}`;\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.ERROR,\n                    RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                    `Uploading file at ${filePath}`,\n                    errorResponse\n                );\n                reject(new CommandExecutionError(errorResponse));\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\nfunction getParentMetadataFile(filePath) {\n    const index = filePath.lastIndexOf('/');\n    const directory = filePath.substring(0, index + 1);\n\n    return directory + 'internal_' + filePath.substring(index + 1);\n}\n\nfunction setServiceLogLevel(logLevel) {\n    if (logLevel) {\n        process.env.SERVICE_LOG_LEVEL = logLevel;\n    }\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n    if (message) {\n        resultViewerJson.push({\n            Level: level,\n            Category: category,\n            Message: message,\n            AdditionalInformation: additionalInfo\n        });\n    }\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n    const RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n    const fileContent = { data, columns, header, headerIcon };\n    fs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n    this.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nasync function getDeploymentTestClasses(contentVersionIdsOfTestClassesAndTestSuites) {\n\tthis.asyncCopadoLogMessage(`Finding test classes for ${isValidation === 'true' ? 'validating the rollback' : 'rolling back the changes'}`);\n\tconst commands = [];\n\tcontentVersionIdsOfTestClassesAndTestSuites.forEach(contentVersionId => {\n\t\tconst command = {};\n\t\tcommand.value = `\n\t\t\t  mkdir -p ${TEMP_DIRECTORY}/${contentVersionId}\n\t\t\t  copado --downloadfiles \"${contentVersionId}\" --downloaddir ${TEMP_DIRECTORY}/${contentVersionId}\n\t\t  `;\n\t\tcommands.push(command);\n\t});\n\n\tconst totalCpus = cpus().length;\n\tconst parallelCommandExecutor = new this.ParallelCommandExecutor(commands, totalCpus == 1 ? 1 : totalCpus - 1);\n\tawait Promise.all(parallelCommandExecutor.startExecution());\n\n\tlet testClasses = new Set();\n\tconst testSuitesAndTestClassesFileContent = await Promise.all(\n\t\tthis.getPromisesToReadTestSuitesAndTestClassesFile(contentVersionIdsOfTestClassesAndTestSuites)\n\t);\n\ttestSuitesAndTestClassesFileContent.forEach(fileContent => {\n\t\ttestClasses = new Set([...testClasses, ...this.getSelectedTestClasses(fileContent)]);\n\t});\n\n\tif (!testClasses.size) {\n\t\tthrow new Error('No test classes were selected by the user');\n\t}\n\treturn [...testClasses].join(' ');\n}\n\nclass CommandExecutionError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n    }\n}\n\nfunction getPromisesToReadTestSuitesAndTestClassesFile(contentVersionIdsOfTestClassesAndTestSuites) {\n\tconst promises = [];\n\tcontentVersionIdsOfTestClassesAndTestSuites.forEach(contentVersionId => {\n\t\tconst testSuiteFilePath = `${TEMP_DIRECTORY}/${contentVersionId}/${CONSTANTS.TEST_SUITE_FILE_NAME}`;\n\t\tconst testClassFilePath = `${TEMP_DIRECTORY}/${contentVersionId}/${CONSTANTS.TEST_CLASS_FILE_NAME}`;\n\t\tif (fs.existsSync(testSuiteFilePath)) {\n\t\t\tpromises.push(this.readFileAsync(testSuiteFilePath, true));\n\t\t}\n\t\tif (fs.existsSync(testClassFilePath)) {\n\t\t\tpromises.push(this.readFileAsync(testClassFilePath, true));\n\t\t}\n\t});\n\treturn promises;\n}\n\nfunction getSelectedTestClasses(testClassesAndTestSuitesFileContent) {\n\tlet result = new Set();\n\ttestClassesAndTestSuitesFileContent?.forEach(data => {\n\t\tif (data.children) {\n\t\t\tresult = new Set([...result, ...this.getSelectedTestClasses(data.children)]);\n\t\t} else if (data.s) {\n\t\t\tresult.add(data.n);\n\t\t}\n\t});\n\treturn result;\n}\n\nfunction getContentVersionIdsOfTestClassesAndTestSuites(testSuiteAndTestClassFileVersionDetails) {\n\tlet result;\n\ttry {\n\t\tresult = testSuiteAndTestClassFileVersionDetails ? JSON.parse(testSuiteAndTestClassFileVersionDetails) : [];\n\t} catch (error) {\n\t\tthrow new Error(`Error finding test suite and test class file ids, ${error.toString()}`);\n\t}\n\treturn result;\n}\n\nclass ParallelCommandExecutor {\n\tcommands;\n\tmaxAllowedChildProcesses;\n\n\tconstructor(commands, maxAllowedChildProcesses) {\n\t\tthis.commands = commands;\n\t\tthis.maxAllowedChildProcesses = maxAllowedChildProcesses;\n\t}\n\n\tstartExecution() {\n\t\tconst promises = [];\n\t\tlet totalConsumedChildProcesses = 0;\n\t\tconst totalCommands = this.commands?.length;\n\t\tif (!totalCommands || totalCommands < 1) {\n\t\t\tthrow new Error('No commands supplied to the command processor');\n\t\t}\n\n\t\twhile (this.commands.length && this.maxAllowedChildProcesses > totalConsumedChildProcesses) {\n\t\t\tpromises.push(\n\t\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\t\tthis._executeCommand(this.commands.shift(), resolve, reject);\n\t\t\t\t})\n\t\t\t);\n\t\t\ttotalConsumedChildProcesses++;\n\t\t}\n\t\tlogger(`Parallel command executor started ${promises.length} child process(es) for processing ${totalCommands} command(s)`);\n\t\treturn promises;\n\t}\n\n\t_executeCommand(command, resolve, reject) {\n\t\tlet output = '',\n\t\t\terror = '';\n\t\tconst childProcess = child_process.spawn(command.value, [], {\n\t\t\tshell: true\n\t\t});\n\n\t\tchildProcess.stdout.on('data', data => {\n\t\t\toutput += data?.toString();\n\t\t});\n\n\t\tchildProcess.stderr.on('data', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('error', data => {\n\t\t\terror += data?.toString();\n\t\t});\n\n\t\tchildProcess.on('close', code => {\n\t\t\tif (!command.disableLogs) {\n\t\t\t\tlogger(`command: ${command.value}, \\ncode: ${code}`);\n\t\t\t\tif (output) {\n\t\t\t\t\tlogger(output);\n\t\t\t\t}\n\t\t\t\tif (error) {\n\t\t\t\t\tlogger(error);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (code !== 0) {\n\t\t\t\tlet errorMessage = '';\n\t\t\t\tif (command.hasJsonResponse) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\terrorMessage = JSON.parse(output);\n\t\t\t\t\t} catch (err) {\n\t\t\t\t\t\terrorMessage = err.toString();\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\terrorMessage = error;\n\t\t\t\t}\n\t\t\t\terrorMessage = errorMessage ? errorMessage : `Error executing the command ${command.value}`;\n\t\t\t\treject(errorMessage);\n\t\t\t} else {\n\t\t\t\tthis._handleNextExecution(resolve, reject);\n\t\t\t}\n\t\t});\n\t}\n\n\t_handleNextExecution(resolve, reject) {\n\t\tif (this.commands.length) {\n\t\t\tthis._executeCommand(this.commands.shift(), resolve, reject);\n\t\t} else {\n\t\t\tlogger('Parallel command executor resolved a child process');\n\t\t\tresolve('Parallel command executor resolved a child process');\n\t\t}\n\t}\n}\n\nfunction readFileAsync(filePath, isJsonContent) {\n\treturn new Promise((resolve, reject) => {\n\t\tfs.readFile(filePath, (error, data) => {\n\t\t\tif (error) {\n\t\t\t\treject(error);\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tresolve(isJsonContent ? JSON.parse(data.toString()) : data.toString());\n\t\t\t\t} catch (err) {\n\t\t\t\t\treject(err.toString());\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t});\n}\n\nmodule.exports.fetchBranch = fetchBranch;\nmodule.exports.execute = execute;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.log = log;\nmodule.exports.configureGit = configureGit;\nmodule.exports.enrichChangeList = enrichChangeList;\nmodule.exports.findFilePaths = findFilePaths;\nmodule.exports.readFileContent = readFileContent;\nmodule.exports.downloadFile = downloadFile;\nmodule.exports.getFilePaths = getFilePaths;\nmodule.exports.getFilesInScope = getFilesInScope;\nmodule.exports.varReplace = varReplace;\nmodule.exports.findAndReplace = findAndReplace;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.callMetadataProcessor = callMetadataProcessor;\nmodule.exports.rollback = rollback;\nmodule.exports.getMetadataTypeToNames = getMetadataTypeToNames;\nmodule.exports.updateMap = updateMap;\nmodule.exports.buildManifest = buildManifest;\nmodule.exports.getTestRunParam = getTestRunParam;\nmodule.exports.getSFDeployCmd = getSFDeployCmd;\nmodule.exports.handleRollbackResult = handleRollbackResult;\nmodule.exports.filterFailedMedataByProblemType = filterFailedMedataByProblemType;\nmodule.exports.getFailedTestsErrorMessage = getFailedTestsErrorMessage;\nmodule.exports.getFailedComponentsErrorMessage = getFailedComponentsErrorMessage;\nmodule.exports.populateErrorResponse = populateErrorResponse;\nmodule.exports.setInstanceUrl = setInstanceUrl;\nmodule.exports.gitCommit = gitCommit;\nmodule.exports.gitPush = gitPush;\nmodule.exports.hasChange = hasChange;\nmodule.exports.resetChangesInCurrentBranch = resetChangesInCurrentBranch;\nmodule.exports.getSelectedRollbackChanges = getSelectedRollbackChanges;\nmodule.exports.hasSelectedSFDXChanges = hasSelectedSFDXChanges;\nmodule.exports.updateSelectedRollBackChangesFile = updateSelectedRollBackChangesFile;\nmodule.exports.getChanges = getChanges;\nmodule.exports.fetchTargetBranch = fetchTargetBranch;\nmodule.exports.uploadRollbackResult = uploadRollbackResult;\nmodule.exports.addParentMetadataToOriginalChangeList = addParentMetadataToOriginalChangeList;\nmodule.exports.getParentMetadataFile = getParentMetadataFile;\nmodule.exports.setServiceLogLevel = setServiceLogLevel;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.logger = logger;\nmodule.exports.getDeploymentTestClasses = getDeploymentTestClasses;\nmodule.exports.checkDeploymentStatus = checkDeploymentStatus;\nmodule.exports.executeCommandAsync = executeCommandAsync;\nmodule.exports.getSelectedTestClasses = getSelectedTestClasses;\nmodule.exports.getContentVersionIdsOfTestClassesAndTestSuites = getContentVersionIdsOfTestClassesAndTestSuites;\nmodule.exports.getPromisesToReadTestSuitesAndTestClassesFile = getPromisesToReadTestSuitesAndTestClassesFile;\nmodule.exports.ParallelCommandExecutor = ParallelCommandExecutor;\nmodule.exports.readFileAsync = readFileAsync;\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0k0900000Isk2EAAR",
                    "LastReferencedDate": "2023-11-20T11:52:00.000+0000",
                    "LastViewedDate": "2023-11-20T11:52:00.000+0000",
                    "Name": "SFDX Rollback"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v59.0/sobjects/copado__Function__c/a0l7Q000000XBKvQAO"
                    },
                    "copado__API_Name__c": "vlocity_rollback",
                    "copado__Image_Name__c": "copado-multicloud-vlocity:v1",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"name\" : \"sfdxRollbackFileId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.rollbackFileId}\"\n}, {\n  \"name\" : \"isValidation\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.isValidation}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationInstanceUrl\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationSessionid\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"name\" : \"destinationEnvVariables\",\n  \"defaultValue\" : \"{$Destination.apex.EnvironmentVariables}\"\n}, {\n  \"name\" : \"findAndReplaceFileId\",\n  \"defaultValue\" : \"{$Context.apex.GlobalFindAndReplaceDestinationId}\"\n}, {\n  \"name\" : \"promotion\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.promotion}\"\n}, {\n  \"name\" : \"gitName\",\n  \"defaultValue\" : \"{$User.Name}\"\n}, {\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"name\" : \"targetBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.targetBranch}\"\n}, {\n  \"name\" : \"serviceLogLevel\",\n  \"defaultValue\" : \"{$Pipeline.Property.service_log_level}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"name\" : \"vlocityDirectory\",\n  \"defaultValue\" : \"vlocity\"\n}, {\n  \"name\" : \"vlocityRollbackFileId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.vlocityRollbackFileId}\"\n}, {\n  \"name\" : \"vlocitySettingsDocumentId\",\n  \"defaultValue\" : \"{$Context.apex.cmcSf.VlocitySettingsDestinationId}\"\n}, {\n  \"name\" : \"attachVlocityLogFile\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.Promotion__r.cmcSf__Attach_Vlocity_Build_File__c}\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\n/**\n* Performs complete or partial rollback of the selected promotion changes\n\n\n* @param rollbackFileId\n* @param isValidation\n* @param promotion (or rollback branch name)\n* @param targetBranch\n* @param destinationInstanceUrl\n* @param destinationSessionid\n* @param gitName\n* @param gitEmail\n* @param maxBuffer\n* @param destinationEnvVariables\n* @param findAndReplaceFileId\n* @param vlocityDirectory\n* @param vlocityRollbackFileId\n* @param vlocitySettingsDocumentId\n* @param attachVlocityLogFile\n*/\n\nconst child_process = require('child_process'),\n    fs = require('fs'),\n    {\n        sfdxRollbackFileId,\n        isValidation,\n        promotion,\n        gitEmail,\n        gitName,\n        targetBranch,\n        destinationInstanceUrl,\n        destinationSessionid,\n        findAndReplaceFileId,\n        destinationEnvVariables,\n        maxBuffer,\n        vlocityDirectory,\n        vlocityRollbackFileId,\n        vlocitySettingsDocumentId,\n        attachVlocityLogFile,\n        isTest\n    } = process.env,\n    url = destinationInstanceUrl.substring(0, destinationInstanceUrl.indexOf('/', destinationInstanceUrl.indexOf('/') + 2)),\n    rollbackBranch = `rollback/${promotion}`,\n    TEMP_DIRECTORY = getPath('/tmp'),\n    APP_DIRECTORY = getPath('/app'),\n    SOURCE_DIRECTORY = `${APP_DIRECTORY}/source`,\n    TARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n    ROLLBACK_CHANGES_JSON = 'Copado Rollback changes',\n    VLOCITY_ROLLBACK_CHANGES_JSON = 'Copado Vlocity Rollback changes',\n    VLOCITY_BUILD_LOG = 'VlocityBuildLog.yaml',\n    VLOCITY_SETTINGS_YAML_FILE = 'vlocity-settings',\n    CATEGORY = { VLOCITY: 'Vlocity', SFDX: 'SFDX' },\n    JOB_FILE = 'jobfile.yaml',\n    js_yaml = isTest ? require('js-yaml') : require('/usr/local/lib/node_modules/js-yaml'),\n    STDIO = {\n        INHERIT: 'inherit'\n    },\n    UPDATE_ACTION = 'Update',\n    MAXBUFFER = parseInt(maxBuffer),\n    resultViewerJson = [],\n    RESULT_INFO = {\n        LEVEL: {\n            INFO: 'INFO',\n            ERROR: 'ERROR',\n            WARN: 'WARN'\n        },\n        CATEGORY: {\n            UNKNOWN_EXCEPTION: 'Unknown Exception',\n            COPADO_INFO: 'Copado Info',\n            GIT: 'Git',\n            COPADO_SERVICE: 'Copado Service',\n            VBT_CLI: 'VBT CLI',\n            METADATA_EXECUTION: 'Datapacks Deployment',\n            FILE_SYSTEM: 'File System'\n        },\n        ADDITIONAL_INFORMATION: {\n            CONSOLIDATED_RESULT: `Consolidated ${isValidation === 'true' ? 'Validation' : 'Deployment'} Result`,\n            GIT_STATUS: 'Git Status',\n            ROLLBACK_BRANCH_CHECKOUT: 'Rollback Branch Checkout',\n            GIT_COMMIT: 'Git Commit',\n            GIT_RESET: 'Git Reset',\n            GIT_CONFIGURATION: 'Git configuration',\n            COPADO_GIT_AUTHENTICATION: 'Copado Git Authentication',\n            GIT_PUSH: 'Git Push',\n            POPULATE_INFO_ON_RESULT: 'Populate Information on the result record',\n            ENV_VARIABLE_REPLACEMENT: 'Environment Variable Replacement',\n            GLOBAL_FIND_AND_REPLACE: 'Global Find and Replace',\n            VLOCITY_ROLLBACK: 'Datapacks Rollback'\n        }\n    },\n    CUSTOM_ERROR = {\n        COMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n    },\n    RESULT_TABLE_COLUMNS = [\n        {\n            label: 'Level',\n            fieldName: 'Level',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Level',\n            initialWidth: 80\n        },\n        {\n            label: 'Category',\n            fieldName: 'Category',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Category',\n            initialWidth: 120\n        },\n        {\n            label: 'Additional Information',\n            fieldName: 'AdditionalInformation',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Additional_Information',\n            initialWidth: 200\n        },\n        {\n            label: 'Message',\n            fieldName: 'Message',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Message'\n        }\n    ],\n    RESULT_TABLE_HEADER = {\n        label: 'Vlocity Rollback Result',\n        customLabel: 'Rollback_Result'\n    },\n    HEADER_ICON = 'standard:note';\n\nlet hasSfdxChanges, executionError;\n\n// EXECUTION\n\nasync function execute() {\n    try {\n        this.displayVersions();\n        this.validateRollbackChangesFileIds(vlocityRollbackFileId, sfdxRollbackFileId);\n\n        const vlocityRollbackFileContent = this.readFileContent(`${TEMP_DIRECTORY}/${VLOCITY_ROLLBACK_CHANGES_JSON}`);\n        this.hasSfdxRollbackChanges(vlocityRollbackFileContent, `${TEMP_DIRECTORY}/${ROLLBACK_CHANGES_JSON}`);\n\n        this.fetchBranch(SOURCE_DIRECTORY, rollbackBranch);\n\n        const selectedRollbackChanges = this.getSelectedRollbackChanges(vlocityRollbackFileContent);\n        let validRollbackChanges = [];\n        if (selectedRollbackChanges?.length) {\n            validRollbackChanges = this.getFilesInScope(selectedRollbackChanges);\n            this.varReplace(destinationEnvVariables);\n            this.findAndReplace(findAndReplaceFileId, `rollback/${promotion}`);\n        }\n\n        if (!validRollbackChanges?.length) {\n            this.uploadResultFileAndExit(`Could not find any valid vlocity changes to rollback`);\n        }\n\n        await Promise.all(\n            [\n                new Promise((resolve, reject) => {\n                    try {\n                        this.writeJobFile(JOB_FILE, validRollbackChanges);\n                        this.updateJobFileFromSettings(vlocitySettingsDocumentId, JOB_FILE);\n                        this.deployVlocity(JOB_FILE, attachVlocityLogFile === 'true');\n                        resolve();\n                    } catch (error) {\n                        reject(error);\n                    }\n                })\n            ],\n            [\n                new Promise((resolve, reject) => {\n                    try {\n                        this.fetchBranch(TARGET_DIRECTORY, targetBranch);\n                        this.configureGit(gitEmail, gitName);\n                        resolve();\n                    } catch (error) {\n                        reject(error);\n                    }\n                })\n            ]\n        );\n\n        if (validRollbackChanges?.length) {\n            process.chdir(SOURCE_DIRECTORY);\n            this.resetChangesInCurrentBranch();\n            process.chdir(TARGET_DIRECTORY);\n        }\n\n        this.copyFilesFromSourceDirectory(validRollbackChanges);\n        this.executeCommand(`copado -p \"Saving Vlocity Changes\" -r '${JSON.stringify({ vlocityChangesToBePushed: true })}'`);\n\n        if (isValidation !== 'true' && !hasSfdxChanges) {\n            this.gitCommit(`Copado Rollback for promotion ${promotion}`);\n            this.gitPush(targetBranch);\n        }\n    } catch (err) {\n        console.log('Error stack: ', err.stack);\n        executionError = err.message || err?.toString() || 'Unknown Error occurred';\n        if (!(err instanceof CommandExecutionError)) {\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, `See logs for more info`, executionError);\n        }\n    } finally {\n        if (resultViewerJson?.length) {\n            this.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n        }\n        if (executionError) {\n            this.executeCommand(\n                this.getErrorCmdString(executionError),\n                RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                RESULT_INFO.ADDITIONAL_INFORMATION.POPULATE_INFO_ON_RESULT\n            );\n            process.exit(1);\n        }\n    }\n}\n\n// SCRIPT FUNCTIONS\n\nfunction copyFilesFromSourceDirectory(validRollbackChanges) {\n    validRollbackChanges.forEach((change) => {\n        const additionalInfo = JSON.parse(change.j);\n        this.copyFiles(`${SOURCE_DIRECTORY}/${additionalInfo?.filePath}/.`, `${TARGET_DIRECTORY}/${additionalInfo?.filePath}/`);\n    });\n}\n\nfunction validateRollbackChangesFileIds(vlocityChangesFileId, sfdxChangesFileId) {\n    if (!vlocityChangesFileId) {\n        this.uploadResultFileAndExit(`No Vlocity Datapacks found for Rollback. Exiting Vlocity Rollback Step.`);\n    } else {\n        this.downloadFile(vlocityRollbackFileId, TEMP_DIRECTORY, VLOCITY_ROLLBACK_CHANGES_JSON);\n    }\n    if (!sfdxChangesFileId) {\n        this.asyncCopadoLogMessage(`No Salesforce Rollback Changes found.`);\n        hasSfdxChanges = false;\n    } else {\n        this.downloadFile(sfdxChangesFileId, TEMP_DIRECTORY, ROLLBACK_CHANGES_JSON);\n    }\n}\n\nfunction hasSfdxRollbackChanges(vlocityChanges, sfdxFilePath) {\n    if (!vlocityChanges.some((change) => change.c === CATEGORY.VLOCITY && change.s === true)) {\n        this.uploadResultFileAndExit(`No Vlocity Datapacks found for Rollback. Exiting Vlocity Rollback Step.`);\n    }\n    if (hasSfdxChanges) {\n        const sfdxChanges = this.readFileContent(sfdxFilePath);\n        hasSfdxChanges = sfdxChanges.some((change) => change.c === CATEGORY.SFDX && change.s === true);\n    }\n}\n\nfunction fetchBranch(directory, branch) {\n    fs.mkdirSync(directory, { recursive: true });\n    process.chdir(directory);\n\n    this.executeCommand(`copado -p 'Fetching ${branch}'`);\n    this.executeCommand(\n        `copado-git-get ${branch} --depth 1`,\n        RESULT_INFO.CATEGORY.COPADO_SERVICE,\n        RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_GIT_AUTHENTICATION\n    );\n}\n\nfunction configureGit(gitEmail, gitName) {\n    const configureGit = `\n        git config --local user.email \"${gitEmail}\" || exit 1\n        git config --local user.name \"${gitName}\" || exit 1\n        git config --global diff.renames false || exit 1\n        git config --global merge.renames false || exit 1\n        git config --global status.renames false || exit 1\n    `;\n    this.executeCommand(`${configureGit}`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CONFIGURATION);\n}\n\nfunction getSelectedRollbackChanges(selectedChanges) {\n    const result = [];\n    selectedChanges.forEach((change) => {\n        if (change.s && change.c === CATEGORY.VLOCITY && change.a.toLowerCase() === UPDATE_ACTION.toLowerCase()) {\n            const additionalInfo = JSON.parse(change.j);\n            const datapackKey = additionalInfo?.vk?.split('/');\n            change.n = datapackKey[1]\n                ?.replace('\\\\', '-')\n                .replace(/[^A-Za-z0-9/_\\-]+/g, '-')\n                .replace(/[-]+/g, '-')\n                .replace(/[-_]+_/g, '_')\n                .replace(/[-]+\\/[-]+/g, '/')\n                .replace(/^[-_\\\\/]+/, '')\n                .replace(/[-_\\\\/]+$/, '');\n\n            change.j = JSON.stringify({ ...additionalInfo, filePath: `${vlocityDirectory}/${change.t}/${change.n}` });\n            result.push(change);\n        }\n    });\n    return result;\n}\n\nfunction executeCommand(command, category, additionalnfo, hasJsonResponse) {\n    let errorMessage;\n    const options = {\n        shell: true,\n        maxBuffer: MAXBUFFER\n    };\n    const response = child_process.spawnSync(command, options);\n    const { outputStream, errorStream } = this.log(response);\n    if (response?.status == 0) {\n        return hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n    }\n    if (!hasJsonResponse) {\n        errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n    } else {\n        try {\n            return JSON.parse(outputStream);\n        } catch (error) {\n            errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n        }\n    }\n    if (errorMessage) {\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalnfo, errorMessage);\n        throw new CommandExecutionError(errorMessage);\n    }\n}\n\nfunction getErrorCmdString(error) {\n    const suffix = 'Please check the logs for details.';\n    return `{ copado -p \"Error\" -e \"${error.trim()}; ${suffix}\";\n}`;\n}\n\nfunction log(response) {\n    const outputStream = response?.stdout?.toString().trim();\n    const errorStream = response?.stderr?.toString().trim();\n    if (outputStream) {\n        console.log(outputStream);\n    }\n    if (errorStream) {\n        console.log(errorStream);\n    }\n    return { outputStream, errorStream };\n}\n\nfunction downloadFile(fileId, downloadDir, fileName) {\n    return this.executeCommand(\n        `copado --downloadfiles ${fileId} --downloaddir ${downloadDir}`,\n        RESULT_INFO.CATEGORY.COPADO_SERVICE,\n        `File: ${fileId} download in directory ${downloadDir}`\n    );\n}\n\nfunction readFileContent(filePath) {\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Could not find file at path: ${filePath}`);\n    }\n    const data = fs.readFileSync(filePath, 'utf-8');\n\n    try {\n        return JSON.parse(data);\n    } catch (err) {\n        throw new Error(`Content at ${filePath} is not a valid JSON`);\n    }\n}\n\nfunction writeJobFile(jobFile, vlocityChanges) {\n    const jobFileParameters = this.defaultJobParameters(vlocityChanges);\n    fs.writeFileSync(jobFile, js_yaml.dump(jobFileParameters), 'utf8');\n}\n\nfunction defaultJobParameters(vlocityDataPacks) {\n    return {\n        projectPath: `./${vlocityDirectory}`,\n        oauthConnection: true,\n        autoUpdateSettings: true,\n        separateMatrixVersions: true,\n        separateCalculationProcedureVersions: true,\n        reactivateOmniScriptsWhenEmbeddedTemplateFound: true,\n        manifest: vlocityDataPacks.map((currentData) => {\n            return JSON.parse(currentData.j)?.vk;\n        })\n    };\n}\nfunction updateJobFileFromSettings(vlocitySettingsDocumentId, jobFileName) {\n    if (vlocitySettingsDocumentId) {\n        this.downloadFile(vlocitySettingsDocumentId, TEMP_DIRECTORY, VLOCITY_SETTINGS_YAML_FILE);\n        const vlocitySettings = js_yaml.load(fs.readFileSync(`${TEMP_DIRECTORY}/${VLOCITY_SETTINGS_YAML_FILE}`, 'utf-8'));\n        let settings = vlocitySettings?.deploy ? Object.keys(vlocitySettings.deploy) : [];\n\n        if (settings.length) {\n            const jobYaml = js_yaml.load(fs.readFileSync(jobFileName, 'utf-8'));\n            settings.forEach((setting) => {\n                if (setting !== 'manifest' && setting !== 'projectPath' && setting !== 'maxDepth') {\n                    jobYaml[setting] = vlocitySettings.deploy[setting];\n                }\n            });\n            fs.writeFileSync(jobFileName, js_yaml.dump(jobYaml), 'utf8');\n            this.asyncCopadoLogMessage('Vlocity Settings would be applied');\n        } else {\n            this.asyncCopadoLogMessage('Vlocity Settings not found');\n        }\n    }\n}\n\nfunction deployVlocity(jobFile, attachFile) {\n    this.asyncCopadoLogMessage(`Rolling back Vlocity changes on the destination environment`);\n    const deployVlocityCommand = `vlocity -sf.sessionId ${destinationSessionid} -sf.instanceUrl ${url} -job ${jobFile} packDeploy --json-pretty`;\n\n    console.log('Deploy Command: ' + deployVlocityCommand);\n    console.log('jobfile.yaml \\n' + fs.readFileSync(jobFile, 'utf-8'));\n\n    const response = this.executeCommand(\n        deployVlocityCommand,\n        RESULT_INFO.CATEGORY.VBT_CLI,\n        RESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_ROLLBACK,\n        true\n    );\n    if (attachFile || response?.status === 'error') {\n        this.uploadFile(VLOCITY_BUILD_LOG);\n    }\n    this.evaluateResponse(response);\n}\n\nfunction evaluateResponse(response) {\n    if (response?.status === 'error' && response?.message) {\n        this.handleDeploymentErrors(response);\n    }\n\n    if (response?.status === 'success' && response?.message === '0 Completed') {\n        this.asyncCopadoLogMessage('No Vlocity datapack rolled back');\n    }\n}\n\nfunction handleDeploymentErrors(response) {\n    let errorCount = 0,\n        successCount = 0,\n        warningCount = 0;\n    response?.records.forEach((record) => {\n        if (record?.VlocityDataPackStatus === 'Success') {\n            console.log(`INFO: Deployment was successful for ${record?.VlocityDataPackDisplayLabel}`);\n            successCount++;\n        } else if (record?.VlocityDataPackStatus === 'Error') {\n            if (record?.ErrorMessage.includes('Activation Error >>')) {\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.WARN,\n                    RESULT_INFO.CATEGORY.VBT_CLI,\n                    RESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_ROLLBACK,\n                    record?.ErrorMessage\n                );\n\n                console.log(`WARNING: ${record?.ErrorMessage}`);\n                warningCount++;\n                return;\n            }\n            this.populateResultViewer(\n                RESULT_INFO.LEVEL.ERROR,\n                RESULT_INFO.CATEGORY.VBT_CLI,\n                RESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_ROLLBACK,\n                record?.ErrorMessage\n            );\n            console.log(`ERROR: ${record?.ErrorMessage}`);\n            errorCount++;\n        }\n    });\n\n    if (warningCount > 0) {\n        this.asyncCopadoLogMessage(`copado -p 'Warnings during deployment'`);\n    }\n\n    if (successCount > 0 && errorCount > 0) {\n        this.asyncCopadoLogMessage('Git merge aborted due to errors', RESULT_INFO.LEVEL.ERROR);\n        console.log(`ERROR: Some datapacks were successfully deployed but the changes were not merged into the destination branch.`);\n    }\n\n    if ((response?.status === 'error' && response?.records?.length === 0) || errorCount > 0) {\n        this.populateResultViewer(\n            RESULT_INFO.LEVEL.ERROR,\n            RESULT_INFO.CATEGORY.VBT_CLI,\n            RESULT_INFO.ADDITIONAL_INFORMATION.VLOCITY_ROLLBACK,\n            `Deployment for following DataPacks failed : ${response.message}`\n        );\n        throw new Error(`Deployment for following DataPacks failed : ${response.message}`);\n    }\n}\n\nfunction getFilesInScope(selectedRollbackChanges) {\n    const filesInScope = [];\n\n    selectedRollbackChanges.forEach((change) => {\n        if (change.j && change.j !== '') {\n            const jsonAdditionalInfo = JSON.parse(change.j);\n            let filesToBeAdded = fs.existsSync(jsonAdditionalInfo?.filePath);\n            if (filesToBeAdded) {\n                filesInScope.push(change);\n            }\n        }\n    });\n    return filesInScope;\n}\n\nfunction varReplace(destinationEnvVariables) {\n    if (destinationEnvVariables && JSON.parse(destinationEnvVariables)?.length) {\n        this.asyncCopadoLogMessage('Replacing environment variables');\n        const varreplace = `varreplace '${destinationEnvVariables}' '${SOURCE_DIRECTORY}'`;\n        this.executeCommand(varreplace, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.ENV_VARIABLE_REPLACEMENT);\n    }\n}\n\nfunction findAndReplace(findAndReplaceFileId, branch) {\n    const COPADO_YML = 'Copado',\n        PATH_TO_YAML = `${TEMP_DIRECTORY}/${COPADO_YML}`;\n    if (findAndReplaceFileId) {\n        this.asyncCopadoLogMessage('Applying global find and replace rules');\n        this.downloadFile(findAndReplaceFileId, `${TEMP_DIRECTORY}/`, COPADO_YML);\n        if (fs.existsSync(PATH_TO_YAML)) {\n            const findAndReplace = `yamlreplace \"${PATH_TO_YAML}\" \"${SOURCE_DIRECTORY}\" -b \"${branch}\"`;\n            this.executeCommand(findAndReplace, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.GLOBAL_FIND_AND_REPLACE);\n        } else {\n            throw new Error('Could not find the Copado.yml file');\n        }\n    }\n}\n\nfunction asyncCopadoLogMessage(msg, level) {\n    this.populateResultViewer(level ? level : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n    new Promise((resolve) => {\n        child_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, () => {\n            resolve();\n        });\n    });\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname} /__tests__/__mockDir__${filePath} ` : filePath;\n}\n\nfunction uploadFile(fileName) {\n    this.executeCommand(`copado --uploadfile ${fileName} || true`);\n}\n\nfunction copyFiles(source, target) {\n    this.executeCommand(\n        `\n        cp -R ${source} ${target}\n    `,\n        RESULT_INFO.CATEGORY.FILE_SYSTEM\n    );\n}\n\nfunction gitCommit(commitMessage) {\n    if (!this.hasChange()) {\n        this.uploadResultFileAndExit(`There are no changes to be committed`);\n    }\n    this.asyncCopadoLogMessage(`Committing Changes`);\n    this.executeCommand(\n        `\ngit add . || exit 1\ngit commit -m \"${commitMessage}\"\n`,\n        RESULT_INFO.CATEGORY.GIT,\n        RESULT_INFO.ADDITIONAL_INFORMATION.GIT_COMMIT\n    );\n}\n\nfunction gitPush(branchName) {\n    this.asyncCopadoLogMessage(`Pushing all the changes to ${branchName}`);\n    this.executeCommand(`git push origin \"${branchName}\"`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_PUSH);\n}\n\nfunction hasChange() {\n    const gitStatus = this.executeCommand(`git status --porcelain`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_STATUS);\n    return gitStatus ? true : false;\n}\n\nfunction resetChangesInCurrentBranch() {\n    this.executeCommand(`git reset --hard || true`, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_RESET);\n}\n\nfunction getChanges(changes, rollbackCategories) {\n    const result = [];\n    rollbackCategories.forEach((category) => {\n        result.push(...changes[category]);\n    });\n    return result;\n}\n\nfunction fetchTargetBranch(targetDirectory, branch) {\n    const fetchBranch = `\n        mkdir -p ${targetDirectory} || exit 1\n        cd ${TARGET_DIRECTORY} || exit 1\n        copado-git-get ${branch} --depth 1\n    `;\n    this.executeCommand(fetchBranch, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_GIT_AUTHENTICATION);\n}\n\nfunction uploadRollbackResult(rollbackResult) {\n    const resultFilePath = '/tmp/RollbackResult.json';\n    fs.writeFileSync(resultFilePath, JSON.stringify(rollbackResult, null, 2));\n    this.uploadFileAtPath(resultFilePath);\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n    if (message) {\n        resultViewerJson.push({\n            Level: level,\n            Category: category,\n            Message: message,\n            AdditionalInformation: additionalInfo\n        });\n    }\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n    const RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n    const fileContent = { data, columns, header, headerIcon };\n    fs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n    this.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n    new Promise((resolve, reject) => {\n        child_process.exec(`copado --uploadfile ${filePath}`, {}, (error, stdout, stderr) => {\n            if (error?.code) {\n                const errorResponse = stderr ? stderr : `Error executing the command : ${error?.cmd}`;\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.ERROR,\n                    RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                    `Uploading file at ${filePath}`,\n                    errorResponse\n                );\n                reject(new CommandExecutionError(errorResponse));\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\nfunction uploadResultFileAndExit(message) {\n    this.asyncCopadoLogMessage(message);\n    if (resultViewerJson?.length) {\n        this.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n    }\n    process.exit(0);\n}\n\nfunction displayVersions() {\n    child_process.execSync(\n        `\n            echo \"Node version: \"\n            node -v\n            echo \"VBT version: \"\n            vlocity -v\n        `,\n        { stdio: 'inherit' }\n    );\n}\n\nclass CommandExecutionError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n    }\n}\n\nmodule.exports.fetchBranch = fetchBranch;\nmodule.exports.execute = execute;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.log = log;\nmodule.exports.configureGit = configureGit;\nmodule.exports.validateRollbackChangesFileIds = validateRollbackChangesFileIds;\nmodule.exports.readFileContent = readFileContent;\nmodule.exports.downloadFile = downloadFile;\nmodule.exports.hasSfdxRollbackChanges = hasSfdxRollbackChanges;\nmodule.exports.getFilesInScope = getFilesInScope;\nmodule.exports.varReplace = varReplace;\nmodule.exports.findAndReplace = findAndReplace;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.writeJobFile = writeJobFile;\nmodule.exports.updateJobFileFromSettings = updateJobFileFromSettings;\nmodule.exports.deployVlocity = deployVlocity;\nmodule.exports.defaultJobParameters = defaultJobParameters;\nmodule.exports.getPath = getPath;\nmodule.exports.copyFiles = copyFiles;\nmodule.exports.uploadFile = uploadFile;\nmodule.exports.gitCommit = gitCommit;\nmodule.exports.gitPush = gitPush;\nmodule.exports.hasChange = hasChange;\nmodule.exports.resetChangesInCurrentBranch = resetChangesInCurrentBranch;\nmodule.exports.getSelectedRollbackChanges = getSelectedRollbackChanges;\nmodule.exports.handleDeploymentErrors = handleDeploymentErrors;\nmodule.exports.getChanges = getChanges;\nmodule.exports.fetchTargetBranch = fetchTargetBranch;\nmodule.exports.uploadRollbackResult = uploadRollbackResult;\nmodule.exports.evaluateResponse = evaluateResponse;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.copyFilesFromSourceDirectory = copyFilesFromSourceDirectory;\nmodule.exports.displayVersions = displayVersions;\nmodule.exports.uploadResultFileAndExit = uploadResultFileAndExit;\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": "1",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q000000XBKvQAO",
                    "LastReferencedDate": "2023-11-01T18:00:20.000+0000",
                    "LastViewedDate": "2023-11-01T18:00:20.000+0000",
                    "Name": "Vlocity Rollback"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v58.0/sobjects/copado__Function__c/a0l7Q00000E0bIWQAZ"
                    },
                    "copado__API_Name__c": "vlocity_git_snapshot",
                    "copado__Image_Name__c": "copado-multicloud-vlocity:v1",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceDirectory\",\n  \"defaultValue\" : \"vlocity\"\n}, {\n  \"required\" : true,\n  \"name\" : \"selections\",\n  \"defaultValue\" : \"{$Job.ExecutionParent.copado__Scope__c}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"endpointUrl\",\n  \"defaultValue\" : \"{$Source.Credential.EndpointURL}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"metadataRefreshResult\",\n  \"defaultValue\" : \"{$Job.PrevStep.Result__r.Result_Data__c}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n    { sourceSessionId, isTest, sourceDirectory, endpointUrl, selections, metadataRefreshResult } = process.env,\n    fs = require('fs'),\n    js_yaml = isTest ? require('js-yaml') : require('/usr/local/lib/node_modules/js-yaml'),\n    JOB_FILE = 'jobfile.yaml';\n\n// SCRIPT FUNCTIONS\n\nfunction execute() {\n    try {\n        this.displayVersions();\n        const vlocitySelections = this.getVlocitySelections(JSON.parse(selections));\n        this.createJobFile(JOB_FILE, vlocitySelections);\n        this.retrieveVlocityDataPacks(JOB_FILE);\n        this.updateResult();\n    } catch (err) {\n        //Error status = 3, is when we have Custom Error Message, where error is already populated on result and hence we do not need to call it again.\n        if (err?.status === 3) {\n            process.exit(1);\n        }\n        this.executeCommand(this.getErrorCmdString(err.toString()));\n    }\n}\n\nfunction retrieveVlocityDataPacks(jobFile) {\n    const vlocityCmd = `vlocity -sf.instanceUrl ${endpointUrl} -sf.sessionId ${sourceSessionId} -job ${jobFile} packExport --json || true`;\n    this.logger('Vlocity Command: \\n' + vlocityCmd);\n    this.logger('jobfile.yaml: \\n' + fs.readFileSync(jobFile, 'utf-8'));\n    const response = JSON.parse(this.executeCommand(`\n            copado -p 'Retrieving datapacks'\n            ${vlocityCmd}\n        `));\n    if(response?.status === 'error') {\n        this.executeCommand(`copado -p 'Snapshot successful. Failed to retrieve few datapacks, check logs for more details.'`);\n        response?.message.split('\\n').forEach(msg => {\n            this.logger('WARNING: '+msg);\n        });\n    }\n    \n}\n\nfunction createJobFile(jobFile, vlocityDataPacks) {\n    let maxDepth;\n    if(vlocityDataPacks?.length) {\n        maxDepth = 0;\n    }\n    const jobFileParameters = this.defaultJobParameters(vlocityDataPacks, maxDepth);\n    fs.writeFileSync(jobFile, js_yaml.dump(jobFileParameters), 'utf8');\n}\n\nfunction defaultJobParameters(vlocityDataPacks, maxDepth) {\n    return {\n        projectPath: `./${sourceDirectory}`,\n        oauthConnection: true,\n        autoUpdateSettings: true,\n        separateMatrixVersions: true,\n        separateCalculationProcedureVersions: true,\n        maxDepth,\n        manifest: vlocityDataPacks\n    };\n}\n\nfunction logger(text) {\n    console.log(text);\n}\n\nfunction maskSensitiveInformation(data, sensitiveFlags) {\n    const maskingSequence = '*****';\n\n    const arrayOfData = data.split(' ');\n    Object.keys(sensitiveFlags).forEach(subStr => {\n        const keyIndex = arrayOfData.indexOf(subStr);\n        if (keyIndex > -1) {\n            arrayOfData[keyIndex + 1] = maskingSequence;\n            arrayOfData.splice(keyIndex + 2, sensitiveFlags[subStr].split(' ').length - 1);\n        }\n    });\n    return arrayOfData.join(' ');\n}\n\nfunction updateResult() {\n    this.executeCommand(`copado -p 'Updating result' -r ${JSON.stringify(metadataRefreshResult)}`);\n}\n\nfunction getVlocitySelections(selections) {\n    if (selections?.Vlocity === null || (!selections?.Vlocity?.included?.length && !selections?.Vlocity?.excluded?.length)) {\n        const message = JSON.stringify(\"Snapshot doesn't contain any Vlocity Datapacks\");\n        this.logger(`INFO:: ${message}`);\n        this.executeCommand(`copado -p ${message}`);\n\n        this.updateResult();\n        process.exit(0);\n    } else if (!selections?.Vlocity?.excluded?.length) {\n        // Returning nothing means do not add anything in manifest so it can retrieve everything.\n        return;\n    } else if (selections?.Vlocity?.included?.length) {\n        return selections.Vlocity.included;\n    }\n}\n\nfunction executeCommand(cmd, ioconfig) {\n    const response = child_process.spawnSync(cmd, this.getOptions(ioconfig));\n    const { output, error } = log(response);\n    if (response?.status != 0) {\n        if (response?.status == 2) {\n            if (isTest) {\n                throw output;\n            }\n            process.exit(2);\n        }\n        throw error ? error : `Error executing the command ${cmd}`;\n    }\n    return output;\n}\n\nfunction getOptions(ioconfig) {\n    const { maxBuffer } = process.env;\n    const options = {\n        shell: true,\n        maxBuffer: parseInt(maxBuffer)\n    };\n    if (ioconfig) {\n        options.stdio = ioconfig;\n    }\n    return options;\n}\n\nfunction getErrorCmdString(error) {\n    const suffix = 'Please check the logs for details.';\n    return `{ copado -p \"Error\" -e \"${error.trim()}; ${suffix}\"; exit 2; }`;\n}\n\nfunction log(response) {\n    const output = response?.stdout?.toString().trim();\n    const error = response?.stderr?.toString().trim();\n    if (output) {\n        console.log(output);\n    }\n    if (error) {\n        console.log(error);\n    }\n    return { output, error };\n}\n\nfunction displayVersions() {\n    child_process.execSync(\n        `\n            echo \"Node version: \"\n            node -v\n            echo \"VBT version: \"\n            vlocity -v\n        `,\n        { stdio: 'inherit' }\n    );\n}\n\nmodule.exports.execute = execute;\nmodule.exports.logger = logger;\nmodule.exports.maskSensitiveInformation = maskSensitiveInformation;\nmodule.exports.retrieveVlocityDataPacks = retrieveVlocityDataPacks;\nmodule.exports.getVlocitySelections = getVlocitySelections;\nmodule.exports.updateResult = updateResult;\nmodule.exports.createJobFile = createJobFile;\nmodule.exports.defaultJobParameters = defaultJobParameters;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getOptions = getOptions;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.log = log;\nmodule.exports.displayVersions = displayVersions;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0l7Q00000E0bIWQAZ",
                    "LastReferencedDate": "2023-09-13T12:05:44.000+0000",
                    "LastViewedDate": "2023-09-13T12:05:44.000+0000",
                    "Name": "Vlocity Git Snapshot"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v60.0/sobjects/copado__Function__c/a0oRR0000038uEdYAI"
                    },
                    "copado__API_Name__c": "sfdx_git_repository_validation",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"mainBranch\",\n  \"defaultValue\" : \"{$Context.Main_Branch__c}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n\tprocess = require('process'),\n\tfs = require('fs'),\n\t{ mainBranch, maxBuffer, isTest } = process.env,\n\tCOPADO_INFO_PREFIX = 'CopadoFunction INFO',\n\tRESULT_INFO = {\n\t\tLEVEL: {\n\t\t\tINFO: 'INFO',\n\t\t\tERROR: 'ERROR',\n\t\t\tWARN: 'WARN'\n\t\t},\n\t\tCATEGORY: {\n\t\t\tUNKNOWN_EXCEPTION: 'Unknown Exception',\n\t\t\tGIT: 'Git',\n\t\t\tCOPADO_SERVICE: 'Copado Service'\n\t\t},\n\t\tADDITIONAL_INFORMATION: {\n\t\t\tCOPADO_GIT_AUTHENTICATION: 'Copado Git Authentication',\n\t\t\tUPLOAD_FILES: 'Upload Files'\n\t\t}\n\t},\n\tCUSTOM_ERROR = {\n\t\tCOMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n\t},\n\tRESULT_TABLE_HEADER = {\n\t\tlabel: 'Git Requirement Check Result',\n\t\tcustomLabel: 'Git_Requirement_Check_Result'\n\t},\n\tHEADER_ICON = 'standard:note',\n\tRESULT_TABLE_COLUMNS = [\n\t\t{\n\t\t\tlabel: 'Level',\n\t\t\tfieldName: 'Level',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Level',\n\t\t\tinitialWidth: 80\n\t\t},\n\t\t{\n\t\t\tlabel: 'Category',\n\t\t\tfieldName: 'Category',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Category',\n\t\t\tinitialWidth: 120\n\t\t},\n\t\t{\n\t\t\tlabel: 'Additional Information',\n\t\t\tfieldName: 'AdditionalInformation',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Additional_Information',\n\t\t\tinitialWidth: 200\n\t\t},\n\t\t{\n\t\t\tlabel: 'Message',\n\t\t\tfieldName: 'Message',\n\t\t\ttype: 'text',\n\t\t\twrapText: true,\n\t\t\tcustomLabel: 'Message'\n\t\t}\n\t],\n\tTEMP_DIRECTORY = getPath('/tmp');\n\nlet resultViewerJson = [],\n\texecutionError;\n\nfunction execute() {\n\tlet isRepoAuthenticated = false,\n\t\tbranchCount = 0,\n\t\tisMainBranch = false;\n\n\ttry {\n\t\tthis.logger('fetching list of remote branches');\n\t\tlet response = child_process.execSync(`copado-git-get --remote \"$mainBranch\"`, { encoding: 'utf-8' });\n\t\tif (this.isAuthError(response)) {\n\t\t\tthis.populateResultViewer(\n\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\t\tRESULT_INFO.ADDITIONAL_INFORMATION.COPADO_GIT_AUTHENTICATION,\n\t\t\t\tresponse\n\t\t\t);\n\t\t} else {\n\t\t\tisRepoAuthenticated = true;\n            if (response && response !== '\\n') {\n\t\t\t\tbranchCount = response.split(',').length;\n\t\t\t\tif (response?.trim() === mainBranch) {\n\t\t\t\t\tisMainBranch = true;\n\t\t\t\t}\n\t\t\t}\n        }\n\t\tconst jsonResult = { isRepoAuthenticated, isMainBranch, branchCount };\n\t\tconst uploadResult = `copado -p 'Uploading results' --result-data '${JSON.stringify(jsonResult)}'`;\n\t\tthis.executeCommand(uploadResult, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES);\n\t} catch (err) {\n\t\tthis.logger(`Error stack: ${err.stack}`);\n\t\tif (!(err instanceof CommandExecutionError)) {\n\t\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, 'See logs for more info', err.message);\n\t\t}\n\t\texecutionError = err.message || err?.toString() || 'Unknown Error occurred';\n\t} finally {\n\t\tif (resultViewerJson?.length) {\n\t\t\tthis.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n\t\t}\n\t\tif (executionError) {\n\t\t\tthis.executeCommand(this.getErrorCmdString(executionError));\n\t\t\tprocess.exit(1);\n\t\t}\n\t}\n}\n\nfunction isAuthError(result) {\n\tif (result) {\n\t\treturn result.includes('128') && result.includes('Error');\n\t}\n\treturn false;\n}\n\nfunction executeCommand(command, category, additionalInfo, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.log(response, disableLogs);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthis.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n\t\tconst truncatedError = JSON.stringify(\n\t\t\terrorMessage\n\t\t\t\t.split('\\n')\n\t\t\t\t.filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n\t\t\t\t.join(' ')\n\t\t);\n\t\tthrow new CommandExecutionError(truncatedError, category, additionalInfo);\n\t}\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(maxBuffer)\n\t};\n\treturn options;\n}\n\nfunction log(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tconsole.log(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tconsole.log(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n\tif (message) {\n\t\tresultViewerJson.push({\n\t\t\tLevel: level,\n\t\t\tCategory: category,\n\t\t\tAdditionalInformation: additionalInfo,\n\t\t\tMessage: message\n\t\t});\n\t}\n}\n\nfunction logger(text) {\n\tconsole.log(text);\n}\n\nfunction getErrorCmdString(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `copado -p \"Error\" -e ${JSON.stringify(error?.trim()?.substring(0, 32760) + '; ' + suffix)}`;\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n\tconst RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n\tconst fileContent = { data, columns, header, headerIcon };\n\tfs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n\tthis.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n\tnew Promise((resolve, reject) => {\n\t\tchild_process.exec(`copado --uploadfile ${filePath}`, {}, (error, stdout, stderr) => {\n\t\t\tif (error?.code) {\n\t\t\t\tconst errorResponse = stderr ? stderr : `Error executing the command : ${error?.cmd}`;\n\t\t\t\tthis.populateResultViewer(\n\t\t\t\t\tRESULT_INFO.LEVEL.ERROR,\n\t\t\t\t\tRESULT_INFO.CATEGORY.COPADO_SERVICE,\n\t\t\t\t\t`Uploading file at ${filePath}`,\n\t\t\t\t\terrorResponse\n\t\t\t\t);\n\t\t\t\treject(new CommandExecutionError(errorResponse));\n\t\t\t} else {\n\t\t\t\tresolve();\n\t\t\t}\n\t\t});\n\t});\n}\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\nclass CommandExecutionError extends Error {\n\tconstructor(message, category, additionalInfo) {\n\t\tsuper(`${category ? category + ' - ' : ''}${additionalInfo ? additionalInfo + ' : ' : ''}${message}`);\n\t\tthis.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n\t}\n}\n\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getOptions = getOptions;\nmodule.exports.execute = execute;\nmodule.exports.log = log;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.isAuthError = isAuthError;\nmodule.exports.logger = logger;\nmodule.exports.getPath = getPath;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.getErrorCmdString = getErrorCmdString;\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0oRR0000038uEdYAI",
                    "LastReferencedDate": "2024-03-01T11:55:40.000+0000",
                    "LastViewedDate": "2024-03-01T11:55:40.000+0000",
                    "Name": "SFDX Git Repository Validation"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v60.0/sobjects/copado__Function__c/a0oRR000003AhbRYAS"
                    },
                    "copado__ApexClass__c": "cmcSf.RepositoryBranchCreationCallback",
                    "copado__API_Name__c": "SFDX_Create_Git_Branches",
                    "copado__Callback_Type__c": "ApexClass",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"branches\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.branches}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"mainBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.Pipeline__r.Main_Branch__c}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"required\" : true,\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"gitUser\",\n  \"defaultValue\" : \"{$User.Name}\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n    process = require('process'),\n    fs = require('fs'),\n    {branches, mainBranch, maxBuffer, isTest, gitEmail, gitUser} = process.env,\n    APP_DIRECTORY = getPath('/app'),\n    TEMP_DIRECTORY = getPath('/tmp'),\n    TARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n    RESULT_INFO = {\n        LEVEL: {\n            INFO: 'INFO',\n            ERROR: 'ERROR',\n            WARN: 'WARN'\n        },\n        CATEGORY: {\n            GIT: 'Git',\n            COPADO_INFO: 'Copado Info',\n            COPADO_SERVICE: 'Copado Service',\n            UNKNOWN_EXCEPTION: 'Unknown Exception',\n            FILE_SYSTEM: 'File System'\n        },\n        ADDITIONAL_INFORMATION: {\n            GIT_CHECKOUT: 'Git Checkout',\n            GIT_PUSH: 'Git Push',\n            UPLOAD_FILES: 'Upload Files',\n            COPADO_GIT_GET: 'Copado Git Service',\n            GIT_CONFIG: 'Git Configuration',\n            SETUP_DIRECTORY: 'Setup Directory',\n            GIT_BRANCH_NAME: 'Git Branch Name'\n        }\n    },\n    MAXBUFFER = parseInt(maxBuffer),\n    COPADO_INFO_PREFIX = 'CopadoFunction INFO',\n    resultViewerJson = [],\n    CUSTOM_ERROR = {\n        COMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n    },\n    RESULT_TABLE_HEADER = {\n        label: 'Create Git Branches Result',\n        customLabel: 'create_git_branches_result'\n    },\n    HEADER_ICON = 'standard:note',\n    RESULT_TABLE_COLUMNS = [\n        {\n            label: 'Level',\n            fieldName: 'Level',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Level',\n            initialWidth: 80\n        },\n        {\n            label: 'Category',\n            fieldName: 'Category',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Category',\n            initialWidth: 120\n        },\n        {\n            label: 'Additional Information',\n            fieldName: 'AdditionalInformation',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Additional_Information',\n            initialWidth: 200\n        },\n        {\n            label: 'Message',\n            fieldName: 'Message',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Message'\n        }\n    ];\n\nlet executionError;\nlet remoteBranches;\n\nfunction execute() {\n    try {\n        this.logger('START Creating environment branches');\n        const branchGraph = this.createBranchGraph(JSON.parse(branches));\n        remoteBranches = this.getRemoteBranches();\n        this.createWorkingDirectory();\n        this.createGitBranches(branchGraph, mainBranch);\n        this.logger('END Creating environment branches');\n    } catch (err) {\n        this.log(`Error: ${err.stack}`);\n        if (!(err instanceof CommandExecutionError)) {\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, 'See logs for more info', err.message);\n        }\n        executionError = err.message || err?.toString() || 'Unknown Error occurred';\n    } finally {\n        if (resultViewerJson?.length) {\n            this.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n        }\n        if (executionError) {\n            this.executeCommand(this.getErrorCommand(executionError));\n            process.exit(1);\n        }\n    }\n}\n\n\nfunction createGitBranches(branches, parentBranch) {\n    if (!branches[parentBranch] || branches[parentBranch].length === 0) {\n        return;\n    }\n\n    this.fetchGitBranch(parentBranch);\n    this.changeWorkingDirectory(TARGET_DIRECTORY);\n    this.configureGit(gitUser, gitEmail);\n\n    branches[parentBranch].forEach(branchToBeCreated => {\n        if (remoteBranches.includes(branchToBeCreated)) {\n            throw new Error(`There was an error initializing the pipeline, ${branchToBeCreated} already exists!`);\n        }\n\n        this.createEnvironmentBranch(parentBranch, branchToBeCreated);\n        this.pushChanges(branchToBeCreated);\n\n        this.logger(`Created branch ${branchToBeCreated} from ${parentBranch}`);\n        this.createGitBranches(branches, branchToBeCreated);\n    });\n}\n\nfunction createBranchGraph(branches) {\n    const branchGraph = {};\n    branches.forEach(({source, destination}) => {\n        if (destination === null) {\n            throw new Error('An error occurred while creating branches. Please visit Pipeline Manager for the pipeline and try again');\n        }\n        this.validateBranchName(destination);\n        this.validateBranchName(source);\n\n        if (!branchGraph[destination]) {\n            branchGraph[destination] = [];\n        }\n        branchGraph[destination].push(source);\n    });\n    return branchGraph;\n}\n\nfunction validateBranchName(branch) {\n    const checkReferenceFormatCommand = `git check-ref-format --branch \"${branch}\" || exit 1`;\n    this.executeCommand(checkReferenceFormatCommand, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_BRANCH_NAME);\n}\n\nfunction getRemoteBranches() {\n    let response = child_process.execSync(`copado-git-get --remote \"${mainBranch}\"`, {encoding: 'utf-8'});\n    return response?.trim().split(', ');\n}\n\nfunction configureGit(gitEmail, gitUser) {\n    const gitConfig = `\n    git config --local user.email \"${gitEmail}\" || exit 1\n    git config --local user.name \"${gitUser}\" || exit 1\n    git config --global diff.renames false || exit 1\n    git config --global merge.renames false || exit 1\n    git config --global status.renames false || exit 1\n    `;\n    this.executeCommand(gitConfig, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CONFIG);\n}\n\nfunction createWorkingDirectory() {\n    this.executeCommand(`mkdir -p ${TARGET_DIRECTORY}`, RESULT_INFO.CATEGORY.FILE_SYSTEM, RESULT_INFO.ADDITIONAL_INFORMATION.SETUP_DIRECTORY);\n}\n\nfunction fetchGitBranch(branch) {\n    if (!branch) {\n        throw new Error('No source branch provided');\n    }\n    this.logger(`START Fetching ${branch}`);\n\n    const cmd = `cd ${TARGET_DIRECTORY}\n        copado-git-get ${branch}`;\n\n    this.executeCommand(cmd, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_GIT_GET);\n    this.logger(`END Fetching ${branch}`);\n}\n\nfunction createEnvironmentBranch(sourceBranch, destinationBranch) {\n    this.log(`Creating branch ${destinationBranch} from ${sourceBranch}`);\n    if (sourceBranch) {\n        this.executeCommand(`copado -p \"Creating branch ${destinationBranch} from ${sourceBranch}\"`);\n        this.executeCommand(\n            `git checkout -b ${destinationBranch} ${sourceBranch}`,\n            RESULT_INFO.CATEGORY.GIT,\n            RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CHECKOUT\n        );\n    } else {\n        throw new Error('No environment branch provided');\n    }\n}\n\nfunction changeWorkingDirectory(dir) {\n    process.chdir(dir);\n}\n\nfunction executeCommand(command, category, additionalInfo, hasJsonResponse, disableLogs) {\n    let errorMessage;\n    const response = child_process.spawnSync(command, this.getOptions());\n    const {outputStream, errorStream} = this.log(response, disableLogs);\n    if (response?.status == 0) {\n        return hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n    }\n    if (!hasJsonResponse) {\n        errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n    } else {\n        try {\n            return JSON.parse(outputStream);\n        } catch (error) {\n            errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n        }\n    }\n    if (errorMessage) {\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n        const truncatedError = JSON.stringify(\n            errorMessage\n                .split('\\n')\n                .filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n                .join(' ')\n        );\n        throw new CommandExecutionError(truncatedError, category, additionalInfo);\n    }\n}\n\nfunction pushChanges(branchName) {\n    this.executeCommand(`copado -p 'Pushing environment branch ${branchName}'`);\n    const gitPush = `git push origin ${branchName}`;\n    this.executeCommand(gitPush, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_PUSH);\n}\n\nfunction logger(message) {\n    console.log(message);\n}\n\nfunction log(response, disableLogs) {\n    const outputStream = response?.stdout?.toString().trim();\n    const errorStream = response?.stderr?.toString().trim();\n    if (!disableLogs) {\n        if (outputStream) {\n            console.log(outputStream);\n        }\n        if (errorStream) {\n            console.log(errorStream);\n        }\n    }\n    return {outputStream, errorStream};\n}\n\nfunction getOptions() {\n    return {\n        shell: true,\n        maxBuffer: MAXBUFFER\n    };\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n    if (message) {\n        resultViewerJson.push({\n            Level: level,\n            Category: category,\n            AdditionalInformation: additionalInfo,\n            Message: message\n        });\n    }\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n    const RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n    const fileContent = {data, columns, header, headerIcon};\n    fs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n    this.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n    new Promise((resolve, reject) => {\n        child_process.exec(`copado --uploadfile ${filePath}`, {}, err => {\n            if (err) {\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.ERROR,\n                    RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                    RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES,\n                    err\n                );\n                reject(new CommandExecutionError(err, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES));\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction getErrorCommand(error) {\n    const suffix = 'Please check the logs for details.';\n    return `{ copado -p 'Error' -e '${error}. ${suffix}'; exit 2; }`;\n}\n\nclass CommandExecutionError extends Error {\n    constructor(message, category, additionalInfo) {\n        super(`${category ? category + ' - ' : ''}${additionalInfo ? additionalInfo + ' : ' : ''}${message}`);\n        this.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n    }\n}\n\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.createEnvironmentBranch = createEnvironmentBranch;\nmodule.exports.execute = execute;\nmodule.exports.log = log;\nmodule.exports.getOptions = getOptions;\nmodule.exports.changeWorkingDirectory = changeWorkingDirectory;\nmodule.exports.pushChanges = pushChanges;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.fetchGitBranch = fetchGitBranch;\nmodule.exports.createWorkingDirectory = createWorkingDirectory;\nmodule.exports.configureGit = configureGit;\nmodule.exports.getErrorCommand = getErrorCommand;\nmodule.exports.createGitBranches = createGitBranches;\nmodule.exports.createBranchGraph = createBranchGraph;\nmodule.exports.logger = logger;\nmodule.exports.getRemoteBranches = getRemoteBranches;\nmodule.exports.validateBranchName = validateBranchName;\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0oRR000003AhbRYAS",
                    "LastReferencedDate": "2024-03-19T09:09:35.000+0000",
                    "LastViewedDate": "2024-03-19T09:09:35.000+0000",
                    "Name": "SFDX Create Git Branches"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v60.0/sobjects/copado__Function__c/a0k0900000KDCJ9AAP"
                    },
                    "copado__ApexClass__c": "cmcSf.DeleteOutdatedFilesOnCredential",
                    "copado__API_Name__c": "SFDX_Create_Deleted_Metadata",
                    "copado__Callback_Type__c": "ApexClass",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"oldMetadataFileId\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"newMetadataFileId\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"deletedMetadataFileId\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"credentialRecordId\",\n  \"defaultValue\" : \"\"\n}, {\n  \"required\" : true,\n  \"name\" : \"metadataFileName\",\n  \"defaultValue\" : \"MetaData\"\n}, {\n  \"required\" : true,\n  \"name\" : \"deletedMetadataFileName\",\n  \"defaultValue\" : \"DeletedMetaData\"\n}, {\n  \"required\" : true,\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"required\" : true,\n  \"name\" : \"deletedMetadataExpirationDays\",\n  \"defaultValue\" : \"365\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n\tfs = require('fs'),\n\tprocess = require('process'),\n\t{\n\t\toldMetadataFileId,\n\t\tnewMetadataFileId,\n\t\tdeletedMetadataFileId,\n\t\tcredentialRecordId,\n\t\tmetadataFileName,\n\t\tdeletedMetadataFileName,\n\t\tmaxBuffer,\n\t\tdeletedMetadataExpirationDays,\n\t\tisTest\n\t} = process.env,\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tOLD_METADATA_FILE_DIRECTORY = `${TEMP_DIRECTORY}/oldMetadata`,\n\tNEW_METADATA_FILE_DIRECTORY = `${TEMP_DIRECTORY}/newMetadata`,\n\tSTDIO = {\n\t\tINHERIT: 'inherit'\n\t};\n\n// SCRIPT FUNCTIONS\n\nasync function execute() {\n\ttry {\n\t\tthis.changeWorkingDirectory(TEMP_DIRECTORY);\n\t\tthis.asyncCopadoLogMessage('Getting Metadata Details');\n\t\tconst [oldMetadataFileContent, newMetadataFileContent, deletedMetadataFileContent] = await Promise.all(this.getMetadataContentFromFile());\n\t\tthis.asyncCopadoLogMessage('Comparing Old And New Metadata File');\n\t\tconst { isDeletedMetadataChanged, deletedMetadatas } = this.getDeletedMetadataInfo(\n\t\t\toldMetadataFileContent,\n\t\t\tnewMetadataFileContent,\n\t\t\tdeletedMetadataFileContent\n\t\t);\n\t\tif (isDeletedMetadataChanged) {\n\t\t\tthis.asyncCopadoLogMessage('Creating Deleted Metadata File');\n\t\t\tthis.logger(`Deleted Metadata ${JSON.stringify(deletedMetadatas)}`);\n\t\t\tthis.uploadFile(`${TEMP_DIRECTORY}/${deletedMetadataFileName}`, deletedMetadatas, deletedMetadataFileName, credentialRecordId);\n\t\t}\n\t} catch (error) {\n\t\tthis.executeCommand(this.getErrorCommand(error));\n\t\tprocess.exit(1);\n\t}\n}\n\nfunction getMetadataContentFromFile() {\n\tconst promises = [];\n\tpromises.push(\n\t\tnew Promise((resolve, reject) => {\n\t\t\tsetTimeout(() => {\n\t\t\t\ttry {\n\t\t\t\t\tconst oldMetadataFileContent = this.getOldMetadataFileContent();\n\t\t\t\t\tresolve(oldMetadataFileContent);\n\t\t\t\t} catch (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\t\t\t}, 0);\n\t\t})\n\t);\n\n\tpromises.push(\n\t\tnew Promise((resolve, reject) => {\n\t\t\tsetTimeout(() => {\n\t\t\t\ttry {\n\t\t\t\t\tconst newMetadataFileContent = this.getNewMetadataFileContent();\n\t\t\t\t\tresolve(newMetadataFileContent);\n\t\t\t\t} catch (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\t\t\t}, 0);\n\t\t})\n\t);\n\n\tpromises.push(\n\t\tnew Promise((resolve, reject) => {\n\t\t\tsetTimeout(() => {\n\t\t\t\ttry {\n\t\t\t\t\tif (deletedMetadataFileId) {\n\t\t\t\t\t\tconst deletedMetadataFileContent = this.getDeletedMetadataFileContent();\n\t\t\t\t\t\tresolve(deletedMetadataFileContent);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresolve([]);\n\t\t\t\t\t}\n\t\t\t\t} catch (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\t\t\t}, 0);\n\t\t})\n\t);\n\treturn promises;\n}\n\nfunction getOldMetadataFileContent() {\n\tthis.createDirectory(OLD_METADATA_FILE_DIRECTORY);\n\tconst result = this.getMetadata(oldMetadataFileId, metadataFileName, OLD_METADATA_FILE_DIRECTORY);\n\treturn result;\n}\n\nfunction getNewMetadataFileContent() {\n\tthis.createDirectory(NEW_METADATA_FILE_DIRECTORY);\n\tconst result = this.getMetadata(newMetadataFileId, metadataFileName, NEW_METADATA_FILE_DIRECTORY);\n\treturn result;\n}\n\nfunction getDeletedMetadataFileContent() {\n\tconst result = this.getMetadata(deletedMetadataFileId, deletedMetadataFileName, TEMP_DIRECTORY);\n\treturn result;\n}\n\nfunction getDeletedMetadataInfo(oldMetadataFileContent, newMetadataFileContent, deletedMetadataFileContent) {\n\tlet isDeletedMetadataChanged = false;\n\tconst today = new Date();\n\n\tconst newMetadatasByTypeAndName = this.getMetadataByTypeAndName(newMetadataFileContent);\n\tconst deletedMetadatas = deletedMetadataFileContent.filter(deletedMetadata => {\n\t\tconst deletedMetadataByTypeAndName = `${deletedMetadata.t}:${deletedMetadata.n}`;\n\t\tconst isDeletedMetadataRecreatedOrExpired =\n\t\t\tnewMetadatasByTypeAndName.has(deletedMetadataByTypeAndName) || this.isDeletedMetadataExpired(deletedMetadata.additionDate, today);\n\t\tif (isDeletedMetadataRecreatedOrExpired) {\n\t\t\tisDeletedMetadataChanged = true;\n\t\t}\n\t\treturn !isDeletedMetadataRecreatedOrExpired;\n\t});\n\n\tconst deletedMetadatasByTypeAndName = this.getMetadataByTypeAndName(deletedMetadatas);\n\toldMetadataFileContent.forEach(oldMetadata => {\n\t\tconst oldMetadataByTypeAndName = `${oldMetadata.t}:${oldMetadata.n}`;\n\t\tif (!newMetadatasByTypeAndName.has(oldMetadataByTypeAndName) && !deletedMetadatasByTypeAndName.has(oldMetadataByTypeAndName)) {\n\t\t\tisDeletedMetadataChanged = true;\n\t\t\tconst deletedMetadata = { ...oldMetadata };\n\t\t\t// The additionDate property represents the date on which the metadata was added in the deleted metadata file\n\t\t\tdeletedMetadata.additionDate = today;\n\t\t\tdeletedMetadatas.push(deletedMetadata);\n\t\t}\n\t});\n\n\treturn { isDeletedMetadataChanged, deletedMetadatas };\n}\n\nfunction isDeletedMetadataExpired(deletedMetadataAdditionDate, today) {\n\tlet result = false;\n\tif (deletedMetadataAdditionDate && today) {\n\t\ttry {\n\t\t\tconst deletedMetadataExpirationDate = this.getDeletedMetadataExpirationDate(new Date(deletedMetadataAdditionDate));\n\t\t\tresult = deletedMetadataExpirationDate <= today;\n\t\t} catch (error) {\n\t\t\tthis.logger(error);\n\t\t}\n\t}\n\treturn result;\n}\n\nfunction getDeletedMetadataExpirationDate(deletedMetadataAdditionDate) {\n\tconst result = deletedMetadataAdditionDate;\n\tconst expirationDaysInMilliSecond = (deletedMetadataExpirationDays ? parseInt(deletedMetadataExpirationDays) : 365) * 24 * 60 * 60 * 1000;\n\tresult.setTime(result.getTime() + expirationDaysInMilliSecond);\n\treturn result;\n}\n\n// FUNCTION COMMONS\n\nfunction changeWorkingDirectory(directory) {\n\tprocess.chdir(directory);\n}\n\nfunction getMetadata(fileId, fileName, directory) {\n\tthis.downloadFile(fileId, directory);\n\tconst fileDetails = fs.readFileSync(`${directory}/${fileName}`, 'utf-8');\n\tconst result = JSON.parse(fileDetails);\n\treturn result;\n}\n\nfunction uploadFile(filePath, data, fileName, parentId) {\n\tfs.writeFileSync(filePath, JSON.stringify(data));\n\tconst command = `copado --uploadfile \"${filePath}\" --name \"${fileName}\" --parentid \"${parentId}\"`;\n\tthis.executeCommand(command);\n}\n\nfunction createDirectory(directory) {\n\tconst command = `\n        mkdir -p \"${directory}\";\n    `;\n\tthis.executeCommand(command);\n}\n\nfunction downloadFile(fileId, downloadDirectory) {\n\tconst command = `copado --downloadfiles ${fileId} --downloaddir ${downloadDirectory}`;\n\tthis.executeCommand(command);\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDirectory__${filePath}` : filePath;\n}\n\nfunction getMetadataByTypeAndName(metadatas) {\n\tconst result = new Set();\n\tmetadatas.forEach(metadata => {\n\t\tresult.add(`${metadata.t}:${metadata.n}`);\n\t});\n\treturn result;\n}\n\nfunction asyncCopadoLogMessage(message) {\n\tif (message) {\n\t\tnew Promise(resolve => {\n\t\t\tchild_process.exec(`copado -p \"${message}\"`, { stdio: STDIO.INHERIT }, () => {\n\t\t\t\tresolve();\n\t\t\t});\n\t\t});\n\t}\n}\n\nfunction getErrorCommand(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `copado -p \"Error\" -e ${JSON.stringify(error?.toString()?.trim()?.substring(0, 32760) + '; ' + suffix)}`;\n}\n\nfunction executeCommand(command, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.getOutputAndErrorStream(response, disableLogs);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthrow new Error(errorMessage);\n\t}\n}\n\nfunction getOutputAndErrorStream(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tthis.logger(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tthis.logger(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction logger(message) {\n\tconsole.log(message);\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(maxBuffer)\n\t};\n\treturn options;\n}\n\nmodule.exports.execute = execute;\nmodule.exports.changeWorkingDirectory = changeWorkingDirectory;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.getMetadataContentFromFile = getMetadataContentFromFile;\nmodule.exports.getDeletedMetadataInfo = getDeletedMetadataInfo;\nmodule.exports.uploadFile = uploadFile;\nmodule.exports.createDirectory = createDirectory;\nmodule.exports.downloadFile = downloadFile;\nmodule.exports.getOldMetadataFileContent = getOldMetadataFileContent;\nmodule.exports.getNewMetadataFileContent = getNewMetadataFileContent;\nmodule.exports.getDeletedMetadataFileContent = getDeletedMetadataFileContent;\nmodule.exports.getMetadata = getMetadata;\nmodule.exports.getMetadataByTypeAndName = getMetadataByTypeAndName;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getOutputAndErrorStream = getOutputAndErrorStream;\nmodule.exports.logger = logger;\nmodule.exports.getErrorCommand = getErrorCommand;\nmodule.exports.getOptions = getOptions;\nmodule.exports.getDeletedMetadataExpirationDate = getDeletedMetadataExpirationDate;\nmodule.exports.isDeletedMetadataExpired = isDeletedMetadataExpired;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0k0900000KDCJ9AAP",
                    "LastReferencedDate": "2024-03-06T14:31:24.000+0000",
                    "LastViewedDate": "2024-03-06T14:31:24.000+0000",
                    "Name": "SFDX Create Deleted Metadata"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v60.0/sobjects/copado__Function__c/a0oRR0000042U9NYAU"
                    },
                    "copado__API_Name__c": "SFDX_Create_Environment_Branch",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"branches\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.branches}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"required\" : true,\n  \"name\" : \"gitEmail\",\n  \"defaultValue\" : \"{$User.Email}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"gitUser\",\n  \"defaultValue\" : \"{$User.Name}\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n    process = require('process'),\n    fs = require('fs'),\n    {branches, maxBuffer, isTest, gitEmail, gitUser} = process.env,\n    APP_DIRECTORY = getPath('/app'),\n    TEMP_DIRECTORY = getPath('/tmp'),\n    TARGET_DIRECTORY = `${APP_DIRECTORY}/repository`,\n    RESULT_INFO = {\n        LEVEL: {\n            INFO: 'INFO',\n            ERROR: 'ERROR',\n            WARN: 'WARN'\n        },\n        CATEGORY: {\n            GIT: 'Git',\n            COPADO_INFO: 'Copado Info',\n            COPADO_SERVICE: 'Copado Service',\n            UNKNOWN_EXCEPTION: 'Unknown Exception',\n            FILE_SYSTEM: 'File System'\n        },\n        ADDITIONAL_INFORMATION: {\n            GIT_CHECKOUT: 'Git Checkout',\n            GIT_PUSH: 'Git Push',\n            UPLOAD_FILES: 'Upload Files',\n            COPADO_GIT_GET: 'Copado Git Service',\n            GIT_CONFIG: 'Git Configuration',\n            SETUP_DIRECTORY: 'Setup Directory',\n            GIT_BRANCH_NAME: 'Git Branch Name'\n        }\n    },\n    STDIO = {\n        INHERIT: 'inherit',\n        PIPE: 'pipe',\n        IGNORE: 'ignore'\n    },\n    MAXBUFFER = parseInt(maxBuffer),\n    COPADO_INFO_PREFIX = 'CopadoFunction INFO',\n    resultViewerJson = [],\n    CUSTOM_ERROR = {\n        COMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n    },\n    RESULT_TABLE_HEADER = {\n        label: 'Create Environment Branch Result',\n        customLabel: 'create_environment_branch_result'\n    },\n    HEADER_ICON = 'standard:note',\n    RESULT_TABLE_COLUMNS = [\n        {\n            label: 'Level',\n            fieldName: 'Level',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Level',\n            initialWidth: 80\n        },\n        {\n            label: 'Category',\n            fieldName: 'Category',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Category',\n            initialWidth: 120\n        },\n        {\n            label: 'Additional Information',\n            fieldName: 'AdditionalInformation',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Additional_Information',\n            initialWidth: 200\n        },\n        {\n            label: 'Message',\n            fieldName: 'Message',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Message'\n        }\n    ];\n\nlet executionError;\n\nfunction execute() {\n    try {\n        const environmentBranch = JSON.parse(branches)['source'];\n        const parentBranch = JSON.parse(branches)['destination'];\n\n        this.logger('START Creating environment branch');\n        this.validateBranches(environmentBranch, parentBranch);\n        this.createWorkingDirectory();\n        this.fetchGitBranch(parentBranch);\n        this.changeWorkingDirectory(TARGET_DIRECTORY);\n        this.configureGit(gitUser, gitEmail);\n        this.createEnvironmentBranch(environmentBranch, parentBranch);\n        this.pushEnvironmentBranch(environmentBranch);\n        this.logger('END Creating environment branch');\n    } catch (err) {\n        this.log(`Error: ${err.stack}`);\n        if (!(err instanceof CommandExecutionError)) {\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, 'See logs for more info', err.message);\n        }\n        executionError = err.message || err?.toString() || 'Unknown Error occurred';\n    } finally {\n        if (resultViewerJson?.length) {\n            this.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n        }\n        if (executionError) {\n            this.executeCommand(this.getErrorCommand(executionError));\n            process.exit(1);\n        }\n    }\n}\n\n\nfunction fetchGitBranch(branch) {\n    this.logger(`START Fetching ${branch}`);\n\n    const cmd = `cd ${TARGET_DIRECTORY}\n        copado-git-get ${branch}`;\n\n    this.executeCommand(cmd, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_GIT_GET);\n    this.logger(`END Fetching ${branch}`);\n}\n\nfunction getRemoteBranches(parentBranch) {\n    const response = child_process.execSync(`copado-git-get --remote \"${parentBranch}\"`, {encoding: 'utf-8'});\n    return response?.trim().split(', ');\n}\n\nfunction validateBranches(environmentBranch, parentBranch) {\n\n    if (parentBranch === null || environmentBranch === null) {\n        throw new Error('Error creating environment branch: Please check Pipeline Manager for the pipeline and try again');\n    }\n\n\tthis.validateBranchName([parentBranch, environmentBranch]);\n\n\n    const remoteBranches = this.getRemoteBranches(parentBranch);\n    if (!remoteBranches.includes(parentBranch)) {\n        throw new Error(`Error creating environment branch: ${parentBranch} does not exist!`);\n    }\n\n    if (remoteBranches.includes(environmentBranch)) {\n        throw new Error(`Error creating environment branch: ${environmentBranch} already exists!`);\n    }\n}\n\nfunction configureGit(gitEmail, gitUser) {\n    const gitConfig = `\n    git config --local user.email \"${gitEmail}\" || exit 1\n    git config --local user.name \"${gitUser}\" || exit 1\n    git config --global diff.renames false || exit 1\n    git config --global merge.renames false || exit 1\n    git config --global status.renames false || exit 1\n    `;\n    this.executeCommand(gitConfig, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CONFIG);\n}\n\nfunction validateBranchName(branches) {\n\n\tbranches.forEach(branch => {\n    const checkReferenceFormatCommand = `git check-ref-format --branch \"${branch}\" || exit 1`;\n    this.executeCommand(checkReferenceFormatCommand, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_BRANCH_NAME);\n    });\n}\n\nfunction createWorkingDirectory() {\n    this.executeCommand(`mkdir -p ${TARGET_DIRECTORY}`, RESULT_INFO.CATEGORY.FILE_SYSTEM, RESULT_INFO.ADDITIONAL_INFORMATION.SETUP_DIRECTORY);\n}\n\nfunction createEnvironmentBranch(environmentBranch, parentBranch) {\n    this.log(`Creating branch ${environmentBranch} from ${parentBranch}`);\n    if (parentBranch) {\n        this.asyncCopadoLogMessage(`\"Creating branch ${environmentBranch} from ${parentBranch}\"`);\n        this.executeCommand(\n            `git checkout -b ${environmentBranch} ${parentBranch}`,\n            RESULT_INFO.CATEGORY.GIT,\n            RESULT_INFO.ADDITIONAL_INFORMATION.GIT_CHECKOUT\n        );\n    } else {\n        throw new Error('No environment branch provided');\n    }\n}\n\nfunction pushEnvironmentBranch(branchName) {\n\n    this.asyncCopadoLogMessage(`Pushing environment branch ${branchName}`);\n    const gitPush = `git push origin ${branchName}`;\n    this.executeCommand(gitPush, RESULT_INFO.CATEGORY.GIT, RESULT_INFO.ADDITIONAL_INFORMATION.GIT_PUSH);\n}\n\nfunction executeCommand(command, category, additionalInfo, hasJsonResponse, disableLogs) {\n    let errorMessage;\n    const response = child_process.spawnSync(command, this.getOptions());\n    const {outputStream, errorStream} = this.log(response, disableLogs);\n    if (response?.status == 0) {\n        return hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n    }\n    if (!hasJsonResponse) {\n        errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n    } else {\n        try {\n            return JSON.parse(outputStream);\n        } catch (error) {\n            errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n        }\n    }\n    if (errorMessage) {\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n        const truncatedError = JSON.stringify(\n            errorMessage\n                .split('\\n')\n                .filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n                .join(' ')\n        );\n        throw new CommandExecutionError(truncatedError, category, additionalInfo);\n    }\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction logger(message) {\n    console.log(message);\n}\n\nfunction log(response, disableLogs) {\n    const outputStream = response?.stdout?.toString().trim();\n    const errorStream = response?.stderr?.toString().trim();\n    if (!disableLogs) {\n        if (outputStream) {\n            console.log(outputStream);\n        }\n        if (errorStream) {\n            console.log(errorStream);\n        }\n    }\n    return {outputStream, errorStream};\n}\n\nfunction changeWorkingDirectory(dir) {\n    process.chdir(dir);\n}\n\nfunction getOptions() {\n    return {\n        shell: true,\n        maxBuffer: MAXBUFFER\n    };\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n    if (message) {\n        resultViewerJson.push({\n            Level: level,\n            Category: category,\n            AdditionalInformation: additionalInfo,\n            Message: message\n        });\n    }\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n    const RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n    const fileContent = {data, columns, header, headerIcon};\n    fs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n    this.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n    new Promise((resolve, reject) => {\n        child_process.exec(`copado --uploadfile ${filePath}`, {}, err => {\n            if (err) {\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.ERROR,\n                    RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                    RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES,\n                    err\n                );\n                reject(new CommandExecutionError(err, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES));\n            } else {\n                resolve();\n            }\n        });\n    });\n}\nfunction asyncCopadoLogMessage(msg, logLevel) {\n    if (msg) {\n        this.populateResultViewer(logLevel ? logLevel : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n        new Promise(resolve => {\n            child_process.exec(`copado -p \"${msg}\"`, { stdio: STDIO.INHERIT }, () => {\n                resolve();\n            });\n        });\n    }\n}\n\nfunction getErrorCommand(error) {\n    const suffix = 'Please check the logs for details.';\n    return `{ copado -p 'Error' -e '${error}. ${suffix}'; exit 2; }`;\n}\n\nclass CommandExecutionError extends Error {\n    constructor(message, category, additionalInfo) {\n        super(`${category ? category + ' - ' : ''}${additionalInfo ? additionalInfo + ' : ' : ''}${message}`);\n        this.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n    }\n}\n\n\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.createEnvironmentBranch = createEnvironmentBranch;\nmodule.exports.execute = execute;\nmodule.exports.log = log;\nmodule.exports.getOptions = getOptions;\nmodule.exports.changeWorkingDirectory = changeWorkingDirectory;\nmodule.exports.pushEnvironmentBranch = pushEnvironmentBranch;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.fetchGitBranch = fetchGitBranch;\nmodule.exports.createWorkingDirectory = createWorkingDirectory;\nmodule.exports.configureGit = configureGit;\nmodule.exports.getErrorCommand = getErrorCommand;\nmodule.exports.logger = logger;\nmodule.exports.getRemoteBranches = getRemoteBranches;\nmodule.exports.validateBranches = validateBranches;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.validateBranchName = validateBranchName;\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0oRR0000042U9NYAU",
                    "LastReferencedDate": "2024-03-19T09:04:38.000+0000",
                    "LastViewedDate": "2024-03-19T09:04:38.000+0000",
                    "Name": "SFDX Create Environment Branch"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v60.0/sobjects/copado__Function__c/a0oRR000004smdFYAQ"
                    },
                    "copado__API_Name__c": "calculate_file_differences",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationSessionId\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEndPoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationEndPoint\",\n  \"defaultValue\" : \"{$Destination.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"pipelineId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.Pipeline__c}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEnvironmentId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.Source__c}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEnvironmentFileId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.sourceEnvironmentFileId}\"\n}, {\n  \"name\" : \"metadataChunkInfo\",\n  \"defaultValue\" : \"{\\\"staticresource\\\": 10, \\\"contentasset\\\": 10}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"targetEnvironmentFileId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.targetEnvironmentFileId}\"\n}, {\n  \"name\" : \"defaultMetadataChunkInfo\",\n  \"defaultValue\" : \"5000\"\n}, {\n  \"name\" : \"processesUsedForRetrieval\",\n  \"defaultValue\" : \"7\"\n}, {\n  \"name\" : \"maximumRetryCount\",\n  \"defaultValue\" : \"1\"\n}, {\n  \"name\" : \"overriddenApiVersion\",\n  \"defaultValue\" : \"\"\n} ]",
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst {spawnSync, spawn, exec, fork} = require('child_process'),\n\n    process = require('process'),\n    fs = require('fs'),\n    {\n        sourceSessionId,\n        destinationSessionId,\n        maxBuffer,\n        destinationEndPoint,\n        sourceEndPoint,\n        metadataChunkInfo,\n        processesUsedForRetrieval,\n        defaultMetadataChunkInfo,\n        isTest,\n        pipelineId,\n        sourceEnvironmentId,\n        sourceEnvironmentFileId,\n        targetEnvironmentFileId,\n        API_VERSION,\n        maximumRetryCount,\n        overriddenApiVersion\n    } = process.env,\n    {cpus} = require('os'),\n    APP_DIRECTORY = getPath('/app'),\n    TEMP_DIRECTORY = getPath('/tmp'),\n    CREDENTIAL_FILE_NAME = 'MetaData',\n    PROFILE = 'Profile',\n    RESULT_INFO = {\n        LEVEL: {\n            INFO: 'INFO',\n            ERROR: 'ERROR',\n            WARN: 'WARN'\n        },\n        CATEGORY: {\n            GIT: 'Git',\n            COPADO_INFO: 'Copado Info',\n            COPADO_SERVICE: 'Copado Service',\n            COPADO_METADATA_INTELLIGENCE: 'Copado Metadata Intelligence',\n            COPADO_FILE_DIFFERENCE_ANALYSER: 'Copado File Difference Analyser',\n            UNKNOWN_EXCEPTION: 'Unknown Exception',\n            FILE_SYSTEM: 'File System',\n            SF_CLI: 'Salesforce CLI'\n        },\n        ADDITIONAL_INFORMATION: {\n            UPLOAD_FILES: 'Upload Files',\n            DOWNLOAD_FILE: 'Download File',\n            SETUP_DIRECTORY: 'Setup Directory',\n            ENRICHER_SERVICE: 'Enricher Service',\n            SF_CONFIG: 'SF Configuration',\n            SF_CREATE_PROJECT: 'SF Create Project',\n            COPADO_FILE_DIFFERENCE_ANALYSER_SERVICE: 'Copado File Difference Analyser Service',\n            METADATA_RETRIEVAL_ERROR: 'Metadata Retrieval Error'\n        }\n    },\n    STDIO = {\n        INHERIT: 'inherit',\n        PIPE: 'pipe',\n        IGNORE: 'ignore'\n    },\n    MAXBUFFER = parseInt(maxBuffer),\n    COPADO_INFO_PREFIX = 'CopadoFunction INFO',\n    resultViewerJson = [],\n    CUSTOM_ERROR = {\n        COMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n    },\n    RESULT_TABLE_HEADER = {\n        label: 'File Difference Analysis Result',\n        customLabel: 'file_difference_analysis_result'\n    },\n    HEADER_ICON = 'standard:note',\n    RESULT_TABLE_COLUMNS = [\n        {\n            label: 'Level',\n            fieldName: 'Level',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Level',\n            initialWidth: 80\n        },\n        {\n            label: 'Category',\n            fieldName: 'Category',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Category',\n            initialWidth: 120\n        },\n        {\n            label: 'Additional Information',\n            fieldName: 'AdditionalInformation',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Additional_Information',\n            initialWidth: 200\n        },\n        {\n            label: 'Message',\n            fieldName: 'Message',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Message'\n        }\n    ],\n    OPERATION_AND_DIRECTORY = [\n        {\n            'operation': 'Add',\n            'directory': APP_DIRECTORY + '/source-project'\n        },\n        {\n            'operation': 'Update',\n            'directory': APP_DIRECTORY + '/source-project'\n        },\n        {\n            'operation': 'Delete',\n            'directory': APP_DIRECTORY + '/target-project'\n        }\n    ],\n    nestedMetadataToBeBypassed = [\n        'workflowfieldupdate',\n        'workflowknowledgepublish',\n        'workflowtask',\n        'workflowalert',\n        'workflowsend',\n        'workflowoutboundmessage',\n        'workflowrule',\n        'sharingownerrule',\n        'sharingcriteriarule',\n        'sharingguestrule',\n        'sharingterritoryrule',\n        'customlabel',\n        'assignmentrule',\n        'autoresponserule',\n        'matchingrule',\n        'customfield',\n        'index',\n        'businessprocess',\n        'recordtype',\n        'compactlayout',\n        'weblink',\n        'validationrule',\n        'sharingreason',\n        'listview',\n        'fieldset'\n    ],\n    metadataSupportedByCli = getMetadataSupportedByCli(),\n    ignoredMetadata = ['document'],\n    maxAllowedProcesses = parseInt(processesUsedForRetrieval) ? parseInt(processesUsedForRetrieval) : 8,\n    defaultMetadataChunkSize = parseInt(defaultMetadataChunkInfo) ? parseInt(defaultMetadataChunkInfo) : 5000,\n    metadataChunkSize = getParsedData(metadataChunkInfo),\n    retryLimit = parseInt(maximumRetryCount) ? parseInt(maximumRetryCount) : 1;\n\nlet executionError;\n\nasync function execute() {\n    try {\n        this.logger('START Calculating file differences between the two environments');\n        this.createWorkingDirectory(APP_DIRECTORY);\n\n        await Promise.all([\n            this.retrieveMetadataFromEnvironment(sourceEnvironmentFileId, 'source-project', sourceEndPoint, sourceSessionId),\n            this.retrieveMetadataFromEnvironment(targetEnvironmentFileId, 'target-project', destinationEndPoint, destinationSessionId)\n        ]);\n\n        this.changeWorkingDirectory(APP_DIRECTORY);\n\n        this.calculateFileDifferences();\n        const changeObjects = this.getMetadataNameAndTypeForFilePaths();\n\n        const fileName = `${pipelineId}_${sourceEnvironmentId}_DifferenceMetadata`;\n\n        fs.writeFileSync(fileName, JSON.stringify(changeObjects));\n\n        this.uploadFileAtPath(fileName, sourceEnvironmentId);\n        this.executeCommand(`copado -p 'Uploaded result of calculated differences on the environment'`);\n        this.logger('DONE Calculating file differences between the two environments');\n\n    } catch (err) {\n        this.log(`Error: ${err.stack}`);\n        if (!(err instanceof CommandExecutionError)) {\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, 'See logs for more info', err.message);\n        }\n        executionError = err.message || err?.toString() || 'Unknown Error occurred';\n    } finally {\n        if (resultViewerJson?.length) {\n            this.uploadResultViewerJson(resultViewerJson, RESULT_TABLE_COLUMNS, RESULT_TABLE_HEADER, HEADER_ICON);\n        }\n        if (executionError) {\n            this.executeCommand(this.getErrorCommand(executionError));\n            process.exit(1);\n        }\n    }\n}\n\nasync function retrieveMetadataFromEnvironment(environmentFileId, directory, endPoint, sessionId) {\n    this.asyncCopadoLogMessage(`START Retrieving Metadata`);\n    const metadataNamesByType = this.getMetadataNamesByType(environmentFileId, TEMP_DIRECTORY, CREDENTIAL_FILE_NAME);\n\n    const apiVersion = this.getApiVersion(overriddenApiVersion, API_VERSION);\n    let profiles = this.getProfilesForRetrieval(\n        metadataNamesByType,\n        metadataSupportedByCli,\n        PROFILE,\n        apiVersion,\n        ignoredMetadata,\n        metadataChunkSize,\n        defaultMetadataChunkSize,\n        nestedMetadataToBeBypassed\n    );\n    let metadatas = this.getMetadataItemsForRetrieval(\n        metadataNamesByType,\n        metadataSupportedByCli,\n        apiVersion,\n        TEMP_DIRECTORY,\n        ignoredMetadata,\n        metadataChunkSize,\n        defaultMetadataChunkSize,\n        nestedMetadataToBeBypassed\n    );\n    if (!profiles.length && !metadatas.length) {\n        throw new Error('No metadata available for retrieval');\n    }\n    const workDir = `${APP_DIRECTORY}/${directory}`;\n    this.createSFDXProject(APP_DIRECTORY, directory, 'standard', 'force-app', apiVersion);\n    this.changeWorkingDirectory(workDir);\n    this.configureSFDXCli(apiVersion, endPoint);\n    const processUsedForRetrieval = this.getMaxAllowedProcesses(maxAllowedProcesses);\n    const {errors} = await this.runMetadataRetrieval(processUsedForRetrieval, metadatas, profiles, sessionId, TEMP_DIRECTORY, workDir, endPoint);\n    const errorsMsg = errors;\n    if (errorsMsg) {\n        this.updateResultStatus(errorsMsg);\n    }\n}\n\nfunction updateResultStatus(errors) {\n    let message = '';\n    const hasRetrievalError = errors && Object.keys(errors).length;\n    if (hasRetrievalError) {\n        message =\n            'Retrieval process completed, but some metadata types could not be retrieved. Please view the Retrieval Error.json for details.';\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.SF_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.METADATA_RETRIEVAL_ERROR, message);\n    } else {\n        message = 'Retrieval completed successfully';\n    }\n    this.executeCommand(`copado -p \"${message}\"`);\n\n}\n\nfunction calculateFileDifferences() {\n\n    this.asyncCopadoLogMessage('Calculating file differences');\n\n    const copaDiffCommand = `copadiff ${APP_DIRECTORY}/source-project ${APP_DIRECTORY}/target-project ${TEMP_DIRECTORY}`;\n    this.executeCommand(copaDiffCommand, RESULT_INFO.CATEGORY.COPADO_FILE_DIFFERENCE_ANALYSER, RESULT_INFO.ADDITIONAL_INFORMATION.COPADO_FILE_DIFFERENCE_ANALYSER_SERVICE);\n    const fileDifferences = fs.readFileSync(`${TEMP_DIRECTORY}/output.json`, 'utf8');\n    this.sortFilePathsByOperation(fileDifferences);\n}\n\nfunction getMetadataNameAndTypeForFilePaths() {\n    let combinedChangeObjects = [];\n    OPERATION_AND_DIRECTORY.forEach(operationAndDirectory => {\n    \tif (fs.existsSync(`${TEMP_DIRECTORY}/${operationAndDirectory.operation}`)) {\n        \tthis.enrichFilePaths(operationAndDirectory.directory, `${TEMP_DIRECTORY}/${operationAndDirectory.operation}`);\n        \tconst changeObjects = this.getChangeObjects(fs.readFileSync(`${TEMP_DIRECTORY}/${operationAndDirectory.operation}.json`, 'utf8'), operationAndDirectory.operation);\n        \tcombinedChangeObjects.push(...changeObjects);\n        }\n    });\n\n    return combinedChangeObjects;\n}\n\nfunction getApiVersion(overriddenApiVersion, apiVersion) {\n    const finalApiVersion = overriddenApiVersion || apiVersion;\n    const regExpApiVersion = /\\d\\d\\.0/;\n    if (!regExpApiVersion.test(finalApiVersion)) {\n        throw new Error(`Invalid API version ${finalApiVersion}`);\n    }\n    return finalApiVersion;\n}\n\nasync function runMetadataRetrieval(maxAllowedProcesses, metadatas, profiles, sessionId, directory, workDir, endPoint) {\n    let result, errorMessage, pool;\n    try {\n\n        pool = new this.SpawnPool(maxAllowedProcesses, metadatas, profiles, sessionId, workDir, endPoint);\n        await Promise.all(pool.execute());\n\n    } catch (error) {\n        errorMessage = error?.toString();\n    } finally {\n        result = {errors: pool.getErrors(), sfCommandLogs: pool.getSfCommandLogs()};\n        this.uploadExecutionDetails(result.errors, result.sfCommandLogs, directory, workDir);\n        if (errorMessage) {\n            this.executeCommand(this.getErrorCommand(errorMessage));\n        }\n    }\n    return result;\n}\n\nfunction getProfilesForRetrieval(\n    metadataNamesByType,\n    metadataSupportedByCli,\n    profileMetadata,\n    apiVersion,\n    ignoredMetadata,\n    metadataChunkSize,\n    defaultMetadataChunkSize,\n    nestedMetadataToBeBypassed\n) {\n    let result = [];\n    if (metadataNamesByType.has(profileMetadata) && this.isValidMetadata(ignoredMetadata, profileMetadata, metadataSupportedByCli, nestedMetadataToBeBypassed)) {\n        const profileNames = metadataNamesByType.get(profileMetadata);\n        metadataNamesByType.delete(profileMetadata);\n        result = [...result, ...this.getMetadataItemForRetrieval(profileNames, profileMetadata, profileNames.length, apiVersion)];\n    }\n    return result;\n}\n\nfunction isValidMetadata(ignoredMetadata, metadata, metadataSupportedByCli, nestedMetadataToBeBypassed) {\n    const metadataName = metadata?.toLowerCase();\n    return (\n        !ignoredMetadata.includes(metadataName) && metadataSupportedByCli.includes(metadataName) && !nestedMetadataToBeBypassed.includes(metadataName));\n}\n\nfunction getMetadataItemsForRetrieval(\n    metadataNamesByType,\n    metadataSupportedByCli,\n    apiVersion,\n    directory,\n    ignoredMetadata,\n    metadataChunkSize,\n    defaultMetadataChunkSize,\n    nestedMetadataToBeBypassed\n) {\n    let result = [];\n    for (const [metadataType, metadataNames] of metadataNamesByType.entries()) {\n        if (this.isValidMetadata(ignoredMetadata, metadataType, metadataSupportedByCli, nestedMetadataToBeBypassed)) {\n            result = [\n                ...result,\n                ...this.getMetadataItemForRetrieval(\n                    metadataNames,\n                    metadataType,\n                    this.getMetadataChunkSize(metadataType, metadataChunkSize, defaultMetadataChunkSize),\n                    apiVersion,\n                    directory\n                )\n            ];\n        }\n    }\n    return result;\n}\n\nfunction getMetadataChunkSize(metadata, metadataChunkSize, defaultMetadataChunkSize) {\n    const metadataName = metadata?.toLowerCase();\n    return metadataChunkSize[metadataName] ? metadataChunkSize[metadataName] : defaultMetadataChunkSize;\n}\n\nfunction getMaxAllowedProcesses(neededCpus) {\n    const totalCpus = cpus().length;\n    if (totalCpus === 1) {\n        return 1;\n    }\n    const maxAvailableCpus = totalCpus - 1;\n    if (neededCpus < maxAvailableCpus) {\n        return neededCpus;\n    }\n    logger(`Due to system limitation we will be using ${maxAvailableCpus} child process for metadata retrieval`);\n    return maxAvailableCpus;\n}\n\nfunction getMetadataItemForRetrieval(metadataNames, metadataType, maxAllowedItemsPerType, apiVersion, directory) {\n    const result = [];\n    const metadatas = [];\n    while (metadataNames.length > maxAllowedItemsPerType) {\n        metadatas.push(metadataNames.splice(0, maxAllowedItemsPerType));\n    }\n    metadatas.push(metadataNames);\n    metadatas.forEach(metadata => {\n        result.push({\n            metadataType,\n            metadataNames: metadata,\n            retryCount: 0,\n            path: metadataType.toLowerCase() === 'profile' ? '' : getPackageXMLfilePath(metadata, metadataType, apiVersion, directory)\n        });\n    });\n    return result;\n}\n\nfunction getPackageXMLfilePath(metadataNames, metadataType, apiVersion, directory) {\n    let manifest = [];\n    manifest.push('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\" ?>\\n');\n    manifest.push('<Package xmlns=\"http://soap.sforce.com/2006/04/metadata\">\\n');\n    manifest.push('\\t<types>\\n');\n    metadataNames.forEach(metadataName => {\n        manifest.push(`\\t\\t<members>${metadataName}</members>\\n`);\n    });\n    manifest.push(`\\t\\t<name>${metadataType}</name>\\n`);\n    manifest.push('\\t</types>\\n');\n    manifest.push(`\\t<version>${apiVersion}</version>\\n`);\n    manifest.push('</Package>\\n');\n    const path = directory + '/' + Math.random() + '.xml';\n    fs.writeFileSync(path, manifest.join(' '));\n    return path;\n}\n\nfunction createSFDXProject(appDirectory, projectName, template, defaultDirectory, apiVersion) {\n    const sfProjectCreateCommand = `sf project generate --name \"${projectName}\" --default-package-dir \"${defaultDirectory}\" --template \"${template}\" --api-version \"${apiVersion}\"`;\n    this.executeCommand(`\n        cd '${appDirectory}'\n        ${sfProjectCreateCommand}\n    `, RESULT_INFO.CATEGORY.SF_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.SF_CREATE_PROJECT);\n}\n\nfunction configureSFDXCli(sourceApiVersion, sourceEndPoint) {\n    const baseUrl = sourceEndPoint?.substring(0, sourceEndPoint?.indexOf('/', sourceEndPoint?.indexOf('/') + 2));\n    if (!baseUrl) throw new Error('Make sure the credentials used are authenticated');\n    const command = `\n    sf config set org-instance-url=${baseUrl}\n    sf config set org-api-version=${sourceApiVersion}`;\n    this.executeCommand(command, RESULT_INFO.CATEGORY.SF_CLI, RESULT_INFO.ADDITIONAL_INFORMATION.SF_CONFIG);\n}\n\nfunction getChangeObjects(jsonData, operation) {\n    const res = JSON.parse(jsonData.toString());\n    return res.map(item => ({n: item.n, t: item.t, a: operation}));\n}\n\nfunction sortFilePathsByOperation(fileData) {\n    const result = JSON.parse(fileData);\n    OPERATION_AND_DIRECTORY.forEach(operationAndDirectory => {\n        const fileList = result[operationAndDirectory.operation.toLowerCase()];\n        const filePaths = result[operationAndDirectory.operation.toLowerCase()].filter(fp => !(fp.includes('-meta.xml') && fileList.includes(fp.split('-meta.xml')[0]))).map(fp => fp.split(operationAndDirectory.directory)[1]).join('\\n');\n        \n        if (filePaths?.length) {\n        \tfs.writeFileSync(`${TEMP_DIRECTORY}/${operationAndDirectory.operation}`, filePaths, 'utf-8');\n        }\n    });\n}\n\nfunction enrichFilePaths(directoryPath, operation) {\n    const outputFile = `${operation}.json`;\n    const enrichFilePathsCommand = `enricher --repo '${directoryPath}' --changefile '${operation}' --out '${outputFile}'`;\n    this.executeCommand(enrichFilePathsCommand, RESULT_INFO.CATEGORY.COPADO_METADATA_INTELLIGENCE, RESULT_INFO.ADDITIONAL_INFORMATION.ENRICHER_SERVICE);\n}\n\nfunction createWorkingDirectory(dir) {\n    this.executeCommand(`mkdir -p ${dir}`, RESULT_INFO.CATEGORY.FILE_SYSTEM, RESULT_INFO.ADDITIONAL_INFORMATION.SETUP_DIRECTORY);\n}\n\nfunction executeCommand(command, category, additionalInfo, hasJsonResponse, disableLogs) {\n    let errorMessage;\n    const response = spawnSync(command, this.getOptions());\n    const {outputStream, errorStream} = this.log(response, disableLogs);\n    if (response?.status === 0) {\n        return hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n    }\n    if (!hasJsonResponse) {\n        errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n    } else {\n        try {\n            return JSON.parse(outputStream);\n        } catch (error) {\n            errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n        }\n    }\n    if (errorMessage) {\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalInfo, errorMessage);\n        const truncatedError = JSON.stringify(\n            errorMessage\n                .split('\\n')\n                .filter(msg => !msg.includes(COPADO_INFO_PREFIX))\n                .join(' ')\n        );\n        throw new CommandExecutionError(truncatedError, category, additionalInfo);\n    }\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction logger(message) {\n    console.log(message);\n}\n\nfunction log(response, disableLogs) {\n    const outputStream = response?.stdout?.toString().trim();\n    const errorStream = response?.stderr?.toString().trim();\n    if (!disableLogs) {\n\n        if (outputStream) {\n            console.log(outputStream);\n        }\n        if (errorStream) {\n            console.log(errorStream);\n        }\n    }\n    return {outputStream, errorStream};\n}\n\nfunction changeWorkingDirectory(dir) {\n    process.chdir(dir);\n}\n\nfunction getOptions() {\n    return {\n        shell: true,\n        maxBuffer: MAXBUFFER\n    };\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n    if (message) {\n        resultViewerJson.push({\n            Level: level,\n            Category: category,\n            AdditionalInformation: additionalInfo,\n            Message: message\n        });\n    }\n}\n\nfunction uploadResultViewerJson(data, columns, header, headerIcon) {\n    const RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/ResultViewer.json`;\n\n    const fileContent = {data, columns, header, headerIcon};\n    fs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n    this.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath, environmentId) {\n    new Promise((resolve, reject) => {\n        let uploadFileCommand = `copado --uploadfile ${filePath}`;\n        if (environmentId) {\n            uploadFileCommand += ` -i ${environmentId}`;\n        }\n        exec(uploadFileCommand, {}, err => {\n            if (err) {\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.ERROR,\n                    RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                    RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES,\n                    err\n                );\n                reject(new CommandExecutionError(err, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES));\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\nfunction asyncCopadoLogMessage(msg, logLevel) {\n    if (msg) {\n        this.populateResultViewer(logLevel ? logLevel : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n        new Promise(resolve => {\n            exec(`copado -p \"${msg}\"`, {stdio: STDIO.INHERIT}, () => {\n                resolve();\n            });\n        });\n    }\n}\n\nfunction getParsedData(data) {\n    let result = {};\n    try {\n        result = JSON.parse(data);\n    } catch (error) {\n        logger(`Error occurred while parsing data : ${error}`);\n    }\n    return result;\n}\n\nfunction getErrorCommand(error) {\n    const suffix = 'Please check the logs for details.';\n    return `{ copado -p 'Error' -e '${error}. ${suffix}'; exit 2; }`;\n}\n\nfunction getMetadataSupportedByCli() {\n    return [\n        'dashboard',\n        'document',\n        'emailtemplate',\n        'profile',\n        'report',\n        'staticresource',\n        'accesscontrolpolicy',\n        'accountforecastsettings',\n        'accountingfieldmapping',\n        'accountingmodelconfig',\n        'accountingsettings',\n        'accountinsightssettings',\n        'accountintelligencesettings',\n        'accountrelationshipsharerule',\n        'accountsettings',\n        'acctmgrtargetsettings',\n        'actionablelistdefinition',\n        'actionlauncheritemdef',\n        'actionlinkgrouptemplate',\n        'actionplantemplate',\n        'actionssettings',\n        'activationplatform',\n        'activitiessettings',\n        'addresssettings',\n        'advaccountforecastset',\n        'advacctforecastdimsource',\n        'advacctforecastperiodgroup',\n        'ai4msettings',\n        'aiapplication',\n        'aiapplicationconfig',\n        'aiassistanttemplate',\n        'aireplyrecommendationssettings',\n        'aiscoringmodeldefinition',\n        'aiscoringmodeldefversion',\n        'aiusecasedefinition',\n        'analyticsnapshot',\n        'analyticssettings',\n        'animationrule',\n        'apexclass',\n        'apexcomponent',\n        'apexemailnotifications',\n        'apexpage',\n        'apexsettings',\n        'apextestsuite',\n        'apextrigger',\n        'appanalyticssettings',\n        'appexperiencesettings',\n        'applicationrecordtypeconfig',\n        'applicationsubtypedefinition',\n        'appmenu',\n        'appointmentassignmentpolicy',\n        'appointmentschedulingpolicy',\n        'approvalprocess',\n        'assessmentquestion',\n        'assessmentquestionset',\n        'assignmentrules',\n        'assistantcontextitem',\n        'assistantdefinition',\n        'assistantrecommendationtype',\n        'assistantskillquickaction',\n        'assistantskillsobjectaction',\n        'assistantversion',\n        'associationenginesettings',\n        'audience',\n        'auradefinitionbundle',\n        'authprovider',\n        'automatedcontactssettings',\n        'autoresponserules',\n        'batchcalcjobdefinition',\n        'batchprocessjobdefinition',\n        'benefitaction',\n        'blacklistedconsumer',\n        'bldgenrgyintensitycnfg',\n        'blockchainsettings',\n        'bot',\n        'botblock',\n        'botsettings',\n        'bottemplate',\n        'botversion',\n        'branchmanagementsettings',\n        'brandingset',\n        'briefcasedefinition',\n        'businesshourssettings',\n        'businessprocess',\n        'businessprocessfeedbackconfiguration',\n        'businessprocessgroup',\n        'businessprocesstypedefinition',\n        'callcenter',\n        'callcenterroutingmap',\n        'callcoachingmediaprovider',\n        'callctragentfavtrfrdest',\n        'campaigninfluencemodel',\n        'campaignsettings',\n        'canvasmetadata',\n        'carebenefitverifysettings',\n        'carelimittype',\n        'careproviderafflroleconfig',\n        'careprovidersearchconfig',\n        'carerequestconfiguration',\n        'caresystemfieldmapping',\n        'casesettings',\n        'casesubjectparticle',\n        'certificate',\n        'channellayout',\n        'channelobjectlinkingrule',\n        'chatteranswerssettings',\n        'chatteremailsmdsettings',\n        'chatterextension',\n        'chattersettings',\n        'claimfinancialsettings',\n        'claimmgmtfoundationenabledsettings',\n        'clausecatgconfiguration',\n        'cleandataservice',\n        'cmsconnectsource',\n        'codebuildersettings',\n        'collectionsdashboardsettings',\n        'commandaction',\n        'commercesettings',\n        'communitiessettings',\n        'community',\n        'communitytemplatedefinition',\n        'communitythemedefinition',\n        'compactlayout',\n        'companysettings',\n        'connectedapp',\n        'connectedappsettings',\n        'contentasset',\n        'contentsettings',\n        'contextdefinition',\n        'contractsettings',\n        'conversationalintelligencesettings',\n        'conversationchanneldefinition',\n        'conversationvendorfielddef',\n        'conversationvendorinfo',\n        'corswhitelistorigin',\n        'csptrustedsite',\n        'currencysettings',\n        'customaddressfieldsettings',\n        'customapplication',\n        'customapplicationcomponent',\n        'customdatatype',\n        'customerdataplatformsettings',\n        'customexperience',\n        'customfeedfilter',\n        'customfield',\n        'customhelpmenusection',\n        'customindex',\n        'customizablepropensityscoringsettings',\n        'customlabels',\n        'custommetadata',\n        'customnotificationtype',\n        'customobject',\n        'customobjecttranslation',\n        'custompageweblink',\n        'custompermission',\n        'customsite',\n        'customtab',\n        'dashboardfolder',\n        'datacalcinsighttemplate',\n        'datacategorygroup',\n        'dataconnectoringestapi',\n        'dataconnectors3',\n        'datadotcomsettings',\n        'dataimportmanagementsettings',\n        'datakitobjecttemplate',\n        'datapackagekitdefinition',\n        'datapackagekitobject',\n        'datapipeline',\n        'datasource',\n        'datasourcebundledefinition',\n        'datasourceobject',\n        'datasourcetenant',\n        'datasrcdatamodelfieldmap',\n        'datastreamdefinition',\n        'datastreamtemplate',\n        'dataweaveresource',\n        'decisionmatrixdefinition',\n        'decisionmatrixdefinitionversion',\n        'decisiontable',\n        'decisiontabledatasetlink',\n        'delegategroup',\n        'deploymentsettings',\n        'devhubsettings',\n        'digitalexperience',\n        'digitalexperiencebundle',\n        'digitalexperienceconfig',\n        'disclosuredefinition',\n        'disclosuredefinitionversion',\n        'disclosuretype',\n        'discoveryaimodel',\n        'discoverygoal',\n        'discoverysettings',\n        'discoverystory',\n        'documentcategory',\n        'documentcategorydocumenttype',\n        'documentchecklistsettings',\n        'documentfolder',\n        'documentgenerationsetting',\n        'documenttype',\n        'duplicaterule',\n        'dynamicformssettings',\n        'dynamictrigger',\n        'eacsettings',\n        'eclairgeodata',\n        'einsteinagentsettings',\n        'einsteinassistantsettings',\n        'einsteindealinsightssettings',\n        'einsteindocumentcapturesettings',\n        'emailadministrationsettings',\n        'emailfolder',\n        'emailintegrationsettings',\n        'emailservicesfunction',\n        'emailtemplatefolder',\n        'emailtemplatesettings',\n        'embeddedservicebranding',\n        'embeddedserviceconfig',\n        'embeddedservicefieldservice',\n        'embeddedserviceflowconfig',\n        'embeddedserviceliveagent',\n        'embeddedservicemenusettings',\n        'employeefieldaccesssettings',\n        'employeeusersettings',\n        'enhancednotessettings',\n        'entitlementprocess',\n        'entitlementsettings',\n        'entitlementtemplate',\n        'entityimplements',\n        'escalationrules',\n        'esignatureconfig',\n        'esignatureenvelopeconfig',\n        'essentialssettings',\n        'eventdelivery',\n        'eventrelayconfig',\n        'eventsettings',\n        'eventsubscription',\n        'eventtype',\n        'experiencebundle',\n        'experiencebundlesettings',\n        'explainabilityactiondefinition',\n        'explainabilityactionversion',\n        'explainabilitymsgtemplate',\n        'expressionsetdefinition',\n        'expressionsetdefinitionversion',\n        'expressionsetmessagetoken',\n        'expressionsetobjectalias',\n        'extdatatranobjecttemplate',\n        'externalaimodel',\n        'externalclientapplication',\n        'externalclientappsettings',\n        'externalcredential',\n        'externaldataconnector',\n        'externaldatasource',\n        'externalserviceregistration',\n        'extlclntappconfigurablepolicies',\n        'extlclntappglobaloauthsettings',\n        'extlclntappmobileconfigurablepolicies',\n        'extlclntappmobilesettings',\n        'extlclntappnotificationsettings',\n        'extlclntappoauthconfigurablepolicies',\n        'extlclntappoauthsettings',\n        'extlclntappsampleconfigurablepolicies',\n        'extlclntappsamplesettings',\n        'featureparameterboolean',\n        'featureparameterdate',\n        'featureparameterinteger',\n        'fieldrestrictionrule',\n        'fieldservicemobileextension',\n        'fieldservicesettings',\n        'fieldset',\n        'fieldsrctrgtrelationship',\n        'filesconnectsettings',\n        'fileuploadanddownloadsecuritysettings',\n        'flexipage',\n        'flow',\n        'flowcategory',\n        'flowdefinition',\n        'flowsettings',\n        'flowtest',\n        'forecastingfilter',\n        'forecastingfiltercondition',\n        'forecastingobjectlistsettings',\n        'forecastingsettings',\n        'forecastingsourcedefinition',\n        'forecastingtype',\n        'forecastingtypesource',\n        'form',\n        'formulasettings',\n        'fueltype',\n        'fueltypesustnuom',\n        'functionreference',\n        'fundraisingconfig',\n        'gatewayproviderpaymentmethodtype',\n        'genaiprompttemplate',\n        'genaiprompttemplateactv',\n        'globalpicklist',\n        'globalvalueset',\n        'globalvaluesettranslation',\n        'googleappssettings',\n        'group',\n        'highvelocitysalessettings',\n        'homepagecomponent',\n        'homepagelayout',\n        'icon',\n        'ideassettings',\n        'identityprovidersettings',\n        'identityverificationprocdef',\n        'iframewhitelisturlsettings',\n        'inboundcertificate',\n        'inboundnetworkconnection',\n        'incidentmgmtsettings',\n        'includeesttaxinquotesettings',\n        'index',\n        'industriesautomotivesettings',\n        'industrieseinsteinfeaturesettings',\n        'industriesloyaltysettings',\n        'industriesmanufacturingsettings',\n        'industriessettings',\n        'insighttype',\n        'installedpackage',\n        'integrationhubsettings',\n        'integrationhubsettingstype',\n        'integrationproviderdef',\n        'interesttaggingsettings',\n        'internaldataconnector',\n        'internalorganization',\n        'inventorysettings',\n        'invlatepymntriskcalcsettings',\n        'invocableactionsettings',\n        'iotsettings',\n        'ipaddressrange',\n        'keywordlist',\n        'knowledgesettings',\n        'languagesettings',\n        'layout',\n        'leadconfigsettings',\n        'leadconvertsettings',\n        'letterhead',\n        'licensedefinition',\n        'licensingsettings',\n        'lightningbolt',\n        'lightningcomponentbundle',\n        'lightningexperiencesettings',\n        'lightningexperiencetheme',\n        'lightningmessagechannel',\n        'lightningonboardingconfig',\n        'listview',\n        'liveagentsettings',\n        'livechatagentconfig',\n        'livechatbutton',\n        'livechatdeployment',\n        'livechatsensitivedatarule',\n        'livemessagesettings',\n        'locationuse',\n        'loyaltyprogramsetup',\n        'macrosettings',\n        'mailmergesettings',\n        'managedcontenttype',\n        'managedtopics',\n        'mapsandlocationsettings',\n        'marketingappextension',\n        'marketingresourcetype',\n        'marketsegmentdefinition',\n        'matchingrules',\n        'mediaadsalessettings',\n        'meetingssettings',\n        'messagingchannel',\n        'mfgprogramtemplate',\n        'mfgserviceconsolesettings',\n        'milestonetype',\n        'mktcalcinsightobjectdef',\n        'mktdatatranobject',\n        'mldatadefinition',\n        'mldomain',\n        'mlpredictiondefinition',\n        'mlrecommendationdefinition',\n        'mobileapplicationdetail',\n        'mobilesecurityassignment',\n        'mobilesecuritypolicy',\n        'mobilesecuritypolicyset',\n        'mobilesettings',\n        'mobsecuritycertpinconfig',\n        'moderationrule',\n        'mutingpermissionset',\n        'mydomaindiscoverablelogin',\n        'mydomainsettings',\n        'namedcredential',\n        'namesettings',\n        'navigationmenu',\n        'network',\n        'networkbranding',\n        'notificationssettings',\n        'notificationtypeconfig',\n        'oauthcustomscope',\n        'oauthoidcsettings',\n        'objecthierarchyrelationship',\n        'objectlinkingsettings',\n        'objectsourcetargetmap',\n        'ocrsampledocument',\n        'ocrtemplate',\n        'omnichannelpricingsettings',\n        'omnichannelsettings',\n        'omnidatatransform',\n        'omniintegrationprocedure',\n        'omniinteractionaccessconfig',\n        'omniinteractionconfig',\n        'omniscript',\n        'omnisupervisorconfig',\n        'omniuicard',\n        'onlinesalessettings',\n        'opportunityinsightssettings',\n        'opportunityscoresettings',\n        'opportunitysettings',\n        'orchestration',\n        'orchestrationcontext',\n        'ordermanagementsettings',\n        'ordersettings',\n        'orgsettings',\n        'outboundnetworkconnection',\n        'pardoteinsteinsettings',\n        'pardotsettings',\n        'participantrole',\n        'partydatamodelsettings',\n        'pathassistant',\n        'pathassistantsettings',\n        'paymentgatewayprovider',\n        'paymentsmanagementenabledsettings',\n        'paymentssettings',\n        'permissionset',\n        'permissionsetgroup',\n        'permissionsetlicensedefinition',\n        'personaccountownerpoweruser',\n        'picklistsettings',\n        'pipelineinspmetricconfig',\n        'platformcachepartition',\n        'platformeventchannel',\n        'platformeventchannelmember',\n        'platformeventsettings',\n        'platformeventsubscriberconfig',\n        'platformslacksettings',\n        'portal',\n        'portalssettings',\n        'posttemplate',\n        'predictionbuildersettings',\n        'presencedeclinereason',\n        'presenceuserconfig',\n        'pricingrecipe',\n        'privacysettings',\n        'processflowmigration',\n        'productattributeset',\n        'productsettings',\n        'productspecificationtypedefinition',\n        'profilepasswordpolicy',\n        'profilesessionsetting',\n        'prompt',\n        'queue',\n        'queueroutingconfig',\n        'quickaction',\n        'quicktextsettings',\n        'quotesettings',\n        'realtimeeventsettings',\n        'recommendationbuildersettings',\n        'recommendationstrategy',\n        'recordactiondeployment',\n        'recordaggregationdefinition',\n        'recordalertcategory',\n        'recordalertdatasource',\n        'recordpagesettings',\n        'recordtype',\n        'redirectwhitelisturl',\n        'registeredexternalservice',\n        'relationshipgraphdefinition',\n        'remotesitesetting',\n        'reportfolder',\n        'reporttype',\n        'restrictionrule',\n        'retailexecutionsettings',\n        'role',\n        'salesagreementsettings',\n        'salesworkqueuesettings',\n        'samlssoconfig',\n        'sandboxsettings',\n        'schedulingobjective',\n        'schedulingrule',\n        'schemasettings',\n        'scontrol',\n        'scorecategory',\n        'searchableobjdatasyncinfo',\n        'searchcriteriaconfiguration',\n        'searchsettings',\n        'securitysettings',\n        'serviceaisetupdefinition',\n        'serviceaisetupfield',\n        'servicechannel',\n        'servicecloudvoicesettings',\n        'servicepresencestatus',\n        'serviceprocess',\n        'servicesetupassistantsettings',\n        'settings',\n        'sharingcriteriarule',\n        'sharingguestrule',\n        'sharingownerrule',\n        'sharingreason',\n        'sharingrules',\n        'sharingset',\n        'sharingsettings',\n        'sharingterritoryrule',\n        'sitedotcom',\n        'sitesettings',\n        'skill',\n        'skilltype',\n        'slackapp',\n        'socialcustomerservicesettings',\n        'socialprofilesettings',\n        'sourcetrackingsettings',\n        'standardvalueset',\n        'standardvaluesettranslation',\n        'stnryassetenvsrccnfg',\n        'streamingappdataconnector',\n        'subscriptionmanagementsettings',\n        'surveysettings',\n        'sustainabilityuom',\n        'sustnuomconversion',\n        'svccatalogcategory',\n        'svccatalogfiltercondition',\n        'svccatalogfiltercriteria',\n        'svccatalogfulfillmentflow',\n        'svccatalogitemdef',\n        'svccatalogitemdeffiltrcrit',\n        'synonymdictionary',\n        'systemnotificationsettings',\n        'territory',\n        'territory2',\n        'territory2model',\n        'territory2rule',\n        'territory2settings',\n        'territory2type',\n        'timelineobjectdefinition',\n        'timesheettemplate',\n        'topicsforobjects',\n        'trailheadsettings',\n        'transactionsecuritypolicy',\n        'translations',\n        'trialorgsettings',\n        'uiobjectrelationconfig',\n        'uiplugin',\n        'uiviewdefinition',\n        'userauthcertificate',\n        'usercriteria',\n        'userengagementsettings',\n        'userinterfacesettings',\n        'usermanagementsettings',\n        'userprofilesearchscope',\n        'userprovisioningconfig',\n        'validationrule',\n        'vehicleassetemssnsrccnfg',\n        'viewdefinition',\n        'visualizationplugin',\n        'voicesettings',\n        'warrantylifecyclemgmtsettings',\n        'waveapplication',\n        'wavecomponent',\n        'wavedashboard',\n        'wavedataflow',\n        'wavedataset',\n        'wavelens',\n        'waverecipe',\n        'wavetemplatebundle',\n        'wavexmd',\n        'web3settings',\n        'weblink',\n        'webstorebundle',\n        'webstoretemplate',\n        'webtoxsettings',\n        'workdotcomsettings',\n        'workflow',\n        'workflowalert',\n        'workflowfieldupdate',\n        'workflowknowledgepublish',\n        'workflowoutboundmessage',\n        'workflowrule',\n        'workflowsend',\n        'workflowtask',\n        'workforceengagementsettings',\n        'workskillrouting',\n        'xorghub'\n    ];\n\n}\n\nfunction uploadExecutionDetails(errors, sfCommandLogs, tempDirectory, workDir) {\n    let command = ``;\n\n    let environment = workDir.includes('source') ? 'Source' : 'Target';\n    if (Object.keys(errors).length) {\n        const errorFilePath = `${tempDirectory}/RetrievalError.json`;\n        fs.writeFileSync(errorFilePath, JSON.stringify(errors));\n        command += `copado --uploadfile \"${errorFilePath}\" --name \"${environment} Retrieval Error.json\" || true`;\n    }\n\n    if (Object.keys(sfCommandLogs).length) {\n        const sfCommandLogFilePath = `${tempDirectory}/SalesforceRetrieveResult.json`;\n        fs.writeFileSync(sfCommandLogFilePath, JSON.stringify(sfCommandLogs));\n        command += `\n            copado --uploadfile \"${sfCommandLogFilePath}\" --name \"${environment} Salesforce Retrieve Result.json\" || true\n        `;\n    }\n    this.executeCommand(command, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES);\n}\n\nfunction getMetadataNamesByType(contentVersionId, downloadDirectory, fileName) {\n\n    const result = new Map();\n    if (!contentVersionId) {\n        throw new Error('Content version ID missing from the metadata refresh');\n    }\n    this.executeCommand(`copado --downloadfiles '${contentVersionId}' --downloaddir '${downloadDirectory}'`, RESULT_INFO.CATEGORY.COPADO_SERVICE, RESULT_INFO.ADDITIONAL_INFORMATION.DOWNLOAD_FILE);\n    const metadatas = this.getMetaDataFileContent(downloadDirectory, fileName);\n    metadatas.forEach(metadata => {\n        // In the below condition we want to make sure that we do not retrieve\n        // the vlocity and managed packaged static resources in the snapshot process\n        if (!metadata.vk && !(metadata.t?.toLowerCase() === 'staticresource' && metadata.n?.includes('__'))) {\n            if (result.has(metadata.t)) {\n                result.get(metadata.t)?.push(metadata.n);\n            } else {\n                result.set(metadata.t, [metadata.n]);\n            }\n        }\n    });\n    return result;\n}\n\nfunction getMetaDataFileContent(downloadDirectory, fileName) {\n\n    this.logger('Downloading metadata file content..');\n    const file = `${downloadDirectory}/${fileName}`;\n    if (!fs.existsSync(file)) {\n        throw `Error fetching ${fileName} file`;\n    }\n    return JSON.parse(fs.readFileSync(`${file}`, 'utf-8'));\n}\n\nclass SpawnPool {\n    maxAllowedProcesses;\n    totalRunningProcesses;\n    metadatas;\n    profiles;\n    sessionId;\n    errors;\n    sfCommandLogs;\n    workDir;\n    endPoint;\n\n    constructor(maxAllowedProcesses, metadatas, profiles, sessionId, workDir, endPoint) {\n        this.maxAllowedProcesses = maxAllowedProcesses;\n        this.totalRunningProcesses = 0;\n        this.metadatas = metadatas;\n        this.profiles = profiles;\n        this.sessionId = sessionId;\n        this.workDir = workDir;\n        this.endPoint = endPoint;\n        this.errors = {};\n        this.sfCommandLogs = {};\n    }\n\n    execute() {\n        const promises = [];\n        while (this.totalRunningProcesses < this.maxAllowedProcesses && (this.metadatas.length || this.profiles.length)) {\n            this.totalRunningProcesses++;\n            if (this.totalRunningProcesses === 1 && this.profiles.length) {\n                promises.push(new Promise((resolve, reject) => {\n                    this.retrieveProfiles(resolve, reject);\n                }));\n            } else {\n                promises.push(\n                    new Promise((resolve, reject) => {\n                        this.handleNextExecution(resolve, reject);\n                    }));\n            }\n        }\n\n        logger(`Total promises : ${promises.length}`);\n        return promises;\n    }\n\n\n    executeProcess(metadata, sessionId, resolve, reject) {\n        changeWorkingDirectory(this.workDir);\n\n        let command = `\n\t\t\tcopado -p 'Retrieving Metadata : ${metadata.metadataNames.length} ${metadata.metadataType}(s) path ${metadata.path}'\n            sf project retrieve start --target-org \"${sessionId}\" --manifest \"${metadata.path}\" --wait 60 --json\n        `;\n        logger(`Metadata retrieval starting for ${metadata.metadataType} - ${metadata.path}`);\n        const childProcess = spawn(command, [], {shell: true});\n        let stdoutData = '';\n        let stderrData = '';\n        let errorData;\n\n        childProcess.stdout.on('data', data => {\n            stdoutData += data?.toString();\n            childProcess.stdout.resume();\n        });\n\n        childProcess.stderr.on('data', data => {\n            stderrData += data.toString();\n            childProcess.stderr.resume();\n        });\n\n        childProcess.on('error', error => {\n            errorData = error;\n            childProcess.error.resume();\n        });\n\n        childProcess.on('close', code => {\n            const response = {code, stdoutData, stderrData, errorData};\n            this.handleExecutionResultForMetadata(response, metadata, sessionId, resolve, reject);\n            logger(\n                `Metadata retrieval completed for ${metadata.metadataType} - ${metadata.path}`\n            );\n            logger(`Remaining Retrieval for metadata : ${this.metadatas.length}`);\n        });\n    }\n\n    handleExecutionResultForMetadata(response, metadata, sessionId, resolve, reject) {\n        const data = getParsedData(response.stdoutData);\n        const error = this.getErrorsFromExecutionResult(data);\n        this.sfCommandLogs[`${metadata.metadataType} : ${metadata.metadataNames.toString()}`] = data;\n        this.validateUnhandledException(data, reject);\n        if (data?.result?.errorStatusCode === 'LIMIT_EXCEEDED' && metadata?.length > 1) {\n            logger(`LIMIT_EXCEEDED for ${metadata.metadataType}, dividing the metadata in chunks`);\n            this.metadatas = [\n                ...this.metadatas,\n                ...getMetadataItemForRetrieval(\n                    metadata.metadataType,\n                    parseInt(metadata.metadataNames.length / 2),\n                    API_VERSION,\n                    TEMP_DIRECTORY\n                )\n            ];\n        } else if (data?.result?.success === false || data?.code === 2 || response.code === 1 || response.errorData || error) {\n            if (metadata.retryCount < retryLimit) {\n                logger(`Error occured for ${metadata.metadataType}, retrying retrieval`);\n                this.addToMetadata(metadata);\n            } else {\n                logger(\n                    `Error occured for ${metadata.metadataType}, handling error - ${data?.result?.errorMessage || data?.message || response.errorData || error\n                    }`\n                );\n                this.handleErrors(metadata, `${data?.result?.errorMessage || data?.message || response.errorData || error}`);\n            }\n        }\n        if (this.metadatas.length) {\n            this.executeProcess(this.metadatas.shift(), sessionId, resolve, reject);\n        } else {\n            this.handleNextExecution(resolve, reject);\n        }\n    }\n\n    validateUnhandledException(response, reject) {\n        if (response.status === 1 && response.name === 'UnexpectedForceIgnore') {\n            reject(response.message);\n        }\n    }\n\n    getErrorsFromExecutionResult(response) {\n        const errors = [];\n        response?.result?.files?.forEach(file => {\n            if (file.state === 'Failed' && file.error) {\n                errors.push(file.error);\n            }\n        });\n        return errors.length ? errors.toString() : null;\n    }\n\n    addToMetadata(metadata) {\n        metadata.retryCount += 1;\n        this.metadatas.push(metadata);\n    }\n\n    addToProfile(profile) {\n        profile.retryCount += 1;\n        this.profiles.push(profile);\n    }\n\n    handleErrors(metadata, error) {\n        this.errors[`Error occured while retrieving ${metadata.metadataType} (${metadata.metadataNames.toString()})`] = error;\n    }\n\n    handleNextExecution(resolve, reject) {\n        let currentProcessableMetadata;\n        if (this.metadatas.length) {\n            currentProcessableMetadata = this.metadatas.shift();\n        }\n        if (currentProcessableMetadata) {\n            this.executeProcess(currentProcessableMetadata, this.sessionId, resolve, reject);\n        } else {\n            logger('Thread successfully completed for retrieving metadata');\n            resolve('Thread successfully completed for retrieving metadata');\n        }\n    }\n\n    retrieveProfiles(resolve, reject) {\n\n        let currentProcessableProfiles;\n        if (this.profiles.length) {\n            currentProcessableProfiles = this.profiles.shift();\n        }\n        if (currentProcessableProfiles) {\n            logger('Retrieving profiles');\n            this.executeProfileRetrievalProcess(currentProcessableProfiles, this.sessionId, resolve, reject);\n        } else {\n            logger('Thread successfully completed for retrieving profile');\n            resolve('Thread successfully completed for retrieving profile');\n        }\n    }\n\n    executeProfileRetrievalProcess(profiles, sessionId, resolve, reject) {\n\n        changeWorkingDirectory(this.workDir);\n\n        const tempFilePath = '/tmp/childProcess.js';\n        fs.writeFileSync(tempFilePath, this.getFileContent());\n        const child = fork(tempFilePath);\n\n        profiles.sessionId = this.sessionId;\n        profiles.endPoint = this.endPoint;\n        profiles.workDir = this.workDir;\n        child.send(profiles);\n\n        let data, errorMessage;\n        child.on('message', (message) => {\n            if (message.status === 'success') {\n                logger('Profiles retrieved successfully');\n                data = message.data;\n            } else if (message.status === 'retry') {\n                this.executeProfileRetrievalProcess(message.profiles, sessionId, resolve, reject);\n            } else if (message.status === 'error') {\n                console.error('Failed to retrieve profiles:', message.errorMessage);\n                errorMessage = message.errorMessage.toString();\n            }\n        });\n\n        child.on('exit', code => {\n            const response = {code, data, errorMessage};\n            this.handleExecutionResultForProfile(response, profiles, sessionId, resolve, reject);\n            logger(\n                `Metadata retrieval completed for ${profiles.metadataType}`\n            );\n        });\n    }\n\n    handleExecutionResultForProfile(response, profiles, sessionId, resolve, reject) {\n\n        this.sfCommandLogs[`${profiles.metadataType} : ${profiles.metadataNames.toString()}`] = response.data;\n\n        if (response.data?.result?.success === false || response.code === 1 || response.errorMessage) {\n            this.errors[`Error occured while retrieving ${profiles.metadataType} (${profiles.metadataNames.toString()})`] = response.errorMessage;\n        }\n        this.retrieveProfiles(resolve, reject);\n    }\n\n    getErrors() {\n        return this.errors;\n    }\n\n    getSfCommandLogs() {\n        return this.sfCommandLogs;\n    }\n\n\n    getFileContent() {\n        const fileContent = `\n    const fs = require('fs'),\n    process = require('process'),\n    { Retriever, CopaReconcilerInput, Operation } = require('/usr/local/lib/node_modules/@mcdx/copado-metadata-reconciler');\n    const retryLimit = 1;\n    const TEMP_DIRECTORY = '/tmp';\n    \n    function getParsedData(data) {\n        let result = {};\n        try {\n            result = JSON.parse(data);\n        } catch (error) {\n            console.log(\\`Error occurred while parsing data : \\${error}\\`);\n        }\n       return result;\n\t}\n\n    function getMetadataReconcilerRequest(profiles) {\n        const request = new CopaReconcilerInput();\n        request.repositoryPath = profiles.workDir;\n        request.accessToken = profiles.sessionId;\n        request.instanceUrl = profiles.endPoint?.substring(0, profiles.endPoint?.indexOf('/', profiles.endPoint?.indexOf('/') + 2));\n        request.jsonOutputPath = profiles.workDir + TEMP_DIRECTORY;\n        request.profiles = profiles.metadataNames;\n        request.operation = Operation.FULL_PROFILE;\n        return request;\n    }\n    \nprocess.on('message', async (profiles) => {\n try {\n       \tconsole.log(\\`Retrieving \\${profiles.metadataNames.length} Profiles\\`);\n        const request = getMetadataReconcilerRequest(profiles);\n        await new Retriever().run(request);\n        const OUTPUT_JSON_FILE_PATH = \\`\\${profiles.workDir}\\${TEMP_DIRECTORY}/output.json\\`;\n\t\tconst data = getParsedData(fs.readFileSync(OUTPUT_JSON_FILE_PATH, 'utf-8'));\n        process.send({ status: 'success', data });\n        process.exit(0);\n        } catch(error) {\n            const errorMessage = error.message || error?.toString() || 'Unknown Error occurred';\n            if (errorMessage) {\n                if (profiles.retryCount < retryLimit) {\n                \tprofiles.retryCount++;\n                    console.log('An error occurred, retrying retrieval for Profiles');\n                    process.send({ status: 'retry', profiles });\n                    process.exit(0);\n                } else {\n                \tconsole.log(\\`Failure to retrieve profiles : \\${errorMessage}\\`);\n                    process.send({ status: 'error', profiles, errorMessage });\n                    process.exit(1);\n                }\n            }\n        }\n    });\n\t`;\n        return fileContent;\n    }\n}\n\nclass CommandExecutionError extends Error {\n    constructor(message, category, additionalInfo) {\n        super(`${category ? category + ' - ' : ''}${additionalInfo ? additionalInfo + ' : ' : ''}${message}`);\n        this.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n    }\n}\n\n\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.execute = execute;\nmodule.exports.log = log;\nmodule.exports.getOptions = getOptions;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.uploadResultViewerJson = uploadResultViewerJson;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.createWorkingDirectory = createWorkingDirectory;\nmodule.exports.getErrorCommand = getErrorCommand;\nmodule.exports.logger = logger;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.sortFilePathsByOperation = sortFilePathsByOperation;\nmodule.exports.getChangeObjects = getChangeObjects;\nmodule.exports.getParsedData = getParsedData;\nmodule.exports.getMetadataSupportedByCli = getMetadataSupportedByCli;\nmodule.exports.SpawnPool = SpawnPool;\nmodule.exports.runMetadataRetrieval = runMetadataRetrieval;\nmodule.exports.configureSFDXCli = configureSFDXCli;\nmodule.exports.createSFDXProject = createSFDXProject;\nmodule.exports.changeWorkingDirectory = changeWorkingDirectory;\nmodule.exports.enrichFilePaths = enrichFilePaths;\nmodule.exports.getMaxAllowedProcesses = getMaxAllowedProcesses;\nmodule.exports.uploadExecutionDetails = uploadExecutionDetails;\nmodule.exports.getMetadataNamesByType = getMetadataNamesByType;\nmodule.exports.getProfilesForRetrieval = getProfilesForRetrieval;\nmodule.exports.getMetadataItemsForRetrieval = getMetadataItemsForRetrieval;\nmodule.exports.getMetadataChunkSize = getMetadataChunkSize;\nmodule.exports.getMetaDataFileContent = getMetaDataFileContent;\nmodule.exports.getMetadataItemForRetrieval = getMetadataItemForRetrieval;\nmodule.exports.retrieveMetadataFromEnvironment = retrieveMetadataFromEnvironment;\nmodule.exports.getMetadataNameAndTypeForFilePaths = getMetadataNameAndTypeForFilePaths;\nmodule.exports.isValidMetadata = isValidMetadata;\nmodule.exports.calculateFileDifferences = calculateFileDifferences;\nmodule.exports.updateResultStatus = updateResultStatus;\nmodule.exports.getApiVersion = getApiVersion;\n\n!isTest && this.execute();",

                    
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "M",
                    "Id": "a0oRR000004smdFYAQ",
                    "LastReferencedDate": "2024-04-19T08:51:38.000+0000",
                    "LastViewedDate": "2024-04-19T08:51:38.000+0000",
                    "Name": "Calculate File Differences"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v60.0/sobjects/copado__Function__c/a0l7Q00000Dw8xpQAB"
                    },
                    "copado__API_Name__c": "sfdx_validate_metadata_schema",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"name\" : \"metadataFileId\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"metadataType\",\n  \"defaultValue\" : \"\"\n}, {\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n\t{ isTest, maxBuffer, metadataFileId, metadataType } = process.env,\n\tfs = require('fs'),\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tOUTPUT_JSON_PATH = `${TEMP_DIRECTORY}/output.json`;\n\n// SCRIPT FUNCTIONS\n\nfunction execute() {\n\ttry {\n\t\tthis.downloadFile(metadataFileId, TEMP_DIRECTORY);\n\t\tconst metadataFilePath = this.getMetadataFilePath(TEMP_DIRECTORY);\n\t\tthis.validateMetadataSchema(metadataType, metadataFilePath, TEMP_DIRECTORY);\n\t} catch (err) {\n\t\tconsole.log('Error stack: ', err.stack);\n\t\tconst executionError = err.message || err?.toString() || 'Unknown Error occurred';\n\t\tif (executionError) {\n\t\t\tthis.executeCommand(this.getErrorCmdString(executionError));\n\t\t\tprocess.exit(1);\n\t\t}\n\t}\n}\n\nfunction getMetadataFilePath(directory) {\n\tconst files = fs.readdirSync(directory);\n\tif (files.length) {\n\t\treturn `${directory}/${files[0]}`;\n\t}\n\n\tthrow new Error(`Couldn't find downloaded ${metadataType} file`);\n}\n\nfunction validateMetadataSchema(metadataType, metadataPath, outputPath) {\n\tconst command = `metadata-processor --out \"${outputPath}\" validator --metadata \"${metadataType}\" --file \"${metadataPath}\"`;\n\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { errorStream } = this.log(response);\n\tif (response?.status == 0 || response?.status == 6) {\n\t\tthis.processValidationResponse(OUTPUT_JSON_PATH);\n\t} else {\n\t\tthrow new Error(errorStream ? errorStream : `Error executing the command ${command}`);\n\t}\n}\n\nfunction processValidationResponse(filePath) {\n\tif (fs.existsSync(filePath)) {\n\t\tconst output = JSON.parse(fs.readFileSync(filePath, 'utf8'));\n\t\tif (output.isValid) {\n\t\t\treturn;\n\t\t}\n\n\t\tconst validationError = this.getValidationError(output);\n\t\tthrow new Error(validationError ? validationError : 'Error in Validating Metadata Schema');\n\t}\n}\n\nfunction getValidationError({ lineNumber, columnNumber, description }) {\n\tlet result = '';\n\n\tif (lineNumber) {\n\t\tresult += `Line ${lineNumber}, `;\n\t}\n\tif (columnNumber) {\n\t\tresult += `Column ${columnNumber}: `;\n\t}\n\tif (description) {\n\t\tresult += description;\n\t}\n\n\treturn result;\n}\n\nfunction downloadFile(fileId, downloadDir) {\n\tthis.executeCommand(`copado --downloadfiles ${fileId} --downloaddir ${downloadDir}`);\n}\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction getErrorCmdString(error) {\n\tconst errorMessage = JSON.stringify(error).trim()?.substring(0, 32760);\n\treturn `copado -p \"Error\" -e ${errorMessage}`;\n}\n\nfunction executeCommand(command, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.log(response, disableLogs);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthrow new Error(errorMessage);\n\t}\n}\n\nfunction log(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tconst statusCode = response?.status;\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tconsole.log(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tconsole.log(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream, statusCode };\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(maxBuffer)\n\t};\n\treturn options;\n}\n\nmodule.exports.execute = execute;\nmodule.exports.getMetadataFilePath = getMetadataFilePath;\nmodule.exports.validateMetadataSchema = validateMetadataSchema;\nmodule.exports.processValidationResponse = processValidationResponse;\nmodule.exports.downloadFile = downloadFile;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.log = log;\nmodule.exports.getOptions = getOptions;\nmodule.exports.getValidationError = getValidationError;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0l7Q00000Dw8xpQAB",
                    "LastReferencedDate": "2024-04-22T05:09:43.000+0000",
                    "LastViewedDate": "2024-04-22T05:09:43.000+0000",
                    "Name": "SFDX Validate Metadata Schema"
                },
                {
                    "attributes": {
                        "type": "copado__Function__c",
                        "url": "/services/data/v60.0/sobjects/copado__Function__c/a0k0900000KDFQ9AAP"
                    },
                    "copado__ApexClass__c": "cmcSf.SelectiveCommitSetupCallback",
                    "copado__API_Name__c": "SFDX_Selective_Commit_Setup",
                    "copado__Callback_Type__c": "ApexClass",
                    "copado__Image_Name__c": "copado-multicloud-dx:v4",
                    "copado__Options__c": "[ ]",
                    "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"baseBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.baseBranch}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.destinationBranch}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"featureBranch\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.featureBranch}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"metadataTypeAndName\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.metadataTypeAndName}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"filePrefix\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.filePrefix}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"userStoryId\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.userStoryId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"git_json\",\n  \"defaultValue\" : \"{$Context.Repository.Credential}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceEndpoint\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"name\" : \"overriddenApiVersion\",\n  \"defaultValue\" : \"\"\n} ]",
                    "copado__Script__c": "#!/usr/bin/env node\n'use strict';\n\nconst child_process = require('child_process'),\n\t{ existsSync, readFileSync, writeFileSync, copyFileSync } = require('fs'),\n\tprocess = require('process'),\n\t{\n\t\tbaseBranch,\n\t\tdestinationBranch,\n\t\tfeatureBranch,\n\t\tmetadataTypeAndName,\n\t\tfilePrefix,\n\t\tuserStoryId,\n\t\tsourceSessionId,\n\t\tsourceEndpoint,\n\t\tmaxBuffer,\n\t\tAPI_VERSION,\n\t\toverriddenApiVersion,\n\t\tisTest\n\t} = process.env,\n\tTEMP_DIRECTORY = getPath('/tmp'),\n\tAPP_DIRECTORY = getPath('/app'),\n\tREPOSITORY_DIRECTORY = `${APP_DIRECTORY}/repository`,\n\tSTDIO = {\n\t\tINHERIT: 'inherit'\n\t},\n\tSELECTIVE_COMMIT_FILE_NAMES = {\n\t\tSOURCE_ORG_FILE: `${filePrefix}_source`,\n\t\tDESTINATION_BRANCH_FILE: `${filePrefix}_destination`,\n\t\tBASE_BRANCH_FILE: `${filePrefix}_base`,\n\t\tFEATURE_BRANCH_FILE: `${filePrefix}_feature`\n\t};\n\n// SCRIPT FUNCTIONS\n\nasync function execute() {\n\ttry {\n\t\tthis.changeWorkingDirectory(APP_DIRECTORY);\n\t\tthis.createDirectory(REPOSITORY_DIRECTORY);\n\t\tthis.changeWorkingDirectory(REPOSITORY_DIRECTORY);\n\t\tthis.fetchRemoteBranch(baseBranch, 1);\n\t\tconst apiVersion = this.getApiVersion(overriddenApiVersion, API_VERSION);\n\t\tthis.validateSfdxProjectJson(baseBranch, apiVersion);\n\t\tconst sourceOrgBaseUrl = this.getOrgBaseUrl(sourceEndpoint);\n\t\tthis.configureSfdxCli(apiVersion, sourceOrgBaseUrl);\n\t\tconst retrievedMetadataDetails = this.retrieveMetadataFromSourceOrg(sourceSessionId, metadataTypeAndName);\n\t\tconst metadataFilePath = this.getMetadataFilePath(retrievedMetadataDetails);\n\n\t\tconst fileUploadPromises = [];\n\t\tfileUploadPromises.push(this.getFileUploadPromiseForSourceOrg(metadataFilePath, userStoryId));\n\t\tfileUploadPromises.push(this.getFileUploadPromiseForBaseBranch(metadataFilePath, userStoryId));\n\t\tfileUploadPromises.push(this.getFileUploadPromiseForDestinationBranch(metadataFilePath, destinationBranch, userStoryId));\n\t\tfileUploadPromises.push(this.getFileUploadPromiseForFeatureBranch(metadataFilePath, featureBranch, userStoryId));\n\t\tawait Promise.all(fileUploadPromises);\n\t} catch (error) {\n\t\tthis.executeCommand(this.getErrorCommand(error));\n\t\tif (!isTest) {\n\t\t\tprocess.exit(1);\n\t\t}\n\t}\n}\n\nfunction fetchRemoteBranch(branch, gitDepth) {\n\tthis.asyncCopadoLogMessage(`Fetching ${branch} branch`);\n\tconst command = `copado-git-get --depth \"${gitDepth}\" \"${branch}\"`;\n\tthis.executeCommand(command);\n}\n\nfunction getApiVersion(overriddenApiVersion, apiVersion) {\n\tconst finalApiVersion = overriddenApiVersion || apiVersion;\n\tconst regularExpressionForValidApiVersion = /\\d\\d\\.0/;\n\tif (!regularExpressionForValidApiVersion.test(finalApiVersion)) {\n\t\tthrow new Error(`Invalid API Version: ${finalApiVersion}`);\n\t}\n\treturn finalApiVersion;\n}\n\nfunction validateSfdxProjectJson(branch, apiVersion) {\n\tthis.asyncCopadoLogMessage('Validating project json');\n\tconst sfdxProjectJsonPath = 'sfdx-project.json';\n\tif (existsSync(sfdxProjectJsonPath)) {\n\t\tlet fileContent = this.readFromPath(sfdxProjectJsonPath);\n\t\tif (fileContent.sourceApiVersion !== apiVersion) {\n\t\t\tfileContent.sourceApiVersion = apiVersion;\n\t\t\twriteFileSync(sfdxProjectJsonPath, JSON.stringify(fileContent, null, 2));\n\t\t}\n\t} else {\n\t\tthrow new Error(`Invalid configuration in ${branch}, sfdx-project.json is invalid or missing at project root.`);\n\t}\n}\n\nfunction getOrgBaseUrl(orgEndPoint) {\n\tconst orgBaseUrl = orgEndPoint?.substring(0, orgEndPoint?.indexOf('/', orgEndPoint?.indexOf('/') + 2));\n\treturn orgBaseUrl;\n}\n\nfunction configureSfdxCli(apiVersion, sourceOrgBaseUrl) {\n\tthis.asyncCopadoLogMessage('Configuring sf cli');\n\tconst command = `\n\t\tsf config set org-instance-url=${sourceOrgBaseUrl} || exit 1\n    \tsf config set org-api-version=${apiVersion}\n\t`;\n\tthis.executeCommand(command);\n}\n\nfunction retrieveMetadataFromSourceOrg(sourceSessionId, metadata) {\n\tthis.asyncCopadoLogMessage('Retrieving metadata from source org');\n\tconst command = `\n    \tsf project retrieve start --target-org \"${sourceSessionId}\" --metadata \"${metadata.replaceAll('\"', '\\\\\"')}\"  --ignore-conflicts --json\n    `;\n\treturn this.executeCommand(command, true);\n}\n\nfunction getMetadataFilePath(retrievedMetadataDetails) {\n\tthis.asyncCopadoLogMessage('Finding metadata file path');\n\tlet result = '';\n\tif (retrievedMetadataDetails.status && retrievedMetadataDetails.message) {\n\t\tthrow new Error(retrievedMetadataDetails.message);\n\t}\n\tretrievedMetadataDetails?.result?.files?.forEach(file => {\n\t\tif (file.state === 'Failed' && file.error) {\n\t\t\tthrow new Error(file.error);\n\t\t} else {\n\t\t\tresult = file.filePath;\n\t\t}\n\t});\n\n\tif (!result) {\n\t\tthrow new Error('No metadata file path found');\n\t}\n\treturn result;\n}\n\nfunction getFileUploadPromiseForSourceOrg(metadataFilePath, userStoryId) {\n\tthis.asyncCopadoLogMessage('Finding and uploading metadata content from source org');\n\treturn this.getFileUploadPromise(metadataFilePath, SELECTIVE_COMMIT_FILE_NAMES.SOURCE_ORG_FILE, userStoryId);\n}\n\nfunction getFileUploadPromiseForBaseBranch(metadataFilePath, userStoryId) {\n\tthis.asyncCopadoLogMessage('Finding and uploading metadata content from base branch');\n\tthis.gitReset();\n\treturn this.getFileUploadPromise(metadataFilePath, SELECTIVE_COMMIT_FILE_NAMES.BASE_BRANCH_FILE, userStoryId);\n}\n\nfunction getFileUploadPromiseForDestinationBranch(metadataFilePath, destinationBranch, userStoryId) {\n\tthis.asyncCopadoLogMessage('Finding and uploading metadata content from destination branch');\n\tthis.fetchAndCheckoutGitBranch(destinationBranch, 1);\n\treturn this.getFileUploadPromise(metadataFilePath, SELECTIVE_COMMIT_FILE_NAMES.DESTINATION_BRANCH_FILE, userStoryId);\n}\n\nfunction getFileUploadPromiseForFeatureBranch(metadataFilePath, featureBranch, userStoryId) {\n\tthis.asyncCopadoLogMessage('Finding and uploading metadata content from feature branch');\n\t// Error handling in place for the scenario when feature branch doesn't exist\n\ttry {\n\t\tthis.fetchAndCheckoutGitBranch(featureBranch, 1);\n\t} catch (error) {\n\t\tthis.logger(error);\n\t\tconst promise = new Promise((resolve, reject) => {\n\t\t\tresolve();\n\t\t});\n\t\treturn promise;\n\t}\n\treturn this.getFileUploadPromise(metadataFilePath, SELECTIVE_COMMIT_FILE_NAMES.FEATURE_BRANCH_FILE, userStoryId);\n}\n\n// FUNCTION COMMONS\n\nfunction getPath(filePath) {\n\treturn isTest ? `${__dirname}/__tests__/__mockDirectory__${filePath}` : filePath;\n}\n\nfunction changeWorkingDirectory(directory) {\n\tprocess.chdir(directory);\n}\n\nfunction asyncCopadoLogMessage(message) {\n\tif (message) {\n\t\tnew Promise(resolve => {\n\t\t\tchild_process.exec(`copado -p \"${message}\"`, { stdio: STDIO.INHERIT }, () => {\n\t\t\t\tresolve();\n\t\t\t});\n\t\t});\n\t}\n}\n\nfunction createDirectory(directory) {\n\tthis.asyncCopadoLogMessage('Set up working directory');\n\tconst command = `mkdir -p ${directory}`;\n\tthis.executeCommand(command);\n}\n\nfunction readFromPath(filePath) {\n\tif (!existsSync(filePath)) {\n\t\tthrow new Error(`Could not find file at path: ${filePath}`);\n\t}\n\tlet result;\n\tconst data = readFileSync(filePath, 'utf-8');\n\ttry {\n\t\tresult = JSON.parse(data);\n\t} catch (error) {\n\t\tthrow new Error(`Content at ${filePath} is not a valid JSON, ${error.toString()}`);\n\t}\n\treturn result;\n}\n\nfunction gitReset() {\n\tconst command = `\n\t\tgit reset --hard || exit 1\n\t\tgit clean -fd\n\t`;\n\tthis.executeCommand(command);\n}\n\nfunction getFileUploadPromise(metadataFilePath, selectiveCommitFileName, userStoryId) {\n\tconst promise = new Promise((resolve, reject) => {\n\t\ttry {\n\t\t\tif (existsSync(metadataFilePath)) {\n\t\t\t\tconst tempFilePathForUploadingMetadataContent = `${TEMP_DIRECTORY}/${selectiveCommitFileName}`;\n\t\t\t\tcopyFileSync(metadataFilePath, tempFilePathForUploadingMetadataContent);\n\t\t\t\tconst command = `copado --uploadfile \"${tempFilePathForUploadingMetadataContent}\" --name \"${selectiveCommitFileName}\" --parentid \"${userStoryId}\"`;\n\t\t\t\tchild_process.exec(command, this.getOptions(), (error, stdout, stderr) => {\n\t\t\t\t\tconst response = { command, error, stdout, stderr };\n\t\t\t\t\tthis.logger(response);\n\t\t\t\t\tif (error?.code) {\n\t\t\t\t\t\tconst errorMessage = stderr ? stderr : `Error executing the command : ${command}`;\n\t\t\t\t\t\treject(errorMessage);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresolve();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t} else {\n\t\t\t\tresolve();\n\t\t\t}\n\t\t} catch (error) {\n\t\t\treject(error);\n\t\t}\n\t});\n\treturn promise;\n}\n\nfunction fetchAndCheckoutGitBranch(branch, depth) {\n\tconst command = `git fetch origin ${branch} --depth ${depth} && git checkout ${branch}`;\n\tthis.executeCommand(command);\n}\n\nfunction getErrorCommand(error) {\n\tconst suffix = 'Please check the logs for details.';\n\treturn `copado -p \"Error\" -e ${JSON.stringify(error?.toString()?.trim()?.substring(0, 32760) + '; ' + suffix)}`;\n}\n\nfunction executeCommand(command, hasJsonResponse, disableLogs) {\n\tlet errorMessage;\n\tconst response = child_process.spawnSync(command, this.getOptions());\n\tconst { outputStream, errorStream } = this.getOutputAndErrorStream(response, disableLogs);\n\tif (response?.status == 0) {\n\t\treturn hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n\t}\n\tif (!hasJsonResponse) {\n\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t} else {\n\t\ttry {\n\t\t\treturn JSON.parse(outputStream);\n\t\t} catch (error) {\n\t\t\terrorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n\t\t}\n\t}\n\tif (errorMessage) {\n\t\tthrow new Error(errorMessage);\n\t}\n}\n\nfunction getOutputAndErrorStream(response, disableLogs) {\n\tconst outputStream = response?.stdout?.toString().trim();\n\tconst errorStream = response?.stderr?.toString().trim();\n\tif (!disableLogs) {\n\t\tif (outputStream) {\n\t\t\tthis.logger(outputStream);\n\t\t}\n\t\tif (errorStream) {\n\t\t\tthis.logger(errorStream);\n\t\t}\n\t}\n\treturn { outputStream, errorStream };\n}\n\nfunction logger(message) {\n\tconsole.log(message);\n}\n\nfunction getOptions() {\n\tconst options = {\n\t\tshell: true,\n\t\tmaxBuffer: parseInt(maxBuffer)\n\t};\n\treturn options;\n}\n\nmodule.exports.execute = execute;\nmodule.exports.changeWorkingDirectory = changeWorkingDirectory;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.createDirectory = createDirectory;\nmodule.exports.fetchRemoteBranch = fetchRemoteBranch;\nmodule.exports.getApiVersion = getApiVersion;\nmodule.exports.validateSfdxProjectJson = validateSfdxProjectJson;\nmodule.exports.getOrgBaseUrl = getOrgBaseUrl;\nmodule.exports.configureSfdxCli = configureSfdxCli;\nmodule.exports.retrieveMetadataFromSourceOrg = retrieveMetadataFromSourceOrg;\nmodule.exports.getMetadataFilePath = getMetadataFilePath;\nmodule.exports.getFileUploadPromise = getFileUploadPromise;\nmodule.exports.getFileUploadPromiseForSourceOrg = getFileUploadPromiseForSourceOrg;\nmodule.exports.getFileUploadPromiseForBaseBranch = getFileUploadPromiseForBaseBranch;\nmodule.exports.getFileUploadPromiseForDestinationBranch = getFileUploadPromiseForDestinationBranch;\nmodule.exports.getFileUploadPromiseForFeatureBranch = getFileUploadPromiseForFeatureBranch;\nmodule.exports.gitReset = gitReset;\nmodule.exports.fetchAndCheckoutGitBranch = fetchAndCheckoutGitBranch;\nmodule.exports.readFromPath = readFromPath;\nmodule.exports.getErrorCommand = getErrorCommand;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.getOutputAndErrorStream = getOutputAndErrorStream;\nmodule.exports.logger = logger;\nmodule.exports.getOptions = getOptions;\nmodule.exports.getPath = getPath;\n\n// EXECUTION\n\n!isTest && this.execute();",
                    "copado__Type__c": "Standard",
                    "copado__Worker_Size__c": "S",
                    "Id": "a0k0900000KDFQ9AAP",
                    "LastReferencedDate": "2024-04-29T07:37:47.000+0000",
                    "LastViewedDate": "2024-04-29T07:37:47.000+0000",
                    "Name": "SFDX Selective Commit Setup"
                }
            ],
            "ObjectType": "copado__Function__c"
        },
        {
            "Records": [
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v60.0/sobjects/copado__JobTemplate__c/a0xRR000003B9RFYA0"
                    },
                    "copado__ApiName__c": "SFDX_Initialize_Pipeline_Branches_Only_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0xRR000003B9RFYA0",
                    "LastReferencedDate": "2024-02-26T12:49:15.000+0000",
                    "LastViewedDate": "2024-02-26T12:49:15.000+0000",
                    "Name": "SFDX Initialize Pipeline - Branches Only"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v55.0/sobjects/copado__JobTemplate__c/a0u7Q000000Xw28QAC"
                    },
                    "copado__ApiName__c": "sfdx_commit_1",
                    "copado__Description__c": "<p>Standard job template to perform git commit in User Stories</p>",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 2,
                    "Id": "a0u7Q000000Xw28QAC",
                    "LastReferencedDate": "2022-09-15T06:40:09.000+0000",
                    "LastViewedDate": "2022-09-15T06:40:09.000+0000",
                    "Name": "SFDX Commit"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v55.0/sobjects/copado__JobTemplate__c/a0u7Q000000Xw29QAC"
                    },
                    "copado__ApiName__c": "sfdx_deploy_1",
                    "copado__Description__c": "<p>DX Source Deployment</p>",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "copado__VolumeOptions__c": "[\n    {\n        \"name\": \"volumeSize\",\n        \"value\": \"10\"\n    },\n    {\n        \"name\": \"volumeTTL\",\n        \"value\": \"100\"\n    },\n    {\n        \"name\": \"preserveVolumeAfterExecution\",\n        \"value\": \"true\"\n    },\n    {\n        \"name\": \"volumeEnabled\",\n        \"value\": \"true\"\n    }\n]",
                    "Id": "a0u7Q000000Xw29QAC",
                    "LastReferencedDate": "2022-09-15T06:40:13.000+0000",
                    "LastViewedDate": "2022-09-15T06:40:13.000+0000",
                    "Name": "SFDX Deploy"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v55.0/sobjects/copado__JobTemplate__c/a0u7Q000000Xw2AQAS"
                    },
                    "copado__ApiName__c": "sfdx_promote_1",
                    "copado__Description__c": "<p>DX Source Promote</p>",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q000000Xw2AQAS",
                    "LastReferencedDate": "2022-09-15T06:40:13.000+0000",
                    "LastViewedDate": "2022-09-15T06:40:13.000+0000",
                    "Name": "SFDX Promote"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobTemplate__c/a0u7Q0000004wGoQAI"
                    },
                    "copado__ApiName__c": "SFDX Package Distribution_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q0000004wGoQAI",
                    "LastReferencedDate": "2023-04-12T05:16:21.000+0000",
                    "LastViewedDate": "2023-04-12T05:16:21.000+0000",
                    "Name": "SFDX Package Distribution"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v52.0/sobjects/copado__JobTemplate__c/a0t09000002vfccAAA"
                    },
                    "copado__ApiName__c": "SFDX Package Import_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "CreatedDate": "2021-09-17T14:07:46.000+0000",
                    "Id": "a0t09000002vfccAAA",
                    "IsDeleted": false,
                    "LastModifiedDate": "2021-10-04T09:11:43.000+0000",
                    "LastReferencedDate": "2021-10-04T09:11:43.000+0000",
                    "LastViewedDate": "2021-10-04T09:11:43.000+0000",
                    "Name": "SFDX Package Import",
                    "SystemModstamp": "2021-10-04T09:11:43.000+0000"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobTemplate__c/a0u7Q0000004wGqQAI"
                    },
                    "copado__ApiName__c": "SFDX Package Version Publish_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q0000004wGqQAI",
                    "LastReferencedDate": "2023-01-19T12:11:24.000+0000",
                    "LastViewedDate": "2023-01-19T12:11:24.000+0000",
                    "Name": "SFDX Package Version Publish"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobTemplate__c/a0u7Q0000004wGrQAI"
                    },
                    "copado__ApiName__c": "SFDX Package Version Update_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q0000004wGrQAI",
                    "LastReferencedDate": "2022-09-27T13:29:50.000+0000",
                    "LastViewedDate": "2022-09-27T13:29:50.000+0000",
                    "Name": "SFDX Package Version Update"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobTemplate__c/a0u7Q0000004wGsQAI"
                    },
                    "copado__ApiName__c": "SFDX Package Version Create_1",
                    "copado__Description__c": "<p>Creates Package Version</p>",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q0000004wGsQAI",
                    "LastReferencedDate": "2022-09-16T12:40:16.000+0000",
                    "LastViewedDate": "2022-09-16T12:40:16.000+0000",
                    "Name": "SFDX Package Version Create"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobTemplate__c/a0u7Q0000004wGtQAI"
                    },
                    "copado__ApiName__c": "SFDX Package Create_1",
                    "copado__Description__c": "<p>Creates Package</p>",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q0000004wGtQAI",
                    "LastReferencedDate": "2023-01-03T11:11:02.000+0000",
                    "LastViewedDate": "2023-01-03T11:11:02.000+0000",
                    "Name": "SFDX Package Create"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v54.0/sobjects/copado__JobTemplate__c/a0u7Q000000XrrkQAC"
                    },
                    "copado__ApiName__c": "SFDX Run Apex Tests_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q000000XrrkQAC",
                    "LastReferencedDate": "2022-04-21T10:30:02.000+0000",
                    "LastViewedDate": "2022-04-21T10:30:02.000+0000",
                    "Name": "SFDX Run Apex Tests"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobTemplate__c/a0u7Q0000004yiqQAA"
                    },
                    "copado__ApiName__c": "SFDX Package Version Git Configure_1",
                    "copado__Description__c": "<p><span style=\"font-size: 14px;\">SFDX Package Version Git Configure</span></p>",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q0000004yiqQAA",
                    "LastReferencedDate": "2023-01-22T12:12:15.000+0000",
                    "LastViewedDate": "2023-01-22T12:12:15.000+0000",
                    "Name": "SFDX Package Version Git Configure"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v55.0/sobjects/copado__JobTemplate__c/a0t09000000lkYtAAI"
                    },
                    "copado__ApiName__c": "SFDX Test Records Creation In User Story_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0t09000000lkYtAAI",
                    "LastReferencedDate": "2022-07-11T06:25:51.000+0000",
                    "LastViewedDate": "2022-07-11T06:25:51.000+0000",
                    "Name": "SFDX Test Records Creation In User Story"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobTemplate__c/a0t09000000llqoAAA"
                    },
                    "copado__ApiName__c": "SFDX Refresh Metadata_1",
                    "copado__Description__c": "<p><span style=\"font-size: 14px;\">Standard job template to refresh metadata cache of the org</span></p>",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0t09000000llqoAAA",
                    "LastReferencedDate": "2022-12-08T07:33:18.000+0000",
                    "LastViewedDate": "2022-12-08T07:33:18.000+0000",
                    "Name": "SFDX Refresh Metadata"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobTemplate__c/a0u7Q000000ZJ20QAG"
                    },
                    "copado__ApiName__c": "SFDX Git Initialization_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0u7Q000000ZJ20QAG",
                    "LastReferencedDate": "2023-05-12T03:54:51.000+0000",
                    "LastViewedDate": "2023-05-12T03:54:51.000+0000",
                    "Name": "SFDX Git Initialization"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobTemplate__c/a0u7Q000004z6sOQAQ"
                    },
                    "copado__ApiName__c": "SFDX Vlocity Commit_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "copado__VolumeOptions__c": "[\r\n  {\r\n    \"name\": \"volumeSize\",\r\n    \"value\": \"10\"\r\n  },\r\n  {\r\n    \"name\": \"volumeTTL\",\r\n    \"value\": \"100\"\r\n  },\r\n  {\r\n    \"name\": \"preserveVolumeAfterExecution\",\r\n    \"value\": \"true\"\r\n  },\r\n  {\r\n    \"name\": \"volumeEnabled\",\r\n    \"value\": \"true\"\r\n  }\r\n]",
                    "Id": "a0u7Q000004z6sOQAQ",
                    "LastReferencedDate": "2023-05-25T06:31:55.000+0000",
                    "LastViewedDate": "2023-05-25T06:31:55.000+0000",
                    "Name": "SFDX Vlocity Commit"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobTemplate__c/a0u7Q000000qiAMQAY"
                    },
                    "copado__ApiName__c": "SFDX Vlocity Deploy_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "copado__VolumeOptions__c": "[\r\n{\r\n\"name\": \"volumeSize\",\r\n\"value\": \"10\"\r\n},\r\n{\r\n\"name\": \"volumeTTL\",\r\n\"value\": \"100\"\r\n},\r\n{\r\n\"name\": \"preserveVolumeAfterExecution\",\r\n\"value\": \"true\"\r\n},\r\n{\r\n\"name\": \"volumeEnabled\",\r\n\"value\": \"true\"\r\n}\r\n]",
                    "Id": "a0u7Q000000qiAMQAY",
                    "LastReferencedDate": "2023-05-31T07:54:39.000+0000",
                    "LastViewedDate": "2023-05-31T07:54:39.000+0000",
                    "Name": "SFDX Vlocity Deploy"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobTemplate__c/a0t090000086CbPAAU"
                    },
                    "copado__ApiName__c": "SFDX_Git_Snapshot_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0t090000086CbPAAU",
                    "LastReferencedDate": "2023-06-21T18:08:28.000+0000",
                    "LastViewedDate": "2023-06-21T18:08:28.000+0000",
                    "Name": "SFDX Git Snapshot"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobTemplate__c/a0t090000086EMQAA2"
                    },
                    "copado__ApiName__c": "SFDX_Rollback_1",
                    "copado__Description__c": "<p>Performs complete or partial rollback of the selected promotion changes</p>",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0t090000086EMQAA2",
                    "LastReferencedDate": "2023-07-18T11:58:17.000+0000",
                    "LastViewedDate": "2023-07-18T11:58:17.000+0000",
                    "Name": "SFDX Rollback"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobTemplate__c/a0u7Q000005d0apQAA"
                    },
                    "copado__ApiName__c": "SFDX_Vlocity_Git_Snapshot_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "copado__VolumeOptions__c": "[\r\n{\r\n\"name\": \"volumeSize\",\r\n\"value\": \"10\"\r\n},\r\n{\r\n\"name\": \"volumeTTL\",\r\n\"value\": \"100\"\r\n},\r\n{\r\n\"name\": \"preserveVolumeAfterExecution\",\r\n\"value\": \"true\"\r\n},\r\n{\r\n\"name\": \"volumeEnabled\",\r\n\"value\": \"true\"\r\n}\r\n]",
                    "Id": "a0u7Q000005d0apQAA",
                    "LastReferencedDate": "2023-09-15T07:21:51.000+0000",
                    "LastViewedDate": "2023-09-15T07:21:51.000+0000",
                    "Name": "SFDX Vlocity Git Snapshot"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v59.0/sobjects/copado__JobTemplate__c/a0u7Q000000MYKyQAO"
                    },
                    "copado__ApiName__c": "SFDX_Vlocity_Rollback_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "copado__VolumeOptions__c": "[\r\n{\r\n\"name\": \"volumeSize\",\r\n\"value\": \"10\"\r\n},\r\n{\r\n\"name\": \"volumeTTL\",\r\n\"value\": \"100\"\r\n},\r\n{\r\n\"name\": \"preserveVolumeAfterExecution\",\r\n\"value\": \"true\"\r\n},\r\n{\r\n\"name\": \"volumeEnabled\",\r\n\"value\": \"true\"\r\n}\r\n]",
                    "Id": "a0u7Q000000MYKyQAO",
                    "LastReferencedDate": "2023-10-17T05:38:27.000+0000",
                    "LastViewedDate": "2023-10-17T05:38:27.000+0000",
                    "Name": "SFDX Vlocity Rollback"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v60.0/sobjects/copado__JobTemplate__c/a0xRR000003H1KXYA0"
                    },
                    "copado__ApiName__c": "SFDX_Initialize_Pipeline_with_Changes_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0xRR000003H1KXYA0",
                    "LastReferencedDate": "2024-03-18T06:00:47.000+0000",
                    "LastViewedDate": "2024-03-18T06:00:47.000+0000",
                    "Name": "SFDX Initialize Pipeline with Changes"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v60.0/sobjects/copado__JobTemplate__c/a0xRR000003UZQ1YAO"
                    },
                    "copado__ApiName__c": "SFDX_Difference_Analysis_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0xRR000003UZQ1YAO",
                    "LastReferencedDate": "2024-04-19T08:55:00.000+0000",
                    "LastViewedDate": "2024-04-19T08:55:00.000+0000",
                    "Name": "SFDX Difference Analysis"
                },
                {
                    "attributes": {
                        "type": "copado__JobTemplate__c",
                        "url": "/services/data/v60.0/sobjects/copado__JobTemplate__c/a0t0900000A4KcWAAV"
                    },
                    "copado__ApiName__c": "SFDX_Selective_Commit_Setup_1",
                    "copado__Type__c": "Standard",
                    "copado__Version__c": 1,
                    "Id": "a0t0900000A4KcWAAV",
                    "LastReferencedDate": "2024-04-29T06:49:40.000+0000",
                    "LastViewedDate": "2024-04-29T06:49:40.000+0000",
                    "Name": "SFDX Selective Commit Setup"
                }
            ],
            "ObjectType": "copado__JobTemplate__c"
        },
        {
            "Records": [
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q000008cMZkQAM"
                    },
                    "copado__ApiName__c": "SFDX Package Distribution_Install package",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_install_package\",\"parameters\":[{\"name\":\"packages\",\"value\":\"{$Context.apex.cmcSf.GetInstallationKeys}\",\"required\":true},{\"name\":\"destinationBaseUrl\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"destinationSession\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"retrialTimes\",\"value\":\"{$Property.sfdx_package_install_retrial_time}\",\"required\":false},{\"name\":\"apiVersion\",\"value\":\"{$Context.JobExecution__r.DataJson.apiVersion}\"},{\"name\":\"devhubSession\",\"value\":\"{$Source.Credential.SessionId}\"},{\"name\":\"devhubBaseUrl\",\"value\":\"{$Source.Credential.Endpoint}\"},{\"name\":\"installationSecurityType\",\"value\":\"{$Context.JobExecution__r.DataJson.installSecurityType}\"},{\"name\":\"pollInterval\",\"value\":\"{$Property.sfdx_package_install_poll_time_in_seconds}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q0000004wGoQAI",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000008cMZkQAM",
                    "LastReferencedDate": "2023-04-12T05:16:34.000+0000",
                    "LastViewedDate": "2023-04-12T05:16:33.000+0000",
                    "Name": "Install package"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q000008cMZlQAM"
                    },
                    "copado__ApiName__c": "SFDX Package Distribution_Get Dependencies",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Get_Package_Version_Dependencies\",\"parameters\":[{\"name\":\"endpoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"session\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"subscriberVersionId\",\"value\":\"{$Context.JobExecution__r.DataJson.subscriberId}\",\"required\":true},{\"name\":\"installationKey\",\"value\":\"{$Context.JobExecution__r.DataJson.installationKey}\",\"required\":false}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q0000004wGoQAI",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000008cMZlQAM",
                    "Name": "Get Dependencies"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q000000NQaAQAW"
                    },
                    "copado__ApiName__c": "SFDX Commit_Commit",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_commit\",\"parameters\":[{\"name\":\"fileChangesId\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\",\"required\":true},{\"name\":\"fileName\",\"value\":\"Copado Commit changes\",\"required\":true},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"sourceEndPoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"namespace\",\"value\":\"\"},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"baseBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.baseBranch}\",\"required\":true},{\"name\":\"sourceEnv\",\"value\":\"{$Source.apex.EnvironmentVariables}\",\"required\":true},{\"name\":\"findAndReplaceFileId\",\"value\":\"{$Context.apex.GlobalFindAndReplaceSourceId}\",\"required\":false},{\"name\":\"featureBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.featureBranchName}\",\"required\":true},{\"name\":\"recreateIfExists\",\"value\":\"{$Context.JobExecution__r.DataJson.recreateFeatureBranch}\",\"required\":true},{\"name\":\"commitMessage\",\"value\":\"{$Context.JobExecution__r.DataJson.message}\",\"required\":true},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\",\"required\":true},{\"name\":\"sourceEnvironmentBranch\",\"value\":\"{$Context.apex.SourceEnvironmentBranch}\",\"required\":true},{\"name\":\"gitDepth\",\"value\":\"{$Pipeline.Property.gitDepth_commit}\"},{\"name\":\"timeout\",\"value\":\"180000\"},{\"name\":\"chunkSize\",\"value\":\"10\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"overriddenApiVersion\",\"value\":\"\"},{\"name\":\"commitId\",\"value\":\"{$Context.JobExecution__r.DataJson.commitId}\"},{\"name\":\"vlocityFilesPath\",\"value\":\"/app/vlocity/\"},{\"name\":\"disableEarlyCommitCompletion\",\"value\":\"{$Pipeline.Property.disableEarlyCommitCompletion}\"}],\"sharedResource\":\"\"}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q000000Xw28QAC",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000NQaAQAW",
                    "Name": "Commit"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q000000NTrrQAG"
                    },
                    "copado__ApiName__c": "sfdx_commit_1_Create Test Records_2",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.Test_Record_Automation\",\"parameters\":[{\"name\":\"userStoryId\",\"value\":\"{$Context.JobExecution__r.DataJson.userStoryId}\"},{\"name\":\"recreateFeatureBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.recreateFeatureBranch}\"},{\"name\":\"fileWithSelectedChanges\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"},{\"name\":\"commitResult\",\"value\":\"{$Job.PrevStep.ResultDataJson__c}\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__JobTemplate__c": "a0u7Q000000Xw28QAC",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000000NTrrQAG",
                    "Name": "Create Test Records"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q000000NTwWQAW"
                    },
                    "copado__ApiName__c": "sfdx_deploy_sfdx_deploy",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_deploy\",\"parameters\":[{\"name\":\"fileChangesId\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\",\"required\":true},{\"name\":\"promotion\",\"value\":\"{$Context.JobExecution__r.DataJson.promotionBranchName}\",\"required\":true},{\"name\":\"targetBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.destinationBranchName}\",\"required\":true},{\"name\":\"destinationInstanceUrl\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"destinationSessionid\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"destinationEnv\",\"value\":\"{$Destination.apex.EnvironmentVariables}\",\"required\":true},{\"name\":\"findAndReplaceRules\",\"value\":\"{$Context.apex.GlobalFindAndReplaceDestinationId}\"},{\"name\":\"isValidation\",\"value\":\"{$Context.JobExecution__r.DataJson.deploymentDryRun}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"},{\"name\":\"testLevel\",\"value\":\"{$Job.ExecutionParent.Promotion__r.cmcSf__Apex_Test_Level__c}\"},{\"name\":\"debugMode\",\"value\":\"{$Job.ExecutionParent.Promotion__r.cmcSf__Debug_Mode__c}\"},{\"name\":\"gitDepth\",\"value\":\"{$Pipeline.Property.gitDepth_deploy}\"},{\"name\":\"validationId\",\"value\":\"{$Job.ExecutionParent.Promotion__r.cmcSf__Validate_Deploy_Request_Id__c}\"},{\"name\":\"testSuiteAndTestClassFileVersionDetails\",\"value\":\"{$Context.apex.cmcSf.GetFileVersionIdOfTestClassTestSuite}\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"waitTime\",\"value\":\"220\"},{\"name\":\"sourceInstanceUrl\",\"value\":\"{$Source.Credential.Endpoint}\"},{\"name\":\"sourceSessionid\",\"value\":\"{$Source.Credential.SessionId}\"},{\"name\":\"mergeProfile\",\"value\":\"false\"},{\"name\":\"overriddenApiVersion\",\"value\":\"\"},{\"name\":\"isProductionEnvironment\",\"value\":\"{$Context.apex.cmcSf.IdentifyProductionEnvironment}\",\"required\":true},{\"name\":\"hasVlocityChanges\",\"value\":\"{$Context.apex.cmcSf.HasVlocityChanges}\"},{\"name\":\"rollBackEnabled\",\"value\":\"{$Context.apex.cmcSf.IsRollBackEnabled}\"},{\"name\":\"fetchDeployReportRetrialTimes\",\"value\":\"{$Pipeline.Property.fetch_deploy_report_retrial_times}\"},{\"name\":\"deployPollTime\",\"value\":\"{$Pipeline.Property.deploy_poll_time}\"}],\"sharedResource\":\"{$Context.JobExecution__r.Pipeline__r.Git_Repository__r.URI__c}/{$Destination.Branch}\"}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q000000Xw29QAC",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000NTwWQAW",
                    "Name": "Deploy"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v55.0/sobjects/copado__JobStep__c/a0t7Q000000N7q1QAC"
                    },
                    "copado__ApiName__c": "sfdx_deploy_Encode Deploy changes",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_encode_file_names\",\"parameters\":[{\"name\":\"file_changes_id\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"},{\"name\":\"file_name\",\"value\":\"Copado Deploy changes\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q000000Xw29QAC",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000N7q1QAC",
                    "Name": "Encode file names"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000000N7q2QAC"
                    },
                    "copado__ApiName__c": "sfdx_promote_sfdx_promote",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_promote\",\"parameters\":[{\"name\":\"userStoryBranches\",\"value\":\"{$Context.JobExecution__r.DataJson.userStoryBranches}\",\"required\":true},{\"name\":\"promotionBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.promotionBranchName}\",\"required\":true},{\"name\":\"targetBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.destinationBranchName}\",\"required\":true},{\"name\":\"tag\",\"value\":\"{$Context.JobExecution__r.Promotion__r.Release__r.Version__c}\",\"required\":false},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"recreatePromotionBranch\",\"value\":\"{$Context.JobExecution__r.Promotion__r.cmcSf__Recreate_Promotion_Branch__c}\",\"required\":false},{\"name\":\"promotionId\",\"value\":\"{$Job.ExecutionParent.Id}\"},{\"name\":\"fileChangesId\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"},{\"name\":\"conflictResolutionAttachments\",\"value\":\"{$Context.apex.GetConflictResolutionAttachments}\"},{\"name\":\"gitName\",\"value\":\"{$User.Name}\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"},{\"name\":\"repositoryId\",\"value\":\"{$Pipeline.Git_Repository__r.Id}\"},{\"name\":\"gitDepth\",\"value\":\"{$Pipeline.Property.gitDepth_promote}\",\"required\":false},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"fileName\",\"value\":\"Copado Promotion changes\",\"required\":true},{\"name\":\"overriddenApiVersion\",\"value\":\"\"},{\"name\":\"disableXMLDeDuplication\",\"value\":\"{$Pipeline.Property.DisableXMLDeDuplication}\"}],\"sharedResource\":\"{$Context.JobExecution__r.Pipeline__r.Git_Repository__r.URI__c}/{$Destination.Branch}\"}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q000000Xw2AQAS",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000N7q2QAC",
                    "Name": "Promote"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v52.0/sobjects/copado__JobStep__c/a0s09000000KT2TAAW"
                    },
                    "copado__ApiName__c": "SFDX Package Import_Retrieve Package Information",
                    "copado__ConfigJson__c": "{\"functionName\":\"Devhub_Package_Info\",\"parameters\":[{\"name\":\"packageNameOrId\",\"value\":\"{$Context.JobExecution__r.DataJson.packageNameOrId}\",\"required\":true},{\"name\":\"session\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"baseUrl\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"jobStepId\",\"value\":\"{$Context.Id}\",\"required\":false}]}",
                    "copado__JobTemplate__c": "a0t09000002vfccAAA",
                    "copado__Order__c": 2,
                    "copado__CustomType__c": "Function",
                    "copado__Type__c": "Function",
                    "CreatedDate": "2021-10-04T09:11:43.000+0000",
                    "Id": "a0s09000000KT2TAAW",
                    "IsDeleted": false,
                    "LastModifiedDate": "2021-10-04T09:59:20.000+0000",
                    "Name": "Retrieve Package Information",
                    "SystemModstamp": "2021-10-04T09:59:20.000+0000"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v53.0/sobjects/copado__JobStep__c/a0s09000000KT2UAAW"
                    },
                    "copado__ApiName__c": "SFDX Package Import_Upsert Package Information",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.ImportPackageAndVersions\",\"parameters\":[{\"name\":\"prevResultId\",\"value\":\"{$Job.PrevStep.Result__r.Id}\"},{\"name\":\"pipelineId\",\"value\":\"{$Context.JobExecution__r.DataJson.pipelineId}\"},{\"name\":\"jsonInformation\",\"value\":\"{$Context.JobExecution__r.DataJson.jsonInformation}\"},{\"name\":\"type\",\"value\":\"wait\"}]}",
                    "copado__JobTemplate__c": "a0t09000002vfccAAA",
                    "copado__Order__c": 3,
                    "copado__CustomType__c": "Flow",
                    "copado__Type__c": "Flow",
                    "CreatedDate": "2021-10-04T09:11:43.000+0000",
                    "Id": "a0s09000000KT2UAAW",
                    "IsDeleted": false,
                    "LastModifiedDate": "2021-10-31T21:44:48.000+0000",
                    "Name": "Upsert Package Information",
                    "SystemModstamp": "2021-10-31T21:44:48.000+0000"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v52.0/sobjects/copado__JobStep__c/a0s09000000KT2WAAW"
                    },
                    "copado__ApiName__c": "SFDX Package Import_Update Source on Job Execution",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.Update_Source_on_Job_Execution\",\"parameters\":[{\"name\":\"type\",\"value\":\"wait\"},{\"name\":\"jsonInformation\",\"value\":\"{$Context.JobExecution__r.DataJson.jsonInformation}\"}]}",
                    "copado__JobTemplate__c": "a0t09000002vfccAAA",
                    "copado__Order__c": 1,
                    "copado__CustomType__c": "Flow",
                    "copado__Type__c": "Flow",
                    "CreatedDate": "2021-10-04T09:14:13.000+0000",
                    "Id": "a0s09000000KT2WAAW",
                    "IsDeleted": false,
                    "LastModifiedDate": "2021-10-04T10:48:24.000+0000",
                    "Name": "Update Source on Job Execution",
                    "SystemModstamp": "2021-10-04T10:48:24.000+0000"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q00000720dNQAQ"
                    },
                    "copado__ApiName__c": "SFDX Package Version Publish_Promote Package to Release",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_package_version_publish\",\"parameters\":[{\"name\":\"versionDetails\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\",\"required\":true},{\"name\":\"sessionId\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"endpoint\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"maxBuffer\",\"value\":\"5242880\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q0000004wGqQAI",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q00000720dNQAQ",
                    "Name": "Publish Package Version"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q00000720dOQAQ"
                    },
                    "copado__ApiName__c": "SFDX Package Version Publish_Update Destination on Job Execution",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.UpdatePackageVersionRequisite\",\"parameters\":[{\"name\":\"packageVersionId\",\"value\":\"{$Context.JobExecution__r.DataJson.packageVersionId}\"},{\"name\":\"type\",\"value\":\"wait\"}]}",
                    "copado__CustomType__c": "Flow",
                    "copado__JobTemplate__c": "a0u7Q0000004wGqQAI",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q00000720dOQAQ",
                    "Name": "Update Package Version Requisite"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000001Re2XQAS"
                    },
                    "copado__ApiName__c": "SFDX Package Version Update_Update Package Version",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Package_Version_Update\",\"parameters\":[{\"name\":\"devhubSession\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"devhubEndpoint\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"packageVersion\",\"value\":\"{$Context.JobExecution__r.DataJson.packageVersion}\",\"required\":false},{\"name\":\"installationKey\",\"value\":\"{$Context.JobExecution__r.DataJson.installationKey}\"},{\"name\":\"apiVersion\",\"value\":\"{$Context.JobExecution__r.DataJson.apiVersion}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q0000004wGrQAI",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000001Re2XQAS",
                    "Name": "Update Package Version"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000001Re2YQAS"
                    },
                    "copado__ApiName__c": "SFDX Package Version Update_Update Records",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.UpdatePackageVersion\",\"parameters\":[{\"name\":\"prevResultId\",\"value\":\"{$Job.PrevStep.Result__c}\"},{\"name\":\"type\",\"value\":\"wait\"},{\"name\":\"installationKey\",\"value\":\"{$Context.JobExecution__r.DataJson.installationKey}\"}]}",
                    "copado__CustomType__c": "Flow",
                    "copado__JobTemplate__c": "a0u7Q0000004wGrQAI",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000001Re2YQAS",
                    "Name": "Update Records"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000001Re2ZQAS"
                    },
                    "copado__ApiName__c": "SFDX Package Version Create_Create SFDX Package Version",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Package_Version_Create\",\"parameters\":[{\"name\":\"endPoint\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"session\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"packageId\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\",\"required\":false},{\"name\":\"versionName\",\"value\":\"{$Context.JobExecution__r.DataJson.versionName}\"},{\"name\":\"versionNumber\",\"value\":\"{$Context.JobExecution__r.DataJson.versionNumber}\"},{\"name\":\"description\",\"value\":\"{$Context.JobExecution__r.DataJson.description}\"},{\"name\":\"jsonInformation\",\"value\":\"{$Context.JobExecution__r.DataJson.jsonInformation}\",\"required\":false},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"},{\"name\":\"pollInterval\",\"value\":\"{$Property.sfdx_package_version_create_poll_time_in_seconds}\"},{\"name\":\"retrialTimes\",\"value\":\"{$Property.sfdx_package_version_create_retrial_number}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q0000004wGsQAI",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000001Re2ZQAS",
                    "Name": "Create SFDX Package Version"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000001Re2aQAC"
                    },
                    "copado__ApiName__c": "SFDX Package Version Create_Update Destination on Job Execution",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.UpdatePackageRequisite\",\"parameters\":[{\"name\":\"packageId\",\"value\":\"{$Context.JobExecution__r.DataJson.packageId}\"},{\"name\":\"type\",\"value\":\"wait\"}]}",
                    "copado__CustomType__c": "Flow",
                    "copado__JobTemplate__c": "a0u7Q0000004wGsQAI",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000001Re2aQAC",
                    "Name": "Update Package Requisite"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000001Re2bQAC"
                    },
                    "copado__ApiName__c": "SFDX Package Version Publish_Insert Package Version Information",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.CreatePackageVersion\",\"parameters\":[{\"name\":\"packageVersionJson\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\"},{\"name\":\"jsonInformation\",\"value\":\"{$Job.PrevStep.JobExecution__r.DataJson__c}\"},{\"name\":\"jobExecutionId\",\"value\":\"{$Context.JobExecution__r.Id}\"}]}",
                    "copado__CustomType__c": "Flow",
                    "copado__JobTemplate__c": "a0u7Q0000004wGsQAI",
                    "copado__Order__c": 3,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000001Re2bQAC",
                    "Name": "Insert Package Version Information"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000002nFwNQAU"
                    },
                    "copado__ApiName__c": "SFDX Package Create_Create Package on Destination",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDXPackageCreate\",\"parameters\":[{\"name\":\"devhubEndpoint\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"devhubSession\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"packageName\",\"value\":\"{$Job.ExecutionParent.Name}\",\"required\":false},{\"name\":\"path\",\"value\":\"{$Job.ExecutionParent.cmcSf__PackagePath__c}\"},{\"name\":\"jsonInformation\",\"value\":\"{$Context.JobExecution__r.DataJson.jsonInformation}\"},{\"name\":\"description\",\"value\":\"{$Job.ExecutionParent.copado__Description__c}\"},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"branch\",\"value\":\"{$Job.ExecutionParent.copado__DefaultBranch__c}\"},{\"name\":\"gitName\",\"value\":\"{$User.Name}\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q0000004wGtQAI",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000002nFwNQAU",
                    "Name": "Create Package on Destination"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000002nFwOQAU"
                    },
                    "copado__ApiName__c": "SFDX Package Create_Update Package",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.UpdatePackage\",\"parameters\":[{\"name\":\"packageRecordId\",\"value\":\"{$Context.JobExecution__r.DataJson.packageId}\"},{\"name\":\"packageInfo\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__JobTemplate__c": "a0u7Q0000004wGtQAI",
                    "copado__Order__c": 3,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000002nFwOQAU",
                    "Name": "Update Package"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000002nFwPQAU"
                    },
                    "copado__ApiName__c": "SFDX Package Create_Update Destination on Job Ex",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.UpdateDestinationOnJobExecution\",\"parameters\":[{\"name\":\"packageId\",\"value\":\"{$Context.JobExecution__r.DataJson.packageId}\"}]}",
                    "copado__CustomType__c": "Flow",
                    "copado__JobTemplate__c": "a0u7Q0000004wGtQAI",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000002nFwPQAU",
                    "Name": "Update Destination on Job Execution"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v54.0/sobjects/copado__JobStep__c/a0t7Q000000Li7RQAS"
                    },
                    "copado__ApiName__c": "SFDX Run Apex Tests_Run Apex Tests",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDXRunApexTests\",\"parameters\":[{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"sourceEndpoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"testMinutesTimeout\",\"value\":\"1440\"},{\"name\":\"testResultIds\",\"value\":\"{$Context.JobExecution__r.DataJson.resultIds}\"},{\"name\":\"testSuiteAndTestClassFileVersionDetails\",\"value\":\"{$Context.apex.cmcSf.GetFileVersionIdOfTestClassTestSuite}\",\"required\":true},{\"name\":\"consolidatedResultId\",\"value\":\"{$Context.JobExecution__r.DataJson.resultId}\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewerForApexTest",
                    "copado__JobTemplate__c": "a0u7Q000000XrrkQAC",
                    "copado__Order__c": 3,
                    "copado__SkipCondition__c": "{$Context.apex.cmcSf.HasNoApexWithAddOperationInQualityGate.matches(\"true\")}",
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000Li7RQAS",
                    "Name": "Run Apex Tests"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v54.0/sobjects/copado__JobStep__c/a0t7Q000000Li7SQAS"
                    },
                    "copado__ApiName__c": "SFDX Run Apex Tests_Populate Source Environment",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.SetSourceEnvironmentOnApexTestJobExecution\",\"parameters\":[{\"name\":\"jobExecutionId\",\"value\":\"{$Context.JobExecution__r.Id}\"},{\"name\":\"testIds\",\"value\":\"{$Context.JobExecution__r.DataJson.testIds}\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__JobTemplate__c": "a0u7Q000000XrrkQAC",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000000Li7SQAS",
                    "Name": "Set Source Environment"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v54.0/sobjects/copado__JobStep__c/a0t7Q000000Li7TQAS"
                    },
                    "copado__ApiName__c": "SFDX Run Apex Tests_Evaluate Apex Tests Acceptance Criteria",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.EvaluateApexTestsAcceptanceCriteria\",\"parameters\":[{\"name\":\"acceptanceCriteria\",\"value\":\"{$Context.JobExecution__r.DataJson.acceptanceCriteria}\"},{\"name\":\"resultIds\",\"value\":\"{$Context.JobExecution__r.DataJson.resultIds}\"},{\"name\":\"consolidatedResultId\",\"value\":\"{$Context.JobExecution__r.DataJson.resultId}\"},{\"name\":\"fileWithSelectedChanges\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"},{\"name\":\"recreateFeatureBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.recreateFeatureBranch}\"},{\"name\":\"prevStepResultId\",\"value\":\"{$Job.PrevStep.Result__r.Id}\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__IsSkipped__c": false,
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewerForApexTest",
                    "copado__JobTemplate__c": "a0u7Q000000XrrkQAC",
                    "copado__Order__c": 4,
                    "copado__SkipCondition__c": "{$Context.apex.cmcSf.HasNoApexWithAddOperationInQualityGate.matches(\"true\")}",
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000000Li7TQAS",
                    "Name": "Evaluate Apex Tests Acceptance Criteria"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000007JaxEQAS"
                    },
                    "copado__ApiName__c": "SFDX Package Version Git Configure_Git Config",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Package_Version_Git_Config\",\"parameters\":[{\"name\":\"packageVersion\",\"value\":\"{$Context.JobExecution__r.DataJson.packageVersion}\",\"required\":true},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"dxNamespace\",\"value\":\"{$Context.apex.cmcSf.GetDxNamespace}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q0000004yiqQAA",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000007JaxEQAS",
                    "Name": "Git Config"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0t7Q000007JaxFQAS"
                    },
                    "copado__ApiName__c": "SFDX Package Version Git Configure_1_Update Record",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.UpdatePackageVersion\",\"parameters\":[{\"name\":\"prevResultId\",\"value\":\"{$Job.PrevStep.Result__c}\"},{\"name\":\"type\",\"value\":\"wait\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__JobTemplate__c": "a0u7Q0000004yiqQAA",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q000007JaxFQAS",
                    "Name": "Update Record"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v55.0/sobjects/copado__JobStep__c/a0s090000020VnJAAU"
                    },
                    "copado__ApiName__c": "SFDX Test Records Creation In User Story_1_Apex Test Record Automation_1",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.Apex_Test_Record_Automation\",\"parameters\":[{\"name\":\"userStoryId\",\"value\":\"{$Context.JobExecution__r.DataJson.userStoryId}\"},{\"name\":\"recreateFeatureBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.recreateFeatureBranch}\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__JobTemplate__c": "a0t09000000lkYtAAI",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Flow",
                    "Id": "a0s090000020VnJAAU",
                    "Name": "Apex Test Record Automation"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v56.0/sobjects/copado__JobStep__c/a0s090000020XIKAA2"
                    },
                    "copado__ApiName__c": "SFDX Metadata Refresh_1_Metadata Refresh_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Refresh_Metadata\",\"parameters\":[{\"name\":\"SESSION_ID\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"ENDPOINT\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"METADATA_FILE_ID\",\"value\":\"{$Context.JobExecution__r.DataJson.metadataFileId}\",\"required\":false},{\"name\":\"IGNORED_TYPE\",\"value\":\"{$Context.JobExecution__r.DataJson.ignoredType}\"},{\"name\":\"TYPE_FILTER\",\"value\":\"{$Context.JobExecution__r.DataJson.typeFilter}\"},{\"name\":\"MAX_BUFFER\",\"value\":\"5242880\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0t09000000llqoAAA",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0s090000020XIKAA2",
                    "Name": "Refresh Metadata"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q000000NkARQA0"
                    },
                    "copado__ApiName__c": "SFDX Initialize Project_1_Initialize Git with SFDX Project_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"Initialize_Git_With_SFDX_Project\",\"parameters\":[{\"name\":\"dataJson\",\"value\":\"{$Context.JobExecution__r.DataJson__c}\",\"required\":false},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"gitName\",\"value\":\"{$User.Name}\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"},{\"name\":\"overriddenApiVersion\",\"value\":\"\"},{\"name\":\"git_json\",\"value\":\"{$Context.apex.cmcSf.GetGitJson}\"}],\"sharedResource\":\"{$Context.JobExecution__r.DataJson.gitRepositoryURI}/{$Context.JobExecution__r.DataJson.branch}\"}",
                    "copado__CustomType__c": "Function",
                    "copado__JobTemplate__c": "a0u7Q000000ZJ20QAG",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000NkARQA0",
                    "Name": "Initialize Git with SFDX Project"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobStep__c/a0t7Q00000BzrjqQAB"
                    },
                    "copado__ApiName__c": "SFDX Vlocity Commit_1_Retrieve Vlocity_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"vlocity_retrieve\",\"parameters\":[{\"name\":\"fileChangesId\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\",\"required\":false},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"sourceEndPoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"sourceDirectory\",\"value\":\"vlocity\",\"required\":true},{\"name\":\"copadoCommitFileName\",\"value\":\"Copado Commit changes\",\"required\":true},{\"name\":\"maxDepth\",\"value\":\"0\"},{\"name\":\"selectedDataPacks\",\"value\":\"\"},{\"name\":\"vlocitySettingsDocumentId\",\"value\":\"{$Context.apex.cmcSf.VlocitySettingsSourceId}\"},{\"name\":\"commitId\",\"value\":\"{$Context.JobExecution__r.DataJson.commitId}\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000004z6sOQAQ",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q00000CUGTcQAP",
                    "LastReferencedDate": "2023-08-18T09:21:19.000+0000",
                    "LastViewedDate": "2023-08-18T09:21:19.000+0000",
                    "Name": "Vlocity Retrieve"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q00000BzrjrQAB"
                    },
                    "copado__ApiName__c": "SFDX Vlocity Commit_1_SFDX Commit_2",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_commit\",\"parameters\":[{\"name\":\"fileChangesId\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\",\"required\":true},{\"name\":\"fileName\",\"value\":\"Copado Commit changes\",\"required\":true},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"sourceEndPoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"namespace\",\"value\":\"\"},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"baseBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.baseBranch}\",\"required\":true},{\"name\":\"sourceEnv\",\"value\":\"{$Source.apex.EnvironmentVariables}\",\"required\":true},{\"name\":\"findAndReplaceFileId\",\"value\":\"{$Context.apex.GlobalFindAndReplaceSourceId}\",\"required\":false},{\"name\":\"featureBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.featureBranchName}\",\"required\":true},{\"name\":\"recreateIfExists\",\"value\":\"{$Context.JobExecution__r.DataJson.recreateFeatureBranch}\",\"required\":true},{\"name\":\"commitMessage\",\"value\":\"{$Context.JobExecution__r.DataJson.message}\",\"required\":true},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\",\"required\":true},{\"name\":\"sourceEnvironmentBranch\",\"value\":\"{$Context.apex.SourceEnvironmentBranch}\",\"required\":true},{\"name\":\"gitDepth\",\"value\":\"{$Pipeline.Property.gitDepth_commit}\"},{\"name\":\"timeout\",\"value\":\"180000\"},{\"name\":\"chunkSize\",\"value\":\"10\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"overriddenApiVersion\",\"value\":\"\"},{\"name\":\"commitId\",\"value\":\"{$Context.JobExecution__r.DataJson.commitId}\"},{\"name\":\"vlocityFilesPath\",\"value\":\"/app/vlocity/\"},{\"name\":\"disableEarlyCommitCompletion\",\"value\":\"{$Pipeline.Property.disableEarlyCommitCompletion}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000004z6sOQAQ",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q00000BzrjrQAB",
                    "LastReferencedDate": "2023-05-25T06:32:10.000+0000",
                    "LastViewedDate": "2023-05-25T06:32:10.000+0000",
                    "Name": "SFDX Commit"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobStep__c/a0t7Q00000CuMs5QAF"
                    },
                    "copado__ApiName__c": "SFDX Vlocity Commit_1_Create_Test_Records_3",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.Test_Record_Automation\",\"parameters\":[{\"name\":\"userStoryId\",\"value\":\"{$Context.JobExecution__r.DataJson.userStoryId}\"},{\"name\":\"recreateFeatureBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.recreateFeatureBranch}\"},{\"name\":\"fileWithSelectedChanges\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"},{\"name\":\"commitResult\",\"value\":\"{$Job.PrevStep.ResultDataJson__c}\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000004z6sOQAQ",
                    "copado__Order__c": 3,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q00000CuMs5QAF",
                    "LastReferencedDate": "2023-07-04T17:01:56.000+0000",
                    "LastViewedDate": "2023-07-04T17:01:56.000+0000",
                    "Name": "Create Test Records"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobStep__c/a0t7Q000000vV7LQAU"
                    },
                    "copado__ApiName__c": "SFDX Vlocity Deploy_1_Deploy Vlocity_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"deploy_vlocity\",\"parameters\":[{\"name\":\"promotionBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.promotionBranchName}\"},{\"name\":\"targetBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.destinationBranchName}\"},{\"name\":\"destinationInstanceUrl\",\"value\":\"{$Destination.Credential.Endpoint}\"},{\"name\":\"destinationSessionid\",\"value\":\"{$Destination.Credential.SessionId}\"},{\"name\":\"validationId\",\"value\":\"{$Job.ExecutionParent.Promotion__r.cmcSf__Validate_Deploy_Request_Id__c}\"},{\"name\":\"gitName\",\"value\":\"{$User.Name}\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"},{\"name\":\"gitDepth\",\"value\":\"100\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"hasVlocityChanges\",\"value\":\"{$Context.apex.cmcSf.HasVlocityChanges}\"},{\"name\":\"isValidation\",\"value\":\"{$Context.JobExecution__r.DataJson.deploymentDryRun}\"},{\"name\":\"vlocityDirectory\",\"value\":\"vlocity\"},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\"},{\"name\":\"repository_id\",\"value\":\"{$Pipeline.Git_Repository__r.Id}\"},{\"name\":\"file_changes_id\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"},{\"name\":\"file_name\",\"value\":\"Copado Deploy changes\"},{\"name\":\"attachVlocityLogFile\",\"value\":\"{$Job.ExecutionParent.Promotion__r.cmcSf__Attach_Vlocity_Build_File__c}\"},{\"name\":\"vlocitySettingsDocumentId\",\"value\":\"{$Context.apex.cmcSf.VlocitySettingsDestinationId}\"},{\"name\":\"rollBackEnabled\",\"value\":\"{$Context.apex.cmcSf.IsRollBackEnabled}\"},{\"name\":\"findAndReplaceRules\",\"value\":\"{$Context.apex.GlobalFindAndReplaceDestinationId}\"},{\"name\":\"destinationEnv\",\"value\":\"{$Destination.apex.EnvironmentVariables}\"},{\"name\":\"prevResult\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\"},{\"name\":\"promotionId\",\"value\":\"{$Job.ExecutionParent.Promotion__r.Id}\"}],\"sharedResource\":\"{$Context.JobExecution__r.Pipeline__r.Git_Repository__r.URI__c}/{$Destination.Branch}\"}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000000qiAMQAY",
                    "copado__Order__c": 3,
                    "copado__SkipCondition__c": "{$Context.JobExecution__r.DataJson.deploymentDryRun.matches(\"true\")}",
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000vV7LQAU",
                    "LastReferencedDate": "2023-11-14T16:34:17.000+0000",
                    "LastViewedDate": "2023-11-14T16:34:17.000+0000",
                    "Name": "Deploy Vlocity"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q000000vV7QQAU"
                    },
                    "copado__ApiName__c": "SFDX Vlocity Deploy_1_Encode file names_2",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_encode_file_names\",\"parameters\":[{\"name\":\"file_changes_id\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\"},{\"name\":\"file_name\",\"value\":\"Copado Deploy changes\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000000qiAMQAY",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000vV7QQAU",
                    "Name": "Encode file names"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v57.0/sobjects/copado__JobStep__c/a0t7Q000000vV7VQAU"
                    },
                    "copado__ApiName__c": "SFDX Vlocity Deploy_1_Deploy Salesforce_3",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_deploy\",\"parameters\":[{\"name\":\"fileChangesId\",\"value\":\"{$Context.JobExecution__r.DataJson.fileWithSelectedChanges}\",\"required\":true},{\"name\":\"promotion\",\"value\":\"{$Context.JobExecution__r.DataJson.promotionBranchName}\",\"required\":true},{\"name\":\"targetBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.destinationBranchName}\",\"required\":true},{\"name\":\"destinationInstanceUrl\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"destinationSessionid\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"destinationEnv\",\"value\":\"{$Destination.apex.EnvironmentVariables}\",\"required\":true},{\"name\":\"findAndReplaceRules\",\"value\":\"{$Context.apex.GlobalFindAndReplaceDestinationId}\"},{\"name\":\"isValidation\",\"value\":\"{$Context.JobExecution__r.DataJson.deploymentDryRun}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"},{\"name\":\"testLevel\",\"value\":\"{$Job.ExecutionParent.Promotion__r.cmcSf__Apex_Test_Level__c}\"},{\"name\":\"debugMode\",\"value\":\"{$Job.ExecutionParent.Promotion__r.cmcSf__Debug_Mode__c}\"},{\"name\":\"gitDepth\",\"value\":\"{$Pipeline.Property.gitDepth_deploy}\"},{\"name\":\"validationId\",\"value\":\"{$Job.ExecutionParent.Promotion__r.cmcSf__Validate_Deploy_Request_Id__c}\"},{\"name\":\"testSuiteAndTestClassFileVersionDetails\",\"value\":\"{$Context.apex.cmcSf.GetFileVersionIdOfTestClassTestSuite}\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"waitTime\",\"value\":\"220\"},{\"name\":\"sourceInstanceUrl\",\"value\":\"{$Source.Credential.Endpoint}\"},{\"name\":\"sourceSessionid\",\"value\":\"{$Source.Credential.SessionId}\"},{\"name\":\"mergeProfile\",\"value\":\"false\"},{\"name\":\"overriddenApiVersion\",\"value\":\"\"},{\"name\":\"isProductionEnvironment\",\"value\":\"{$Context.apex.cmcSf.IdentifyProductionEnvironment}\",\"required\":true},{\"name\":\"hasVlocityChanges\",\"value\":\"{$Context.apex.cmcSf.HasVlocityChanges}\"},{\"name\":\"rollBackEnabled\",\"value\":\"{$Context.apex.cmcSf.IsRollBackEnabled}\"},{\"name\":\"fetchDeployReportRetrialTimes\",\"value\":\"{$Pipeline.Property.fetch_deploy_report_retrial_times}\"},{\"name\":\"deployPollTime\",\"value\":\"{$Pipeline.Property.deploy_poll_time}\"}],\"sharedResource\":\"{$Context.JobExecution__r.Pipeline__r.Git_Repository__r.URI__c}/{$Destination.Branch}\"}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000000qiAMQAY",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000vV7VQAU",
                    "Name": "Deploy Salesforce"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobStep__c/a0s09000007WCMyAAO"
                    },
                    "copado__ApiName__c": "SFDX_Git_Snapshot_1_Refresh_Metadata_3",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.Refresh_Metadata\",\"parameters\":[{\"name\":\"credentialId\",\"value\":\"{$Job.ExecutionParent.copado__Org__c}\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0t090000086CbPAAU",
                    "copado__Order__c": 3,
                    "copado__Type__c": "Flow",
                    "Id": "a0s09000007WCMyAAO",
                    "Name": "Refresh Metadata"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobStep__c/a0s09000007WCN3AAO"
                    },
                    "copado__ApiName__c": "SFDX_Git_Snapshot_1_Git_Snapshot_4",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_git_snapshot\",\"parameters\":[{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\",\"required\":true},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\",\"required\":true},{\"name\":\"sourceEndpoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"branch\",\"value\":\"{$Job.ExecutionParent.copado__Branch__c}\",\"required\":true},{\"name\":\"selectedMetadata\",\"value\":\"{$Job.ExecutionParent.copado__Scope__c}\"},{\"name\":\"snapshotInformation\",\"value\":\"{$Job.ExecutionParent.copado__Other_Information__c}\"},{\"name\":\"metadataRefreshResult\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\",\"required\":true},{\"name\":\"overriddenApiVersion\",\"value\":\"\"},{\"name\":\"maximumRetryCount\",\"value\":\"1\",\"required\":true},{\"name\":\"commitMessage\",\"value\":\"{$Context.JobExecution__r.DataJson.message}\",\"required\":true},{\"name\":\"processesUsedForRetrieval\",\"value\":\"8\",\"required\":true},{\"name\":\"environmentVariables\",\"value\":\"{$Source.apex.EnvironmentVariables}\"},{\"name\":\"findAndReplaceFileId\",\"value\":\"{$Context.apex.GlobalFindAndReplaceSourceId}\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"metadataChunkInfo\",\"value\":\"{\\\"staticresource\\\": 10, \\\"contentasset\\\": 10}\",\"required\":true},{\"name\":\"defaultMetadataChunkInfo\",\"value\":\"5000\",\"required\":true}],\"sharedResource\":\"{$Job.ExecutionParent.copado__Git_Repository__r.URI__c}/{$Job.ExecutionParent.copado__Branch__c}\"}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0t090000086CbPAAU",
                    "copado__Order__c": 4,
                    "copado__Type__c": "Function",
                    "Id": "a0s09000007WCN3AAO",
                    "Name": "Git Snapshot"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v59.0/sobjects/copado__JobStep__c/a0s09000007WE7pAAG"
                    },
                    "copado__ApiName__c": "SFDX_Rollback_1_SFDX_Rollback_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Rollback\",\"parameters\":[{\"name\":\"rollbackFileId\",\"value\":\"{$Context.JobExecution__r.DataJson.rollbackFileId}\",\"required\":false},{\"name\":\"isValidation\",\"value\":\"{$Context.JobExecution__r.DataJson.isValidation}\",\"required\":true},{\"name\":\"testLevel\",\"value\":\"{$Context.JobExecution__r.DataJson.testLevel}\"},{\"name\":\"promotion\",\"value\":\"{$Context.JobExecution__r.DataJson.promotion}\",\"required\":true},{\"name\":\"targetBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.targetBranch}\",\"required\":true},{\"name\":\"destinationInstanceUrl\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"destinationSessionid\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\",\"required\":false},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\",\"required\":false},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"waitTime\",\"value\":\"220\"},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"destinationEnvVariables\",\"value\":\"{$Destination.apex.EnvironmentVariables}\",\"required\":false},{\"name\":\"findAndReplaceFileId\",\"value\":\"{$Context.apex.GlobalFindAndReplaceDestinationId}\"},{\"name\":\"isProductionEnvironment\",\"value\":\"{$Context.apex.cmcSf.IdentifyProductionEnvironment}\"},{\"name\":\"serviceLogLevel\",\"value\":\"{$Pipeline.Property.service_log_level}\"},{\"name\":\"prevResult\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\"},{\"name\":\"testSuiteAndTestClassFileVersionDetails\",\"value\":\"{$Context.apex.cmcSf.GetFileVersionIdOfTestClassTestSuite}\"},{\"name\":\"fetchRollbackReportRetrialTimes\",\"value\":\"{$Pipeline.Property.fetchRollbackReportRetrialTimes}\"},{\"name\":\"rollbackPollTime\",\"value\":\"{$Pipeline.Property.rollbackPollTime}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0t090000086EMQAA2",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0s09000007WE7pAAG",
                    "LastReferencedDate": "2023-11-20T11:56:04.000+0000",
                    "LastViewedDate": "2023-11-20T11:56:04.000+0000",
                    "Name": "SFDX Rollback"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobStep__c/a0t7Q00000DyubnQAB"
                    },
                    "copado__ApiName__c": "SFDX_Vlocity_Git_Snapshot_1_Refresh_Metadata_1",
                    "copado__ConfigJson__c": "{\"flowName\":\"cmcSf.Refresh_Metadata\",\"parameters\":[{\"name\":\"credentialId\",\"value\":\"{$Job.ExecutionParent.copado__Org__c}\"},{\"name\":\"scope\",\"value\":\"{$Job.ExecutionParent.copado__Scope__c}\"}]}",
                    "copado__CustomType__c": "Salesforce Flow",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000005d0apQAA",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Flow",
                    "Id": "a0t7Q00000DyubnQAB",
                    "LastReferencedDate": "2023-09-10T12:15:52.000+0000",
                    "LastViewedDate": "2023-09-10T12:15:52.000+0000",
                    "Name": "Refresh Metadata"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobStep__c/a0t7Q00000DyubGQAR"
                    },
                    "copado__ApiName__c": "SFDX_Vlocity_Git_Snapshot_1_Vlocity_Git_Snapshot_2",
                    "copado__ConfigJson__c": "{\"functionName\":\"vlocity_git_snapshot\",\"parameters\":[{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"sourceDirectory\",\"value\":\"vlocity\",\"required\":true},{\"name\":\"selections\",\"value\":\"{$Job.ExecutionParent.copado__Scope__c}\",\"required\":true},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"endpointUrl\",\"value\":\"{$Source.Credential.EndpointURL}\",\"required\":true},{\"name\":\"metadataRefreshResult\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\",\"required\":true}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000005d0apQAA",
                    "copado__Order__c": 2,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q00000DyubGQAR",
                    "LastReferencedDate": "2023-09-10T11:41:16.000+0000",
                    "LastViewedDate": "2023-09-10T11:41:16.000+0000",
                    "Name": "Vlocity Git Snapshot"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v58.0/sobjects/copado__JobStep__c/a0t7Q00000DyucMQAR"
                    },
                    "copado__ApiName__c": "SFDX_Vlocity_Git_Snapshot_1_SFDX_Git_Snapshot_3",
                    "copado__ConfigJson__c": "{\"functionName\":\"sfdx_git_snapshot\",\"parameters\":[{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\",\"required\":true},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\",\"required\":true},{\"name\":\"sourceEndpoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"branch\",\"value\":\"{$Job.ExecutionParent.copado__Branch__c}\",\"required\":true},{\"name\":\"selectedMetadata\",\"value\":\"{$Job.ExecutionParent.copado__Scope__c}\"},{\"name\":\"snapshotInformation\",\"value\":\"{$Job.ExecutionParent.copado__Other_Information__c}\"},{\"name\":\"metadataRefreshResult\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\",\"required\":true},{\"name\":\"overriddenApiVersion\",\"value\":\"\"},{\"name\":\"maximumRetryCount\",\"value\":\"1\",\"required\":true},{\"name\":\"commitMessage\",\"value\":\"{$Context.JobExecution__r.DataJson.message}\",\"required\":true},{\"name\":\"processesUsedForRetrieval\",\"value\":\"8\",\"required\":true},{\"name\":\"environmentVariables\",\"value\":\"{$Source.apex.EnvironmentVariables}\"},{\"name\":\"findAndReplaceFileId\",\"value\":\"{$Context.apex.GlobalFindAndReplaceSourceId}\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"metadataChunkInfo\",\"value\":\"{\\\"staticresource\\\": 10, \\\"contentasset\\\": 10}\",\"required\":true},{\"name\":\"defaultMetadataChunkInfo\",\"value\":\"5000\",\"required\":true},{\"name\":\"vlocityFolder\",\"value\":\"vlocity\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000005d0apQAA",
                    "copado__Order__c": 3,
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q00000DyucMQAR",
                    "LastReferencedDate": "2023-09-10T11:25:59.000+0000",
                    "LastViewedDate": "2023-09-10T11:25:59.000+0000",
                    "Name": "SFDX Git Snapshot"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v59.0/sobjects/copado__JobStep__c/a0t7Q000000e9FdQAI"
                    },
                    "copado__ApiName__c": "SFDX_Vlocity_Rollback_1_SFDX_Rollback_2",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Rollback\",\"parameters\":[{\"name\":\"rollbackFileId\",\"value\":\"{$Context.JobExecution__r.DataJson.rollbackFileId}\",\"required\":false},{\"name\":\"isValidation\",\"value\":\"{$Context.JobExecution__r.DataJson.isValidation}\",\"required\":true},{\"name\":\"testLevel\",\"value\":\"{$Context.JobExecution__r.DataJson.testLevel}\"},{\"name\":\"promotion\",\"value\":\"{$Context.JobExecution__r.DataJson.promotion}\",\"required\":true},{\"name\":\"targetBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.targetBranch}\",\"required\":true},{\"name\":\"destinationInstanceUrl\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"destinationSessionid\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"gitName\",\"value\":\"{$User.Name}\",\"required\":false},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\",\"required\":false},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"waitTime\",\"value\":\"220\"},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"destinationEnvVariables\",\"value\":\"{$Destination.apex.EnvironmentVariables}\",\"required\":false},{\"name\":\"findAndReplaceFileId\",\"value\":\"{$Context.apex.GlobalFindAndReplaceDestinationId}\"},{\"name\":\"isProductionEnvironment\",\"value\":\"{$Context.apex.cmcSf.IdentifyProductionEnvironment}\"},{\"name\":\"serviceLogLevel\",\"value\":\"{$Pipeline.Property.service_log_level}\"},{\"name\":\"prevResult\",\"value\":\"{$Job.PrevStep.Result__r.Result_Data__c}\"},{\"name\":\"testSuiteAndTestClassFileVersionDetails\",\"value\":\"{$Context.apex.cmcSf.GetFileVersionIdOfTestClassTestSuite}\"},{\"name\":\"fetchRollbackReportRetrialTimes\",\"value\":\"{$Pipeline.Property.fetchRollbackReportRetrialTimes}\"},{\"name\":\"rollbackPollTime\",\"value\":\"{$Pipeline.Property.rollbackPollTime}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000000MYKyQAO",
                    "copado__Order__c": 2,
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000e9FdQAI",
                    "LastReferencedDate": "2023-11-20T11:56:13.000+0000",
                    "LastViewedDate": "2023-11-20T11:56:13.000+0000",
                    "Name": "SFDX Rollback"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v59.0/sobjects/copado__JobStep__c/a0t7Q000000e9FeQAI"
                    },
                    "copado__ApiName__c": "SFDX_Vlocity_Rollback_1_Vlocity_Rollback_3",
                    "copado__ConfigJson__c": "{\"functionName\":\"vlocity_rollback\",\"parameters\":[{\"name\":\"sfdxRollbackFileId\",\"value\":\"{$Context.JobExecution__r.DataJson.rollbackFileId}\"},{\"name\":\"isValidation\",\"value\":\"{$Context.JobExecution__r.DataJson.isValidation}\"},{\"name\":\"destinationInstanceUrl\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"destinationSessionid\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\"},{\"name\":\"destinationEnvVariables\",\"value\":\"{$Destination.apex.EnvironmentVariables}\"},{\"name\":\"findAndReplaceFileId\",\"value\":\"{$Context.apex.GlobalFindAndReplaceDestinationId}\"},{\"name\":\"promotion\",\"value\":\"{$Context.JobExecution__r.DataJson.promotion}\"},{\"name\":\"gitName\",\"value\":\"{$User.Name}\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"},{\"name\":\"targetBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.targetBranch}\"},{\"name\":\"serviceLogLevel\",\"value\":\"{$Pipeline.Property.service_log_level}\"},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"vlocityDirectory\",\"value\":\"vlocity\"},{\"name\":\"vlocityRollbackFileId\",\"value\":\"{$Context.JobExecution__r.DataJson.vlocityRollbackFileId}\"},{\"name\":\"vlocitySettingsDocumentId\",\"value\":\"{$Context.apex.cmcSf.VlocitySettingsDestinationId}\"},{\"name\":\"attachVlocityLogFile\",\"value\":\"{$Context.JobExecution__r.Promotion__r.cmcSf__Attach_Vlocity_Build_File__c}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0u7Q000000MYKyQAO",
                    "copado__Order__c": 1,
                    "copado__SkipCondition__c": "{$Context.JobExecution__r.DataJson.isValidation.matches(\"true\")}",
                    "copado__Type__c": "Function",
                    "Id": "a0t7Q000000e9FeQAI",
                    "LastReferencedDate": "2023-11-13T10:49:13.000+0000",
                    "LastViewedDate": "2023-11-13T10:49:13.000+0000",
                    "Name": "Vlocity Rollback"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v60.0/sobjects/copado__JobStep__c/a0wRR0000009l9NYAQ"
                    },
                    "copado__ApiName__c": "SFDX_Initialize_Pipeline_Branches_Only_1_Create_Git_Branches_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Create_Git_Branches\",\"parameters\":[{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"branches\",\"value\":\"{$Context.JobExecution__r.DataJson.branches}\",\"required\":true},{\"name\":\"mainBranch\",\"value\":\"{$Context.JobExecution__r.Pipeline__r.Main_Branch__c}\",\"required\":true},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\",\"required\":true},{\"name\":\"gitUser\",\"value\":\"{$User.Name}\",\"required\":true}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0xRR000003B9RFYA0",
                    "copado__Order__c": 1,
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Type__c": "Function",
                    "Id": "a0wRR0000009l9NYAQ",
                    "Name": "Create Git Branches"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v60.0/sobjects/copado__JobStep__c/a0wRR000000DUebYAG"
                    },
                    "copado__ApiName__c": "SFDX_Initialize_Pipeline_with_Changes_1_Create_Environment_Branch_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Create_Environment_Branch\",\"parameters\":[{\"name\":\"branches\",\"value\":\"{$Context.JobExecution__r.DataJson.branches}\",\"required\":true},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"gitEmail\",\"value\":\"{$User.Email}\"},{\"name\":\"gitUser\",\"value\":\"{$User.Name}\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0xRR000003H1KXYA0",
                    "copado__Order__c": 1,
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Type__c": "Function",
                    "Id": "a0wRR000000DUebYAG",
                    "Name": "Create Environment Branch"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v60.0/sobjects/copado__JobStep__c/a0wRR000000GYFRYA4"
                    },
                    "copado__ApiName__c": "SFDX_Difference_Analysis_1_Calculate_File_Differences_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"calculate_file_differences\",\"parameters\":[{\"name\":\"maxBuffer\",\"value\":\"5242880\"},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"destinationSessionId\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"sourceEndPoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"destinationEndPoint\",\"value\":\"{$Destination.Credential.Endpoint}\",\"required\":true},{\"name\":\"pipelineId\",\"value\":\"{$Context.JobExecution__r.Pipeline__c}\",\"required\":true},{\"name\":\"sourceEnvironmentId\",\"value\":\"{$Context.JobExecution__r.Source__c}\",\"required\":true},{\"name\":\"sourceEnvironmentFileId\",\"value\":\"{$Context.JobExecution__r.DataJson.sourceEnvironmentFileId}\",\"required\":true},{\"name\":\"metadataChunkInfo\",\"value\":\"{\\\"staticresource\\\": 10, \\\"contentasset\\\": 10}\"},{\"name\":\"targetEnvironmentFileId\",\"value\":\"{$Context.JobExecution__r.DataJson.targetEnvironmentFileId}\",\"required\":true},{\"name\":\"defaultMetadataChunkInfo\",\"value\":\"5000\"},{\"name\":\"processesUsedForRetrieval\",\"value\":\"7\"},{\"name\":\"maximumRetryCount\",\"value\":\"1\"},{\"name\":\"overriddenApiVersion\",\"value\":\"\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0xRR000003UZQ1YAO",
                    "copado__Order__c": 1,
                    "copado__Result_Viewer_Component__c": "cmcSf:resultViewer",
                    "copado__Type__c": "Function",
                    "Id": "a0wRR000000GYFRYA4",
                    "Name": "Calculate File Differences"
                },
                {
                    "attributes": {
                        "type": "copado__JobStep__c",
                        "url": "/services/data/v60.0/sobjects/copado__JobStep__c/a0s09000006vqXXAAY"
                    },
                    "copado__ApiName__c": "SFDX_Precision_Commit_Setup_1_SFDX_Precision_Commit_Setup_1",
                    "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Selective_Commit_Setup\",\"parameters\":[{\"name\":\"baseBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.baseBranch}\",\"required\":true},{\"name\":\"destinationBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.destinationBranch}\",\"required\":true},{\"name\":\"featureBranch\",\"value\":\"{$Context.JobExecution__r.DataJson.featureBranch}\",\"required\":true},{\"name\":\"metadataTypeAndName\",\"value\":\"{$Context.JobExecution__r.DataJson.metadataTypeAndName}\",\"required\":true},{\"name\":\"filePrefix\",\"value\":\"{$Context.JobExecution__r.DataJson.filePrefix}\",\"required\":true},{\"name\":\"userStoryId\",\"value\":\"{$Context.JobExecution__r.DataJson.userStoryId}\",\"required\":true},{\"name\":\"git_json\",\"value\":\"{$Context.Repository.Credential}\",\"required\":true},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"sourceEndpoint\",\"value\":\"{$Source.Credential.Endpoint}\",\"required\":true},{\"name\":\"maxBuffer\",\"value\":\"5242880\",\"required\":true},{\"name\":\"overriddenApiVersion\",\"value\":\"\"}]}",
                    "copado__CustomType__c": "Function",
                    "copado__IsSkipped__c": false,
                    "copado__JobTemplate__c": "a0t0900000A4KcWAAV",
                    "copado__Order__c": 1,
                    "copado__Type__c": "Function",
                    "Id": "a0s09000006vqXXAAY",
                    "Name": "SFDX Selective Commit Setup"
                }
            ],
            "ObjectType": "copado__JobStep__c"
        }
    ],
    "blobsByUID": {}
}